{
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "c067a811-5a98-4d71-83f1-83a5f852600f",
    "datetime_epoch_millis": 1738801677624,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.951,
        "llm_top_1_test_accuracy": 0.65251875,
        "llm_top_2_test_accuracy": 0.7218625,
        "llm_top_5_test_accuracy": 0.78204375,
        "llm_top_10_test_accuracy": 0.8321,
        "llm_top_20_test_accuracy": 0.87753125,
        "llm_top_50_test_accuracy": 0.9227312500000001,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9585937943309545,
        "sae_top_1_test_accuracy": 0.7449374999999999,
        "sae_top_2_test_accuracy": 0.8111062499999999,
        "sae_top_5_test_accuracy": 0.8505875,
        "sae_top_10_test_accuracy": 0.8858562499999999,
        "sae_top_20_test_accuracy": 0.9124625,
        "sae_top_50_test_accuracy": 0.9326124999999998,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.96,
        "llm_top_1_test_accuracy": 0.6436,
        "llm_top_2_test_accuracy": 0.6911999999999999,
        "llm_top_5_test_accuracy": 0.792,
        "llm_top_10_test_accuracy": 0.8333999999999999,
        "llm_top_20_test_accuracy": 0.897,
        "llm_top_50_test_accuracy": 0.9378,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9700000405311584,
        "sae_top_1_test_accuracy": 0.7086,
        "sae_top_2_test_accuracy": 0.8136000000000001,
        "sae_top_5_test_accuracy": 0.8534,
        "sae_top_10_test_accuracy": 0.8917999999999999,
        "sae_top_20_test_accuracy": 0.9358000000000001,
        "sae_top_50_test_accuracy": 0.9491999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9494,
        "llm_top_1_test_accuracy": 0.6652,
        "llm_top_2_test_accuracy": 0.7081999999999999,
        "llm_top_5_test_accuracy": 0.7691999999999999,
        "llm_top_10_test_accuracy": 0.8027999999999998,
        "llm_top_20_test_accuracy": 0.8672000000000001,
        "llm_top_50_test_accuracy": 0.9120000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9550000548362731,
        "sae_top_1_test_accuracy": 0.8068000000000002,
        "sae_top_2_test_accuracy": 0.82,
        "sae_top_5_test_accuracy": 0.8507999999999999,
        "sae_top_10_test_accuracy": 0.9066000000000001,
        "sae_top_20_test_accuracy": 0.9141999999999999,
        "sae_top_50_test_accuracy": 0.9301999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9100000000000001,
        "llm_top_1_test_accuracy": 0.6876,
        "llm_top_2_test_accuracy": 0.7344,
        "llm_top_5_test_accuracy": 0.7704000000000001,
        "llm_top_10_test_accuracy": 0.7972,
        "llm_top_20_test_accuracy": 0.8528,
        "llm_top_50_test_accuracy": 0.8926000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9280000448226928,
        "sae_top_1_test_accuracy": 0.7862,
        "sae_top_2_test_accuracy": 0.8192,
        "sae_top_5_test_accuracy": 0.8493999999999999,
        "sae_top_10_test_accuracy": 0.8757999999999999,
        "sae_top_20_test_accuracy": 0.8892,
        "sae_top_50_test_accuracy": 0.9074,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.8969999999999999,
        "llm_top_1_test_accuracy": 0.6,
        "llm_top_2_test_accuracy": 0.6486000000000001,
        "llm_top_5_test_accuracy": 0.6706,
        "llm_top_10_test_accuracy": 0.7644,
        "llm_top_20_test_accuracy": 0.8072000000000001,
        "llm_top_50_test_accuracy": 0.8624,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9160000443458557,
        "sae_top_1_test_accuracy": 0.6874,
        "sae_top_2_test_accuracy": 0.751,
        "sae_top_5_test_accuracy": 0.7891999999999999,
        "sae_top_10_test_accuracy": 0.8240000000000001,
        "sae_top_20_test_accuracy": 0.8458,
        "sae_top_50_test_accuracy": 0.8775999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.9815,
        "llm_top_1_test_accuracy": 0.673,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.848,
        "llm_top_50_test_accuracy": 0.932,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9770000576972961,
        "sae_top_1_test_accuracy": 0.674,
        "sae_top_2_test_accuracy": 0.886,
        "sae_top_5_test_accuracy": 0.913,
        "sae_top_10_test_accuracy": 0.929,
        "sae_top_20_test_accuracy": 0.95,
        "sae_top_50_test_accuracy": 0.965,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9682000000000001,
        "llm_top_1_test_accuracy": 0.6454,
        "llm_top_2_test_accuracy": 0.693,
        "llm_top_5_test_accuracy": 0.7554000000000001,
        "llm_top_10_test_accuracy": 0.8022,
        "llm_top_20_test_accuracy": 0.8657999999999999,
        "llm_top_50_test_accuracy": 0.9238,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9726000308990479,
        "sae_top_1_test_accuracy": 0.6602,
        "sae_top_2_test_accuracy": 0.6724,
        "sae_top_5_test_accuracy": 0.7438,
        "sae_top_10_test_accuracy": 0.806,
        "sae_top_20_test_accuracy": 0.8793999999999998,
        "sae_top_50_test_accuracy": 0.9186,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.9425,
        "llm_top_1_test_accuracy": 0.65875,
        "llm_top_2_test_accuracy": 0.7795,
        "llm_top_5_test_accuracy": 0.82375,
        "llm_top_10_test_accuracy": 0.867,
        "llm_top_20_test_accuracy": 0.89525,
        "llm_top_50_test_accuracy": 0.9232500000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9507500380277634,
        "sae_top_1_test_accuracy": 0.8165,
        "sae_top_2_test_accuracy": 0.8492500000000001,
        "sae_top_5_test_accuracy": 0.8895,
        "sae_top_10_test_accuracy": 0.9022499999999999,
        "sae_top_20_test_accuracy": 0.9165,
        "sae_top_50_test_accuracy": 0.9325000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9994,
        "llm_top_1_test_accuracy": 0.6466000000000001,
        "llm_top_2_test_accuracy": 0.796,
        "llm_top_5_test_accuracy": 0.909,
        "llm_top_10_test_accuracy": 0.9638,
        "llm_top_20_test_accuracy": 0.9870000000000001,
        "llm_top_50_test_accuracy": 0.998,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9994000434875489,
        "sae_top_1_test_accuracy": 0.8198000000000001,
        "sae_top_2_test_accuracy": 0.8774000000000001,
        "sae_top_5_test_accuracy": 0.9156000000000001,
        "sae_top_10_test_accuracy": 0.9513999999999999,
        "sae_top_20_test_accuracy": 0.9687999999999999,
        "sae_top_50_test_accuracy": 0.9803999999999998,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "c600ccd8de71ccb5cbbab0eb1c6e8cc361ee3481",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 16384,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "unlearning evaluation results": {
    "eval_type_id": "unlearning",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "wmdp-bio",
        "high_school_us_history",
        "college_computer_science",
        "high_school_geography",
        "human_aging"
      ],
      "intervention_method": "clamp_feature_activation",
      "retain_thresholds": [
        0.001,
        0.01
      ],
      "n_features_list": [
        10,
        20
      ],
      "multipliers": [
        25,
        50,
        100,
        200
      ],
      "dataset_size": 1024,
      "seq_len": 1024,
      "n_batch_loss_added": 50,
      "target_metric": "correct",
      "save_metrics": true,
      "model_name": "google/gemma-2-2b-it",
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16"
    },
    "eval_id": "a12ff1c0-e872-422d-8282-bb470139d1c7",
    "datetime_epoch_millis": 1738801911295,
    "eval_result_metrics": {
      "unlearning": {
        "unlearning_score": 0.0018726587295532227
      }
    },
    "eval_result_details": [],
    "sae_bench_commit_hash": "c600ccd8de71ccb5cbbab0eb1c6e8cc361ee3481",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 16384,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}