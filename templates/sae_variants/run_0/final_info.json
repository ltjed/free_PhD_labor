{
  "scr and tpp evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "8a80c8bd-21f0-4ac2-850a-a109864f1be0",
    "datetime_epoch_millis": 1738166894135,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.24189783363496667,
        "scr_metric_threshold_2": 0.10073797558232926,
        "scr_dir2_threshold_2": 0.10727792314287347,
        "scr_dir1_threshold_5": 0.19445330078593534,
        "scr_metric_threshold_5": 0.16277533572712116,
        "scr_dir2_threshold_5": 0.1696090699706945,
        "scr_dir1_threshold_10": 0.19371557076977172,
        "scr_metric_threshold_10": 0.216830451463131,
        "scr_dir2_threshold_10": 0.22068034165186085,
        "scr_dir1_threshold_20": 0.21310985909955366,
        "scr_metric_threshold_20": 0.24833848806275896,
        "scr_dir2_threshold_20": 0.2555758688063006,
        "scr_dir1_threshold_50": 0.18255508584534738,
        "scr_metric_threshold_50": 0.305831548658246,
        "scr_dir2_threshold_50": 0.3144356634598083,
        "scr_dir1_threshold_100": 0.2266033857765543,
        "scr_metric_threshold_100": 0.3220679498398785,
        "scr_dir2_threshold_100": 0.3332957403962267,
        "scr_dir1_threshold_500": 0.1705729708811835,
        "scr_metric_threshold_500": 0.3427748534930416,
        "scr_dir2_threshold_500": 0.3608210324010268
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.45312510186348476,
        "scr_metric_threshold_2": 0.019656056358159712,
        "scr_dir2_threshold_2": 0.019656056358159712,
        "scr_dir1_threshold_5": 0.5312500873115584,
        "scr_metric_threshold_5": 0.02948408453723957,
        "scr_dir2_threshold_5": 0.02948408453723957,
        "scr_dir1_threshold_10": 0.5156252764866015,
        "scr_metric_threshold_10": 0.03439802540241183,
        "scr_dir2_threshold_10": 0.03439802540241183,
        "scr_dir1_threshold_20": 0.5312500873115584,
        "scr_metric_threshold_20": 0.05159711132798542,
        "scr_dir2_threshold_20": 0.05159711132798542,
        "scr_dir1_threshold_50": 0.5468748981365152,
        "scr_metric_threshold_50": 0.07862407898390353,
        "scr_dir2_threshold_50": 0.07862407898390353,
        "scr_dir1_threshold_100": 0.4843747235133985,
        "scr_metric_threshold_100": 0.13267816074447508,
        "scr_dir2_threshold_100": 0.13267816074447508,
        "scr_dir1_threshold_500": 0.1562499708961472,
        "scr_metric_threshold_500": 0.009828028179079856,
        "scr_dir2_threshold_500": 0.009828028179079856
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.3495147428927238,
        "scr_metric_threshold_2": 0.07736393061404061,
        "scr_dir2_threshold_2": 0.07736393061404061,
        "scr_dir1_threshold_5": -0.09708729998443334,
        "scr_metric_threshold_5": 0.16618903247138295,
        "scr_dir2_threshold_5": 0.16618903247138295,
        "scr_dir1_threshold_10": -0.12621372145414522,
        "scr_metric_threshold_10": 0.23782237746377266,
        "scr_dir2_threshold_10": 0.23782237746377266,
        "scr_dir1_threshold_20": -0.08737868572318094,
        "scr_metric_threshold_20": 0.29226362401729183,
        "scr_dir2_threshold_20": 0.29226362401729183,
        "scr_dir1_threshold_50": -0.029126421469711866,
        "scr_metric_threshold_50": 0.4011461171243302,
        "scr_dir2_threshold_50": 0.4011461171243302,
        "scr_dir1_threshold_100": -0.11650510719289281,
        "scr_metric_threshold_100": 0.44985677805619845,
        "scr_dir2_threshold_100": 0.44985677805619845,
        "scr_dir1_threshold_500": -0.09708729998443334,
        "scr_metric_threshold_500": 0.45272207086702393,
        "scr_dir2_threshold_500": 0.45272207086702393
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.5238092084411499,
        "scr_metric_threshold_2": 0.02784819256855401,
        "scr_dir2_threshold_2": 0.02784819256855401,
        "scr_dir1_threshold_5": 0.5396829601737049,
        "scr_metric_threshold_5": 0.04556963247779803,
        "scr_dir2_threshold_5": 0.04556963247779803,
        "scr_dir1_threshold_10": 0.5238092084411499,
        "scr_metric_threshold_10": 0.08354442680784264,
        "scr_dir2_threshold_10": 0.08354442680784264,
        "scr_dir1_threshold_20": 0.4603179859314168,
        "scr_metric_threshold_20": 0.08607603952376044,
        "scr_dir2_threshold_20": 0.08607603952376044,
        "scr_dir1_threshold_50": 0.33333364870170723,
        "scr_metric_threshold_50": 0.1594937136722931,
        "scr_dir2_threshold_50": 0.1594937136722931,
        "scr_dir1_threshold_100": 0.4126986229439953,
        "scr_metric_threshold_100": 0.0,
        "scr_dir2_threshold_100": 0.0,
        "scr_dir1_threshold_500": -0.09523777986972133,
        "scr_metric_threshold_500": -0.010126450863671215,
        "scr_dir2_threshold_500": -0.010126450863671215
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": 0.3828126309672156,
        "scr_metric_threshold_2": 0.12759656040532572,
        "scr_dir2_threshold_2": 0.12759656040532572,
        "scr_dir1_threshold_5": 0.19531274738251833,
        "scr_metric_threshold_5": 0.23738884264763468,
        "scr_dir2_threshold_5": 0.23738884264763468,
        "scr_dir1_threshold_10": 0.08593777648634401,
        "scr_metric_threshold_10": 0.2878338257938472,
        "scr_dir2_threshold_10": 0.2878338257938472,
        "scr_dir1_threshold_20": 0.10156257275956422,
        "scr_metric_threshold_20": 0.23145402430383724,
        "scr_dir2_threshold_20": 0.23145402430383724,
        "scr_dir1_threshold_50": -0.2421871362021789,
        "scr_metric_threshold_50": 0.22551938282841538,
        "scr_dir2_threshold_50": 0.22551938282841538,
        "scr_dir1_threshold_100": 0.1328126309672156,
        "scr_metric_threshold_100": 0.27002972449920604,
        "scr_dir2_threshold_100": 0.27002972449920604,
        "scr_dir1_threshold_500": 0.5,
        "scr_metric_threshold_500": -0.07418390278465108,
        "scr_dir2_threshold_500": -0.07418390278465108
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.016393554752069144,
        "scr_metric_threshold_2": 0.35686274876460633,
        "scr_dir2_threshold_2": 0.35686274876460633,
        "scr_dir1_threshold_5": 0.027322374114521025,
        "scr_metric_threshold_5": 0.45490208361431267,
        "scr_dir2_threshold_5": 0.45490208361431267,
        "scr_dir1_threshold_10": 0.04918033854781611,
        "scr_metric_threshold_10": 0.4941177240567333,
        "scr_dir2_threshold_10": 0.4941177240567333,
        "scr_dir1_threshold_20": 0.03825119347697291,
        "scr_metric_threshold_20": 0.5647059703505524,
        "scr_dir2_threshold_20": 0.5647059703505524,
        "scr_dir1_threshold_50": -0.00546440968122594,
        "scr_metric_threshold_50": 0.6509802858264159,
        "scr_dir2_threshold_50": 0.6509802858264159,
        "scr_dir1_threshold_100": -0.016393554752069144,
        "scr_metric_threshold_100": 0.7294118004549119,
        "scr_dir2_threshold_100": 0.7294118004549119,
        "scr_dir1_threshold_500": -0.05464474822904205,
        "scr_metric_threshold_500": 0.7960782957095651,
        "scr_dir2_threshold_500": 0.7960782957095651
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.07692300638503319,
        "scr_metric_threshold_2": 0.024193715075407077,
        "scr_dir2_threshold_2": 0.024193715075407077,
        "scr_dir1_threshold_5": 0.1333331499344196,
        "scr_metric_threshold_5": 0.07661287027579163,
        "scr_dir2_threshold_5": 0.07661287027579163,
        "scr_dir1_threshold_10": 0.17435887560571312,
        "scr_metric_threshold_10": 0.09677413927777444,
        "scr_dir2_threshold_10": 0.09677413927777444,
        "scr_dir1_threshold_20": 0.24102560340535104,
        "scr_metric_threshold_20": 0.14112912335516434,
        "scr_dir2_threshold_20": 0.14112912335516434,
        "scr_dir1_threshold_50": 0.30769233120498896,
        "scr_metric_threshold_50": 0.2137097878988163,
        "scr_dir2_threshold_50": 0.2137097878988163,
        "scr_dir1_threshold_100": 0.338461472626031,
        "scr_metric_threshold_100": 0.25403232590278196,
        "scr_dir2_threshold_100": 0.25403232590278196,
        "scr_dir1_threshold_500": 0.45641020468235766,
        "scr_metric_threshold_500": 0.5967741392777745,
        "scr_dir2_threshold_500": 0.5967741392777745
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.08968601715063591,
        "scr_metric_threshold_2": 0.12946419424511926,
        "scr_dir2_threshold_2": 0.12946419424511926,
        "scr_dir1_threshold_5": 0.16143477741406173,
        "scr_metric_threshold_5": 0.22767852985167758,
        "scr_dir2_threshold_5": 0.22767852985167758,
        "scr_dir1_threshold_10": 0.2197307954761409,
        "scr_metric_threshold_10": 0.3928570763341127,
        "scr_dir2_threshold_10": 0.3928570763341127,
        "scr_dir1_threshold_20": 0.28251106093866896,
        "scr_metric_threshold_20": 0.48214295692740233,
        "scr_dir2_threshold_20": 0.48214295692740233,
        "scr_dir1_threshold_50": 0.3991030970628273,
        "scr_metric_threshold_50": 0.5669643439219371,
        "scr_dir2_threshold_50": 0.5669643439219371,
        "scr_dir1_threshold_100": 0.4529148677244576,
        "scr_metric_threshold_100": 0.616071378679156,
        "scr_dir2_threshold_100": 0.616071378679156,
        "scr_dir1_threshold_500": 0.22421531016200436,
        "scr_metric_threshold_500": 0.6964285381670564,
        "scr_dir2_threshold_500": 0.6964285381670564
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.042918406627421406,
        "scr_metric_threshold_2": 0.042918406627421406,
        "scr_dir2_threshold_2": 0.09523798711177515,
        "scr_dir1_threshold_5": 0.0643776099411321,
        "scr_metric_threshold_5": 0.0643776099411321,
        "scr_dir2_threshold_5": 0.11904748388971893,
        "scr_dir1_threshold_10": 0.10729601656855352,
        "scr_metric_threshold_10": 0.10729601656855352,
        "scr_dir2_threshold_10": 0.13809513807839202,
        "scr_dir1_threshold_20": 0.13733905469607777,
        "scr_metric_threshold_20": 0.13733905469607777,
        "scr_dir2_threshold_20": 0.19523810064441124,
        "scr_dir1_threshold_50": 0.15021467900985702,
        "scr_metric_threshold_50": 0.15021467900985702,
        "scr_dir2_threshold_50": 0.21904759742235502,
        "scr_dir1_threshold_100": 0.1244634303822985,
        "scr_metric_threshold_100": 0.1244634303822985,
        "scr_dir2_threshold_100": 0.21428575483308432,
        "scr_dir1_threshold_500": 0.27467810939215553,
        "scr_metric_threshold_500": 0.27467810939215553,
        "scr_dir2_threshold_500": 0.419047540656037
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 65536,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "c3219cfe-865b-4543-87db-cee1d629a37b",
    "datetime_epoch_millis": 1738167214711,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.95063125,
        "llm_top_1_test_accuracy": 0.6601500000000001,
        "llm_top_2_test_accuracy": 0.7222312500000001,
        "llm_top_5_test_accuracy": 0.7810437499999999,
        "llm_top_10_test_accuracy": 0.8318375,
        "llm_top_20_test_accuracy": 0.8794125,
        "llm_top_50_test_accuracy": 0.9224687500000001,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9593875378370286,
        "sae_top_1_test_accuracy": 0.75545,
        "sae_top_2_test_accuracy": 0.8435625,
        "sae_top_5_test_accuracy": 0.8890125,
        "sae_top_10_test_accuracy": 0.9093812500000001,
        "sae_top_20_test_accuracy": 0.9297812500000001,
        "sae_top_50_test_accuracy": 0.9457749999999998,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9658000469207764,
        "sae_top_1_test_accuracy": 0.8463999999999998,
        "sae_top_2_test_accuracy": 0.8459999999999999,
        "sae_top_5_test_accuracy": 0.8916000000000001,
        "sae_top_10_test_accuracy": 0.913,
        "sae_top_20_test_accuracy": 0.9478,
        "sae_top_50_test_accuracy": 0.9593999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9490000000000001,
        "llm_top_1_test_accuracy": 0.6798,
        "llm_top_2_test_accuracy": 0.7336,
        "llm_top_5_test_accuracy": 0.7658000000000001,
        "llm_top_10_test_accuracy": 0.8032,
        "llm_top_20_test_accuracy": 0.8652000000000001,
        "llm_top_50_test_accuracy": 0.9082000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9500000238418579,
        "sae_top_1_test_accuracy": 0.7564,
        "sae_top_2_test_accuracy": 0.8033999999999999,
        "sae_top_5_test_accuracy": 0.8342,
        "sae_top_10_test_accuracy": 0.8858,
        "sae_top_20_test_accuracy": 0.906,
        "sae_top_50_test_accuracy": 0.9389999999999998,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9152000000000001,
        "llm_top_1_test_accuracy": 0.6910000000000001,
        "llm_top_2_test_accuracy": 0.7356,
        "llm_top_5_test_accuracy": 0.7594,
        "llm_top_10_test_accuracy": 0.8054,
        "llm_top_20_test_accuracy": 0.857,
        "llm_top_50_test_accuracy": 0.892,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9306000351905823,
        "sae_top_1_test_accuracy": 0.7514,
        "sae_top_2_test_accuracy": 0.8474,
        "sae_top_5_test_accuracy": 0.8544,
        "sae_top_10_test_accuracy": 0.8768,
        "sae_top_20_test_accuracy": 0.9022,
        "sae_top_50_test_accuracy": 0.9224,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.8972,
        "llm_top_1_test_accuracy": 0.6042,
        "llm_top_2_test_accuracy": 0.6414,
        "llm_top_5_test_accuracy": 0.6702,
        "llm_top_10_test_accuracy": 0.7614000000000001,
        "llm_top_20_test_accuracy": 0.8093999999999999,
        "llm_top_50_test_accuracy": 0.8622,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9280000448226928,
        "sae_top_1_test_accuracy": 0.7385999999999999,
        "sae_top_2_test_accuracy": 0.798,
        "sae_top_5_test_accuracy": 0.8408,
        "sae_top_10_test_accuracy": 0.8501999999999998,
        "sae_top_20_test_accuracy": 0.8726,
        "sae_top_50_test_accuracy": 0.8948,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.9815,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.8474999999999999,
        "llm_top_50_test_accuracy": 0.933,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9780000448226929,
        "sae_top_1_test_accuracy": 0.584,
        "sae_top_2_test_accuracy": 0.95,
        "sae_top_5_test_accuracy": 0.963,
        "sae_top_10_test_accuracy": 0.971,
        "sae_top_20_test_accuracy": 0.968,
        "sae_top_50_test_accuracy": 0.974,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9613999999999999,
        "llm_top_1_test_accuracy": 0.6288,
        "llm_top_2_test_accuracy": 0.7,
        "llm_top_5_test_accuracy": 0.7592,
        "llm_top_10_test_accuracy": 0.7988,
        "llm_top_20_test_accuracy": 0.8725999999999999,
        "llm_top_50_test_accuracy": 0.9269999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9708000421524048,
        "sae_top_1_test_accuracy": 0.6164,
        "sae_top_2_test_accuracy": 0.7086000000000001,
        "sae_top_5_test_accuracy": 0.8506,
        "sae_top_10_test_accuracy": 0.8874000000000001,
        "sae_top_20_test_accuracy": 0.9270000000000002,
        "sae_top_50_test_accuracy": 0.9471999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.9417500000000001,
        "llm_top_1_test_accuracy": 0.634,
        "llm_top_2_test_accuracy": 0.76125,
        "llm_top_5_test_accuracy": 0.82675,
        "llm_top_10_test_accuracy": 0.8684999999999999,
        "llm_top_20_test_accuracy": 0.8959999999999999,
        "llm_top_50_test_accuracy": 0.92175,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.95250004529953,
        "sae_top_1_test_accuracy": 0.782,
        "sae_top_2_test_accuracy": 0.8234999999999999,
        "sae_top_5_test_accuracy": 0.8865,
        "sae_top_10_test_accuracy": 0.89325,
        "sae_top_20_test_accuracy": 0.91625,
        "sae_top_50_test_accuracy": 0.9299999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9994,
        "llm_top_1_test_accuracy": 0.7292000000000002,
        "llm_top_2_test_accuracy": 0.7904,
        "llm_top_5_test_accuracy": 0.9098,
        "llm_top_10_test_accuracy": 0.9578,
        "llm_top_20_test_accuracy": 0.9914,
        "llm_top_50_test_accuracy": 0.9972,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9994000196456909,
        "sae_top_1_test_accuracy": 0.9684000000000001,
        "sae_top_2_test_accuracy": 0.9715999999999999,
        "sae_top_5_test_accuracy": 0.991,
        "sae_top_10_test_accuracy": 0.9975999999999999,
        "sae_top_20_test_accuracy": 0.9984,
        "sae_top_50_test_accuracy": 0.9994,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 65536,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "unlearning evaluation results": {
    "eval_type_id": "unlearning",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "wmdp-bio",
        "high_school_us_history",
        "college_computer_science",
        "high_school_geography",
        "human_aging"
      ],
      "intervention_method": "clamp_feature_activation",
      "retain_thresholds": [
        0.001,
        0.01
      ],
      "n_features_list": [
        10,
        20
      ],
      "multipliers": [
        25,
        50,
        100,
        200
      ],
      "dataset_size": 1024,
      "seq_len": 1024,
      "n_batch_loss_added": 50,
      "target_metric": "correct",
      "save_metrics": true,
      "model_name": "google/gemma-2-2b-it",
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16"
    },
    "eval_id": "3ce80ec0-b9ec-4b19-b5b9-8f6db37d30a4",
    "datetime_epoch_millis": 1738157067896,
    "eval_result_metrics": {
      "unlearning": {
        "unlearning_score": 0.0
      }
    },
    "eval_result_details": [],
    "sae_bench_commit_hash": "4153f454e45d23297aadf56f83c2f432798680d1",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 65536,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "training results for layer 12": {
    "config": {
      "trainer_class": "TrainerTopK",
      "dict_class": "AutoEncoderTopK",
      "lr": 0.0001,
      "steps": 29296,
      "seed": 42,
      "activation_dim": 2304,
      "dict_size": 65536,
      "k": 320,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "AutoEncoderTopK",
      "submodule_name": "resid_post_layer_12"
    },
    "final_info": {
      "training_steps": 29296,
      "final_loss": 1673.2169189453125,
      "layer": 12,
      "dict_size": 65536,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "581fa094-b0a6-47a7-9260-0e37ae87373d",
    "datetime_epoch_millis": 1738166151643,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.0022649684414945436,
        "mean_num_split_features": 1.0909090909090908
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 2580,
        "num_split_features": 1
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.0006313131313131314,
        "num_absorption": 1,
        "num_probe_true_positives": 1584,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1669,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1673,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1214,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.0017699115044247787,
        "num_absorption": 2,
        "num_probe_true_positives": 1130,
        "num_split_features": 2
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1032,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.0011655011655011655,
        "num_absorption": 2,
        "num_probe_true_positives": 1716,
        "num_split_features": 1
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 475,
        "num_split_features": 1
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.008522727272727272,
        "num_absorption": 6,
        "num_probe_true_positives": 704,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.0008216926869350862,
        "num_absorption": 1,
        "num_probe_true_positives": 1217,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.001092896174863388,
        "num_absorption": 2,
        "num_probe_true_positives": 1830,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 872,
        "num_split_features": 1
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.0027397260273972603,
        "num_absorption": 3,
        "num_probe_true_positives": 1095,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.0004317789291882556,
        "num_absorption": 1,
        "num_probe_true_positives": 2316,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.0003497726477789437,
        "num_absorption": 1,
        "num_probe_true_positives": 2859,
        "num_split_features": 1
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1659,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 783,
        "num_split_features": 2
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 818,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.0046801872074883,
        "num_absorption": 3,
        "num_probe_true_positives": 641,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.011363636363636364,
        "num_absorption": 2,
        "num_probe_true_positives": 176,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.016260162601626018,
        "num_absorption": 4,
        "num_probe_true_positives": 246,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 65536,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9957540760869565,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.042724609375
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9967105263157895,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 2.96875,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.84375,
        "mse": 0.98046875,
        "cossim": 0.953125
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 143.0,
        "l2_ratio": 0.953125,
        "relative_reconstruction_bias": 1.0
      },
      "sparsity": {
        "l0": 319.994384765625,
        "l1": 924.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  }
}