[
    {
        "Name": "adaptive_sparse_autoencoders",
        "Title": "Adaptive Computation in Sparse Autoencoders",
        "Experiment": "1. Implement Feature Choice and Mutual Choice sparsifying activation functions\n2. Add aux_zipf_loss and aux_k_loss auxiliary losses\n3. Train SAEs with new activation functions and losses on GPT-2 sized residual stream activations\n4. Compare performance (sparsity, reconstruction error, model loss) and feature utilization against baseline TopK SAEs\n5. Analyze distribution of features per token and feature densities\n6. Implement phased training with Mutual Choice followed by Feature Choice",
        "Technical_Details": "The paper proposes two novel sparse autoencoder (SAE) variants: Feature Choice (FC) and Mutual Choice (MC). These allow for variable numbers of active features per token, framing the token-feature matching as a resource allocation problem with a total sparsity upper bound. The FC approach allows each feature to select m tokens to process, where m = M/F (M is total matches, F is number of features). MC combines aspects of FC and token choice. A new aux_zipf_loss is introduced to encourage feature densities to follow a Zipf distribution, mitigating feature under-utilization. The paper also suggests a phased training approach, starting with MC and transitioning to FC.",
        "Research_Impact": "A key challenge in mechanistic interpretability is extracting meaningful, interpretable features from neural networks while maintaining computational efficiency. This research addresses this by introducing adaptive computation in SAEs, allowing more features and computation for difficult-to-reconstruct tokens. The proposed methods achieve higher reconstruction accuracy with fewer dead features compared to standard approaches, potentially leading to more robust and interpretable feature extraction in large language models.",
        "Interestingness": 8,
        "Feasibility": 7,
        "Novelty": 8,
        "novel": false
    },
    {
        "Name": "gated_sparse_autoencoder",
        "Title": "\u00a92024 Google DeepMind. All rights reservedarXiv:2404.16014v2  [cs.LG]  30 Apr 2024",
        "Experiment": "1. Implement Gated SAE architecture with separate gating and magnitude components\n2. Modify loss function to include L1 penalty on gating activations and auxiliary reconstruction task\n3. Train Gated SAEs on activations from GELU-1L, Pythia-2.8B, and Gemma-7B models\n4. Evaluate performance using loss recovered vs. L0 sparsity metrics\n5. Compare against baseline SAEs using Pareto frontier analysis\n6. Conduct shrinkage analysis and human interpretability study",
        "Technical_Details": "The Gated SAE architecture separates feature detection and magnitude estimation by using two sets of weights: w_gate for determining active features and w_mag for estimating magnitudes. The encoder output is computed as h = ReLU(w_gate * x + b_gate) * (w_mag * x + b_mag). The loss function includes an L1 penalty on ReLU(w_gate * x + b_gate) to encourage sparsity, and an auxiliary reconstruction task using these gating activations. Weight tying is employed between encoder and decoder. The architecture can be interpreted as a single-layer encoder with a parameterized JumpReLU activation function.",
        "Research_Impact": "A key challenge in mechanistic interpretability is finding sparse, interpretable features in language model activations. Gated SAEs address this by improving dictionary learning, achieving better reconstruction fidelity at given sparsity levels compared to standard SAEs. They also mitigate the shrinkage problem inherent in L1 regularization, potentially leading to more accurate feature representations. This could enable more reliable extraction of interpretable features across different model sizes and activation sites, advancing our ability to understand the internal workings of large language models.",
        "Interestingness": 8,
        "Feasibility": 7,
        "Novelty": 7,
        "novel": false
    },
    {
        "Name": "batchtopk_sae",
        "Title": "Information Processing Systems (NeurIPS 2024).arXiv:2412.06410v1  [cs.LG]  9 Dec 2024",
        "Experiment": "1. Implement BatchTopK function to replace sample-level TopK operation.2. Modify SAE training procedure to use BatchTopK for sparsity constraint.3. Implement threshold estimation method for inference.4. Train SAEs on GPT-2 Small and Gemma 2 2B activations using both TopK and BatchTopK.5. Compare reconstruction quality (normalized MSE) and impact on language modeling (cross-entropy degradation).6. Evaluate performance across different dictionary sizes (3072, 6144, 12288, 24576).7. Analyze latent activation patterns and flexibility in latent allocation.",
        "Technical_Details": "BatchTopK is a novel training method for Sparse Autoencoders (SAEs) that replaces the sample-level TopK operation with a batch-level constraint. Instead of enforcing a fixed number of active latents per sample, BatchTopK selects the top activations across the entire batch. This allows for variable sparsity per sample, with some samples using more latents and others using fewer. The method introduces a batch dependency during training, which is addressed during inference by estimating a global threshold parameter. This threshold is calculated as the average of minimum positive activation values across multiple batches. The SAE is trained on language model activations (e.g., from the residual stream) using a large text corpus. The loss function combines L2 reconstruction error with an L0 sparsity penalty. Experiments were conducted on GPT-2 Small and Gemma 2 2B models, using dictionary sizes of 3072, 6144, 12288, and 24576, with a bandwidth parameter of 0.001 and the Adam optimizer (learning rate 3e-4).",
        "Research_Impact": "A significant challenge in mechanistic interpretability is developing methods to effectively analyze and interpret the internal representations of large language models. BatchTopK SAEs address this challenge by providing a more flexible and efficient way to compress and represent model activations. By allowing variable sparsity per sample, BatchTopK can potentially capture more nuanced and diverse activation patterns compared to fixed-sparsity methods. This improvement in reconstruction quality, as demonstrated by lower normalized MSE and reduced cross-entropy degradation, could lead to more accurate and insightful interpretations of model behavior. Furthermore, the ability to adaptively allocate latents based on sample complexity aligns well with the varying information content in natural language, potentially revealing more about how language models process different types of inputs.",
        "Interestingness": 8,
        "Feasibility": 7,
        "Novelty": 6,
        "novel": false
    },
    {
        "Name": "jumprelu_sae",
        "Title": "\u00a92024 Google DeepMind. All rights reservedarXiv:2407.14435v3  [cs.LG]  1 Aug 2024",
        "Experiment": "Implement JumpReLU activation function for sparse autoencoders. Modify existing SAE architecture to use JumpReLU instead of ReLU. Train JumpReLU SAEs on language model activations (e.g. Gemma 2 9B). Compare reconstruction fidelity and sparsity trade-offs against Gated and TopK SAEs. Conduct manual and automated interpretability studies on learned features.",
        "Technical_Details": "JumpReLU SAE introduces a threshold parameter \u03c4 for each feature. The activation function zeroes out pre-activations below \u03c4. Loss function combines L2 reconstruction error and L0 sparsity penalty. Straight-through estimators are used to estimate gradients of the expected loss. Pseudo-derivatives provide gradient signals within a small window around the threshold. Training involves computing gradients over batches and using batch-wise mean for parameter updates.",
        "Research_Impact": "Addresses the challenge of balancing reconstruction fidelity and interpretability in sparse representations of language model activations. JumpReLU SAEs achieve state-of-the-art reconstruction fidelity at given sparsity levels without sacrificing interpretability. This improves upon existing methods like Gated and TopK SAEs, potentially enabling more accurate identification of computational subgraphs and causal mechanisms in language models.",
        "Interestingness": 8,
        "Feasibility": 7,
        "Novelty": 6,
        "novel": false
    },
    {
        "Name": "clustered_sparse_autoencoders",
        "Title": "Clustered Sparse Autoencoders for Efficient Interpretability of Large Language Models",
        "Experiment": "1. Implement clustering algorithm to group model layers2. Train single SAE for each cluster instead of per-layer3. Evaluate reconstruction performance and sparsity metrics4. Assess downstream task performance using faithfulness/completeness5. Analyze feature interpretability across clustered layers6. Compare computational efficiency to baseline per-layer approach",
        "Technical_Details": "The approach clusters contiguous layers in a large language model and trains a single sparse autoencoder (SAE) per cluster, rather than per individual layer. This reduces the number of SAEs by a factor k, where k is the number of clusters. The method uses the JumpReLU activation function and optimizes an objective combining L2 reconstruction loss and L0 sparsity. Evaluation metrics include L2 loss, R2 score, L0 sparsity, as well as faithfulness and completeness on downstream tasks. The approach is tested with varying k values from 1 to 5, excluding the final layer of the model.",
        "Research_Impact": "This research addresses the computational challenge of training sparse autoencoders for very large language models, which has become a bottleneck in mechanistic interpretability research. By reducing the number of required SAEs, it enables more efficient analysis of state-of-the-art models with billions of parameters. This approach could accelerate progress in understanding the inner workings of advanced AI systems, addressing a key challenge in the field of AI interpretability and safety.",
        "Interestingness": 8,
        "Feasibility": 7,
        "Novelty": 6,
        "novel": false
    },
    {
        "Name": "mutual_feature_regularization",
        "Title": "1",
        "Experiment": "1. Implement MFR technique for SAEs:        - Add reinitializing of SAE weights when too many inactive features detected        - Implement auxiliary penalty to incentivize features present in other SAE decoders    2. Train SAEs with and without MFR on:        - Synthetic dataset with known features        - GPT-2 Small first layer MLP outputs        - EEG data from TUH EEG Corpus    3. Compare reconstruction loss and feature recovery between baseline and MFR SAEs    4. Analyze L2 distance between decoder matrices to assess feature similarity",
        "Technical_Details": "Mutual Feature Regularization (MFR) consists of two main components:    1. Reinitialization: Check for inactive features in SAE hidden state. If too many are detected, reinitialize the weights of the affected SAE.    2. Auxiliary penalty: Add a penalty term to the loss function that encourages features to be present in decoders of other SAEs trained on the same data.        Implementation details:    - Use TopK activation function for sparsity in SAE hidden state    - Train with AdamW optimizer    - Apply cosine warmup for 100 training steps on the auxiliary penalty    - Set auxiliary penalty coefficient to make initial reconstruction loss and penalty equivalent    - Evaluate using reconstruction loss (Euclidean distance between input and output) and feature recovery metrics",
        "Research_Impact": "MFR addresses the challenge of SAEs learning features that are not actually present in the input data, which limits their interpretability. This is a significant issue in mechanistic interpretability, where the goal is to understand the true features and computations of neural networks. By encouraging feature consistency across multiple SAEs, MFR increases the likelihood that learned features correspond to actual input features. This improvement could lead to more reliable and meaningful interpretations of neural network activations, advancing our understanding of how these models process information.",
        "Interestingness": 7,
        "Feasibility": 8,
        "Novelty": 6,
        "novel": false
    },
    {
        "Name": "switch_sparse_autoencoder",
        "Title": "Switch Sparse Autoencoders",
        "Experiment": "1. Implement Switch layer architecture for sparse autoencoders (SAEs)\n2. Modify existing SAE training pipeline to incorporate Switch layer\n3. Train Switch SAEs on GPT-2 small residual stream activations\n4. Compare performance against TopK, ReLU, and Gated SAEs using metrics like reconstruction MSE, cross-entropy loss recovery, and feature interpretability\n5. Analyze scaling laws by training models with varying numbers of experts (16, 32, 64, 128)\n6. Evaluate expert specialization using nearest neighbor cosine similarity\n7. Perform t-SNE projections to visualize feature clustering\n8. Assess true positive and true negative rates for feature detection",
        "Technical_Details": "The Switch Sparse Autoencoder (Switch SAE) combines the Switch layer architecture with TopK SAEs. It consists of multiple expert SAEs and a trainable routing network. The router computes a probability distribution over experts and routes input activations to the expert with the highest probability. This approach reduces computational costs by avoiding dense matrix multiplications. The model is trained on residual stream activations of GPT-2 small, optimizing for reconstruction MSE. The architecture allows for scaling to a large number of features (up to 34 million in this study) while maintaining computational efficiency. The Switch SAE demonstrates improved performance in terms of reconstruction error vs. sparsity trade-off compared to other SAE variants.",
        "Research_Impact": "A key challenge in mechanistic interpretability is scaling sparse autoencoders to very high widths to identify all features represented in frontier models. This research directly addresses this challenge by introducing the Switch SAE architecture, which reduces the compute cost of training wide SAEs. By leveraging conditional computation, the Switch SAE enables scaling to millions of features while maintaining computational tractability. This advancement allows researchers to probe deeper into the internal representations of large language models, potentially uncovering a more comprehensive set of interpretable features and advancing our understanding of model behavior.",
        "Interestingness": 8,
        "Feasibility": 7,
        "Novelty": 8,
        "novel": false
    },
    {
        "Name": "sparse_autoencoder_improvements",
        "Title": "Sparse Autoencoder Viewer",
        "Experiment": "1. Implement TopK activation function and compare with ReLU and ProLU.\n2. Develop Multi-TopK loss function.\n3. Train autoencoders on GPT-2 small and GPT-4 family models with varying latent sizes.\n4. Evaluate using new metrics: downstream loss, probe loss, explainability, and ablation sparsity.\n5. Analyze scaling laws for MSE, compute, and model size.\n6. Implement and test AuxK loss for reducing dead latents.\n7. Conduct ablation studies on different positions and layers of the models.",
        "Technical_Details": "The paper introduces several technical improvements for training sparse autoencoders:\n1. TopK activation function: Only keeps the k largest latents, zeroing the rest.\n2. Multi-TopK loss: Sums multiple TopK losses with different k values to improve generalization.\n3. AuxK loss: An auxiliary loss that models reconstruction error using top-k dead latents.\n4. Optimization techniques: Using Adam optimizer with specific beta values, EMA of weights, and gradient projection.\n5. Scaling laws: Empirical observations on how MSE scales with compute, number of latents, and sparsity level.\n6. Evaluation metrics: New metrics including downstream loss, probe loss, explainability, and ablation sparsity to better quantify autoencoder quality.\n7. Parallelization strategies: Utilizing data parallel and tensor sharding techniques to handle large models.",
        "Research_Impact": "This research addresses the challenge of training extremely wide and sparse autoencoders, which has been a limiting factor in extracting interpretable features from large language models. Specifically:\n1. It improves the reconstruction-sparsity trade-off, allowing for better feature extraction with fewer active latents.\n2. The introduction of TopK and Multi-TopK activation functions mitigates the overfitting problem observed in ReLU-based autoencoders.\n3. The new evaluation metrics provide a more comprehensive assessment of autoencoder quality, moving beyond simple reconstruction error.\n4. The scaling laws discovered offer insights into the relationship between model size, compute, and autoencoder performance, which can guide future research in this area.\n5. The techniques for reducing dead latents (like AuxK loss) address a common problem in sparse autoencoder training, potentially leading to more efficient feature extraction.",
        "Interestingness": 8,
        "Feasibility": 7,
        "Novelty": 7,
        "novel": false
    },
    {
        "Name": "differential_activation_unlearning",
        "Title": "Differential Activation Analysis for Precise Knowledge Unlearning in Sparse Autoencoders",
        "Experiment": "1. Train a standard sparse autoencoder on general text data\n2. Implement a differential activation analysis method for feature selection\n3. Collect activation statistics on both 'forget' and 'retain' datasets\n4. Define a contrast ratio to identify features that selectively activate on dangerous content\n5. Compare unlearning performance against baseline selection method using standard evaluation metrics",
        "Technical_Details": "Differential Activation Unlearning (DAU) enhances the feature selection process for knowledge unlearning by identifying features that selectively activate on dangerous content versus general content. The approach maintains the standard SAE training but improves how features are selected for clamping during unlearning.\n\nFor each feature i, we compute two key metrics across both 'forget' (WMDP-bio) and 'retain' (WikiText) datasets:\n\n1. Mean activation: \u03bc_forget(i) and \u03bc_retain(i) - the average activation value across all samples\n2. Activation frequency: freq_forget(i) and freq_retain(i) - the proportion of samples where the feature activates above threshold\n\nWe then define a contrast ratio for each feature:\n\ncontrast(i) = (\u03bc_forget(i) * freq_forget(i)) / (\u03bc_retain(i) * freq_retain(i) + \u03b5)\n\nwhere \u03b5 is a small constant (e.g., 1e-6) to prevent division by zero when a feature never activates on the retain dataset.\n\nFeatures with high contrast ratios activate more selectively on dangerous content. The feature selection procedure first discards features with retain set frequency above retain_threshold, then selects the top n_features by contrast ratio for clamping during inference. For features that never activate on the forget dataset, we set contrast(i) = 0.",
        "Rationale": "The unlearning benchmark requires identifying features that specifically encode dangerous knowledge while minimizing impact on general capabilities. The current approach uses only binary sparsity patterns, which may not optimally distinguish between features that encode dangerous knowledge versus general knowledge.\n\nDifferential Activation Unlearning addresses this limitation through these mechanisms:\n\n1. The contrast ratio directly measures how selectively a feature activates on dangerous content compared to general content. A high ratio indicates the feature is primarily used for representing dangerous knowledge.\n\n2. By considering both activation magnitude and frequency, we capture more information about how features are used by the model. Features that activate strongly and frequently on dangerous content but rarely on general content are ideal candidates for clamping.\n\n3. This approach aligns precisely with the unlearning objective: we want to identify and remove features that primarily contribute to dangerous knowledge while preserving features important for general capabilities.\n\n4. The method is simple to implement, requiring only basic statistics on feature activations that can be collected during a single pass through each dataset.\n\n5. By focusing on relative activation patterns between datasets rather than absolute values, the approach is more robust to variations in feature activation scales and thresholds.\n\nWhile we can't guarantee that all features with high contrast ratios exclusively encode dangerous knowledge (some semantic overlap is inevitable in neural representations), this approach provides a more targeted selection method than using sparsity alone. The contrast ratio effectively ranks features by how specifically they activate on dangerous content, allowing for more precise knowledge removal.",
        "Implementation_Plan": "1. Use the existing CustomSAE implementation without modifications\n2. Implement a DifferentialActivationAnalyzer class to collect activation statistics\n3. Add functions to compute mean activations and frequencies across datasets\n4. Implement the contrast ratio calculation for feature ranking\n5. Modify the unlearning evaluation to use the enhanced feature selection method\n6. Add logging of contrast ratios and selected features\n7. Compare unlearning performance against the baseline selection method\n8. Conduct ablation studies with different contrast ratio thresholds",
        "novel": true
    },
    {
        "Name": "activation_pattern_contrast",
        "Title": "Activation Pattern Contrast for Targeted Knowledge Unlearning in Sparse Autoencoders",
        "Experiment": "1. Implement Activation Pattern Contrast method for feature selection\n2. Compute activation statistics on both 'forget' (WMDP-bio) and 'retain' (WikiText) datasets\n3. Calculate contrast scores that identify features with different activation patterns between datasets\n4. Modify feature selection procedure to use contrast scores instead of raw sparsity\n5. Compare unlearning performance against baseline selection method using WMDP-bio and MMLU accuracy metrics\n6. Analyze relationship between contrast scores and unlearning effectiveness\n7. Perform ablation studies comparing different contrast score formulations",
        "Technical_Details": "Activation Pattern Contrast (APC) identifies features that show distinctly different activation patterns between dangerous content and general content. For each feature i, we compute:\n\n1. Mean positive activation: \u03bc_pos_forget(i) = mean(max(0, x_i)) on forget dataset and \u03bc_pos_retain(i) on retain dataset\n2. Activation frequency: freq_forget(i) = proportion of samples where feature i activates above threshold \u03c4 on forget dataset, and freq_retain(i) on retain dataset\n3. Activation intensity: intensity_forget(i) = \u03bc_pos_forget(i) * freq_forget(i) and intensity_retain(i) = \u03bc_pos_retain(i) * freq_retain(i)\n4. Contrast score: contrast(i) = (intensity_forget(i) / (intensity_retain(i) + \u03b5)) - 1\n\nwhere \u03b5 is a small constant (e.g., 1e-6) for numerical stability. The contrast score ranges from -1 (feature never activates on forget dataset) to potentially large positive values (feature activates much more on forget than retain).\n\nThe selection procedure has two steps:\n1. Filter out features with intensity_retain above retain_threshold to avoid removing generally important features\n2. Select the top n_features by contrast score for clamping during inference\n\nDuring inference, selected features are clamped to negative values when they activate, using the same multiplier parameter as the baseline approach. The method is computationally efficient, requiring only a single pass through each dataset to collect activation statistics.",
        "Rationale": "The unlearning benchmark evaluates an SAE's ability to selectively remove dangerous biology knowledge (measured by decreasing WMDP-bio accuracy) while preserving general capabilities (maintaining high MMLU accuracy). The key challenge is identifying features that specifically encode dangerous knowledge.\n\nThe current sparsity-based approach has limitations:\n1. It only considers binary activation patterns (whether a feature activates or not)\n2. It doesn't directly measure the difference in feature usage between dangerous and general content\n3. It may select features that happen to activate on dangerous content but are equally important for general knowledge\n\nActivation Pattern Contrast addresses these limitations through a more nuanced approach:\n\n1. Combining activation magnitude and frequency captures both how strongly and how often a feature activates, providing a more complete measure of a feature's importance for a particular type of content. A feature might activate frequently but weakly, or rarely but strongly - both patterns are relevant for identifying knowledge encoding.\n\n2. The contrast score directly measures the relative usage of features between datasets, identifying features that are disproportionately active on dangerous content compared to general content. This aligns with the hypothesis that features encoding specialized knowledge will show different activation patterns when that knowledge is relevant versus when it isn't.\n\n3. The two-step selection process (filtering by retain intensity, then selecting by contrast score) explicitly addresses the trade-off between knowledge removal and preservation. Features that are highly active on general content are preserved regardless of their contrast score, ensuring general capabilities are maintained.\n\nThis approach is based on empirical observations about how SAEs encode information:\n- SAEs learn sparse, disentangled features that often correspond to specific semantic concepts\n- Features tend to activate when their encoded concepts are present in the input\n- The strength of activation often correlates with the relevance or prominence of the concept\n\nWhile some features may encode both dangerous and general knowledge to varying degrees, the contrast score provides a continuous measure of specialization that allows for more fine-grained selection than binary sparsity patterns. Features with the highest contrast scores are most likely to be specialized for dangerous content and thus good candidates for clamping.\n\nThe method doesn't require architectural changes to the SAE and works with the existing clamping intervention, making it highly compatible with the current unlearning framework while providing a more principled feature selection approach.",
        "Implementation_Plan": "1. Use the existing CustomSAE implementation without modifications\n2. Create an ActivationPatternAnalyzer class with methods:\n   - collect_activation_statistics(sae, dataset, batch_size=32)\n   - compute_mean_positive_activation(activations)\n   - compute_activation_frequency(activations, threshold)\n   - compute_intensity(mean_activation, frequency)\n   - compute_contrast_score(forget_intensity, retain_intensity)\n3. Modify the unlearning evaluation pipeline to:\n   - Collect activation statistics on WMDP-bio and WikiText datasets\n   - Calculate contrast scores for all features\n   - Select features based on contrast scores and retain threshold\n   - Apply clamping intervention during inference\n4. Optimize the implementation to minimize computational overhead:\n   - Use vectorized operations for computing statistics\n   - Process datasets in batches to manage memory usage\n   - Cache activation statistics to avoid redundant computation\n5. Add logging to record:\n   - Contrast scores for all features\n   - Selected features and their statistics\n   - Performance metrics (WMDP-bio and MMLU accuracy)\n6. Compare performance against the baseline selection method\n7. Conduct ablation studies comparing different variants:\n   - Using only mean activation vs. only frequency vs. combined intensity\n   - Different formulations of the contrast score\n   - Different thresholds for feature selection",
        "novel": true
    },
    {
        "Name": "graduated_clamping",
        "Title": "Graduated Clamping: Activation-Proportional Intervention for Precise Knowledge Unlearning",
        "Experiment": "1. Implement graduated clamping intervention that applies attenuation proportional to activation strength\n2. Keep the same feature selection method as baseline (sparsity-based)\n3. Compare unlearning performance between fixed clamping and graduated clamping across different hyperparameter settings\n4. Evaluate WMDP-bio accuracy (measuring unlearning effectiveness) and MMLU accuracy (measuring preservation of general capabilities)\n5. Analyze the relationship between attenuation strength and unlearning performance\n6. Perform ablation studies comparing different attenuation functions",
        "Technical_Details": "Graduated Clamping modifies the intervention applied to selected features during inference, replacing fixed negative clamping with activation-proportional attenuation. The standard clamping approach sets feature activations to a fixed negative value: f(x) = -c when x > 0, where c is the multiplier hyperparameter. In contrast, Graduated Clamping applies an attenuation that depends on the original activation strength: f(x) = -\u03b1 * x when x > 0, where \u03b1 is the attenuation factor hyperparameter.\n\nThe feature selection procedure remains unchanged: features are selected based on their sparsity patterns across the forget and retain datasets, with the same retain_threshold and n_features hyperparameters. During inference, when a selected feature would normally activate (x > 0), instead of setting its activation to a fixed negative value, we set it to a negative value proportional to its original activation: -\u03b1 * x.\n\nThis approach introduces a single new hyperparameter \u03b1 (attenuation factor) that replaces the multiplier parameter from the baseline approach. The attenuation factor controls how strongly activations are suppressed: higher values cause stronger suppression. We sweep \u03b1 across a range of values (e.g., 0.5 to 10.0) to find the optimal setting.\n\nThe key difference from the baseline is that the intervention strength now varies based on the original activation, rather than being fixed. Features that activate strongly are suppressed more heavily, while features that activate weakly are suppressed less. This provides a more nuanced intervention that better preserves the natural activation patterns of the model while still effectively removing dangerous knowledge.\n\nFor a fair comparison with the baseline, we keep all other aspects of the evaluation identical, including the feature selection criteria (retain_threshold and n_features) and the MMLU accuracy threshold (0.99) for determining the minimum achieved WMDP-bio accuracy.",
        "Rationale": "The unlearning benchmark evaluates SAEs on two specific metrics: (1) reduced accuracy on WMDP-bio questions (indicating successful unlearning of dangerous biology knowledge) and (2) maintained accuracy on unrelated MMLU subsets (indicating preservation of general capabilities). The current fixed clamping approach faces a fundamental trade-off: stronger clamping (higher multiplier values) more effectively reduces WMDP-bio accuracy but also tends to degrade MMLU accuracy.\n\nThis trade-off occurs because selected features likely encode a mixture of dangerous and general knowledge to varying degrees. In neural networks, the strength of activation often correlates with the relevance of the encoded information to the current input. While this correlation has not been definitively proven for all cases, prior work in mechanistic interpretability suggests that features in sparse representations tend to activate more strongly when their encoded concepts are directly relevant to the input.\n\nGraduated clamping exploits this potential activation strength difference by applying stronger interventions when features activate strongly and weaker interventions when they activate weakly. If features encoding biology knowledge do indeed activate more strongly for biology-related content, this approach should more effectively target dangerous knowledge while minimizing side effects on general capabilities.\n\nSpecifically, when the model processes WMDP-bio questions, biology-related features will likely activate more strongly, triggering stronger negative interventions that effectively disrupt the model's ability to answer correctly. Conversely, when processing MMLU questions on unrelated topics, these same features may activate only weakly (if at all), resulting in minimal intervention that better preserves the model's general capabilities compared to fixed clamping.\n\nIt's important to note that the effectiveness of graduated clamping depends on the actual activation patterns of the selected features across different types of content. If dangerous knowledge is primarily encoded in weak activations, graduated clamping might be less effective than fixed clamping. However, the feature selection process already identifies features that activate frequently on dangerous content, making it more likely that these features activate strongly when dangerous content is processed.\n\nGraduated clamping may also offer advantages in edge cases where fixed clamping is too disruptive. For example, if a feature encodes both dangerous knowledge and important general knowledge, fixed clamping might completely eliminate both, while graduated clamping might more selectively suppress the feature based on context, potentially preserving more general capabilities.\n\nIn summary, graduated clamping provides a more flexible intervention mechanism that adapts to the context, potentially offering a better balance between the two key metrics of the unlearning benchmark. By making the intervention strength proportional to activation, we align the unlearning mechanism with the natural properties of neural representations, which may lead to more precise knowledge removal.",
        "Implementation_Plan": "1. Keep the existing CustomSAE implementation unchanged\n2. Modify the unlearning evaluation function in `evals/unlearning/main.py`:\n   a. Locate the clamping intervention code (likely in a function like `apply_intervention` or similar)\n   b. Replace the fixed negative clamping logic:\n      FROM: `activations[mask] = -multiplier`\n      TO: `activations[mask] = -alpha * activations[mask]`\n   c. Rename the `multiplier` parameter to `alpha` throughout the code\n   d. Update documentation to reflect the new parameter meaning\n3. Update the hyperparameter sweep in the evaluation function:\n   a. Use a logarithmic range for alpha values: [0.5, 1.0, 2.0, 5.0, 10.0]\n   b. This range covers both gentler and stronger interventions than the fixed approach\n4. Run the evaluation with both methods for comparison:\n   a. Baseline fixed clamping (using original code)\n   b. Graduated clamping (using modified code)\n5. Analyze results to determine:\n   a. Optimal alpha value for graduated clamping\n   b. Comparison of best performance between methods\n   c. Impact on both WMDP-bio and MMLU accuracy\n6. Implement additional analysis to validate assumptions:\n   a. Measure average activation strengths of selected features on WMDP-bio vs. MMLU questions\n   b. Compare activation distributions to verify if features do activate more strongly on relevant content\n   c. Analyze cases where graduated clamping performs better or worse than fixed clamping\n7. Create visualizations to illustrate:\n   a. Relationship between alpha values and both accuracy metrics\n   b. Activation distributions before and after intervention\n   c. Comparison of intervention effects between methods",
        "novel": true
    },
    {
        "Name": "differential_supporting_features",
        "Title": "Differential Supporting Feature Detection for Enhanced Knowledge Unlearning in Sparse Autoencoders",
        "Experiment": "1. Identify primary candidates - features with highest sparsity on forget dataset but below threshold on retain dataset\n2. Compute co-activation statistics between all features and primary candidates on both forget and retain datasets\n3. Calculate differential co-activation scores that measure how differently features co-activate with primary candidates across datasets\n4. Select supporting features that have high differential co-activation scores while maintaining low retain dataset sparsity\n5. Compare unlearning performance using primary candidates alone versus primary plus supporting features\n6. Perform cross-validation to verify robustness of the approach\n7. Analyze characteristics of selected supporting features",
        "Technical_Details": "Differential Supporting Feature Detection identifies features that selectively co-activate with dangerous knowledge features in specific contexts. The method works as follows:\n\n1. Primary candidate selection: Select the top-m features with highest sparsity on forget dataset that also have retain dataset sparsity below retain_threshold. These are the primary candidates P = {p_1, p_2, ..., p_m}.\n\n2. Binary activation vectors: For each sample in both forget and retain datasets, compute binary activation vector a where a_i = 1 if feature i activates above threshold \u03c4, otherwise 0.\n\n3. Co-activation with primary candidates: For each feature i not in P, compute:\n   - forget_co_score(i) = (1/|P|) * sum(freq(i activates when p_j activates) in forget dataset for all p_j in P)\n   - retain_co_score(i) = (1/|P|) * sum(freq(i activates when p_j activates) in retain dataset for all p_j in P)\n\n4. Differential co-activation score: diff_co_score(i) = forget_co_score(i) - retain_co_score(i)\n\n5. Supporting feature selection: Select the top-n features with highest diff_co_score that:\n   - Are not already in P\n   - Have retain dataset sparsity below retain_threshold\n   - Have diff_co_score > min_diff_threshold (typically 0.1)\n\n6. Expanded selection: The final selection is the union of P and S, containing up to m+n features in total.\n\nDuring inference, the standard clamping intervention is applied to all selected features. The approach introduces three main hyperparameters: m (number of primary candidates), n (number of supporting features), and min_diff_threshold (minimum differential co-activation score).\n\nTo validate the approach, we use k-fold cross-validation on the forget dataset, verifying that selected supporting features consistently improve unlearning performance across different subsets of the data.",
        "Rationale": "The unlearning benchmark evaluates how effectively we can remove dangerous knowledge while preserving general capabilities. The current approach selects features based solely on individual sparsity patterns, which may miss important aspects of how knowledge is represented in neural networks.\n\nNeural networks often represent complex concepts through distributed patterns of activation across multiple features. Some features may directly encode specific dangerous concepts (primary candidates), while others may play supporting roles - they help represent dangerous knowledge in specific contexts but may also participate in representing general knowledge in other contexts.\n\nThe key insight of Differential Supporting Feature Detection is that truly knowledge-specific supporting features should co-activate with primary candidates differently across datasets. A feature that frequently co-activates with primary candidates on both datasets is likely encoding general information, while one that co-activates primarily on the forget dataset is more likely to be specifically involved in representing dangerous knowledge.\n\nFor example, consider a primary feature encoding \"biological weapon\". A supporting feature encoding \"delivery mechanism\" might co-activate with it when discussing dangerous biology topics but rarely co-activate in general text. In contrast, a feature encoding \"scientific research\" might co-activate with the primary feature in both dangerous and general contexts, making it less specific to dangerous knowledge.\n\nThis approach improves unlearning through these mechanisms:\n\n1. More precise knowledge targeting: By identifying features that differentially support dangerous knowledge representation, we can more specifically target the knowledge we want to remove while minimizing impact on general capabilities.\n\n2. Reduced false positives: The differential co-activation score helps distinguish between features that are specific to dangerous knowledge contexts and those that are used more generally, reducing the risk of selecting features important for general capabilities.\n\n3. Validation through cross-validation: By verifying that selected supporting features consistently improve unlearning performance across different data subsets, we increase confidence that the approach is capturing meaningful patterns rather than dataset-specific quirks.\n\nLimitations and considerations:\n- The effectiveness depends on the assumption that dangerous knowledge is represented partly through consistent co-activation patterns, which may not always be true.\n- The optimal hyperparameter values may vary across different models and datasets, though the cross-validation step helps address this.\n- The approach adds computational overhead during feature selection, though the inference-time intervention remains unchanged.\n\nDespite these limitations, Differential Supporting Feature Detection offers a principled way to enhance feature selection by considering how features work together to represent knowledge in different contexts. This approach maintains compatibility with the existing clamping intervention while potentially improving its precision in targeting dangerous knowledge.",
        "Implementation_Plan": "1. Use the existing CustomSAE implementation without modifications\n2. Create a DifferentialSupportingFeatureDetector class with methods:\n   - collect_binary_activations(sae, dataset, threshold, batch_size=32)\n   - select_primary_candidates(sparsity_forget, sparsity_retain, m, retain_threshold)\n   - compute_coactivation_scores(binary_activations, primary_candidates)\n   - compute_differential_scores(forget_co_scores, retain_co_scores)\n   - select_supporting_features(diff_co_scores, sparsity_retain, n, primary_candidates, min_diff_threshold, retain_threshold)\n   - get_expanded_selection(primary_candidates, supporting_features)\n   - validate_selection(sae, forget_dataset, retain_dataset, primary_candidates, supporting_features, k_folds=5)\n3. Modify the unlearning evaluation pipeline to:\n   - Collect binary activations on WMDP-bio and WikiText datasets\n   - Compute sparsity statistics for all features on both datasets\n   - Select primary candidates based on sparsity contrast\n   - Compute co-activation scores with primary candidates on both datasets\n   - Calculate differential co-activation scores\n   - Select supporting features based on differential scores and sparsity constraints\n   - Validate selection using cross-validation\n   - Create expanded selection set (primary + supporting)\n   - Apply standard clamping intervention to expanded selection\n4. Implement efficient computation:\n   - Use vectorized operations for computing statistics\n   - Process datasets in batches to manage memory usage\n   - Implement early stopping in cross-validation if results are consistent\n5. Add logging to record:\n   - Primary candidates and their sparsity values\n   - Supporting features and their differential co-activation scores\n   - Cross-validation results\n   - Performance metrics with and without supporting features\n6. Compare performance against baseline selection method\n7. Analyze selected features:\n   - Examine activation patterns of supporting features\n   - Compare characteristics of primary versus supporting features\n   - Identify any patterns in how supporting features complement primary candidates",
        "novel": true
    }
]