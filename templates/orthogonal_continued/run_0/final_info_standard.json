{
  "scr and tpp evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "88e96fee-c5d3-4b15-b62c-29dcb732617d",
    "datetime_epoch_millis": 1738265246728,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.024986714927972265,
        "scr_metric_threshold_2": 0.043177525387746135,
        "scr_dir2_threshold_2": 0.03614451488393293,
        "scr_dir1_threshold_5": -0.027872434927972194,
        "scr_metric_threshold_5": 0.0498206383435329,
        "scr_dir2_threshold_5": 0.04332413350395067,
        "scr_dir1_threshold_10": -0.07679448697169464,
        "scr_metric_threshold_10": 0.046435468185911946,
        "scr_dir2_threshold_10": 0.03922618427139585,
        "scr_dir1_threshold_20": -0.08163246728835066,
        "scr_metric_threshold_20": 0.05054452921164445,
        "scr_dir2_threshold_20": 0.0492876194916143,
        "scr_dir1_threshold_50": -0.2075173334645364,
        "scr_metric_threshold_50": 0.06036789689420945,
        "scr_dir2_threshold_50": 0.05047621256547952,
        "scr_dir1_threshold_100": -0.30730415313533227,
        "scr_metric_threshold_100": 0.03447109483181842,
        "scr_dir2_threshold_100": 0.024344380456222475,
        "scr_dir1_threshold_500": -0.29790819886806863,
        "scr_metric_threshold_500": 0.03959443079463576,
        "scr_dir2_threshold_500": 0.02714555176056758
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.015624810824956856,
        "scr_metric_threshold_2": 0.009828028179079856,
        "scr_dir2_threshold_2": 0.009828028179079856,
        "scr_dir1_threshold_5": -0.23437588766751014,
        "scr_metric_threshold_5": 0.03439802540241183,
        "scr_dir2_threshold_5": 0.03439802540241183,
        "scr_dir1_threshold_10": -0.18750052386935023,
        "scr_metric_threshold_10": 0.04422605358149169,
        "scr_dir2_threshold_10": 0.04422605358149169,
        "scr_dir1_threshold_20": -0.18750052386935023,
        "scr_metric_threshold_20": 0.08845210716298338,
        "scr_dir2_threshold_20": 0.08845210716298338,
        "scr_dir1_threshold_50": -0.8125013387772284,
        "scr_metric_threshold_50": 0.07862407898390353,
        "scr_dir2_threshold_50": 0.07862407898390353,
        "scr_dir1_threshold_100": -1.2968760622906268,
        "scr_metric_threshold_100": 0.13759224805838266,
        "scr_dir2_threshold_100": 0.13759224805838266,
        "scr_dir1_threshold_500": -1.2656264406407132,
        "scr_metric_threshold_500": 0.1597051284003932,
        "scr_dir2_threshold_500": 0.1597051284003932
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.02912584278375721,
        "scr_metric_threshold_2": 0.08882510185734234,
        "scr_dir2_threshold_2": 0.08882510185734234,
        "scr_dir1_threshold_5": -0.12621372145414522,
        "scr_metric_threshold_5": 0.08309451623569147,
        "scr_dir2_threshold_5": 0.08309451623569147,
        "scr_dir1_threshold_10": -0.4466020428771571,
        "scr_metric_threshold_10": 0.03151856249299773,
        "scr_dir2_threshold_10": 0.03151856249299773,
        "scr_dir1_threshold_20": -0.3592233571539762,
        "scr_metric_threshold_20": 0.03151856249299773,
        "scr_dir2_threshold_20": 0.03151856249299773,
        "scr_dir1_threshold_50": -0.3106797071617595,
        "scr_metric_threshold_50": 0.051575953742693734,
        "scr_dir2_threshold_50": 0.051575953742693734,
        "scr_dir1_threshold_100": -0.33980612863147136,
        "scr_metric_threshold_100": 0.06590258858377988,
        "scr_dir2_threshold_100": 0.06590258858377988,
        "scr_dir1_threshold_500": -0.2912624786392547,
        "scr_metric_threshold_500": 0.06303729577295444,
        "scr_dir2_threshold_500": 0.06303729577295444
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": -0.04761841688229979,
        "scr_metric_threshold_2": 0.0075949890455728015,
        "scr_dir2_threshold_2": 0.0075949890455728015,
        "scr_dir1_threshold_5": -0.1587299484845761,
        "scr_metric_threshold_5": 0.03291141800038962,
        "scr_dir2_threshold_5": 0.03291141800038962,
        "scr_dir1_threshold_10": -0.1111105854971546,
        "scr_metric_threshold_10": 0.06582283600077923,
        "scr_dir2_threshold_10": 0.06582283600077923,
        "scr_dir1_threshold_20": -0.2380949227268642,
        "scr_metric_threshold_20": 0.06582283600077923,
        "scr_dir2_threshold_20": 0.06582283600077923,
        "scr_dir1_threshold_50": -0.3333327025965855,
        "scr_metric_threshold_50": 0.07341782504635204,
        "scr_dir2_threshold_50": 0.07341782504635204,
        "scr_dir1_threshold_100": -0.7777769367954473,
        "scr_metric_threshold_100": 0.08354442680784264,
        "scr_dir2_threshold_100": 0.08354442680784264,
        "scr_dir1_threshold_500": -0.7777769367954473,
        "scr_metric_threshold_500": 0.09367087767151386,
        "scr_dir2_threshold_500": 0.09367087767151386
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": -0.015624796273220196,
        "scr_metric_threshold_2": 0.017804278163016753,
        "scr_dir2_threshold_2": 0.017804278163016753,
        "scr_dir1_threshold_5": 0.015625261934431176,
        "scr_metric_threshold_5": 0.044510518539166266,
        "scr_dir2_threshold_5": 0.044510518539166266,
        "scr_dir1_threshold_10": -0.062499650754091765,
        "scr_metric_threshold_10": 0.04747783927687718,
        "scr_dir2_threshold_10": 0.04747783927687718,
        "scr_dir1_threshold_20": -0.05468725261748167,
        "scr_metric_threshold_20": 0.044510518539166266,
        "scr_dir2_threshold_20": 0.044510518539166266,
        "scr_dir1_threshold_50": -0.17968748544808716,
        "scr_metric_threshold_50": 0.07121675891531577,
        "scr_dir2_threshold_50": 0.07121675891531577,
        "scr_dir1_threshold_100": -0.17187462165026607,
        "scr_metric_threshold_100": 0.05934729909609648,
        "scr_dir2_threshold_100": 0.05934729909609648,
        "scr_dir1_threshold_500": -0.16406222351365599,
        "scr_metric_threshold_500": 0.0623146198338074,
        "scr_dir2_threshold_500": 0.0623146198338074
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.08743153202478901,
        "scr_metric_threshold_2": 0.04313739148158649,
        "scr_dir2_threshold_2": 0.04313739148158649,
        "scr_dir1_threshold_5": 0.08743153202478901,
        "scr_metric_threshold_5": 0.09019606651502937,
        "scr_dir2_threshold_5": 0.09019606651502937,
        "scr_dir1_threshold_10": 0.1092894964580841,
        "scr_metric_threshold_10": 0.07843151462849601,
        "scr_dir2_threshold_10": 0.07843151462849601,
        "scr_dir1_threshold_20": 0.1311474608913792,
        "scr_metric_threshold_20": 0.07450976358933016,
        "scr_dir2_threshold_20": 0.07450976358933016,
        "scr_dir1_threshold_50": -0.03278678379574697,
        "scr_metric_threshold_50": 0.13333345799661586,
        "scr_dir2_threshold_50": 0.13333345799661586,
        "scr_dir1_threshold_100": 0.1092894964580841,
        "scr_metric_threshold_100": -0.07450976358933016,
        "scr_dir2_threshold_100": -0.07450976358933016,
        "scr_dir1_threshold_500": 0.08743153202478901,
        "scr_metric_threshold_500": -0.07058824629381905,
        "scr_dir2_threshold_500": -0.07058824629381905
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.025641002128344394,
        "scr_metric_threshold_2": 0.10887099681547797,
        "scr_dir2_threshold_2": 0.10887099681547797,
        "scr_dir1_threshold_5": 0.020512557170790546,
        "scr_metric_threshold_5": 0.04838718980952953,
        "scr_dir2_threshold_5": 0.04838718980952953,
        "scr_dir1_threshold_10": -0.0666667277996379,
        "scr_metric_threshold_10": 0.056451601273808806,
        "scr_dir2_threshold_10": 0.056451601273808806,
        "scr_dir1_threshold_20": 0.025641002128344394,
        "scr_metric_threshold_20": 0.056451601273808806,
        "scr_dir2_threshold_20": 0.056451601273808806,
        "scr_dir1_threshold_50": 0.020512557170790546,
        "scr_metric_threshold_50": -0.012096617196418915,
        "scr_dir2_threshold_50": -0.012096617196418915,
        "scr_dir1_threshold_100": 0.05641014354938642,
        "scr_metric_threshold_100": -0.05241939554166917,
        "scr_dir2_threshold_100": -0.05241939554166917,
        "scr_dir1_threshold_500": 0.06153828284208406,
        "scr_metric_threshold_500": -0.056451601273808806,
        "scr_dir2_threshold_500": -0.056451601273808806
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.053811503376215715,
        "scr_metric_threshold_2": 0.017857176118657926,
        "scr_dir2_threshold_2": 0.017857176118657926,
        "scr_dir1_threshold_5": 0.12556053092505612,
        "scr_metric_threshold_5": 0.017857176118657926,
        "scr_dir2_threshold_5": 0.017857176118657926,
        "scr_dir1_threshold_10": 0.11210752143829489,
        "scr_metric_threshold_10": 0.008928721105389243,
        "scr_dir2_threshold_10": 0.008928721105389243,
        "scr_dir1_threshold_20": -0.008968762086312341,
        "scr_metric_threshold_20": 0.0044642275066343415,
        "scr_dir2_threshold_20": 0.0044642275066343415,
        "scr_dir1_threshold_50": -0.0717490275488404,
        "scr_metric_threshold_50": 0.02678589722404717,
        "scr_dir2_threshold_50": 0.02678589722404717,
        "scr_dir1_threshold_100": -0.08071752234973815,
        "scr_metric_threshold_100": 0.013392948612023585,
        "scr_dir2_threshold_100": 0.013392948612023585,
        "scr_dir1_threshold_500": -0.08071752234973815,
        "scr_metric_threshold_500": 0.017857176118657926,
        "scr_dir2_threshold_500": 0.017857176118657926
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.05150224144123495,
        "scr_metric_threshold_2": 0.05150224144123495,
        "scr_dir2_threshold_2": -0.004761842589270712,
        "scr_dir1_threshold_5": 0.047210196127387125,
        "scr_metric_threshold_5": 0.047210196127387125,
        "scr_dir2_threshold_5": -0.004761842589270712,
        "scr_dir1_threshold_10": 0.03862661712745569,
        "scr_metric_threshold_10": 0.03862661712745569,
        "scr_dir2_threshold_10": -0.019047654188673074,
        "scr_dir1_threshold_20": 0.03862661712745569,
        "scr_metric_threshold_20": 0.03862661712745569,
        "scr_dir2_threshold_20": 0.0285713393672145,
        "scr_dir1_threshold_50": 0.060085820441166386,
        "scr_metric_threshold_50": 0.060085820441166386,
        "scr_dir2_threshold_50": -0.019047654188673074,
        "scr_dir1_threshold_100": 0.042918406627421406,
        "scr_metric_threshold_100": 0.042918406627421406,
        "scr_dir2_threshold_100": -0.03809530837734615,
        "scr_dir1_threshold_500": 0.047210196127387125,
        "scr_metric_threshold_500": 0.047210196127387125,
        "scr_dir2_threshold_500": -0.05238083614515829
      }
    ],
    "sae_bench_commit_hash": "1c64f65e68c0e3cdaf116a205182859fd51f77f7",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "Custom",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "47ec66f1-cfac-489c-ae4d-518b86f5565f",
    "datetime_epoch_millis": 1738266791518,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.9499875,
        "llm_top_1_test_accuracy": 0.6543625,
        "llm_top_2_test_accuracy": 0.71773125,
        "llm_top_5_test_accuracy": 0.7809625,
        "llm_top_10_test_accuracy": 0.8308812499999999,
        "llm_top_20_test_accuracy": 0.87641875,
        "llm_top_50_test_accuracy": 0.9223499999999999,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.8769375406205654,
        "sae_top_1_test_accuracy": 0.62393125,
        "sae_top_2_test_accuracy": 0.6743937500000001,
        "sae_top_5_test_accuracy": 0.7260875,
        "sae_top_10_test_accuracy": 0.7787999999999999,
        "sae_top_20_test_accuracy": 0.82108125,
        "sae_top_50_test_accuracy": 0.86705625,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.906600046157837,
        "sae_top_1_test_accuracy": 0.6292,
        "sae_top_2_test_accuracy": 0.6846,
        "sae_top_5_test_accuracy": 0.705,
        "sae_top_10_test_accuracy": 0.7652,
        "sae_top_20_test_accuracy": 0.8523999999999999,
        "sae_top_50_test_accuracy": 0.9077999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9489999999999998,
        "llm_top_1_test_accuracy": 0.6728,
        "llm_top_2_test_accuracy": 0.7150000000000001,
        "llm_top_5_test_accuracy": 0.7615999999999999,
        "llm_top_10_test_accuracy": 0.807,
        "llm_top_20_test_accuracy": 0.8638,
        "llm_top_50_test_accuracy": 0.909,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.8836000323295593,
        "sae_top_1_test_accuracy": 0.6686,
        "sae_top_2_test_accuracy": 0.7066000000000001,
        "sae_top_5_test_accuracy": 0.7623999999999999,
        "sae_top_10_test_accuracy": 0.7846,
        "sae_top_20_test_accuracy": 0.8274000000000001,
        "sae_top_50_test_accuracy": 0.868,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9156000000000001,
        "llm_top_1_test_accuracy": 0.689,
        "llm_top_2_test_accuracy": 0.7362,
        "llm_top_5_test_accuracy": 0.7598,
        "llm_top_10_test_accuracy": 0.7974,
        "llm_top_20_test_accuracy": 0.8460000000000001,
        "llm_top_50_test_accuracy": 0.889,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.8686000347137451,
        "sae_top_1_test_accuracy": 0.6617999999999998,
        "sae_top_2_test_accuracy": 0.72,
        "sae_top_5_test_accuracy": 0.7556,
        "sae_top_10_test_accuracy": 0.7766,
        "sae_top_20_test_accuracy": 0.8276,
        "sae_top_50_test_accuracy": 0.8591999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.8942,
        "llm_top_1_test_accuracy": 0.6083999999999999,
        "llm_top_2_test_accuracy": 0.6397999999999999,
        "llm_top_5_test_accuracy": 0.6768000000000001,
        "llm_top_10_test_accuracy": 0.7484,
        "llm_top_20_test_accuracy": 0.8076000000000001,
        "llm_top_50_test_accuracy": 0.8632,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.7710000395774841,
        "sae_top_1_test_accuracy": 0.5630000000000001,
        "sae_top_2_test_accuracy": 0.585,
        "sae_top_5_test_accuracy": 0.6176,
        "sae_top_10_test_accuracy": 0.6784,
        "sae_top_20_test_accuracy": 0.7091999999999999,
        "sae_top_50_test_accuracy": 0.7696,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.981,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.847,
        "llm_top_50_test_accuracy": 0.933,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.8995000422000885,
        "sae_top_1_test_accuracy": 0.635,
        "sae_top_2_test_accuracy": 0.701,
        "sae_top_5_test_accuracy": 0.72,
        "sae_top_10_test_accuracy": 0.84,
        "sae_top_20_test_accuracy": 0.852,
        "sae_top_50_test_accuracy": 0.889,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9638,
        "llm_top_1_test_accuracy": 0.661,
        "llm_top_2_test_accuracy": 0.6996,
        "llm_top_5_test_accuracy": 0.7575999999999999,
        "llm_top_10_test_accuracy": 0.806,
        "llm_top_20_test_accuracy": 0.869,
        "llm_top_50_test_accuracy": 0.9282,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.8808000445365906,
        "sae_top_1_test_accuracy": 0.6106,
        "sae_top_2_test_accuracy": 0.6536,
        "sae_top_5_test_accuracy": 0.706,
        "sae_top_10_test_accuracy": 0.7878000000000001,
        "sae_top_20_test_accuracy": 0.8166,
        "sae_top_50_test_accuracy": 0.8632,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.9375,
        "llm_top_1_test_accuracy": 0.6415,
        "llm_top_2_test_accuracy": 0.75425,
        "llm_top_5_test_accuracy": 0.8245,
        "llm_top_10_test_accuracy": 0.86925,
        "llm_top_20_test_accuracy": 0.8917499999999999,
        "llm_top_50_test_accuracy": 0.922,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.8860000371932983,
        "sae_top_1_test_accuracy": 0.60825,
        "sae_top_2_test_accuracy": 0.6637500000000001,
        "sae_top_5_test_accuracy": 0.7844999999999999,
        "sae_top_10_test_accuracy": 0.8029999999999999,
        "sae_top_20_test_accuracy": 0.83725,
        "sae_top_50_test_accuracy": 0.8792500000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9992000000000001,
        "llm_top_1_test_accuracy": 0.648,
        "llm_top_2_test_accuracy": 0.7814,
        "llm_top_5_test_accuracy": 0.9102,
        "llm_top_10_test_accuracy": 0.9593999999999999,
        "llm_top_20_test_accuracy": 0.99,
        "llm_top_50_test_accuracy": 0.9959999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9194000482559204,
        "sae_top_1_test_accuracy": 0.615,
        "sae_top_2_test_accuracy": 0.6806,
        "sae_top_5_test_accuracy": 0.7575999999999999,
        "sae_top_10_test_accuracy": 0.7948000000000001,
        "sae_top_20_test_accuracy": 0.8462,
        "sae_top_50_test_accuracy": 0.9004,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "1c64f65e68c0e3cdaf116a205182859fd51f77f7",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "Custom",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "unlearning evaluation results": {
    "eval_type_id": "unlearning",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "wmdp-bio",
        "high_school_us_history",
        "college_computer_science",
        "high_school_geography",
        "human_aging"
      ],
      "intervention_method": "clamp_feature_activation",
      "retain_thresholds": [
        0.001,
        0.005,
        0.01,
        0.02
      ],
      "n_features_list": [
        10,
        100,
        1000
      ],
      "multipliers": [
        10,
        25,
        50,
        100,
        200
      ],
      "dataset_size": 1024,
      "seq_len": 1024,
      "n_batch_loss_added": 50,
      "target_metric": "correct",
      "save_metrics": true,
      "model_name": "google/gemma-2-2b-it",
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16"
    },
    "eval_id": "1082bce9-016e-4812-a308-6cc35a564822",
    "datetime_epoch_millis": 1738184748213,
    "eval_result_metrics": {
      "unlearning": {
        "unlearning_score": 0.02808988094329834
      }
    },
    "eval_result_details": [],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 65536,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "JumpReLU",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "jumprelu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null,
      "jump_coeff": 0.1
    },
    "eval_result_unstructured": null
  },
  "training results for layer 12": {
    "config": {
      "trainer_class": "CustomTrainer",
      "activation_dim": 2304,
      "dict_size": 18432,
      "lr": 0.0009,
      "l1_penalty": 0.04,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "CustomTrainer",
      "submodule_name": "resid_post_layer_12"
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 100.08680725097656,
      "layer": 12,
      "dict_size": 18432,
      "learning_rate": 0.0009,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "ad2d746a-a110-461e-ad6d-ddcf9b6276e5",
    "datetime_epoch_millis": 1738262973106,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.006518148628764265,
        "mean_num_split_features": 1.04
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.0003897116134060795,
        "num_absorption": 1,
        "num_probe_true_positives": 2566,
        "num_split_features": 1
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.03848620910840282,
        "num_absorption": 60,
        "num_probe_true_positives": 1559,
        "num_split_features": 1
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 2834,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1648,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.043151969981238276,
        "num_absorption": 69,
        "num_probe_true_positives": 1599,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1196,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.0027397260273972603,
        "num_absorption": 3,
        "num_probe_true_positives": 1095,
        "num_split_features": 1
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.005065856129685917,
        "num_absorption": 5,
        "num_probe_true_positives": 987,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.005389221556886228,
        "num_absorption": 9,
        "num_probe_true_positives": 1670,
        "num_split_features": 2
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.015317286652078774,
        "num_absorption": 7,
        "num_probe_true_positives": 457,
        "num_split_features": 1
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 718,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1137,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1869,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.001128668171557562,
        "num_absorption": 1,
        "num_probe_true_positives": 886,
        "num_split_features": 1
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.014605647517039922,
        "num_absorption": 15,
        "num_probe_true_positives": 1027,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 2280,
        "num_split_features": 1
      },
      {
        "first_letter": "q",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 178,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.0047789725209080045,
        "num_absorption": 8,
        "num_probe_true_positives": 1674,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 2926,
        "num_split_features": 1
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.0036036036036036037,
        "num_absorption": 6,
        "num_probe_true_positives": 1665,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 727,
        "num_split_features": 1
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 828,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.019287833827893175,
        "num_absorption": 13,
        "num_probe_true_positives": 674,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 149,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.009009009009009009,
        "num_absorption": 2,
        "num_probe_true_positives": 222,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "1c64f65e68c0e3cdaf116a205182859fd51f77f7",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "Custom",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.7204968944099379,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 2.8125
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.7138157894736842,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 5.65625,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.29296875,
        "mse": 4.4375,
        "cossim": 0.76171875
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 107.0,
        "l2_ratio": 0.70703125,
        "relative_reconstruction_bias": 0.9453125
      },
      "sparsity": {
        "l0": 48.87746810913086,
        "l1": 209.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  }
}