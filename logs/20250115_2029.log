Using GPUs: [0]
Using Anthropic API with model claude-3-5-sonnet-20241022.

Generating idea 1/5
Iteration 1/3
{'Name': 'feature_decomposition_sae', 'Title': 'Feature Decomposition Sparse Autoencoders: Learning Atomic Features Through Hierarchical Decomposition', 'Experiment': '1. Implement feature decomposition loss:\n   - Add auxiliary network to predict features from combinations of other features\n   - Compute decomposition scores for each feature\n   - Add penalty term to loss function\n2. Modify SAE training loop:\n   - Alternate between standard reconstruction and decomposition phases\n   - Track feature decomposition scores during training\n3. Train on GPT-2 and Gemma activations with varying hyperparameters\n4. Evaluate using:\n   - Standard metrics (reconstruction, sparsity)\n   - New atomicity metrics based on feature decomposition scores\n   - Human evaluation of feature interpretability\n5. Ablation studies on decomposition mechanisms', 'Technical_Details': "The Feature Decomposition SAE introduces an auxiliary decomposition network D that takes as input all feature activations except feature i and attempts to predict feature i's activation. For each feature i, we compute a decomposition score s_i = ||D(h_{\\i}) - h_i||_2 where h_{\\i} represents all features except i. Features with low decomposition scores (easily predicted from other features) are penalized during training. The loss function becomes: L = L_reconstruction + λ_1 L_sparsity + λ_2 L_decomposition, where L_decomposition = -Σ_i log(s_i). The decomposition network D is implemented as a small MLP trained jointly with the main SAE. Training alternates between standard SAE updates and decomposition network updates. Feature combinations are explored using both linear and non-linear mechanisms.", 'Research_Impact': "A critical challenge in mechanistic interpretability is ensuring that learned features correspond to fundamental computational elements rather than arbitrary combinations. Current SAEs often learn entangled features that combine multiple concepts, making it difficult to identify the true computational basis of the model. FD-SAE addresses this by explicitly optimizing for atomic features through the decomposition mechanism. This provides a principled way to learn interpretable features that better reflect the model's actual computational elements, potentially enabling more accurate circuit analysis and understanding of model behavior. The method could significantly improve our ability to reverse-engineer neural networks by ensuring we identify truly fundamental computational units.", 'Interestingness': 9, 'Feasibility': 7, 'Novelty': 8}
Iteration 2/3
{'Name': 'feature_decomposition_sae', 'Title': 'Feature Decomposition Sparse Autoencoders: Learning Atomic Features Through Linear Decomposition', 'Experiment': '1. Implement linear feature decomposition:\n   - Compute pairwise feature similarity matrix\n   - For each feature, find best linear combination of other features\n   - Calculate decomposition scores using reconstruction error\n2. Modify SAE training:\n   - Add decomposition penalty to loss function\n   - Implement curriculum for penalty weight\n   - Track feature atomicity metrics\n3. Evaluate on synthetic data with known atomic features\n4. Train on GPT-2 and Gemma activations\n5. Analyze results using:\n   - Reconstruction quality vs sparsity\n   - Feature atomicity metrics:\n     * Linear independence score\n     * Minimal basis size\n     * Feature stability across runs\n6. Compare against PCA and ICA baselines', 'Technical_Details': 'The Feature Decomposition SAE uses linear decomposition to encourage atomic features. For each feature vector w_i in the decoder weight matrix W, we compute a decomposition score: s_i = min_{α} ||w_i - Σ_{j≠i} α_j w_j||_2 where α are constrained to be sparse. Features with low decomposition scores (easily approximated by others) receive higher penalties. The loss function is: L = L_reconstruction + λ_1 L_sparsity + λ_2(t) L_decomposition, where λ_2(t) follows a curriculum schedule increasing from 0. L_decomposition = Σ_i exp(-β s_i). The linear decomposition problem is solved efficiently using LASSO regression. We also implement feature pruning where highly composite features are periodically removed and reinitialized.', 'Research_Impact': "A key challenge in mechanistic interpretability is identifying the fundamental computational elements in neural networks rather than arbitrary combinations of them. Current SAEs can learn redundant or composite features that obscure the true computational basis. This research addresses this by explicitly optimizing for atomic features through linear decomposition, providing a principled way to learn minimal, non-redundant feature sets. The method's focus on linear decomposition makes it particularly suitable for understanding linear combinations in residual stream activations, a common pattern in transformer architectures. This could significantly improve our ability to identify and understand the basic computational elements in large language models.", 'Interestingness': 9, 'Feasibility': 8, 'Novelty': 8}
Iteration 3/3
{'Name': 'feature_decomposition_sae', 'Title': 'Feature Decomposition Sparse Autoencoders: Learning Atomic Features Through Linear Decomposition', 'Experiment': '1. Implement linear feature decomposition:\n   - Compute pairwise feature similarity matrix\n   - For each feature, find best linear combination of other features\n   - Calculate decomposition scores using reconstruction error\n2. Modify SAE training:\n   - Add decomposition penalty to loss function\n   - Implement curriculum for penalty weight\n   - Track feature atomicity metrics\n3. Evaluate on synthetic data with known atomic features\n4. Train on GPT-2 and Gemma activations\n5. Analyze results using:\n   - Reconstruction quality vs sparsity\n   - Feature atomicity metrics:\n     * Linear independence score\n     * Minimal basis size\n     * Feature stability across runs\n6. Compare against PCA and ICA baselines', 'Technical_Details': 'The Feature Decomposition SAE uses linear decomposition to encourage atomic features. For each feature vector w_i in the decoder weight matrix W, we compute a decomposition score: s_i = min_{α} ||w_i - Σ_{j≠i} α_j w_j||_2 where α are constrained to be sparse. Features with low decomposition scores (easily approximated by others) receive higher penalties. The loss function is: L = L_reconstruction + λ_1 L_sparsity + λ_2(t) L_decomposition, where λ_2(t) follows a curriculum schedule increasing from 0. L_decomposition = Σ_i exp(-β s_i). The linear decomposition problem is solved efficiently using LASSO regression. We also implement feature pruning where highly composite features are periodically removed and reinitialized.', 'Research_Impact': "A key challenge in mechanistic interpretability is identifying the fundamental computational elements in neural networks rather than arbitrary combinations of them. Current SAEs can learn redundant or composite features that obscure the true computational basis. This research addresses this by explicitly optimizing for atomic features through linear decomposition, providing a principled way to learn minimal, non-redundant feature sets. The method's focus on linear decomposition makes it particularly suitable for understanding linear combinations in residual stream activations, a common pattern in transformer architectures. This could significantly improve our ability to identify and understand the basic computational elements in large language models.", 'Interestingness': 9, 'Feasibility': 8, 'Novelty': 8}
Idea generation converged after 3 iterations.

Generating idea 2/5
Iteration 1/3
{'Name': 'temporal_sae', 'Title': 'Temporal Sparse Autoencoders: Learning Interpretable Sequential Features in Language Models', 'Experiment': '1. Implement temporal attention layer:\n   - Add relative positional embeddings\n   - Implement causal masking\n   - Add temporal context buffer\n2. Modify SAE architecture:\n   - Add temporal attention before encoding\n   - Implement temporal consistency loss\n3. Train on GPT-2 and Gemma activations\n4. Evaluate using:\n   - Standard reconstruction metrics\n   - Temporal consistency scores\n   - Sequential probing tasks\n   - Unlearning benchmark performance\n5. Analyze learned features:\n   - Temporal attention patterns\n   - Feature activation sequences\n   - Context tracking capabilities', 'Technical_Details': 'The Temporal SAE architecture adds a temporal attention layer before the encoder. For each position t, features attend to activations from positions [t-k, t] using scaled dot-product attention with learned relative position embeddings. The attention outputs are combined with the current activations using a gating mechanism. The temporal consistency loss L_temp = E[||f(x_t) - f(x_{t+1})||_2] is added for semantically similar consecutive tokens x_t, x_{t+1}. The loss is weighted by cosine similarity between input activations to avoid enforcing consistency between unrelated tokens. The total loss is L = L_reconstruction + λ_1 L_sparsity + λ_2 L_temporal. We use a circular buffer to cache previous activations and attention patterns. The causal masking ensures features only attend to past and present activations, maintaining the autoregressive property.', 'Research_Impact': 'A major challenge in mechanistic interpretability is understanding how language models process and maintain sequential information across time steps. Current SAEs, by treating each position independently, struggle to capture temporal dependencies and context tracking mechanisms. This research directly addresses this by introducing explicit temporal modeling into SAEs. The temporal attention mechanism allows features to specialize in tracking specific types of sequential patterns (e.g., matching brackets, subject-verb agreement), while the temporal consistency loss helps identify stable features across related contexts. This is particularly valuable for the unlearning benchmark, as it enables more precise targeting of knowledge that manifests across multiple time steps. The approach could significantly improve our ability to interpret how language models process sequential information and maintain context.', 'Interestingness': 9, 'Feasibility': 6, 'Novelty': 8}