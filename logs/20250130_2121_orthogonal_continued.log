Using GPUs: [0]
Using Anthropic API with model claude-3-5-sonnet-20241022.
Using OpenAI API with deepseek-reasoner.

Generating idea 1/1
Iteration 1/15
!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

THOUGHT:
Based on the experiment logs, I notice that Run 4 achieved the best performance with an optimal dictionary size of 18432 and orthogonality weight of 0.075. However, there's room for improvement in how we apply the orthogonality constraints. The current approach treats all feature competition equally, but the logs suggest that some feature competitions are more detrimental to interpretability than others.

I propose refining the sparsity-guided orthogonality by introducing an adaptive threshold mechanism. Instead of using fixed competition coefficients, we can dynamically adjust the orthogonality weight based on the frequency and magnitude of feature co-activations. This maintains the core idea of using sparsity patterns to guide orthogonality but adds a more nuanced approach to handling feature competition.

This refinement doesn't introduce significant complexity - it simply makes better use of information we already have from the top-k activations. The key insight is that frequent co-activation with high magnitudes likely indicates problematic feature competition, while occasional co-activation might represent legitimate feature sharing that shouldn't be penalized as heavily.

NEW IDEA JSON:
```json
{
    "Name": "adaptive_sparse_orthogonal_sae",
    "Title": "Adaptive Sparsity-Guided Orthogonality for Improved Feature Separation",
    "Experiment": "1. Modify mask intersection computation to track co-activation frequencies and magnitudes\n2. Implement adaptive thresholding for competition coefficients\n3. Train with optimal dictionary size (18432) on gemma-2-2b\n4. Compare against fixed orthogonality baseline\n5. Analyze feature competition reduction patterns",
    "Technical_Details": "The method enhances sparsity-guided orthogonality by introducing adaptive competition coefficients: c_(ij) = sigmoid(α * f_(ij) * m_(ij)) where f_(ij) is the normalized co-activation frequency and m_(ij) is the mean product of activation magnitudes for features i and j. The sigmoid scaling ensures smooth transitions while α controls adaptation sensitivity. The loss remains L = L_recon + λ_1 * L_sparse + λ_2 * Σ_(i,j) c_(ij) * |f_i^T f_j| but with dynamically adjusted c_(ij).",
    "Implementation_Plan": "1. Add functions to track co-activation statistics in compute_mask_intersections\n2. Implement adaptive coefficient computation\n3. Modify orthogonality loss calculation\n4. Add configuration for adaptation sensitivity\n5. Update training loop to maintain co-activation statistics\n6. Add evaluation metrics for adaptive thresholding effectiveness",
    "Interestingness_Evaluation": "The adaptive mechanism provides a principled way to distinguish between problematic and benign feature interactions while maintaining the elegant connection between sparsity and orthogonality.",
    "Interestingness": 8,
    "Feasibility_Evaluation": "Implementation requires only minor modifications to existing code; uses standard operations; computation overhead is minimal since we already track activations; easily fits within 30-minute limit on H100; can be implemented by a junior PhD student in 1-2 weeks.",
    "Feasibility": 9,
    "Novelty_Evaluation": "While building on existing sparsity-guided orthogonality, the adaptive thresholding mechanism is a novel approach to handling feature competition.",
    "Novelty": 8,
    "Expected_Research_Impact": "The more nuanced treatment of feature competition should lead to better feature separation while preserving useful feature relationships, directly improving sparse probing and core metrics.",
    "Research_Impact": 9,
    "Overall_Score": 8.8,
    "Abstract": "We present an enhanced approach to feature disentanglement in sparse autoencoders using adaptive sparsity-guided orthogonality constraints. Building on recent work in using sparsity patterns to guide feature separation, we introduce a dynamic thresholding mechanism that adjusts orthogonality penalties based on the frequency and magnitude of feature co-activations. This allows the model to distinguish between problematic feature competition and legitimate feature sharing, potentially leading to more interpretable representations. Our method maintains computational efficiency by utilizing existing activation statistics and requires minimal modifications to standard sparse autoencoder architectures. We evaluate our approach on large language models and analyze its effectiveness in reducing feature competition while preserving useful feature relationships."
}
```
@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

{'Name': 'adaptive_sparse_orthogonal_sae', 'Title': 'Adaptive Sparsity-Guided Orthogonality for Improved Feature Separation', 'Experiment': '1. Modify mask intersection computation to track co-activation frequencies and magnitudes\n2. Implement adaptive thresholding for competition coefficients\n3. Train with optimal dictionary size (18432) on gemma-2-2b\n4. Compare against fixed orthogonality baseline\n5. Analyze feature competition reduction patterns', 'Technical_Details': 'The method enhances sparsity-guided orthogonality by introducing adaptive competition coefficients: c_(ij) = sigmoid(α * f_(ij) * m_(ij)) where f_(ij) is the normalized co-activation frequency and m_(ij) is the mean product of activation magnitudes for features i and j. The sigmoid scaling ensures smooth transitions while α controls adaptation sensitivity. The loss remains L = L_recon + λ_1 * L_sparse + λ_2 * Σ_(i,j) c_(ij) * |f_i^T f_j| but with dynamically adjusted c_(ij).', 'Implementation_Plan': '1. Add functions to track co-activation statistics in compute_mask_intersections\n2. Implement adaptive coefficient computation\n3. Modify orthogonality loss calculation\n4. Add configuration for adaptation sensitivity\n5. Update training loop to maintain co-activation statistics\n6. Add evaluation metrics for adaptive thresholding effectiveness', 'Interestingness_Evaluation': 'The adaptive mechanism provides a principled way to distinguish between problematic and benign feature interactions while maintaining the elegant connection between sparsity and orthogonality.', 'Interestingness': 8, 'Feasibility_Evaluation': 'Implementation requires only minor modifications to existing code; uses standard operations; computation overhead is minimal since we already track activations; easily fits within 30-minute limit on H100; can be implemented by a junior PhD student in 1-2 weeks.', 'Feasibility': 9, 'Novelty_Evaluation': 'While building on existing sparsity-guided orthogonality, the adaptive thresholding mechanism is a novel approach to handling feature competition.', 'Novelty': 8, 'Expected_Research_Impact': 'The more nuanced treatment of feature competition should lead to better feature separation while preserving useful feature relationships, directly improving sparse probing and core metrics.', 'Research_Impact': 9, 'Overall_Score': 8.8, 'Abstract': 'We present an enhanced approach to feature disentanglement in sparse autoencoders using adaptive sparsity-guided orthogonality constraints. Building on recent work in using sparsity patterns to guide feature separation, we introduce a dynamic thresholding mechanism that adjusts orthogonality penalties based on the frequency and magnitude of feature co-activations. This allows the model to distinguish between problematic feature competition and legitimate feature sharing, potentially leading to more interpretable representations. Our method maintains computational efficiency by utilizing existing activation statistics and requires minimal modifications to standard sparse autoencoder architectures. We evaluate our approach on large language models and analyze its effectiveness in reducing feature competition while preserving useful feature relationships.'}
Iteration 2/15
!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

THOUGHT:
Looking at my previous idea, while the adaptive thresholding mechanism is promising, it could be simplified further while maintaining its effectiveness. The key insight from the experiment logs is that Run 4's success came from finding the right balance between orthogonality and sparsity. Instead of tracking both frequency and magnitude of co-activations, we can focus solely on the frequency within each batch, which is more directly related to feature competition.

The modification I propose is to use a simpler, batch-wise adaptation mechanism that adjusts competition coefficients based only on the proportion of shared activations within each training batch. This maintains the core principle of sparsity-guided orthogonality while being more computationally efficient and easier to implement. It also aligns better with the original prototype idea's focus on using sparsity patterns directly.

This refinement reduces complexity while potentially improving effectiveness by focusing on the most relevant signal - how often features compete within the current context. The batch-wise approach also provides more immediate feedback during training, which could lead to better feature separation.

NEW IDEA JSON:
```json
{
    "Name": "batch_adaptive_orthogonal_sae",
    "Title": "Batch-Adaptive Orthogonality for Improved Feature Separation in Sparse Autoencoders",
    "Experiment": "1. Modify mask intersection computation to use batch-wise statistics\n2. Implement simplified competition coefficient calculation\n3. Train with optimal dictionary size (18432) on gemma-2-2b\n4. Compare against fixed orthogonality baseline\n5. Analyze feature competition patterns within batches",
    "Technical_Details": "The method simplifies adaptive orthogonality by using batch-wise competition coefficients: c_(ij) = n_(ij)/n_batch where n_(ij) is the count of shared activations between features i and j in the current batch, and n_batch is the batch size. The loss remains L = L_recon + λ_1 * L_sparse + λ_2 * Σ_(i,j) c_(ij) * |f_i^T f_j| with batch-computed c_(ij). This approach provides immediate feedback during training while maintaining computational efficiency.",
    "Implementation_Plan": "1. Modify compute_mask_intersections to calculate batch-wise statistics\n2. Simplify competition coefficient computation\n3. Update orthogonality loss calculation\n4. Add batch statistics tracking\n5. Update training loop for batch-wise adaptation\n6. Add evaluation metrics for competition reduction",
    "Interestingness_Evaluation": "The batch-wise adaptation mechanism provides an elegant and direct way to address feature competition while maintaining the connection between sparsity and orthogonality.",
    "Interestingness": 9,
    "Feasibility_Evaluation": "Implementation requires minimal modifications to existing code; uses only basic counting operations; computation overhead is negligible; easily fits within 30-minute limit on H100; can be implemented by a junior PhD student in 1 week.",
    "Feasibility": 10,
    "Novelty_Evaluation": "While building on existing sparsity-guided orthogonality, the batch-wise adaptation mechanism is a novel and simplified approach to handling feature competition.",
    "Novelty": 8,
    "Expected_Research_Impact": "The direct and immediate feedback from batch-wise competition coefficients should lead to cleaner feature separation, improving sparse probing and core metrics.",
    "Research_Impact": 9,
    "Overall_Score": 9.2,
    "Abstract": "We present a simplified approach to feature disentanglement in sparse autoencoders using batch-adaptive orthogonality constraints. Our method builds on recent work in sparsity-guided feature separation by introducing a batch-wise mechanism that adjusts orthogonality penalties based on the current context. This allows for immediate feedback during training while maintaining computational efficiency. The approach requires minimal modifications to standard sparse autoencoder architectures and leverages existing batch statistics. We evaluate our method on large language models and analyze its effectiveness in reducing feature competition through direct batch-wise adaptation."
}
```
@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

{'Name': 'batch_adaptive_orthogonal_sae', 'Title': 'Batch-Adaptive Orthogonality for Improved Feature Separation in Sparse Autoencoders', 'Experiment': '1. Modify mask intersection computation to use batch-wise statistics\n2. Implement simplified competition coefficient calculation\n3. Train with optimal dictionary size (18432) on gemma-2-2b\n4. Compare against fixed orthogonality baseline\n5. Analyze feature competition patterns within batches', 'Technical_Details': 'The method simplifies adaptive orthogonality by using batch-wise competition coefficients: c_(ij) = n_(ij)/n_batch where n_(ij) is the count of shared activations between features i and j in the current batch, and n_batch is the batch size. The loss remains L = L_recon + λ_1 * L_sparse + λ_2 * Σ_(i,j) c_(ij) * |f_i^T f_j| with batch-computed c_(ij). This approach provides immediate feedback during training while maintaining computational efficiency.', 'Implementation_Plan': '1. Modify compute_mask_intersections to calculate batch-wise statistics\n2. Simplify competition coefficient computation\n3. Update orthogonality loss calculation\n4. Add batch statistics tracking\n5. Update training loop for batch-wise adaptation\n6. Add evaluation metrics for competition reduction', 'Interestingness_Evaluation': 'The batch-wise adaptation mechanism provides an elegant and direct way to address feature competition while maintaining the connection between sparsity and orthogonality.', 'Interestingness': 9, 'Feasibility_Evaluation': 'Implementation requires minimal modifications to existing code; uses only basic counting operations; computation overhead is negligible; easily fits within 30-minute limit on H100; can be implemented by a junior PhD student in 1 week.', 'Feasibility': 10, 'Novelty_Evaluation': 'While building on existing sparsity-guided orthogonality, the batch-wise adaptation mechanism is a novel and simplified approach to handling feature competition.', 'Novelty': 8, 'Expected_Research_Impact': 'The direct and immediate feedback from batch-wise competition coefficients should lead to cleaner feature separation, improving sparse probing and core metrics.', 'Research_Impact': 9, 'Overall_Score': 9.2, 'Abstract': 'We present a simplified approach to feature disentanglement in sparse autoencoders using batch-adaptive orthogonality constraints. Our method builds on recent work in sparsity-guided feature separation by introducing a batch-wise mechanism that adjusts orthogonality penalties based on the current context. This allows for immediate feedback during training while maintaining computational efficiency. The approach requires minimal modifications to standard sparse autoencoder architectures and leverages existing batch statistics. We evaluate our method on large language models and analyze its effectiveness in reducing feature competition through direct batch-wise adaptation.'}
Iteration 3/15
!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

THOUGHT:
Looking at the previous idea, while the batch-wise adaptation is clean and efficient, we can further refine it by incorporating a key insight from the experiment logs: the relationship between dictionary size and feature competition. Run 4 showed that optimal dictionary size (18432) played a crucial role in performance.

I propose incorporating dictionary size awareness into our batch-wise adaptation mechanism. Specifically, we can normalize the competition coefficients by the expected number of co-activations given the dictionary size and sparsity level. This maintains the simplicity of batch-wise adaptation while accounting for the natural level of feature overlap we expect given the model's capacity.

This refinement makes the method more robust across different dictionary sizes while keeping the core mechanics unchanged. It's a natural extension that helps the model better distinguish between necessary and unnecessary feature competition based on architectural constraints.

NEW IDEA JSON:
```json
{
    "Name": "capacity_aware_orthogonal_sae",
    "Title": "Capacity-Aware Orthogonality Constraints for Sparse Autoencoders",
    "Experiment": "1. Modify mask intersection computation to include capacity normalization\n2. Implement normalized competition coefficients\n3. Train with optimal dictionary size (18432) on gemma-2-2b\n4. Compare against basic batch adaptation\n5. Analyze feature competition relative to capacity",
    "Technical_Details": "The method enhances batch-wise adaptation with capacity awareness: c_(ij) = (n_(ij)/n_batch) / (k/d) where n_(ij) is shared activations count, n_batch is batch size, k is sparsity level, and d is dictionary size. This normalizes competition coefficients by the expected co-activation rate given the model's capacity. The loss remains L = L_recon + λ_1 * L_sparse + λ_2 * Σ_(i,j) c_(ij) * |f_i^T f_j| with normalized c_(ij).",
    "Implementation_Plan": "1. Add capacity normalization to compute_mask_intersections\n2. Implement normalized coefficient computation\n3. Update orthogonality loss calculation\n4. Add configuration for capacity normalization\n5. Update training loop with normalized coefficients\n6. Add evaluation metrics for capacity-aware competition",
    "Interestingness_Evaluation": "The capacity-aware adaptation provides a principled way to scale orthogonality constraints based on architectural constraints while maintaining computational simplicity.",
    "Interestingness": 9,
    "Feasibility_Evaluation": "Implementation requires only minor modifications to existing code; uses simple arithmetic operations; computation overhead is negligible; easily fits within 30-minute limit on H100; can be implemented by a junior PhD student in 1 week.",
    "Feasibility": 10,
    "Novelty_Evaluation": "The capacity-aware normalization is a novel refinement that makes sparsity-guided orthogonality more robust across different model configurations.",
    "Novelty": 8,
    "Expected_Research_Impact": "By accounting for model capacity in orthogonality constraints, the method should achieve better feature separation across different dictionary sizes, improving sparse probing and core metrics.",
    "Research_Impact": 9,
    "Overall_Score": 9.2,
    "Abstract": "We present a capacity-aware approach to feature disentanglement in sparse autoencoders that adapts orthogonality constraints based on model architecture. Our method extends recent work in sparsity-guided feature separation by introducing a normalization mechanism that accounts for expected feature overlap given the dictionary size and sparsity level. This allows the model to better distinguish between necessary and unnecessary feature competition while maintaining computational efficiency. The approach requires minimal modifications to standard sparse autoencoder architectures and naturally scales with model capacity. We evaluate our method on large language models and analyze its effectiveness in achieving consistent feature separation across different architectural configurations."
}
```
@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

{'Name': 'capacity_aware_orthogonal_sae', 'Title': 'Capacity-Aware Orthogonality Constraints for Sparse Autoencoders', 'Experiment': '1. Modify mask intersection computation to include capacity normalization\n2. Implement normalized competition coefficients\n3. Train with optimal dictionary size (18432) on gemma-2-2b\n4. Compare against basic batch adaptation\n5. Analyze feature competition relative to capacity', 'Technical_Details': "The method enhances batch-wise adaptation with capacity awareness: c_(ij) = (n_(ij)/n_batch) / (k/d) where n_(ij) is shared activations count, n_batch is batch size, k is sparsity level, and d is dictionary size. This normalizes competition coefficients by the expected co-activation rate given the model's capacity. The loss remains L = L_recon + λ_1 * L_sparse + λ_2 * Σ_(i,j) c_(ij) * |f_i^T f_j| with normalized c_(ij).", 'Implementation_Plan': '1. Add capacity normalization to compute_mask_intersections\n2. Implement normalized coefficient computation\n3. Update orthogonality loss calculation\n4. Add configuration for capacity normalization\n5. Update training loop with normalized coefficients\n6. Add evaluation metrics for capacity-aware competition', 'Interestingness_Evaluation': 'The capacity-aware adaptation provides a principled way to scale orthogonality constraints based on architectural constraints while maintaining computational simplicity.', 'Interestingness': 9, 'Feasibility_Evaluation': 'Implementation requires only minor modifications to existing code; uses simple arithmetic operations; computation overhead is negligible; easily fits within 30-minute limit on H100; can be implemented by a junior PhD student in 1 week.', 'Feasibility': 10, 'Novelty_Evaluation': 'The capacity-aware normalization is a novel refinement that makes sparsity-guided orthogonality more robust across different model configurations.', 'Novelty': 8, 'Expected_Research_Impact': 'By accounting for model capacity in orthogonality constraints, the method should achieve better feature separation across different dictionary sizes, improving sparse probing and core metrics.', 'Research_Impact': 9, 'Overall_Score': 9.2, 'Abstract': 'We present a capacity-aware approach to feature disentanglement in sparse autoencoders that adapts orthogonality constraints based on model architecture. Our method extends recent work in sparsity-guided feature separation by introducing a normalization mechanism that accounts for expected feature overlap given the dictionary size and sparsity level. This allows the model to better distinguish between necessary and unnecessary feature competition while maintaining computational efficiency. The approach requires minimal modifications to standard sparse autoencoder architectures and naturally scales with model capacity. We evaluate our method on large language models and analyze its effectiveness in achieving consistent feature separation across different architectural configurations.'}
Iteration 4/15
!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

THOUGHT:
Analyzing the previous idea, while the capacity-aware normalization is valuable, we can make it even more focused on the core problem of feature absorption identified in the original prototype. The experiment logs show that feature absorption often happens in hierarchical relationships, where one feature subsumes another.

I propose refining the capacity-aware mechanism to specifically target hierarchical feature relationships. Instead of using raw co-activation counts, we can compute asymmetric competition coefficients that identify when one feature consistently activates alongside another but not vice versa - a key signature of feature absorption. This maintains all the simplicity of the previous approach while directly addressing the core issue.

This refinement makes the method more precise in preventing feature absorption while keeping the same computational structure. It's a natural specialization that better aligns with the original motivation of preventing feature absorption.

NEW IDEA JSON:
```json
{
    "Name": "hierarchical_orthogonal_sae",
    "Title": "Hierarchical Competition Detection for Preventing Feature Absorption in Sparse Autoencoders",
    "Experiment": "1. Modify mask intersection computation for asymmetric relationships\n2. Implement directional competition coefficients\n3. Train with optimal dictionary size (18432) on gemma-2-2b\n4. Compare against symmetric adaptation\n5. Analyze reduction in feature absorption patterns",
    "Technical_Details": "The method targets feature absorption through asymmetric competition coefficients: c_(ij) = (n_(i|j)/n_j) / (k/d) where n_(i|j) is activations of feature i when j is active, n_j is total activations of j, k is sparsity level, and d is dictionary size. This identifies hierarchical relationships where feature j may be absorbing feature i. The loss becomes L = L_recon + λ_1 * L_sparse + λ_2 * Σ_(i,j) max(c_(ij), c_(ji)) * |f_i^T f_j|.",
    "Implementation_Plan": "1. Add asymmetric statistics to compute_mask_intersections\n2. Implement directional coefficient computation\n3. Update orthogonality loss for asymmetric coefficients\n4. Add configuration for absorption detection\n5. Update training loop with directional penalties\n6. Add evaluation metrics for absorption reduction",
    "Interestingness_Evaluation": "The hierarchical competition detection provides a precise mechanism for preventing feature absorption while maintaining the elegant simplicity of sparsity-guided orthogonality.",
    "Interestingness": 9,
    "Feasibility_Evaluation": "Implementation requires only minor modifications to existing code; uses simple counting operations; computation overhead is negligible; easily fits within 30-minute limit on H100; can be implemented by a junior PhD student in 1 week.",
    "Feasibility": 10,
    "Novelty_Evaluation": "The asymmetric competition detection is a novel refinement that directly targets the feature absorption problem identified in the original work.",
    "Novelty": 9,
    "Expected_Research_Impact": "By specifically targeting hierarchical feature relationships, the method should be particularly effective at preventing feature absorption, improving interpretability metrics.",
    "Research_Impact": 9,
    "Overall_Score": 9.3,
    "Abstract": "We present a hierarchical approach to preventing feature absorption in sparse autoencoders through asymmetric orthogonality constraints. Our method extends sparsity-guided feature separation by introducing directional competition coefficients that identify and penalize cases where one feature subsumes another. This allows the model to specifically target hierarchical feature relationships that often lead to reduced interpretability. The approach maintains computational efficiency while adding precise control over feature absorption patterns. We evaluate our method on large language models and analyze its effectiveness in preserving distinct feature representations in hierarchical contexts."
}
```
@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

{'Name': 'hierarchical_orthogonal_sae', 'Title': 'Hierarchical Competition Detection for Preventing Feature Absorption in Sparse Autoencoders', 'Experiment': '1. Modify mask intersection computation for asymmetric relationships\n2. Implement directional competition coefficients\n3. Train with optimal dictionary size (18432) on gemma-2-2b\n4. Compare against symmetric adaptation\n5. Analyze reduction in feature absorption patterns', 'Technical_Details': 'The method targets feature absorption through asymmetric competition coefficients: c_(ij) = (n_(i|j)/n_j) / (k/d) where n_(i|j) is activations of feature i when j is active, n_j is total activations of j, k is sparsity level, and d is dictionary size. This identifies hierarchical relationships where feature j may be absorbing feature i. The loss becomes L = L_recon + λ_1 * L_sparse + λ_2 * Σ_(i,j) max(c_(ij), c_(ji)) * |f_i^T f_j|.', 'Implementation_Plan': '1. Add asymmetric statistics to compute_mask_intersections\n2. Implement directional coefficient computation\n3. Update orthogonality loss for asymmetric coefficients\n4. Add configuration for absorption detection\n5. Update training loop with directional penalties\n6. Add evaluation metrics for absorption reduction', 'Interestingness_Evaluation': 'The hierarchical competition detection provides a precise mechanism for preventing feature absorption while maintaining the elegant simplicity of sparsity-guided orthogonality.', 'Interestingness': 9, 'Feasibility_Evaluation': 'Implementation requires only minor modifications to existing code; uses simple counting operations; computation overhead is negligible; easily fits within 30-minute limit on H100; can be implemented by a junior PhD student in 1 week.', 'Feasibility': 10, 'Novelty_Evaluation': 'The asymmetric competition detection is a novel refinement that directly targets the feature absorption problem identified in the original work.', 'Novelty': 9, 'Expected_Research_Impact': 'By specifically targeting hierarchical feature relationships, the method should be particularly effective at preventing feature absorption, improving interpretability metrics.', 'Research_Impact': 9, 'Overall_Score': 9.3, 'Abstract': 'We present a hierarchical approach to preventing feature absorption in sparse autoencoders through asymmetric orthogonality constraints. Our method extends sparsity-guided feature separation by introducing directional competition coefficients that identify and penalize cases where one feature subsumes another. This allows the model to specifically target hierarchical feature relationships that often lead to reduced interpretability. The approach maintains computational efficiency while adding precise control over feature absorption patterns. We evaluate our method on large language models and analyze its effectiveness in preserving distinct feature representations in hierarchical contexts.'}
Iteration 5/15
!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

THOUGHT:
The current idea effectively targets hierarchical feature absorption, but examining the experiment logs more carefully reveals another insight: Run 4's success came partly from finding the right balance of penalties. We can refine our approach by adding adaptive scaling of the orthogonality penalty based on the strength of the hierarchical relationship.

However, looking at potential modifications, I realize that adding adaptive scaling would introduce unnecessary complexity without a clear benefit. The current directional competition coefficients already capture the essential information about feature absorption, and the max operation in the loss function provides natural scaling.

The current implementation strikes the right balance between effectiveness and simplicity. It directly addresses the core problem of feature absorption while maintaining computational efficiency and ease of implementation. Any further refinements would likely add complexity without proportional benefits.

I am done.

NEW IDEA JSON:
```json
{
    "Name": "hierarchical_orthogonal_sae",
    "Title": "Hierarchical Competition Detection for Preventing Feature Absorption in Sparse Autoencoders",
    "Experiment": "1. Modify mask intersection computation for asymmetric relationships\n2. Implement directional competition coefficients\n3. Train with optimal dictionary size (18432) on gemma-2-2b\n4. Compare against symmetric adaptation\n5. Analyze reduction in feature absorption patterns",
    "Technical_Details": "The method targets feature absorption through asymmetric competition coefficients: c_(ij) = (n_(i|j)/n_j) / (k/d) where n_(i|j) is activations of feature i when j is active, n_j is total activations of j, k is sparsity level, and d is dictionary size. This identifies hierarchical relationships where feature j may be absorbing feature i. The loss becomes L = L_recon + λ_1 * L_sparse + λ_2 * Σ_(i,j) max(c_(ij), c_(ji)) * |f_i^T f_j|.",
    "Implementation_Plan": "1. Add asymmetric statistics to compute_mask_intersections\n2. Implement directional coefficient computation\n3. Update orthogonality loss for asymmetric coefficients\n4. Add configuration for absorption detection\n5. Update training loop with directional penalties\n6. Add evaluation metrics for absorption reduction",
    "Interestingness_Evaluation": "The hierarchical competition detection provides a precise mechanism for preventing feature absorption while maintaining the elegant simplicity of sparsity-guided orthogonality.",
    "Interestingness": 9,
    "Feasibility_Evaluation": "Implementation requires only minor modifications to existing code; uses simple counting operations; computation overhead is negligible; easily fits within 30-minute limit on H100; can be implemented by a junior PhD student in 1 week.",
    "Feasibility": 10,
    "Novelty_Evaluation": "The asymmetric competition detection is a novel refinement that directly targets the feature absorption problem identified in the original work.",
    "Novelty": 9,
    "Expected_Research_Impact": "By specifically targeting hierarchical feature relationships, the method should be particularly effective at preventing feature absorption, improving interpretability metrics.",
    "Research_Impact": 9,
    "Overall_Score": 9.3,
    "Abstract": "We present a hierarchical approach to preventing feature absorption in sparse autoencoders through asymmetric orthogonality constraints. Our method extends sparsity-guided feature separation by introducing directional competition coefficients that identify and penalize cases where one feature subsumes another. This allows the model to specifically target hierarchical feature relationships that often lead to reduced interpretability. The approach maintains computational efficiency while adding precise control over feature absorption patterns. We evaluate our method on large language models and analyze its effectiveness in preserving distinct feature representations in hierarchical contexts."
}
```
@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

{'Name': 'hierarchical_orthogonal_sae', 'Title': 'Hierarchical Competition Detection for Preventing Feature Absorption in Sparse Autoencoders', 'Experiment': '1. Modify mask intersection computation for asymmetric relationships\n2. Implement directional competition coefficients\n3. Train with optimal dictionary size (18432) on gemma-2-2b\n4. Compare against symmetric adaptation\n5. Analyze reduction in feature absorption patterns', 'Technical_Details': 'The method targets feature absorption through asymmetric competition coefficients: c_(ij) = (n_(i|j)/n_j) / (k/d) where n_(i|j) is activations of feature i when j is active, n_j is total activations of j, k is sparsity level, and d is dictionary size. This identifies hierarchical relationships where feature j may be absorbing feature i. The loss becomes L = L_recon + λ_1 * L_sparse + λ_2 * Σ_(i,j) max(c_(ij), c_(ji)) * |f_i^T f_j|.', 'Implementation_Plan': '1. Add asymmetric statistics to compute_mask_intersections\n2. Implement directional coefficient computation\n3. Update orthogonality loss for asymmetric coefficients\n4. Add configuration for absorption detection\n5. Update training loop with directional penalties\n6. Add evaluation metrics for absorption reduction', 'Interestingness_Evaluation': 'The hierarchical competition detection provides a precise mechanism for preventing feature absorption while maintaining the elegant simplicity of sparsity-guided orthogonality.', 'Interestingness': 9, 'Feasibility_Evaluation': 'Implementation requires only minor modifications to existing code; uses simple counting operations; computation overhead is negligible; easily fits within 30-minute limit on H100; can be implemented by a junior PhD student in 1 week.', 'Feasibility': 10, 'Novelty_Evaluation': 'The asymmetric competition detection is a novel refinement that directly targets the feature absorption problem identified in the original work.', 'Novelty': 9, 'Expected_Research_Impact': 'By specifically targeting hierarchical feature relationships, the method should be particularly effective at preventing feature absorption, improving interpretability metrics.', 'Research_Impact': 9, 'Overall_Score': 9.3, 'Abstract': 'We present a hierarchical approach to preventing feature absorption in sparse autoencoders through asymmetric orthogonality constraints. Our method extends sparsity-guided feature separation by introducing directional competition coefficients that identify and penalize cases where one feature subsumes another. This allows the model to specifically target hierarchical feature relationships that often lead to reduced interpretability. The approach maintains computational efficiency while adding precise control over feature absorption patterns. We evaluate our method on large language models and analyze its effectiveness in preserving distinct feature representations in hierarchical contexts.'}
Idea generation converged after 5 iterations.
Skipping seed idea 0
Skipping seed idea 1
Skipping seed idea 2
Skipping seed idea 3
Skipping seed idea 4
Skipping seed idea 5
Skipping seed idea 6
Skipping seed idea 7
Skipping seed idea 8
Skipping seed idea 9

Checking novelty of idea 10: hierarchical_orthogonal_sae
!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

THOUGHT:
The idea proposes a novel approach to addressing feature absorption in sparse autoencoders through asymmetric orthogonality constraints. The key innovation is the introduction of directional competition coefficients that specifically target hierarchical relationships between features. Before making a decision, I should search for papers that specifically address feature absorption in sparse autoencoders or similar hierarchical approaches to feature disentanglement. Let me search for papers specifically about feature absorption in sparse autoencoders.

RESPONSE:
```json
{
    "Query": "feature absorption sparse autoencoder hierarchical disentanglement",
    "Decision": "undecided"
}
```
@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

Response Status Code: 200
Response Content: {"total": 101, "offset": 0, "next": 10, "data": [{"paperId": "5b2486001752b2ec11b61d56b8f09d32b559ccd5", "title": "Bayesian Hierarchical Sparse Autoencoder for Massive MIMO CSI Feedback", "abstract": "Efficient channel state information (CSI) compression and feedback from user equipment to the base station (BS) are crucial for achieving the promised capacity gains in massive multiple-input multiple-output (MIMO) systems. Deep autoencoder (AE)-based schemes have been proposed to improve the effic
!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

!!!

THOUGHT:
Paper #5 "A is for Absorption" (Chanin et al., 2024) directly addresses the feature absorption problem in sparse autoencoders and identifies it as a significant issue, but importantly, they conclude that "varying SAE size or sparsity is insufficient to solve this issue, and that there are deeper conceptual issues in need of resolution." They identify the problem but don't propose a solution using asymmetric competition coefficients like our proposal does. The other papers discussing hierarchical sparse autoencoders focus on different applications (MIMO, video prediction, fault diagnosis) and don't address the feature absorption problem specifically. Let me make one more search focusing specifically on asymmetric orthogonality constraints to ensure our specific solution hasn't been proposed.

RESPONSE:
```json
{
    "Query": "asymmetric orthogonality sparse autoencoder feature disentanglement",
    "Decision": "undecided"
}
```
@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

@@@

Response Status Code: 200
Response Content: {"total": 40, "offset": 0, "next": 10, "data": [{"paperId": "9b4d1278d95f5b1813342c93b5cb7ebd773d9821", "title": "Scale-Adaptive Asymmetric Sparse Variational AutoEncoder for Point Cloud Compression", "abstract": "Learning-based point cloud compression has achieved great success in Rate-Distortion (RD) efficiency. Existing methods usually utilize Variational AutoEncoder (VAE) network, which might lead to poor detail reconstruction and high computational complexity. To address these issues, we pr
Decision made: novel after round 2
saved
Processing idea: hierarchical_orthogonal_sae
2025-01-30 21:23:41
*Starting idea: 20250130_212318_hierarchical_orthogonal_sae*
2025-01-30 21:23:41
*Starting Experiments*
Starting experiment with prompt for coder: Your goal is to implement the following idea: Hierarchical Competition Detection for Preventing Feature Absorption in Sparse Autoencoders. Pay attention to the following details from the idea:
The proposed experiment is as follows: 1. Modify mask intersection computation for asymmetric relationships
2. Implement directional competition coefficients
3. Train with optimal dictionary size (18432) on gemma-2-2b
4. Compare against symmetric adaptation
5. Analyze reduction in feature absorption patterns.
The implementation plan is as follows: 1. Add asymmetric statistics to compute_mask_intersections
2. Implement directional coefficient computation
3. Update orthogonality loss for asymmetric coefficients
4. Add configuration for absorption detection
5. Update training loop with directional penalties
6. Add evaluation metrics for absorption reduction.

You can also refer to other information in the idea: {'Name': 'hierarchical_orthogonal_sae', 'Title': 'Hierarchical Competition Detection for Preventing Feature Absorption in Sparse Autoencoders', 'Experiment': '1. Modify mask intersection computation for asymmetric relationships\n2. Implement directional competition coefficients\n3. Train with optimal dictionary size (18432) on gemma-2-2b\n4. Compare against symmetric adaptation\n5. Analyze reduction in feature absorption patterns', 'Technical_Details': 'The method targets feature absorption through asymmetric competition coefficients: c_(ij) = (n_(i|j)/n_j) / (k/d) where n_(i|j) is activations of feature i when j is active, n_j is total activations of j, k is sparsity level, and d is dictionary size. This identifies hierarchical relationships where feature j may be absorbing feature i. The loss becomes L = L_recon + λ_1 * L_sparse + λ_2 * Σ_(i,j) max(c_(ij), c_(ji)) * |f_i^T f_j|.', 'Implementation_Plan': '1. Add asymmetric statistics to compute_mask_intersections\n2. Implement directional coefficient computation\n3. Update orthogonality loss for asymmetric coefficients\n4. Add configuration for absorption detection\n5. Update training loop with directional penalties\n6. Add evaluation metrics for absorption reduction', 'Interestingness_Evaluation': 'The hierarchical competition detection provides a precise mechanism for preventing feature absorption while maintaining the elegant simplicity of sparsity-guided orthogonality.', 'Interestingness': 9, 'Feasibility_Evaluation': 'Implementation requires only minor modifications to existing code; uses simple counting operations; computation overhead is negligible; easily fits within 30-minute limit on H100; can be implemented by a junior PhD student in 1 week.', 'Feasibility': 10, 'Novelty_Evaluation': 'The asymmetric competition detection is a novel refinement that directly targets the feature absorption problem identified in the original work.', 'Novelty': 9, 'Expected_Research_Impact': 'By specifically targeting hierarchical feature relationships, the method should be particularly effective at preventing feature absorption, improving interpretability metrics.', 'Research_Impact': 9, 'Overall_Score': 9.3, 'Abstract': 'We present a hierarchical approach to preventing feature absorption in sparse autoencoders through asymmetric orthogonality constraints. Our method extends sparsity-guided feature separation by introducing directional competition coefficients that identify and penalize cases where one feature subsumes another. This allows the model to specifically target hierarchical feature relationships that often lead to reduced interpretability. The approach maintains computational efficiency while adding precise control over feature absorption patterns. We evaluate our method on large language models and analyze its effectiveness in preserving distinct feature representations in hierarchical contexts.', 'novel': True}

You are given a total of up to 10 runs to complete the necessary experiments. You do not need to use all 10.

If the experiments in the idea is already implemented in 'experiment.py' you are given with, you should try to improve its result by further enhancing the implementation.

First, plan the list of experiments you would like to run. For example, if you are sweeping over a specific hyperparameter, plan each value you would like to test for each run (you can try to run with different hyperparameters in the same run across different iterations.).

Note that we already provide the baseline results, so you do not need to re-run it.

For reference, the baseline results are as follows:

Baseline results from TopK SAE: 
{'training results for layer 12': {'config': {'trainer_class': 'TrainerTopK', 'dict_class': 'AutoEncoderTopK', 'lr': 0.0001885618083164127, 'steps': 4882, 'seed': 42, 'activation_dim': 2304, 'dict_size': 18432, 'k': 320, 'device': 'cuda', 'layer': 12, 'lm_name': 'google/gemma-2-2b', 'wandb_name': 'AutoEncoderTopK', 'submodule_name': 'resid_post_layer_12'}, 'final_info': {'training_steps': 4882, 'final_loss': 2490.71484375, 'layer': 12, 'dict_size': 18432, 'learning_rate': 0.0003, 'sparsity_penalty': 0.04}}, 'absorption evaluation results': {'eval_type_id': 'absorption_first_letter', 'eval_config': {'model_name': 'google/gemma-2-2b', 'random_seed': 42, 'f1_jump_threshold': 0.03, 'max_k_value': 10, 'prompt_template': '{word} has the first letter:', 'prompt_token_pos': -6, 'llm_batch_size': 32, 'llm_dtype': 'bfloat16', 'k_sparse_probe_l1_decay': 0.01, 'k_sparse_probe_batch_size': 4096, 'k_sparse_probe_num_epochs': 50}, 'eval_id': '8a77b97b-0aa7-4019-b88e-1d5fc86e7e35', 'datetime_epoch_millis': 1738260105364, 'eval_result_metrics': {'mean': {'mean_absorption_score': 0.011311560801835012, 'mean_num_split_features': 1.2380952380952381}}, 'eval_result_details': [{'first_letter': 'a', 'absorption_rate': 0.0003755163349605708, 'num_absorption': 1, 'num_probe_true_positives': 2663, 'num_split_features': 2}, {'first_letter': 'b', 'absorption_rate': 0.0006333122229259025, 'num_absorption': 1, 'num_probe_true_positives': 1579, 'num_split_features': 1}, {'first_letter': 'd', 'absorption_rate': 0.0012515644555694619, 'num_absorption': 2, 'num_probe_true_positives': 1598, 'num_split_features': 1}, {'first_letter': 'e', 'absorption_rate': 0.002476780185758514, 'num_absorption': 4, 'num_probe_true_positives': 1615, 'num_split_features': 1}, {'first_letter': 'g', 'absorption_rate': 0.0017543859649122807, 'num_absorption': 2, 'num_probe_true_positives': 1140, 'num_split_features': 1}, {'first_letter': 'h', 'absorption_rate': 0.002061855670103093, 'num_absorption': 2, 'num_probe_true_positives': 970, 'num_split_features': 1}, {'first_letter': 'i', 'absorption_rate': 0.0005770340450086555, 'num_absorption': 1, 'num_probe_true_positives': 1733, 'num_split_features': 1}, {'first_letter': 'j', 'absorption_rate': 0.0026041666666666665, 'num_absorption': 1, 'num_probe_true_positives': 384, 'num_split_features': 2}, {'first_letter': 'k', 'absorption_rate': 0.0661764705882353, 'num_absorption': 45, 'num_probe_true_positives': 680, 'num_split_features': 1}, {'first_letter': 'm', 'absorption_rate': 0.002730748225013654, 'num_absorption': 5, 'num_probe_true_positives': 1831, 'num_split_features': 1}, {'first_letter': 'n', 'absorption_rate': 0.0, 'num_absorption': 0, 'num_probe_true_positives': 835, 'num_split_features': 1}, {'first_letter': 'o', 'absorption_rate': 0.06350710900473934, 'num_absorption': 67, 'num_probe_true_positives': 1055, 'num_split_features': 1}, {'first_letter': 'p', 'absorption_rate': 0.000869187309865276, 'num_absorption': 2, 'num_probe_true_positives': 2301, 'num_split_features': 1}, {'first_letter': 'r', 'absorption_rate': 0.0, 'num_absorption': 0, 'num_probe_true_positives': 1592, 'num_split_features': 1}, {'first_letter': 's', 'absorption_rate': 0.0010615711252653928, 'num_absorption': 3, 'num_probe_true_positives': 2826, 'num_split_features': 1}, {'first_letter': 't', 'absorption_rate': 0.0718266253869969, 'num_absorption': 116, 'num_probe_true_positives': 1615, 'num_split_features': 1}, {'first_letter': 'u', 'absorption_rate': 0.0025188916876574307, 'num_absorption': 2, 'num_probe_true_positives': 794, 'num_split_features': 1}, {'first_letter': 'v', 'absorption_rate': 0.0012315270935960591, 'num_absorption': 1, 'num_probe_true_positives': 812, 'num_split_features': 1}, {'first_letter': 'w', 'absorption_rate': 0.0014705882352941176, 'num_absorption': 1, 'num_probe_true_positives': 680, 'num_split_features': 2}, {'first_letter': 'y', 'absorption_rate': 0.005681818181818182, 'num_absorption': 1, 'num_probe_true_positives': 176, 'num_split_features': 2}, {'first_letter': 'z', 'absorption_rate': 0.008733624454148471, 'num_absorption': 2, 'num_probe_true_positives': 229, 'num_split_features': 2}], 'sae_bench_commit_hash': '60adde367f8d77d5f375d2bc8d39ed57e71595f0', 'sae_lens_id': 'custom_sae', 'sae_lens_release_id': 'google/gemma-2-2b_layer_12_sae', 'sae_lens_version': '5.3.0', 'sae_cfg_dict': {'model_name': 'google/gemma-2-2b', 'd_in': 2304, 'd_sae': 18432, 'hook_layer': 12, 'hook_name': 'blocks.12.hook_resid_post', 'context_size': None, 'hook_head_index': None, 'architecture': 'TopK', 'apply_b_dec_to_input': True, 'finetuning_scaling_factor': None, 'activation_fn_str': 'TopK', 'prepend_bos': True, 'normalize_activations': 'none', 'dtype': 'bfloat16', 'device': '', 'dataset_path': '', 'dataset_trust_remote_code': True, 'seqpos_slice': [None], 'training_tokens': -100000, 'sae_lens_training_version': None, 'neuronpedia_id': None}, 'eval_result_unstructured': None}, 'core evaluation results': {'unique_id': 'google/gemma-2-2b_layer_12_sae_custom_sae', 'sae_set': 'google/gemma-2-2b_layer_12_sae', 'sae_id': 'custom_sae', 'eval_cfg': {'model_name': 'google/gemma-2-2b', 'llm_dtype': 'bfloat16', 'batch_size_prompts': 16, 'n_eval_reconstruction_batches': 200, 'n_eval_sparsity_variance_batches': 2000, 'dataset': 'Skylion007/openwebtext', 'context_size': 128, 'compute_kl': True, 'compute_ce_loss': True, 'compute_l2_norms': True, 'compute_sparsity_metrics': True, 'compute_variance_metrics': True, 'compute_featurewise_density_statistics': False, 'compute_featurewise_weight_based_metrics': False, 'exclude_special_tokens_from_reconstruction': True, 'verbose': False}, 'metrics': {'model_behavior_preservation': {'kl_div_score': 0.9909258540372671, 'kl_div_with_ablation': 10.0625, 'kl_div_with_sae': 0.09130859375}, 'model_performance_preservation': {'ce_loss_score': 0.9917763157894737, 'ce_loss_with_ablation': 12.4375, 'ce_loss_with_sae': 3.015625, 'ce_loss_without_sae': 2.9375}, 'reconstruction_quality': {'explained_variance': 0.77734375, 'mse': 1.4140625, 'cossim': 0.9296875}, 'shrinkage': {'l2_norm_in': 149.0, 'l2_norm_out': 139.0, 'l2_ratio': 0.9296875, 'relative_reconstruction_bias': 1.0}, 'sparsity': {'l0': 320.0, 'l1': 952.0}, 'token_stats': {'total_tokens_eval_reconstruction': 409600, 'total_tokens_eval_sparsity_variance': 4096000}}}, 'unlearning evaluation results': {'eval_type_id': 'unlearning', 'eval_config': {'random_seed': 42, 'dataset_names': ['wmdp-bio', 'high_school_us_history', 'college_computer_science', 'high_school_geography', 'human_aging'], 'intervention_method': 'clamp_feature_activation', 'retain_thresholds': [0.001, 0.005, 0.01, 0.02], 'n_features_list': [10, 100, 1000], 'multipliers': [10, 25, 50, 100, 200], 'dataset_size': 1024, 'seq_len': 1024, 'n_batch_loss_added': 50, 'target_metric': 'correct', 'save_metrics': True, 'model_name': 'google/gemma-2-2b-it', 'llm_batch_size': 32, 'llm_dtype': 'bfloat16'}, 'eval_id': '934ed73e-60b9-4548-8843-7eb782da85b6', 'datetime_epoch_millis': 1738206942591, 'eval_result_metrics': {'unlearning': {'unlearning_score': 0.0018726587295532227}}, 'eval_result_details': [], 'sae_bench_commit_hash': '60adde367f8d77d5f375d2bc8d39ed57e71595f0', 'sae_lens_id': 'custom_sae', 'sae_lens_release_id': 'google/gemma-2-2b_layer_12_sae', 'sae_lens_version': '5.3.0', 'sae_cfg_dict': {'model_name': 'google/gemma-2-2b', 'd_in': 2304, 'd_sae': 4608, 'hook_layer': 12, 'hook_name': 'blocks.12.hook_resid_post', 'context_size': None, 'hook_head_index': None, 'architecture': 'Custom', 'apply_b_dec_to_input': True, 'finetuning_scaling_factor': None, 'activation_fn_str': 'relu', 'prepend_bos': True, 'normalize_activations': 'none', 'dtype': 'bfloat16', 'device': '', 'dataset_path': '', 'dataset_trust_remote_code': True, 'seqpos_slice': [None], 'training_tokens': -100000, 'sae_lens_training_version': None, 'neuronpedia_id': None}, 'eval_result_unstructured': None}, 'scr and tpp evaluations results': {'eval_type_id': 'scr', 'eval_config': {'random_seed': 42, 'dataset_names': ['LabHC/bias_in_bios_class_set1', 'canrager/amazon_reviews_mcauley_1and5'], 'perform_scr': True, 'early_stopping_patience': 20, 'train_set_size': 4000, 'test_set_size': 1000, 'context_length': 128, 'probe_train_batch_size': 16, 'probe_test_batch_size': 500, 'probe_epochs': 20, 'probe_lr': 0.001, 'probe_l1_penalty': 0.001, 'sae_batch_size': 125, 'llm_batch_size': 32, 'llm_dtype': 'bfloat16', 'lower_vram_usage': False, 'model_name': 'google/gemma-2-2b', 'n_values': [2, 5, 10, 20, 50, 100, 500], 'column1_vals_lookup': {'LabHC/bias_in_bios_class_set1': [['professor', 'nurse'], ['architect', 'journalist'], ['surgeon', 'psychologist'], ['attorney', 'teacher']], 'canrager/amazon_reviews_mcauley_1and5': [['Books', 'CDs_and_Vinyl'], ['Software', 'Electronics'], ['Pet_Supplies', 'Office_Products'], ['Industrial_and_Scientific', 'Toys_and_Games']]}}, 'eval_id': 'eca00384-2815-4f3b-9a0f-c43a9641dd09', 'datetime_epoch_millis': 1738262060787, 'eval_result_metrics': {'scr_metrics': {'scr_dir1_threshold_2': 0.1666135003720485, 'scr_metric_threshold_2': 0.117377050053775, 'scr_dir2_threshold_2': 0.11814089683053615, 'scr_dir1_threshold_5': 0.26866832487791314, 'scr_metric_threshold_5': 0.16687787413342567, 'scr_dir2_threshold_5': 0.17085293805429583, 'scr_dir1_threshold_10': 0.29196175141811176, 'scr_metric_threshold_10': 0.19463704992358133, 'scr_dir2_threshold_10': 0.19872197015917717, 'scr_dir1_threshold_20': 0.28666004993807526, 'scr_metric_threshold_20': 0.24151138199522765, 'scr_dir2_threshold_20': 0.24088549186443128, 'scr_dir1_threshold_50': 0.25061022779634345, 'scr_metric_threshold_50': 0.2917936325253217, 'scr_dir2_threshold_50': 0.28765504613083787, 'scr_dir1_threshold_100': 0.20003832117510784, 'scr_metric_threshold_100': 0.3192698599244855, 'scr_dir2_threshold_100': 0.3136981258782174, 'scr_dir1_threshold_500': 0.026976481243512648, 'scr_metric_threshold_500': 0.23864530477936774, 'scr_dir2_threshold_500': 0.22937694760332222}}, 'eval_result_details': [{'dataset_name': 'LabHC/bias_in_bios_class_set1_scr_professor_nurse_results', 'scr_dir1_threshold_2': 0.37500011641541114, 'scr_metric_threshold_2': 0.017199085925573582, 'scr_dir2_threshold_2': 0.017199085925573582, 'scr_dir1_threshold_5': 0.4843747235133985, 'scr_metric_threshold_5': 0.017199085925573582, 'scr_dir2_threshold_5': 0.017199085925573582, 'scr_dir1_threshold_10': 0.5156252764866015, 'scr_metric_threshold_10': 0.02948408453723957, 'scr_dir2_threshold_10': 0.02948408453723957, 'scr_dir1_threshold_20': 0.4375002910385279, 'scr_metric_threshold_20': 0.05896816907447914, 'scr_dir2_threshold_20': 0.05896816907447914, 'scr_dir1_threshold_50': 0.2968751309673376, 'scr_metric_threshold_50': 0.09582316490947711, 'scr_dir2_threshold_50': 0.09582316490947711, 'scr_dir1_threshold_100': 0.3124999417922944, 'scr_metric_threshold_100': 0.09828013534206324, 'scr_dir2_threshold_100': 0.09828013534206324, 'scr_dir1_threshold_500': 0.34374956344220814, 'scr_metric_threshold_500': 0.027027114104653437, 'scr_dir2_threshold_500': 0.027027114104653437}, {'dataset_name': 'LabHC/bias_in_bios_class_set1_scr_architect_journalist_results', 'scr_dir1_threshold_2': 0.05825226425346908, 'scr_metric_threshold_2': 0.1346704699783852, 'scr_dir2_threshold_2': 0.1346704699783852, 'scr_dir1_threshold_5': 0.26213605716954286, 'scr_metric_threshold_5': 0.1719197888799928, 'scr_dir2_threshold_5': 0.1719197888799928, 'scr_dir1_threshold_10': 0.26213605716954286, 'scr_metric_threshold_10': 0.19770776575133966, 'scr_dir2_threshold_10': 0.19770776575133966, 'scr_dir1_threshold_20': 0.29126189995330004, 'scr_metric_threshold_20': 0.26647564714594496, 'scr_dir2_threshold_20': 0.26647564714594496, 'scr_dir1_threshold_50': 0.16504817849915482, 'scr_metric_threshold_50': 0.32951294291889943, 'scr_dir2_threshold_50': 0.32951294291889943, 'scr_dir1_threshold_100': -0.20388379291607375, 'scr_metric_threshold_100': 0.3839541894724186, 'scr_dir2_threshold_100': 0.3839541894724186, 'scr_dir1_threshold_500': -0.7475731357776643, 'scr_metric_threshold_500': 0.07163317420543075, 'scr_dir2_threshold_500': 0.07163317420543075}, {'dataset_name': 'LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results', 'scr_dir1_threshold_2': 0.42857142857142855, 'scr_metric_threshold_2': 0.03544318161412681, 'scr_dir2_threshold_2': 0.03544318161412681, 'scr_dir1_threshold_5': 0.5873013770560047, 'scr_metric_threshold_5': 0.058227846955206435, 'scr_dir2_threshold_5': 0.058227846955206435, 'scr_dir1_threshold_10': 0.6349207400434262, 'scr_metric_threshold_10': 0.09113926495559606, 'scr_dir2_threshold_10': 0.09113926495559606, 'scr_dir1_threshold_20': 0.5714285714285714, 'scr_metric_threshold_20': 0.10886085576265946, 'scr_dir2_threshold_20': 0.10886085576265946, 'scr_dir1_threshold_50': 0.36507925995657375, 'scr_metric_threshold_50': 0.1518987246267203, 'scr_dir2_threshold_50': 0.1518987246267203, 'scr_dir1_threshold_100': 0.42857142857142855, 'scr_metric_threshold_100': 0.20000012071825551, 'scr_dir2_threshold_100': 0.20000012071825551, 'scr_dir1_threshold_500': -0.17460275411200937, 'scr_metric_threshold_500': 0.05063300880745302, 'scr_dir2_threshold_500': 0.05063300880745302}, {'dataset_name': 'LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results', 'scr_dir1_threshold_2': 0.1171878346939954, 'scr_metric_threshold_2': 0.041543020933079725, 'scr_dir2_threshold_2': 0.041543020933079725, 'scr_dir1_threshold_5': 0.31250011641530273, 'scr_metric_threshold_5': 0.0890208602099569, 'scr_dir2_threshold_5': 0.0890208602099569, 'scr_dir1_threshold_10': 0.20312514551912844, 'scr_metric_threshold_10': 0.11572710058610643, 'scr_dir2_threshold_10': 0.11572710058610643, 'scr_dir1_threshold_20': 0.07031251455191284, 'scr_metric_threshold_20': 0.14836798243767776, 'scr_dir2_threshold_20': 0.14836798243767776, 'scr_dir1_threshold_50': 0.08593777648634401, 'scr_metric_threshold_50': 0.22551938282841538, 'scr_dir2_threshold_50': 0.22551938282841538, 'scr_dir1_threshold_100': 0.06250011641530274, 'scr_metric_threshold_100': 0.25816026467998676, 'scr_dir2_threshold_100': 0.25816026467998676, 'scr_dir1_threshold_500': 0.25, 'scr_metric_threshold_500': -0.03857552332699319, 'scr_dir2_threshold_500': -0.03857552332699319}, {'dataset_name': 'canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results', 'scr_dir1_threshold_2': 0.04371592886659017, 'scr_metric_threshold_2': 0.49019597301756745, 'scr_dir2_threshold_2': 0.49019597301756745, 'scr_dir1_threshold_5': 0.03278678379574697, 'scr_metric_threshold_5': 0.6274509483096945, 'scr_dir2_threshold_5': 0.6274509483096945, 'scr_dir1_threshold_10': 0.04371592886659017, 'scr_metric_threshold_10': 0.662745071456604, 'scr_dir2_threshold_10': 0.662745071456604, 'scr_dir1_threshold_20': 0.03278678379574697, 'scr_metric_threshold_20': 0.6823528916778143, 'scr_dir2_threshold_20': 0.6823528916778143, 'scr_dir1_threshold_50': 0.09836067709563222, 'scr_metric_threshold_50': 0.6862744089733254, 'scr_dir2_threshold_50': 0.6862744089733254, 'scr_dir1_threshold_100': -0.03278678379574697, 'scr_metric_threshold_100': 0.6823528916778143, 'scr_dir2_threshold_100': 0.6823528916778143, 'scr_dir1_threshold_500': -0.3114752603305745, 'scr_metric_threshold_500': 0.6823528916778143, 'scr_dir2_threshold_500': 0.6823528916778143}, {'dataset_name': 'canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results', 'scr_dir1_threshold_2': 0.09743586922067994, 'scr_metric_threshold_2': 0.0927419335456348, 'scr_dir2_threshold_2': 0.0927419335456348, 'scr_dir1_threshold_5': 0.16410229135546164, 'scr_metric_threshold_5': 0.13306447154960044, 'scr_dir2_threshold_5': 0.13306447154960044, 'scr_dir1_threshold_10': 0.21538460127700665, 'scr_metric_threshold_10': 0.1572581866250075, 'scr_dir2_threshold_10': 0.1572581866250075, 'scr_dir1_threshold_20': 0.29230760766203984, 'scr_metric_threshold_20': 0.20967734182539205, 'scr_dir2_threshold_20': 0.20967734182539205, 'scr_dir1_threshold_50': 0.29743574695473746, 'scr_metric_threshold_50': 0.2943548639067476, 'scr_dir2_threshold_50': 0.2943548639067476, 'scr_dir1_threshold_100': 0.2666666055336954, 'scr_metric_threshold_100': 0.3145161329087304, 'scr_dir2_threshold_100': 0.3145161329087304, 'scr_dir1_threshold_500': 0.29230760766203984, 'scr_metric_threshold_500': 0.4112902721865048, 'scr_dir2_threshold_500': 0.4112902721865048}, {'dataset_name': 'canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results', 'scr_dir1_threshold_2': 0.15695053001361284, 'scr_metric_threshold_2': 0.0714287044746317, 'scr_dir2_threshold_2': 0.0714287044746317, 'scr_dir1_threshold_5': 0.2331838049629021, 'scr_metric_threshold_5': 0.16517854648243513, 'scr_dir2_threshold_5': 0.16517854648243513, 'scr_dir1_threshold_10': 0.33632283160029924, 'scr_metric_threshold_10': 0.17857149509445872, 'scr_dir2_threshold_10': 0.17857149509445872, 'scr_dir1_threshold_20': 0.42600884875093514, 'scr_metric_threshold_20': 0.2857142857142857, 'scr_dir2_threshold_20': 0.2857142857142857, 'scr_dir1_threshold_50': 0.5201793805874345, 'scr_metric_threshold_50': 0.37499990021545476, 'scr_dir2_threshold_50': 0.37499990021545476, 'scr_dir1_threshold_100': 0.5650223891627525, 'scr_metric_threshold_100': 0.415178479959405, 'scr_dir2_threshold_100': 0.415178479959405, 'scr_dir1_threshold_500': 0.3273543367994015, 'scr_metric_threshold_500': 0.4687500083153788, 'scr_dir2_threshold_500': 0.4687500083153788}, {'dataset_name': 'canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results', 'scr_dir1_threshold_2': 0.05579403094120067, 'scr_metric_threshold_2': 0.05579403094120067, 'scr_dir2_threshold_2': 0.06190480515528994, 'scr_dir1_threshold_5': 0.07296144475494565, 'scr_metric_threshold_5': 0.07296144475494565, 'scr_dir2_threshold_5': 0.10476195612190681, 'scr_dir1_threshold_10': 0.1244634303822985, 'scr_metric_threshold_10': 0.1244634303822985, 'scr_dir2_threshold_10': 0.1571427922670651, 'scr_dir1_threshold_20': 0.17167388232356773, 'scr_metric_threshold_20': 0.17167388232356773, 'scr_dir2_threshold_20': 0.16666676127719673, 'scr_dir1_threshold_50': 0.17596567182353345, 'scr_metric_threshold_50': 0.17596567182353345, 'scr_dir2_threshold_50': 0.14285698066766273, 'scr_dir1_threshold_100': 0.20171666463720986, 'scr_metric_threshold_100': 0.20171666463720986, 'scr_dir2_threshold_100': 0.1571427922670651, 'scr_dir1_threshold_500': 0.23605149226469982, 'scr_metric_threshold_500': 0.23605149226469982, 'scr_dir2_threshold_500': 0.1619046348563358}], 'sae_bench_commit_hash': '60adde367f8d77d5f375d2bc8d39ed57e71595f0', 'sae_lens_id': 'custom_sae', 'sae_lens_release_id': 'google/gemma-2-2b_layer_12_sae', 'sae_lens_version': '5.3.0', 'sae_cfg_dict': {'model_name': 'google/gemma-2-2b', 'd_in': 2304, 'd_sae': 18432, 'hook_layer': 12, 'hook_name': 'blocks.12.hook_resid_post', 'context_size': None, 'hook_head_index': None, 'architecture': 'TopK', 'apply_b_dec_to_input': True, 'finetuning_scaling_factor': None, 'activation_fn_str': 'TopK', 'prepend_bos': True, 'normalize_activations': 'none', 'dtype': 'bfloat16', 'device': '', 'dataset_path': '', 'dataset_trust_remote_code': True, 'seqpos_slice': [None], 'training_tokens': -100000, 'sae_lens_training_version': None, 'neuronpedia_id': None}, 'eval_result_unstructured': None}, 'sparse probing evaluation results': {'eval_type_id': 'sparse_probing', 'eval_config': {'random_seed': 42, 'dataset_names': ['LabHC/bias_in_bios_class_set1', 'LabHC/bias_in_bios_class_set2', 'LabHC/bias_in_bios_class_set3', 'canrager/amazon_reviews_mcauley_1and5', 'canrager/amazon_reviews_mcauley_1and5_sentiment', 'codeparrot/github-code', 'fancyzhx/ag_news', 'Helsinki-NLP/europarl'], 'probe_train_set_size': 4000, 'probe_test_set_size': 1000, 'context_length': 128, 'sae_batch_size': 125, 'llm_batch_size': 32, 'llm_dtype': 'bfloat16', 'model_name': 'google/gemma-2-2b', 'k_values': [1, 2, 5, 10, 20, 50], 'lower_vram_usage': False}, 'eval_id': 'de1771b1-1543-4d2f-a6a8-28d5dd789f6e', 'datetime_epoch_millis': 1738262879913, 'eval_result_metrics': {'llm': {'llm_test_accuracy': 0.9510437500000001, 'llm_top_1_test_accuracy': 0.6663687500000001, 'llm_top_2_test_accuracy': 0.7159999999999999, 'llm_top_5_test_accuracy': 0.78038125, 'llm_top_10_test_accuracy': 0.8332875, 'llm_top_20_test_accuracy': 0.87871875, 'llm_top_50_test_accuracy': 0.9227, 'llm_top_100_test_accuracy': None}, 'sae': {'sae_test_accuracy': 0.9603125378489494, 'sae_top_1_test_accuracy': 0.7960375000000001, 'sae_top_2_test_accuracy': 0.8386062499999999, 'sae_top_5_test_accuracy': 0.87916875, 'sae_top_10_test_accuracy': 0.90693125, 'sae_top_20_test_accuracy': 0.9256937500000001, 'sae_top_50_test_accuracy': 0.9390124999999999, 'sae_top_100_test_accuracy': None}}, 'eval_result_details': [{'dataset_name': 'LabHC/bias_in_bios_class_set1_results', 'llm_test_accuracy': 0.9596, 'llm_top_1_test_accuracy': 0.6432, 'llm_top_2_test_accuracy': 0.6916, 'llm_top_5_test_accuracy': 0.7912, 'llm_top_10_test_accuracy': 0.8336, 'llm_top_20_test_accuracy': 0.8962, 'llm_top_50_test_accuracy': 0.9384, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.9680000424385071, 'sae_top_1_test_accuracy': 0.8231999999999999, 'sae_top_2_test_accuracy': 0.8662000000000001, 'sae_top_5_test_accuracy': 0.9026, 'sae_top_10_test_accuracy': 0.9198000000000001, 'sae_top_20_test_accuracy': 0.9338000000000001, 'sae_top_50_test_accuracy': 0.9538, 'sae_top_100_test_accuracy': None}, {'dataset_name': 'LabHC/bias_in_bios_class_set2_results', 'llm_test_accuracy': 0.9498000000000001, 'llm_top_1_test_accuracy': 0.6738000000000001, 'llm_top_2_test_accuracy': 0.7138, 'llm_top_5_test_accuracy': 0.7634000000000001, 'llm_top_10_test_accuracy': 0.8099999999999999, 'llm_top_20_test_accuracy': 0.8714000000000001, 'llm_top_50_test_accuracy': 0.9036000000000002, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.9518000483512878, 'sae_top_1_test_accuracy': 0.7727999999999999, 'sae_top_2_test_accuracy': 0.8100000000000002, 'sae_top_5_test_accuracy': 0.8492000000000001, 'sae_top_10_test_accuracy': 0.9027999999999998, 'sae_top_20_test_accuracy': 0.9198000000000001, 'sae_top_50_test_accuracy': 0.9356, 'sae_top_100_test_accuracy': None}, {'dataset_name': 'LabHC/bias_in_bios_class_set3_results', 'llm_test_accuracy': 0.9103999999999999, 'llm_top_1_test_accuracy': 0.6928000000000001, 'llm_top_2_test_accuracy': 0.7366, 'llm_top_5_test_accuracy': 0.7564, 'llm_top_10_test_accuracy': 0.8016, 'llm_top_20_test_accuracy': 0.8508000000000001, 'llm_top_50_test_accuracy': 0.8962, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.9362000346183776, 'sae_top_1_test_accuracy': 0.7886000000000001, 'sae_top_2_test_accuracy': 0.8242, 'sae_top_5_test_accuracy': 0.8573999999999999, 'sae_top_10_test_accuracy': 0.8821999999999999, 'sae_top_20_test_accuracy': 0.8986000000000001, 'sae_top_50_test_accuracy': 0.9019999999999999, 'sae_top_100_test_accuracy': None}, {'dataset_name': 'canrager/amazon_reviews_mcauley_1and5_results', 'llm_test_accuracy': 0.9030000000000001, 'llm_top_1_test_accuracy': 0.6176, 'llm_top_2_test_accuracy': 0.6417999999999999, 'llm_top_5_test_accuracy': 0.6740000000000002, 'llm_top_10_test_accuracy': 0.7554000000000001, 'llm_top_20_test_accuracy': 0.8074, 'llm_top_50_test_accuracy': 0.8564, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.9218000411987305, 'sae_top_1_test_accuracy': 0.7404000000000001, 'sae_top_2_test_accuracy': 0.7754, 'sae_top_5_test_accuracy': 0.8224, 'sae_top_10_test_accuracy': 0.8291999999999999, 'sae_top_20_test_accuracy': 0.8658000000000001, 'sae_top_50_test_accuracy': 0.8785999999999999, 'sae_top_100_test_accuracy': None}, {'dataset_name': 'canrager/amazon_reviews_mcauley_1and5_sentiment_results', 'llm_test_accuracy': 0.981, 'llm_top_1_test_accuracy': 0.671, 'llm_top_2_test_accuracy': 0.724, 'llm_top_5_test_accuracy': 0.766, 'llm_top_10_test_accuracy': 0.826, 'llm_top_20_test_accuracy': 0.847, 'llm_top_50_test_accuracy': 0.9325000000000001, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.9785000383853912, 'sae_top_1_test_accuracy': 0.9, 'sae_top_2_test_accuracy': 0.919, 'sae_top_5_test_accuracy': 0.935, 'sae_top_10_test_accuracy': 0.949, 'sae_top_20_test_accuracy': 0.966, 'sae_top_50_test_accuracy': 0.972, 'sae_top_100_test_accuracy': None}, {'dataset_name': 'codeparrot/github-code_results', 'llm_test_accuracy': 0.9678000000000001, 'llm_top_1_test_accuracy': 0.6456, 'llm_top_2_test_accuracy': 0.6936000000000001, 'llm_top_5_test_accuracy': 0.768, 'llm_top_10_test_accuracy': 0.7974, 'llm_top_20_test_accuracy': 0.8684, 'llm_top_50_test_accuracy': 0.9284000000000001, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.9736000299453735, 'sae_top_1_test_accuracy': 0.6056, 'sae_top_2_test_accuracy': 0.7094, 'sae_top_5_test_accuracy': 0.8082, 'sae_top_10_test_accuracy': 0.8699999999999999, 'sae_top_20_test_accuracy': 0.9032, 'sae_top_50_test_accuracy': 0.9376, 'sae_top_100_test_accuracy': None}, {'dataset_name': 'fancyzhx/ag_news_results', 'llm_test_accuracy': 0.93775, 'llm_top_1_test_accuracy': 0.65875, 'llm_top_2_test_accuracy': 0.738, 'llm_top_5_test_accuracy': 0.8182499999999999, 'llm_top_10_test_accuracy': 0.8775000000000001, 'llm_top_20_test_accuracy': 0.89675, 'llm_top_50_test_accuracy': 0.9285, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.9530000388622284, 'sae_top_1_test_accuracy': 0.7965, 'sae_top_2_test_accuracy': 0.86225, 'sae_top_5_test_accuracy': 0.89575, 'sae_top_10_test_accuracy': 0.91225, 'sae_top_20_test_accuracy': 0.9247500000000001, 'sae_top_50_test_accuracy': 0.9345, 'sae_top_100_test_accuracy': None}, {'dataset_name': 'Helsinki-NLP/europarl_results', 'llm_test_accuracy': 0.999, 'llm_top_1_test_accuracy': 0.7282, 'llm_top_2_test_accuracy': 0.7886, 'llm_top_5_test_accuracy': 0.9057999999999999, 'llm_top_10_test_accuracy': 0.9648, 'llm_top_20_test_accuracy': 0.9917999999999999, 'llm_top_50_test_accuracy': 0.9975999999999999, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.9996000289916992, 'sae_top_1_test_accuracy': 0.9411999999999999, 'sae_top_2_test_accuracy': 0.9423999999999999, 'sae_top_5_test_accuracy': 0.9628, 'sae_top_10_test_accuracy': 0.9902, 'sae_top_20_test_accuracy': 0.9936, 'sae_top_50_test_accuracy': 0.998, 'sae_top_100_test_accuracy': None}], 'sae_bench_commit_hash': '60adde367f8d77d5f375d2bc8d39ed57e71595f0', 'sae_lens_id': 'custom_sae', 'sae_lens_release_id': 'google/gemma-2-2b_layer_12_sae', 'sae_lens_version': '5.3.0', 'sae_cfg_dict': {'model_name': 'google/gemma-2-2b', 'd_in': 2304, 'd_sae': 18432, 'hook_layer': 12, 'hook_name': 'blocks.12.hook_resid_post', 'context_size': None, 'hook_head_index': None, 'architecture': 'TopK', 'apply_b_dec_to_input': True, 'finetuning_scaling_factor': None, 'activation_fn_str': 'TopK', 'prepend_bos': True, 'normalize_activations': 'none', 'dtype': 'bfloat16', 'device': '', 'dataset_path': '', 'dataset_trust_remote_code': True, 'seqpos_slice': [None], 'training_tokens': -100000, 'sae_lens_training_version': None, 'neuronpedia_id': None}, 'eval_result_unstructured': None}}
Baseline results from standard SAE: 
{'scr and tpp evaluations results': {'eval_type_id': 'scr', 'eval_config': {'random_seed': 42, 'dataset_names': ['LabHC/bias_in_bios_class_set1', 'canrager/amazon_reviews_mcauley_1and5'], 'perform_scr': True, 'early_stopping_patience': 20, 'train_set_size': 4000, 'test_set_size': 1000, 'context_length': 128, 'probe_train_batch_size': 16, 'probe_test_batch_size': 500, 'probe_epochs': 20, 'probe_lr': 0.001, 'probe_l1_penalty': 0.001, 'sae_batch_size': 125, 'llm_batch_size': 32, 'llm_dtype': 'bfloat16', 'lower_vram_usage': False, 'model_name': 'google/gemma-2-2b', 'n_values': [2, 5, 10, 20, 50, 100, 500], 'column1_vals_lookup': {'LabHC/bias_in_bios_class_set1': [['professor', 'nurse'], ['architect', 'journalist'], ['surgeon', 'psychologist'], ['attorney', 'teacher']], 'canrager/amazon_reviews_mcauley_1and5': [['Books', 'CDs_and_Vinyl'], ['Software', 'Electronics'], ['Pet_Supplies', 'Office_Products'], ['Industrial_and_Scientific', 'Toys_and_Games']]}}, 'eval_id': '88e96fee-c5d3-4b15-b62c-29dcb732617d', 'datetime_epoch_millis': 1738265246728, 'eval_result_metrics': {'scr_metrics': {'scr_dir1_threshold_2': 0.024986714927972265, 'scr_metric_threshold_2': 0.043177525387746135, 'scr_dir2_threshold_2': 0.03614451488393293, 'scr_dir1_threshold_5': -0.027872434927972194, 'scr_metric_threshold_5': 0.0498206383435329, 'scr_dir2_threshold_5': 0.04332413350395067, 'scr_dir1_threshold_10': -0.07679448697169464, 'scr_metric_threshold_10': 0.046435468185911946, 'scr_dir2_threshold_10': 0.03922618427139585, 'scr_dir1_threshold_20': -0.08163246728835066, 'scr_metric_threshold_20': 0.05054452921164445, 'scr_dir2_threshold_20': 0.0492876194916143, 'scr_dir1_threshold_50': -0.2075173334645364, 'scr_metric_threshold_50': 0.06036789689420945, 'scr_dir2_threshold_50': 0.05047621256547952, 'scr_dir1_threshold_100': -0.30730415313533227, 'scr_metric_threshold_100': 0.03447109483181842, 'scr_dir2_threshold_100': 0.024344380456222475, 'scr_dir1_threshold_500': -0.29790819886806863, 'scr_metric_threshold_500': 0.03959443079463576, 'scr_dir2_threshold_500': 0.02714555176056758}}, 'eval_result_details': [{'dataset_name': 'LabHC/bias_in_bios_class_set1_scr_professor_nurse_results', 'scr_dir1_threshold_2': 0.015624810824956856, 'scr_metric_threshold_2': 0.009828028179079856, 'scr_dir2_threshold_2': 0.009828028179079856, 'scr_dir1_threshold_5': -0.23437588766751014, 'scr_metric_threshold_5': 0.03439802540241183, 'scr_dir2_threshold_5': 0.03439802540241183, 'scr_dir1_threshold_10': -0.18750052386935023, 'scr_metric_threshold_10': 0.04422605358149169, 'scr_dir2_threshold_10': 0.04422605358149169, 'scr_dir1_threshold_20': -0.18750052386935023, 'scr_metric_threshold_20': 0.08845210716298338, 'scr_dir2_threshold_20': 0.08845210716298338, 'scr_dir1_threshold_50': -0.8125013387772284, 'scr_metric_threshold_50': 0.07862407898390353, 'scr_dir2_threshold_50': 0.07862407898390353, 'scr_dir1_threshold_100': -1.2968760622906268, 'scr_metric_threshold_100': 0.13759224805838266, 'scr_dir2_threshold_100': 0.13759224805838266, 'scr_dir1_threshold_500': -1.2656264406407132, 'scr_metric_threshold_500': 0.1597051284003932, 'scr_dir2_threshold_500': 0.1597051284003932}, {'dataset_name': 'LabHC/bias_in_bios_class_set1_scr_architect_journalist_results', 'scr_dir1_threshold_2': 0.02912584278375721, 'scr_metric_threshold_2': 0.08882510185734234, 'scr_dir2_threshold_2': 0.08882510185734234, 'scr_dir1_threshold_5': -0.12621372145414522, 'scr_metric_threshold_5': 0.08309451623569147, 'scr_dir2_threshold_5': 0.08309451623569147, 'scr_dir1_threshold_10': -0.4466020428771571, 'scr_metric_threshold_10': 0.03151856249299773, 'scr_dir2_threshold_10': 0.03151856249299773, 'scr_dir1_threshold_20': -0.3592233571539762, 'scr_metric_threshold_20': 0.03151856249299773, 'scr_dir2_threshold_20': 0.03151856249299773, 'scr_dir1_threshold_50': -0.3106797071617595, 'scr_metric_threshold_50': 0.051575953742693734, 'scr_dir2_threshold_50': 0.051575953742693734, 'scr_dir1_threshold_100': -0.33980612863147136, 'scr_metric_threshold_100': 0.06590258858377988, 'scr_dir2_threshold_100': 0.06590258858377988, 'scr_dir1_threshold_500': -0.2912624786392547, 'scr_metric_threshold_500': 0.06303729577295444, 'scr_dir2_threshold_500': 0.06303729577295444}, {'dataset_name': 'LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results', 'scr_dir1_threshold_2': -0.04761841688229979, 'scr_metric_threshold_2': 0.0075949890455728015, 'scr_dir2_threshold_2': 0.0075949890455728015, 'scr_dir1_threshold_5': -0.1587299484845761, 'scr_metric_threshold_5': 0.03291141800038962, 'scr_dir2_threshold_5': 0.03291141800038962, 'scr_dir1_threshold_10': -0.1111105854971546, 'scr_metric_threshold_10': 0.06582283600077923, 'scr_dir2_threshold_10': 0.06582283600077923, 'scr_dir1_threshold_20': -0.2380949227268642, 'scr_metric_threshold_20': 0.06582283600077923, 'scr_dir2_threshold_20': 0.06582283600077923, 'scr_dir1_threshold_50': -0.3333327025965855, 'scr_metric_threshold_50': 0.07341782504635204, 'scr_dir2_threshold_50': 0.07341782504635204, 'scr_dir1_threshold_100': -0.7777769367954473, 'scr_metric_threshold_100': 0.08354442680784264, 'scr_dir2_threshold_100': 0.08354442680784264, 'scr_dir1_threshold_500': -0.7777769367954473, 'scr_metric_threshold_500': 0.09367087767151386, 'scr_dir2_threshold_500': 0.09367087767151386}, {'dataset_name': 'LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results', 'scr_dir1_threshold_2': -0.015624796273220196, 'scr_metric_threshold_2': 0.017804278163016753, 'scr_dir2_threshold_2': 0.017804278163016753, 'scr_dir1_threshold_5': 0.015625261934431176, 'scr_metric_threshold_5': 0.044510518539166266, 'scr_dir2_threshold_5': 0.044510518539166266, 'scr_dir1_threshold_10': -0.062499650754091765, 'scr_metric_threshold_10': 0.04747783927687718, 'scr_dir2_threshold_10': 0.04747783927687718, 'scr_dir1_threshold_20': -0.05468725261748167, 'scr_metric_threshold_20': 0.044510518539166266, 'scr_dir2_threshold_20': 0.044510518539166266, 'scr_dir1_threshold_50': -0.17968748544808716, 'scr_metric_threshold_50': 0.07121675891531577, 'scr_dir2_threshold_50': 0.07121675891531577, 'scr_dir1_threshold_100': -0.17187462165026607, 'scr_metric_threshold_100': 0.05934729909609648, 'scr_dir2_threshold_100': 0.05934729909609648, 'scr_dir1_threshold_500': -0.16406222351365599, 'scr_metric_threshold_500': 0.0623146198338074, 'scr_dir2_threshold_500': 0.0623146198338074}, {'dataset_name': 'canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results', 'scr_dir1_threshold_2': 0.08743153202478901, 'scr_metric_threshold_2': 0.04313739148158649, 'scr_dir2_threshold_2': 0.04313739148158649, 'scr_dir1_threshold_5': 0.08743153202478901, 'scr_metric_threshold_5': 0.09019606651502937, 'scr_dir2_threshold_5': 0.09019606651502937, 'scr_dir1_threshold_10': 0.1092894964580841, 'scr_metric_threshold_10': 0.07843151462849601, 'scr_dir2_threshold_10': 0.07843151462849601, 'scr_dir1_threshold_20': 0.1311474608913792, 'scr_metric_threshold_20': 0.07450976358933016, 'scr_dir2_threshold_20': 0.07450976358933016, 'scr_dir1_threshold_50': -0.03278678379574697, 'scr_metric_threshold_50': 0.13333345799661586, 'scr_dir2_threshold_50': 0.13333345799661586, 'scr_dir1_threshold_100': 0.1092894964580841, 'scr_metric_threshold_100': -0.07450976358933016, 'scr_dir2_threshold_100': -0.07450976358933016, 'scr_dir1_threshold_500': 0.08743153202478901, 'scr_metric_threshold_500': -0.07058824629381905, 'scr_dir2_threshold_500': -0.07058824629381905}, {'dataset_name': 'canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results', 'scr_dir1_threshold_2': 0.025641002128344394, 'scr_metric_threshold_2': 0.10887099681547797, 'scr_dir2_threshold_2': 0.10887099681547797, 'scr_dir1_threshold_5': 0.020512557170790546, 'scr_metric_threshold_5': 0.04838718980952953, 'scr_dir2_threshold_5': 0.04838718980952953, 'scr_dir1_threshold_10': -0.0666667277996379, 'scr_metric_threshold_10': 0.056451601273808806, 'scr_dir2_threshold_10': 0.056451601273808806, 'scr_dir1_threshold_20': 0.025641002128344394, 'scr_metric_threshold_20': 0.056451601273808806, 'scr_dir2_threshold_20': 0.056451601273808806, 'scr_dir1_threshold_50': 0.020512557170790546, 'scr_metric_threshold_50': -0.012096617196418915, 'scr_dir2_threshold_50': -0.012096617196418915, 'scr_dir1_threshold_100': 0.05641014354938642, 'scr_metric_threshold_100': -0.05241939554166917, 'scr_dir2_threshold_100': -0.05241939554166917, 'scr_dir1_threshold_500': 0.06153828284208406, 'scr_metric_threshold_500': -0.056451601273808806, 'scr_dir2_threshold_500': -0.056451601273808806}, {'dataset_name': 'canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results', 'scr_dir1_threshold_2': 0.053811503376215715, 'scr_metric_threshold_2': 0.017857176118657926, 'scr_dir2_threshold_2': 0.017857176118657926, 'scr_dir1_threshold_5': 0.12556053092505612, 'scr_metric_threshold_5': 0.017857176118657926, 'scr_dir2_threshold_5': 0.017857176118657926, 'scr_dir1_threshold_10': 0.11210752143829489, 'scr_metric_threshold_10': 0.008928721105389243, 'scr_dir2_threshold_10': 0.008928721105389243, 'scr_dir1_threshold_20': -0.008968762086312341, 'scr_metric_threshold_20': 0.0044642275066343415, 'scr_dir2_threshold_20': 0.0044642275066343415, 'scr_dir1_threshold_50': -0.0717490275488404, 'scr_metric_threshold_50': 0.02678589722404717, 'scr_dir2_threshold_50': 0.02678589722404717, 'scr_dir1_threshold_100': -0.08071752234973815, 'scr_metric_threshold_100': 0.013392948612023585, 'scr_dir2_threshold_100': 0.013392948612023585, 'scr_dir1_threshold_500': -0.08071752234973815, 'scr_metric_threshold_500': 0.017857176118657926, 'scr_dir2_threshold_500': 0.017857176118657926}, {'dataset_name': 'canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results', 'scr_dir1_threshold_2': 0.05150224144123495, 'scr_metric_threshold_2': 0.05150224144123495, 'scr_dir2_threshold_2': -0.004761842589270712, 'scr_dir1_threshold_5': 0.047210196127387125, 'scr_metric_threshold_5': 0.047210196127387125, 'scr_dir2_threshold_5': -0.004761842589270712, 'scr_dir1_threshold_10': 0.03862661712745569, 'scr_metric_threshold_10': 0.03862661712745569, 'scr_dir2_threshold_10': -0.019047654188673074, 'scr_dir1_threshold_20': 0.03862661712745569, 'scr_metric_threshold_20': 0.03862661712745569, 'scr_dir2_threshold_20': 0.0285713393672145, 'scr_dir1_threshold_50': 0.060085820441166386, 'scr_metric_threshold_50': 0.060085820441166386, 'scr_dir2_threshold_50': -0.019047654188673074, 'scr_dir1_threshold_100': 0.042918406627421406, 'scr_metric_threshold_100': 0.042918406627421406, 'scr_dir2_threshold_100': -0.03809530837734615, 'scr_dir1_threshold_500': 0.047210196127387125, 'scr_metric_threshold_500': 0.047210196127387125, 'scr_dir2_threshold_500': -0.05238083614515829}], 'sae_bench_commit_hash': '1c64f65e68c0e3cdaf116a205182859fd51f77f7', 'sae_lens_id': 'custom_sae', 'sae_lens_release_id': 'google/gemma-2-2b_layer_12_sae', 'sae_lens_version': '5.3.0', 'sae_cfg_dict': {'model_name': 'google/gemma-2-2b', 'd_in': 2304, 'd_sae': 18432, 'hook_layer': 12, 'hook_name': 'blocks.12.hook_resid_post', 'context_size': None, 'hook_head_index': None, 'architecture': 'Custom', 'apply_b_dec_to_input': True, 'finetuning_scaling_factor': None, 'activation_fn_str': 'relu', 'prepend_bos': True, 'normalize_activations': 'none', 'dtype': 'bfloat16', 'device': '', 'dataset_path': '', 'dataset_trust_remote_code': True, 'seqpos_slice': [None], 'training_tokens': -100000, 'sae_lens_training_version': None, 'neuronpedia_id': None}, 'eval_result_unstructured': None}, 'sparse probing evaluation results': {'eval_type_id': 'sparse_probing', 'eval_config': {'random_seed': 42, 'dataset_names': ['LabHC/bias_in_bios_class_set1', 'LabHC/bias_in_bios_class_set2', 'LabHC/bias_in_bios_class_set3', 'canrager/amazon_reviews_mcauley_1and5', 'canrager/amazon_reviews_mcauley_1and5_sentiment', 'codeparrot/github-code', 'fancyzhx/ag_news', 'Helsinki-NLP/europarl'], 'probe_train_set_size': 4000, 'probe_test_set_size': 1000, 'context_length': 128, 'sae_batch_size': 125, 'llm_batch_size': 32, 'llm_dtype': 'bfloat16', 'model_name': 'google/gemma-2-2b', 'k_values': [1, 2, 5, 10, 20, 50], 'lower_vram_usage': False}, 'eval_id': '47ec66f1-cfac-489c-ae4d-518b86f5565f', 'datetime_epoch_millis': 1738266791518, 'eval_result_metrics': {'llm': {'llm_test_accuracy': 0.9499875, 'llm_top_1_test_accuracy': 0.6543625, 'llm_top_2_test_accuracy': 0.71773125, 'llm_top_5_test_accuracy': 0.7809625, 'llm_top_10_test_accuracy': 0.8308812499999999, 'llm_top_20_test_accuracy': 0.87641875, 'llm_top_50_test_accuracy': 0.9223499999999999, 'llm_top_100_test_accuracy': None}, 'sae': {'sae_test_accuracy': 0.8769375406205654, 'sae_top_1_test_accuracy': 0.62393125, 'sae_top_2_test_accuracy': 0.6743937500000001, 'sae_top_5_test_accuracy': 0.7260875, 'sae_top_10_test_accuracy': 0.7787999999999999, 'sae_top_20_test_accuracy': 0.82108125, 'sae_top_50_test_accuracy': 0.86705625, 'sae_top_100_test_accuracy': None}}, 'eval_result_details': [{'dataset_name': 'LabHC/bias_in_bios_class_set1_results', 'llm_test_accuracy': 0.9596, 'llm_top_1_test_accuracy': 0.6432, 'llm_top_2_test_accuracy': 0.6916, 'llm_top_5_test_accuracy': 0.7912, 'llm_top_10_test_accuracy': 0.8336, 'llm_top_20_test_accuracy': 0.8962, 'llm_top_50_test_accuracy': 0.9384, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.906600046157837, 'sae_top_1_test_accuracy': 0.6292, 'sae_top_2_test_accuracy': 0.6846, 'sae_top_5_test_accuracy': 0.705, 'sae_top_10_test_accuracy': 0.7652, 'sae_top_20_test_accuracy': 0.8523999999999999, 'sae_top_50_test_accuracy': 0.9077999999999999, 'sae_top_100_test_accuracy': None}, {'dataset_name': 'LabHC/bias_in_bios_class_set2_results', 'llm_test_accuracy': 0.9489999999999998, 'llm_top_1_test_accuracy': 0.6728, 'llm_top_2_test_accuracy': 0.7150000000000001, 'llm_top_5_test_accuracy': 0.7615999999999999, 'llm_top_10_test_accuracy': 0.807, 'llm_top_20_test_accuracy': 0.8638, 'llm_top_50_test_accuracy': 0.909, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.8836000323295593, 'sae_top_1_test_accuracy': 0.6686, 'sae_top_2_test_accuracy': 0.7066000000000001, 'sae_top_5_test_accuracy': 0.7623999999999999, 'sae_top_10_test_accuracy': 0.7846, 'sae_top_20_test_accuracy': 0.8274000000000001, 'sae_top_50_test_accuracy': 0.868, 'sae_top_100_test_accuracy': None}, {'dataset_name': 'LabHC/bias_in_bios_class_set3_results', 'llm_test_accuracy': 0.9156000000000001, 'llm_top_1_test_accuracy': 0.689, 'llm_top_2_test_accuracy': 0.7362, 'llm_top_5_test_accuracy': 0.7598, 'llm_top_10_test_accuracy': 0.7974, 'llm_top_20_test_accuracy': 0.8460000000000001, 'llm_top_50_test_accuracy': 0.889, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.8686000347137451, 'sae_top_1_test_accuracy': 0.6617999999999998, 'sae_top_2_test_accuracy': 0.72, 'sae_top_5_test_accuracy': 0.7556, 'sae_top_10_test_accuracy': 0.7766, 'sae_top_20_test_accuracy': 0.8276, 'sae_top_50_test_accuracy': 0.8591999999999999, 'sae_top_100_test_accuracy': None}, {'dataset_name': 'canrager/amazon_reviews_mcauley_1and5_results', 'llm_test_accuracy': 0.8942, 'llm_top_1_test_accuracy': 0.6083999999999999, 'llm_top_2_test_accuracy': 0.6397999999999999, 'llm_top_5_test_accuracy': 0.6768000000000001, 'llm_top_10_test_accuracy': 0.7484, 'llm_top_20_test_accuracy': 0.8076000000000001, 'llm_top_50_test_accuracy': 0.8632, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.7710000395774841, 'sae_top_1_test_accuracy': 0.5630000000000001, 'sae_top_2_test_accuracy': 0.585, 'sae_top_5_test_accuracy': 0.6176, 'sae_top_10_test_accuracy': 0.6784, 'sae_top_20_test_accuracy': 0.7091999999999999, 'sae_top_50_test_accuracy': 0.7696, 'sae_top_100_test_accuracy': None}, {'dataset_name': 'canrager/amazon_reviews_mcauley_1and5_sentiment_results', 'llm_test_accuracy': 0.981, 'llm_top_1_test_accuracy': 0.671, 'llm_top_2_test_accuracy': 0.724, 'llm_top_5_test_accuracy': 0.766, 'llm_top_10_test_accuracy': 0.826, 'llm_top_20_test_accuracy': 0.847, 'llm_top_50_test_accuracy': 0.933, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.8995000422000885, 'sae_top_1_test_accuracy': 0.635, 'sae_top_2_test_accuracy': 0.701, 'sae_top_5_test_accuracy': 0.72, 'sae_top_10_test_accuracy': 0.84, 'sae_top_20_test_accuracy': 0.852, 'sae_top_50_test_accuracy': 0.889, 'sae_top_100_test_accuracy': None}, {'dataset_name': 'codeparrot/github-code_results', 'llm_test_accuracy': 0.9638, 'llm_top_1_test_accuracy': 0.661, 'llm_top_2_test_accuracy': 0.6996, 'llm_top_5_test_accuracy': 0.7575999999999999, 'llm_top_10_test_accuracy': 0.806, 'llm_top_20_test_accuracy': 0.869, 'llm_top_50_test_accuracy': 0.9282, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.8808000445365906, 'sae_top_1_test_accuracy': 0.6106, 'sae_top_2_test_accuracy': 0.6536, 'sae_top_5_test_accuracy': 0.706, 'sae_top_10_test_accuracy': 0.7878000000000001, 'sae_top_20_test_accuracy': 0.8166, 'sae_top_50_test_accuracy': 0.8632, 'sae_top_100_test_accuracy': None}, {'dataset_name': 'fancyzhx/ag_news_results', 'llm_test_accuracy': 0.9375, 'llm_top_1_test_accuracy': 0.6415, 'llm_top_2_test_accuracy': 0.75425, 'llm_top_5_test_accuracy': 0.8245, 'llm_top_10_test_accuracy': 0.86925, 'llm_top_20_test_accuracy': 0.8917499999999999, 'llm_top_50_test_accuracy': 0.922, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.8860000371932983, 'sae_top_1_test_accuracy': 0.60825, 'sae_top_2_test_accuracy': 0.6637500000000001, 'sae_top_5_test_accuracy': 0.7844999999999999, 'sae_top_10_test_accuracy': 0.8029999999999999, 'sae_top_20_test_accuracy': 0.83725, 'sae_top_50_test_accuracy': 0.8792500000000001, 'sae_top_100_test_accuracy': None}, {'dataset_name': 'Helsinki-NLP/europarl_results', 'llm_test_accuracy': 0.9992000000000001, 'llm_top_1_test_accuracy': 0.648, 'llm_top_2_test_accuracy': 0.7814, 'llm_top_5_test_accuracy': 0.9102, 'llm_top_10_test_accuracy': 0.9593999999999999, 'llm_top_20_test_accuracy': 0.99, 'llm_top_50_test_accuracy': 0.9959999999999999, 'llm_top_100_test_accuracy': None, 'sae_test_accuracy': 0.9194000482559204, 'sae_top_1_test_accuracy': 0.615, 'sae_top_2_test_accuracy': 0.6806, 'sae_top_5_test_accuracy': 0.7575999999999999, 'sae_top_10_test_accuracy': 0.7948000000000001, 'sae_top_20_test_accuracy': 0.8462, 'sae_top_50_test_accuracy': 0.9004, 'sae_top_100_test_accuracy': None}], 'sae_bench_commit_hash': '1c64f65e68c0e3cdaf116a205182859fd51f77f7', 'sae_lens_id': 'custom_sae', 'sae_lens_release_id': 'google/gemma-2-2b_layer_12_sae', 'sae_lens_version': '5.3.0', 'sae_cfg_dict': {'model_name': 'google/gemma-2-2b', 'd_in': 2304, 'd_sae': 18432, 'hook_layer': 12, 'hook_name': 'blocks.12.hook_resid_post', 'context_size': None, 'hook_head_index': None, 'architecture': 'Custom', 'apply_b_dec_to_input': True, 'finetuning_scaling_factor': None, 'activation_fn_str': 'relu', 'prepend_bos': True, 'normalize_activations': 'none', 'dtype': 'bfloat16', 'device': '', 'dataset_path': '', 'dataset_trust_remote_code': True, 'seqpos_slice': [None], 'training_tokens': -100000, 'sae_lens_training_version': None, 'neuronpedia_id': None}, 'eval_result_unstructured': None}, 'unlearning evaluation results': {'eval_type_id': 'unlearning', 'eval_config': {'random_seed': 42, 'dataset_names': ['wmdp-bio', 'high_school_us_history', 'college_computer_science', 'high_school_geography', 'human_aging'], 'intervention_method': 'clamp_feature_activation', 'retain_thresholds': [0.001, 0.005, 0.01, 0.02], 'n_features_list': [10, 100, 1000], 'multipliers': [10, 25, 50, 100, 200], 'dataset_size': 1024, 'seq_len': 1024, 'n_batch_loss_added': 50, 'target_metric': 'correct', 'save_metrics': True, 'model_name': 'google/gemma-2-2b-it', 'llm_batch_size': 32, 'llm_dtype': 'bfloat16'}, 'eval_id': '1082bce9-016e-4812-a308-6cc35a564822', 'datetime_epoch_millis': 1738184748213, 'eval_result_metrics': {'unlearning': {'unlearning_score': 0.02808988094329834}}, 'eval_result_details': [], 'sae_bench_commit_hash': '60adde367f8d77d5f375d2bc8d39ed57e71595f0', 'sae_lens_id': 'custom_sae', 'sae_lens_release_id': 'google/gemma-2-2b_layer_12_sae', 'sae_lens_version': '5.3.0', 'sae_cfg_dict': {'model_name': 'google/gemma-2-2b', 'd_in': 2304, 'd_sae': 65536, 'hook_layer': 12, 'hook_name': 'blocks.12.hook_resid_post', 'context_size': None, 'hook_head_index': None, 'architecture': 'JumpReLU', 'apply_b_dec_to_input': True, 'finetuning_scaling_factor': None, 'activation_fn_str': 'jumprelu', 'prepend_bos': True, 'normalize_activations': 'none', 'dtype': 'bfloat16', 'device': '', 'dataset_path': '', 'dataset_trust_remote_code': True, 'seqpos_slice': [None], 'training_tokens': -100000, 'sae_lens_training_version': None, 'neuronpedia_id': None, 'jump_coeff': 0.1}, 'eval_result_unstructured': None}, 'training results for layer 12': {'config': {'trainer_class': 'CustomTrainer', 'activation_dim': 2304, 'dict_size': 18432, 'lr': 0.0009, 'l1_penalty': 0.04, 'warmup_steps': 1000, 'resample_steps': None, 'device': 'cuda', 'layer': 12, 'lm_name': 'google/gemma-2-2b', 'wandb_name': 'CustomTrainer', 'submodule_name': 'resid_post_layer_12'}, 'final_info': {'training_steps': 4882, 'final_loss': 100.08680725097656, 'layer': 12, 'dict_size': 18432, 'learning_rate': 0.0009, 'sparsity_penalty': 0.04}}, 'absorption evaluation results': {'eval_type_id': 'absorption_first_letter', 'eval_config': {'model_name': 'google/gemma-2-2b', 'random_seed': 42, 'f1_jump_threshold': 0.03, 'max_k_value': 10, 'prompt_template': '{word} has the first letter:', 'prompt_token_pos': -6, 'llm_batch_size': 32, 'llm_dtype': 'bfloat16', 'k_sparse_probe_l1_decay': 0.01, 'k_sparse_probe_batch_size': 4096, 'k_sparse_probe_num_epochs': 50}, 'eval_id': 'ad2d746a-a110-461e-ad6d-ddcf9b6276e5', 'datetime_epoch_millis': 1738262973106, 'eval_result_metrics': {'mean': {'mean_absorption_score': 0.006518148628764265, 'mean_num_split_features': 1.04}}, 'eval_result_details': [{'first_letter': 'a', 'absorption_rate': 0.0003897116134060795, 'num_absorption': 1, 'num_probe_true_positives': 2566, 'num_split_features': 1}, {'first_letter': 'b', 'absorption_rate': 0.03848620910840282, 'num_absorption': 60, 'num_probe_true_positives': 1559, 'num_split_features': 1}, {'first_letter': 'c', 'absorption_rate': 0.0, 'num_absorption': 0, 'num_probe_true_positives': 2834, 'num_split_features': 1}, {'first_letter': 'd', 'absorption_rate': 0.0, 'num_absorption': 0, 'num_probe_true_positives': 1648, 'num_split_features': 1}, {'first_letter': 'e', 'absorption_rate': 0.043151969981238276, 'num_absorption': 69, 'num_probe_true_positives': 1599, 'num_split_features': 1}, {'first_letter': 'f', 'absorption_rate': 0.0, 'num_absorption': 0, 'num_probe_true_positives': 1196, 'num_split_features': 1}, {'first_letter': 'g', 'absorption_rate': 0.0027397260273972603, 'num_absorption': 3, 'num_probe_true_positives': 1095, 'num_split_features': 1}, {'first_letter': 'h', 'absorption_rate': 0.005065856129685917, 'num_absorption': 5, 'num_probe_true_positives': 987, 'num_split_features': 1}, {'first_letter': 'i', 'absorption_rate': 0.005389221556886228, 'num_absorption': 9, 'num_probe_true_positives': 1670, 'num_split_features': 2}, {'first_letter': 'j', 'absorption_rate': 0.015317286652078774, 'num_absorption': 7, 'num_probe_true_positives': 457, 'num_split_features': 1}, {'first_letter': 'k', 'absorption_rate': 0.0, 'num_absorption': 0, 'num_probe_true_positives': 718, 'num_split_features': 1}, {'first_letter': 'l', 'absorption_rate': 0.0, 'num_absorption': 0, 'num_probe_true_positives': 1137, 'num_split_features': 1}, {'first_letter': 'm', 'absorption_rate': 0.0, 'num_absorption': 0, 'num_probe_true_positives': 1869, 'num_split_features': 1}, {'first_letter': 'n', 'absorption_rate': 0.001128668171557562, 'num_absorption': 1, 'num_probe_true_positives': 886, 'num_split_features': 1}, {'first_letter': 'o', 'absorption_rate': 0.014605647517039922, 'num_absorption': 15, 'num_probe_true_positives': 1027, 'num_split_features': 1}, {'first_letter': 'p', 'absorption_rate': 0.0, 'num_absorption': 0, 'num_probe_true_positives': 2280, 'num_split_features': 1}, {'first_letter': 'q', 'absorption_rate': 0.0, 'num_absorption': 0, 'num_probe_true_positives': 178, 'num_split_features': 1}, {'first_letter': 'r', 'absorption_rate': 0.0047789725209080045, 'num_absorption': 8, 'num_probe_true_positives': 1674, 'num_split_features': 1}, {'first_letter': 's', 'absorption_rate': 0.0, 'num_absorption': 0, 'num_probe_true_positives': 2926, 'num_split_features': 1}, {'first_letter': 't', 'absorption_rate': 0.0036036036036036037, 'num_absorption': 6, 'num_probe_true_positives': 1665, 'num_split_features': 1}, {'first_letter': 'u', 'absorption_rate': 0.0, 'num_absorption': 0, 'num_probe_true_positives': 727, 'num_split_features': 1}, {'first_letter': 'v', 'absorption_rate': 0.0, 'num_absorption': 0, 'num_probe_true_positives': 828, 'num_split_features': 1}, {'first_letter': 'w', 'absorption_rate': 0.019287833827893175, 'num_absorption': 13, 'num_probe_true_positives': 674, 'num_split_features': 1}, {'first_letter': 'y', 'absorption_rate': 0.0, 'num_absorption': 0, 'num_probe_true_positives': 149, 'num_split_features': 1}, {'first_letter': 'z', 'absorption_rate': 0.009009009009009009, 'num_absorption': 2, 'num_probe_true_positives': 222, 'num_split_features': 1}], 'sae_bench_commit_hash': '1c64f65e68c0e3cdaf116a205182859fd51f77f7', 'sae_lens_id': 'custom_sae', 'sae_lens_release_id': 'google/gemma-2-2b_layer_12_sae', 'sae_lens_version': '5.3.0', 'sae_cfg_dict': {'model_name': 'google/gemma-2-2b', 'd_in': 2304, 'd_sae': 18432, 'hook_layer': 12, 'hook_name': 'blocks.12.hook_resid_post', 'context_size': None, 'hook_head_index': None, 'architecture': 'Custom', 'apply_b_dec_to_input': True, 'finetuning_scaling_factor': None, 'activation_fn_str': 'relu', 'prepend_bos': True, 'normalize_activations': 'none', 'dtype': 'bfloat16', 'device': '', 'dataset_path': '', 'dataset_trust_remote_code': True, 'seqpos_slice': [None], 'training_tokens': -100000, 'sae_lens_training_version': None, 'neuronpedia_id': None}, 'eval_result_unstructured': None}, 'core evaluation results': {'unique_id': 'google/gemma-2-2b_layer_12_sae_custom_sae', 'sae_set': 'google/gemma-2-2b_layer_12_sae', 'sae_id': 'custom_sae', 'eval_cfg': {'model_name': 'google/gemma-2-2b', 'llm_dtype': 'bfloat16', 'batch_size_prompts': 16, 'n_eval_reconstruction_batches': 200, 'n_eval_sparsity_variance_batches': 2000, 'dataset': 'Skylion007/openwebtext', 'context_size': 128, 'compute_kl': True, 'compute_ce_loss': True, 'compute_l2_norms': True, 'compute_sparsity_metrics': True, 'compute_variance_metrics': True, 'compute_featurewise_density_statistics': False, 'compute_featurewise_weight_based_metrics': False, 'exclude_special_tokens_from_reconstruction': True, 'verbose': False}, 'metrics': {'model_behavior_preservation': {'kl_div_score': 0.7204968944099379, 'kl_div_with_ablation': 10.0625, 'kl_div_with_sae': 2.8125}, 'model_performance_preservation': {'ce_loss_score': 0.7138157894736842, 'ce_loss_with_ablation': 12.4375, 'ce_loss_with_sae': 5.65625, 'ce_loss_without_sae': 2.9375}, 'reconstruction_quality': {'explained_variance': 0.29296875, 'mse': 4.4375, 'cossim': 0.76171875}, 'shrinkage': {'l2_norm_in': 149.0, 'l2_norm_out': 107.0, 'l2_ratio': 0.70703125, 'relative_reconstruction_bias': 0.9453125}, 'sparsity': {'l0': 48.87746810913086, 'l1': 209.0}, 'token_stats': {'total_tokens_eval_reconstruction': 409600, 'total_tokens_eval_sparsity_variance': 4096000}}}}

After you complete each change, we will run the command `python experiment.py --out_dir=run_i' where i is the run number and evaluate the results.
YOUR PROPOSED CHANGE MUST USE THIS COMMAND FORMAT, DO NOT ADD ADDITIONAL COMMAND LINE ARGS.
You can then implement the next thing on your list.
Currently on iteration 0 of run 1
I'll help implement the hierarchical competition detection for preventing feature absorption. Let me plan out the experiments:                                                                                                        

Experiment Plan (10 runs):                                                                                                                                                                                                            

 1 Runs 1-3: Test different directional competition coefficient formulas                                                                                                                                                              
    • Run 1: Basic asymmetric statistics (n_i|j/n_j)/(k/d)                                                                                                                                                                            
    • Run 2: Enhanced with activation magnitude weights                                                                                                                                                                               
    • Run 3: With exponential scaling                                                                                                                                                                                                 
 2 Runs 4-6: Tune hierarchical penalty weights                                                                                                                                                                                        
    • Run 4: λ_2 = 0.05                                                                                                                                                                                                               
    • Run 5: λ_2 = 0.1                                                                                                                                                                                                                
    • Run 6: λ_2 = 0.2                                                                                                                                                                                                                
 3 Runs 7-9: Combine best settings with different sparsity levels                                                                                                                                                                     
    • Run 7: k=280                                                                                                                                                                                                                    
    • Run 8: k=320 (baseline)                                                                                                                                                                                                         
    • Run 9: k=360                                                                                                                                                                                                                    
 4 Run 10: Final run with best configuration                                                                                                                                                                                          

Let's start with Run 1 - implementing basic asymmetric competition coefficients.                                                                                                                                                      

Here are the changes needed for Run 1:                                                                                                                                                                                                

experiment.py                                                                                                                                                                                                                         

                                                                                                                                                                                                                                      
 <<<<<<< SEARCH                                                                                                                                                                                                                       
     def compute_mask_intersections(self, top_indices_BK):                                                                                                                                                                            
         """Compute normalized intersection sizes between feature masks"""                                                                                                                                                            
         B = top_indices_BK.size(0)                                                                                                                                                                                                   
         F = self.dict_size                                                                                                                                                                                                           
                                                                                                                                                                                                                                      
         # Convert indices to binary masks                                                                                                                                                                                            
         masks = torch.zeros((B, F), device=top_indices_BK.device)                                                                                                                                                                    
         masks.scatter_(1, top_indices_BK, 1.0)                                                                                                                                                                                       
                                                                                                                                                                                                                                      
         # Compute intersections between all pairs of features                                                                                                                                                                        
         intersections = torch.mm(masks.t(), masks)  # F x F                                                                                                                                                                          
                                                                                                                                                                                                                                      
         # Normalize by minimum activation count                                                                                                                                                                                      
         counts = intersections.diag().unsqueeze(0)  # 1 x F                                                                                                                                                                          
         min_counts = torch.min(counts, counts.t())  # F x F                                                                                                                                                                          
         normalized = intersections / (min_counts + 1e-8)                                                                                                                                                                             
                                                                                                                                                                                                                                      
         return normalized                                                                                                                                                                                                            
 =======                                                                                                                                                                                                                              
     def compute_competition_coefficients(self, top_indices_BK):                                                                                                                                                                      
         """Compute directional competition coefficients between features"""                                                                                                                                                          
         B = top_indices_BK.size(0)                                                                                                                                                                                                   
         F = self.dict_size                                                                                                                                                                                                           
         k = self.k                                                                                                                                                                                                                   
                                                                                                                                                                                                                                      
         # Convert indices to binary masks                                                                                                                                                                                            
         masks = torch.zeros((B, F), device=top_indices_BK.device)                                                                                                                                                                    
         masks.scatter_(1, top_indices_BK, 1.0)                                                                                                                                                                                       
                                                                                                                                                                                                                                      
         # Compute co-activation counts                                                                                                                                                                                               
         coact_counts = torch.mm(masks.t(), masks)  # F x F                                                                                                                                                                           
                                                                                                                                                                                                                                      
         # Get individual activation counts                                                                                                                                                                                           
         act_counts = coact_counts.diag().unsqueeze(1)  # F x 1                                                                                                                                                                       
                                                                                                                                                                                                                                      
         # Compute conditional probabilities n_i|j/n_j                                                                                                                                                                                
         cond_probs = coact_counts / (act_counts.t() + 1e-8)  # F x F                                                                                                                                                                 
                                                                                                                                                                                                                                      
         # Normalize by sparsity ratio k/d to get competition coefficients                                                                                                                                                            
         sparsity_ratio = k / F                                                                                                                                                                                                       
         competition_coeffs = cond_probs / sparsity_ratio                                                                                                                                                                             
                                                                                                                                                                                                                                      
         return competition_coeffs                                                                                                                                                                                                    
 >>>>>>> REPLACE                                                                                                                                                                                                                      
                                                                                                                                                                                                                                      

                                                                                                                                                                                                                                      
 <<<<<<< SEARCH                                                                                                                                                                                                                       
         # Compute sparsity-weighted orthogonality loss                                                                                                                                                                               
         mask_intersections = self.ae.compute_mask_intersections(top_indices)                                                                                                                                                         
         feature_dots = t.einsum('bi,bj->ij', f, f) / x.size(0)  # Normalize by batch size                                                                                                                                            
         ortho_loss = (mask_intersections * feature_dots.pow(2)).mean()                                                                                                                                                               
 =======                                                                                                                                                                                                                              
         # Compute hierarchical competition loss                                                                                                                                                                                      
         competition_coeffs = self.ae.compute_competition_coefficients(top_indices)                                                                                                                                                   
         feature_dots = t.einsum('bi,bj->ij', f, f) / x.size(0)                                                                                                                                                                       
                                                                                                                                                                                                                                      
         # Take max of directional coefficients to penalize both directions                                                                                                                                                           
         max_coeffs = torch.maximum(competition_coeffs, competition_coeffs.t())                                                                                                                                                       
         competition_loss = (max_coeffs * feature_dots.pow(2)).mean()                                                                                                                                                                 
 >>>>>>> REPLACE                                                                                                                                                                                                                      
                                                                                                                                                                                                                                      

                                                                                                                                                                                                                                      
 <<<<<<< SEARCH                                                                                                                                                                                                                       
         loss = l2_loss + self.auxk_alpha * auxk_loss + self.ortho_weight * ortho_loss                                                                                                                                                
 =======                                                                                                                                                                                                                              
         loss = l2_loss + self.auxk_alpha * auxk_loss + self.ortho_weight * competition_loss                                                                                                                                          
 >>>>>>> REPLACE                                                                                                                                                                                                                      
                                                                                                                                                                                                                                      

Let's run this first experiment:                                                                                                                                                                                                      

                                                                                                                                                                                                                                      
 python experiment.py --out_dir=run_1                                                                                                                                                                                                 
                                                                                                                                                                                                                                      

This implements the basic directional competition coefficients as described in the technical details. The key changes are:                                                                                                            

 1 Replaced symmetric mask intersections with directional competition coefficients                                                                                                                                                    
 2 Added normalization by sparsity ratio k/d                                                                                                                                                                                          
 3 Modified loss to use max of directional coefficients                                                                                                                                                                               

The competition coefficient c_ij = (n_i|j/n_j)/(k/d) captures when feature i is disproportionately active whenever feature j is active, indicating potential absorption.                                                              

Let me know how this first run goes and we can proceed with the next experiments based on the results.                                                                                                                                

Tokens: 63k sent, 1.3k received. Cost: $0.21 message, $0.21 session.
Applied edit to experiment.py

python experiment.py --out_dir=run_1
Step 0: 40830.703125
Step 100: 7386.97705078125
Step 200: 5485.3828125
Step 300: 4976.0263671875
Step 400: 4614.46826171875
Step 500: 4387.033203125
Step 600: 4327.2236328125
Step 700: 4074.906494140625
Step 800: 4123.2275390625
Step 900: 4031.1259765625
Step 1000: 4122.5556640625
Step 1100: 4003.232666015625
Step 1200: 3894.17919921875
Step 1300: 3926.52880859375
Step 1400: 3945.601318359375
Step 1500: 3955.361083984375
Step 1600: 3878.410888671875
Step 1700: 3878.587158203125
Step 1800: 3809.8662109375
Step 1900: 3776.204345703125
Step 2000: 3784.980712890625
Step 2100: 3820.122314453125
Step 2200: 3673.468994140625
Step 2300: 3636.9169921875
Step 2400: 3614.30810546875

 training complete! 

all info: /gpfs/radev/project/lafferty/tl784/free_PhD_labor/results/orthogonal_continued/20250130_212318_hierarchical_orthogonal_sae/run_1/final_info.json

Running absorption evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Loading probe and training data
Training k-sparse probes
Loading validation data
Evaluating raw k-sparse probing scores
Building metadata

Running core evaluation...
Using device: cuda
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Saved evaluation results to: run_1/google_gemma-2-2b_layer_12_sae_custom_sae_eval_results.json

Running scr evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9750000238418579
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9720000624656677
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9950000643730164
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9950000643730164
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9310000538825989, scr_score: 0.3124999417922944
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9360000491142273, scr_score: 0.390624927240368
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9360000491142273, scr_score: 0.390624927240368
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9350000619888306, scr_score: 0.37500011641541114
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9310000538825989, scr_score: 0.3124999417922944
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9320000410079956, scr_score: 0.32812475261725127
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9310000538825989, scr_score: 0.3124999417922944
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.5850000381469727, scr_score: 0.004914087313907592
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.5860000252723694, scr_score: 0.007371057746493725
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.5950000286102295, scr_score: 0.02948408453723957
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.6010000109672546, scr_score: 0.04422605358149169
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.6100000143051147, scr_score: 0.06633908037223754
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.6180000305175781, scr_score: 0.08599513673039726
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.5800000429153442, scr_score: -0.007370911297758397
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9890000224113464
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9550000429153442
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9590000510215759
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9920000433921814
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9920000433921814
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.859000027179718, scr_score: 0.06796087851472148
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8760000467300415, scr_score: 0.23300963569983096
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8760000467300415, scr_score: 0.23300963569983096
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8810000419616699, scr_score: 0.28155328569204763
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8550000190734863, scr_score: 0.02912584278375721
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8680000305175781, scr_score: 0.15533956423790243
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.7940000295639038, scr_score: -0.56310715007005
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.6780000329017639, scr_score: 0.10888249310703833
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.6850000619888306, scr_score: 0.12893988435673434
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.703000009059906, scr_score: 0.1805156673124691
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.7200000286102295, scr_score: 0.2292263282443374
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.7410000562667847, scr_score: 0.2893983312064664
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.6890000104904175, scr_score: 0.14040105560003607
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.7000000476837158, scr_score: 0.1719197888799928
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9830000400543213
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.984000027179718
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9730000495910645
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9720000624656677
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.999000072479248
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.999000072479248
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9410000443458557, scr_score: 0.49206359718628334
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9450000524520874, scr_score: 0.5555557658011382
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9450000524520874, scr_score: 0.5555557658011382
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9450000524520874, scr_score: 0.5555557658011382
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9410000443458557, scr_score: 0.49206359718628334
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9260000586509705, scr_score: 0.2539686744594192
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.8690000176429749, scr_score: -0.6507935456708595
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.597000002861023, scr_score: 0.022784816238899015
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6140000224113464, scr_score: 0.06582283600077923
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6230000257492065, scr_score: 0.08860765223967824
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6350000500679016, scr_score: 0.11898745752415006
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6430000066757202, scr_score: 0.13924051014931188
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6630000472068787, scr_score: 0.1898735189567649
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.625, scr_score: 0.09367087767151386
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9940000176429749
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9940000176429749
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9690000414848328
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.968000054359436
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9970000386238098
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9980000257492065
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8580000400543213, scr_score: 0.1328126309672156
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8660000562667847, scr_score: 0.19531274738251833
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.862000048160553, scr_score: 0.16406268917486697
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8420000672340393, scr_score: 0.007812863797821078
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8480000495910645, scr_score: 0.05468771827869265
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8360000252723694, scr_score: -0.03906245634426147
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8510000109672546, scr_score: 0.07812491268852294
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.6660000085830688, scr_score: 0.026706240376149513
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.6850000619888306, scr_score: 0.08308621873453508
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.6910000443458557, scr_score: 0.10089032002917621
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.7150000333786011, scr_score: 0.17210690207611637
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.7290000319480896, scr_score: 0.2136499230091961
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.7460000514984131, scr_score: 0.2640950830237842
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.675000011920929, scr_score: 0.05341248075229903
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9440000653266907
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9520000219345093
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9960000514984131
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9970000386238098
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.815000057220459, scr_score: 0.04371592886659017
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.815000057220459, scr_score: 0.04371592886659017
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.8110000491142273, scr_score: 0.021857964433295084
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.8080000281333923, scr_score: 0.00546440968122594
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.7580000162124634, scr_score: -0.26775965717237565
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.7520000338554382, scr_score: -0.3005464409681226
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.7460000514984131, scr_score: -0.33333322476386956
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8070000410079956, scr_score: 0.4627451182053349
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8230000138282776, scr_score: 0.525490096164477
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8360000252723694, scr_score: 0.5764705222370857
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8540000319480896, scr_score: 0.6470587685309047
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8600000143051147, scr_score: 0.6705881060476262
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8630000352859497, scr_score: 0.6823528916778143
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8740000128746033, scr_score: 0.725490049415746
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9640000462532043
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9640000462532043
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9770000576972961
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9750000238418579
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9960000514984131
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9960000514984131
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.7910000085830688, scr_score: 0.046153559299134936
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8060000538825989, scr_score: 0.12307687134902433
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8190000653266907, scr_score: 0.18974359914866223
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8250000476837158, scr_score: 0.22051274056970427
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8350000381469727, scr_score: 0.27179474482639304
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8400000333786011, scr_score: 0.29743574695473746
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8230000138282776, scr_score: 0.2102561563194528
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7310000061988831, scr_score: 0.060483807005948444
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7400000095367432, scr_score: 0.09677413927777444
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.753000020980835, scr_score: 0.1491935348194436
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7600000500679016, scr_score: 0.17741945562699032
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7720000147819519, scr_score: 0.22580640509523522
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7890000343322754, scr_score: 0.2943548639067476
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.796000063419342, scr_score: 0.3225807847142943
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9630000591278076
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9590000510215759
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9780000448226929
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9780000448226929
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9940000176429749
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9930000305175781
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.7740000486373901, scr_score: 0.08520176975018703
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.7870000600814819, scr_score: 0.14349778781226621
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.800000011920929, scr_score: 0.20179353858893082
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.8160000443458557, scr_score: 0.27354256613777117
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.8250000476837158, scr_score: 0.31390132731264025
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.8380000591278076, scr_score: 0.37219734537471943
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.8280000686645508, scr_score: 0.3273543367994015
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.7500000596046448, scr_score: 0.04910730084933944
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.7740000486373901, scr_score: 0.15625009146916644
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.7880000472068787, scr_score: 0.21875007483840891
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.8020000457763672, scr_score: 0.28125005820765137
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.8210000395774841, scr_score: 0.3660714452021861
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.8230000138282776, scr_score: 0.37499990021545476
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.8370000123977661, scr_score: 0.43749988358469727
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.971000075340271
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.971000075340271
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9620000720024109
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9630000591278076
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9930000305175781
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9940000176429749
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7420000433921814, scr_score: 0.05579403094120067
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7380000352859497, scr_score: 0.03862661712745569
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7490000128746033, scr_score: 0.08583681325484281
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7440000176429749, scr_score: 0.0643776099411321
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7570000290870667, scr_score: 0.12017164088233277
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7630000114440918, scr_score: 0.1459226336960092
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7660000324249268, scr_score: 0.15879825800978847
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7670000195503235, scr_score: 0.0285713393672145
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7740000486373901, scr_score: 0.06190480515528994
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7830000519752502, scr_score: 0.10476195612190681
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7910000085830688, scr_score: 0.14285698066766273
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.8030000329017639, scr_score: 0.19999994323368195
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.8020000457763672, scr_score: 0.19523810064441124
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.8170000314712524, scr_score: 0.2666665909782426

Running tpp evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Removing 24 from test set
Removing 12 from test set
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 0: 0.9540000557899475
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 1: 0.9630000591278076
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 2: 0.9520000219345093
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 6: 0.9920000433921814
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 9: 0.9810000658035278
Removing 28 from train set
Removing 0 from train set
Removing 29 from train set
Removing 31 from train set
Removing 7 from train set
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 1: 0.9540000557899475
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 2: 0.9240000247955322
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 3: 0.9310000538825989
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 5: 0.9260000586509705
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 6: 0.8640000224113464

Running sparse_probing evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Removing 24 from test set
Removing 12 from test set
Num non-zero elements: 2304
Test accuracy for 0: 0.935
Num non-zero elements: 2304
Test accuracy for 1: 0.952
Num non-zero elements: 2304
Test accuracy for 2: 0.942
Num non-zero elements: 2304
Test accuracy for 6: 0.988
Num non-zero elements: 2304
Test accuracy for 9: 0.981
Num non-zero elements: 1
Test accuracy for 0: 0.57
Num non-zero elements: 1
Test accuracy for 1: 0.629
Num non-zero elements: 1
Test accuracy for 2: 0.686
Num non-zero elements: 1
Test accuracy for 6: 0.782
Num non-zero elements: 1
Test accuracy for 9: 0.549
Num non-zero elements: 2
Test accuracy for 0: 0.582
Num non-zero elements: 2
Test accuracy for 1: 0.661
Num non-zero elements: 2
Test accuracy for 2: 0.713
Num non-zero elements: 2
Test accuracy for 6: 0.801
Num non-zero elements: 2
Test accuracy for 9: 0.701
Num non-zero elements: 5
Test accuracy for 0: 0.721
Num non-zero elements: 5
Test accuracy for 1: 0.7
Num non-zero elements: 5
Test accuracy for 2: 0.763
Num non-zero elements: 5
Test accuracy for 6: 0.902
Num non-zero elements: 5
Test accuracy for 9: 0.87
Num non-zero elements: 10
Test accuracy for 0: 0.782
Num non-zero elements: 10
Test accuracy for 1: 0.799
Num non-zero elements: 10
Test accuracy for 2: 0.801
Num non-zero elements: 10
Test accuracy for 6: 0.886
Num non-zero elements: 10
Test accuracy for 9: 0.9
Num non-zero elements: 20
Test accuracy for 0: 0.817
Num non-zero elements: 20
Test accuracy for 1: 0.88
Num non-zero elements: 20
Test accuracy for 2: 0.879
Num non-zero elements: 20
Test accuracy for 6: 0.967
Num non-zero elements: 20
Test accuracy for 9: 0.938
Num non-zero elements: 50
Test accuracy for 0: 0.91
Num non-zero elements: 50
Test accuracy for 1: 0.925
Num non-zero elements: 50
Test accuracy for 2: 0.921
Num non-zero elements: 50
Test accuracy for 6: 0.982
Num non-zero elements: 50
Test accuracy for 9: 0.954
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for 0: 0.9510000348091125
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for 1: 0.9630000591278076
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 19 epochs
Test accuracy for 2: 0.9450000524520874
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 17 epochs
Test accuracy for 6: 0.9830000400543213
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 19 epochs
Test accuracy for 9: 0.9730000495910645
Num non-zero elements: 1
Test accuracy for 0: 0.674
Num non-zero elements: 1
Test accuracy for 1: 0.667
Num non-zero elements: 1
Test accuracy for 2: 0.873
Num non-zero elements: 1
Test accuracy for 6: 0.982
Num non-zero elements: 1
Test accuracy for 9: 0.845
Num non-zero elements: 2
Test accuracy for 0: 0.723
Num non-zero elements: 2
Test accuracy for 1: 0.681
Num non-zero elements: 2
Test accuracy for 2: 0.865
Num non-zero elements: 2
Test accuracy for 6: 0.987
Num non-zero elements: 2
Test accuracy for 9: 0.932
Num non-zero elements: 5
Test accuracy for 0: 0.786
Num non-zero elements: 5
Test accuracy for 1: 0.732
Num non-zero elements: 5
Test accuracy for 2: 0.901
Num non-zero elements: 5
Test accuracy for 6: 0.988
Num non-zero elements: 5
Test accuracy for 9: 0.957
Num non-zero elements: 10
Test accuracy for 0: 0.811
Num non-zero elements: 10
Test accuracy for 1: 0.915
Num non-zero elements: 10
Test accuracy for 2: 0.902
Num non-zero elements: 10
Test accuracy for 6: 0.988
Num non-zero elements: 10
Test accuracy for 9: 0.96
Num non-zero elements: 20
Test accuracy for 0: 0.874
Num non-zero elements: 20
Test accuracy for 1: 0.927
Num non-zero elements: 20
Test accuracy for 2: 0.917
Num non-zero elements: 20
Test accuracy for 6: 0.991
Num non-zero elements: 20
Test accuracy for 9: 0.965
Num non-zero elements: 50
Test accuracy for 0: 0.915
Num non-zero elements: 50
Test accuracy for 1: 0.945
Num non-zero elements: 50
Test accuracy for 2: 0.925
Num non-zero elements: 50
Test accuracy for 6: 0.991
Num non-zero elements: 50
Test accuracy for 9: 0.966
Removing 24 from test set
Removing 12 from test set
Num non-zero elements: 2304
Test accuracy for 11: 0.963
Num non-zero elements: 2304
Test accuracy for 13: 0.951
Num non-zero elements: 2304
Test accuracy for 14: 0.955
Num non-zero elements: 2304
Test accuracy for 18: 0.916
Num non-zero elements: 2304
Test accuracy for 19: 0.948
Num non-zero elements: 1
Test accuracy for 11: 0.559
Num non-zero elements: 1
Test accuracy for 13: 0.667
Num non-zero elements: 1
Test accuracy for 14: 0.652
Num non-zero elements: 1
Test accuracy for 18: 0.692
Num non-zero elements: 1
Test accuracy for 19: 0.803
Num non-zero elements: 2
Test accuracy for 11: 0.691
Num non-zero elements: 2
Test accuracy for 13: 0.701
Num non-zero elements: 2
Test accuracy for 14: 0.67
Num non-zero elements: 2
Test accuracy for 18: 0.713
Num non-zero elements: 2
Test accuracy for 19: 0.77
Num non-zero elements: 5
Test accuracy for 11: 0.784
Num non-zero elements: 5
Test accuracy for 13: 0.738
Num non-zero elements: 5
Test accuracy for 14: 0.75
Num non-zero elements: 5
Test accuracy for 18: 0.744
Num non-zero elements: 5
Test accuracy for 19: 0.843
Num non-zero elements: 10
Test accuracy for 11: 0.86
Num non-zero elements: 10
Test accuracy for 13: 0.786
Num non-zero elements: 10
Test accuracy for 14: 0.791
Num non-zero elements: 10
Test accuracy for 18: 0.745
Num non-zero elements: 10
Test accuracy for 19: 0.865
Num non-zero elements: 20
Test accuracy for 11: 0.92
Num non-zero elements: 20
Test accuracy for 13: 0.884
Num non-zero elements: 20
Test accuracy for 14: 0.88
Num non-zero elements: 20
Test accuracy for 18: 0.764
Num non-zero elements: 20
Test accuracy for 19: 0.904
Num non-zero elements: 50
Test accuracy for 11: 0.936
Num non-zero elements: 50
Test accuracy for 13: 0.92
Num non-zero elements: 50
Test accuracy for 14: 0.908
Num non-zero elements: 50
Test accuracy for 18: 0.841
Num non-zero elements: 50
Test accuracy for 19: 0.923
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 12 epochs
Test accuracy for 11: 0.9600000381469727
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 14 epochs
Test accuracy for 13: 0.9550000429153442
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 17 epochs
Test accuracy for 14: 0.9440000653266907
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for 18: 0.9190000295639038
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 24 epochs
Test accuracy for 19: 0.9640000462532043
Num non-zero elements: 1
Test accuracy for 11: 0.842
Num non-zero elements: 1
Test accuracy for 13: 0.803
Num non-zero elements: 1
Test accuracy for 14: 0.846
Num non-zero elements: 1
Test accuracy for 18: 0.716
Num non-zero elements: 1
Test accuracy for 19: 0.855
Num non-zero elements: 2
Test accuracy for 11: 0.855
Num non-zero elements: 2
Test accuracy for 13: 0.811
Num non-zero elements: 2
Test accuracy for 14: 0.861
Num non-zero elements: 2
Test accuracy for 18: 0.721
Num non-zero elements: 2
Test accuracy for 19: 0.854
Num non-zero elements: 5
Test accuracy for 11: 0.879
Num non-zero elements: 5
Test accuracy for 13: 0.865
Num non-zero elements: 5
Test accuracy for 14: 0.869
Num non-zero elements: 5
Test accuracy for 18: 0.884
Num non-zero elements: 5
Test accuracy for 19: 0.892
Num non-zero elements: 10
Test accuracy for 11: 0.894
Num non-zero elements: 10
Test accuracy for 13: 0.886
Num non-zero elements: 10
Test accuracy for 14: 0.9
Num non-zero elements: 10
Test accuracy for 18: 0.889
Num non-zero elements: 10
Test accuracy for 19: 0.934
Num non-zero elements: 20
Test accuracy for 11: 0.948
Num non-zero elements: 20
Test accuracy for 13: 0.894
Num non-zero elements: 20
Test accuracy for 14: 0.914
Num non-zero elements: 20
Test accuracy for 18: 0.896
Num non-zero elements: 20
Test accuracy for 19: 0.944
Num non-zero elements: 50
Test accuracy for 11: 0.959
Num non-zero elements: 50
Test accuracy for 13: 0.943
Num non-zero elements: 50
Test accuracy for 14: 0.931
Num non-zero elements: 50
Test accuracy for 18: 0.911
Num non-zero elements: 50
Test accuracy for 19: 0.954
Removing 24 from test set
Removing 12 from test set
Num non-zero elements: 2304
Test accuracy for 20: 0.94
Num non-zero elements: 2304
Test accuracy for 21: 0.913
Num non-zero elements: 2304
Test accuracy for 22: 0.895
Num non-zero elements: 2304
Test accuracy for 25: 0.967
Num non-zero elements: 2304
Test accuracy for 26: 0.852
Num non-zero elements: 1
Test accuracy for 20: 0.721
Num non-zero elements: 1
Test accuracy for 21: 0.766
Num non-zero elements: 1
Test accuracy for 22: 0.641
Num non-zero elements: 1
Test accuracy for 25: 0.691
Num non-zero elements: 1
Test accuracy for 26: 0.624
Num non-zero elements: 2
Test accuracy for 20: 0.823
Num non-zero elements: 2
Test accuracy for 21: 0.769
Num non-zero elements: 2
Test accuracy for 22: 0.675
Num non-zero elements: 2
Test accuracy for 25: 0.773
Num non-zero elements: 2
Test accuracy for 26: 0.686
Num non-zero elements: 5
Test accuracy for 20: 0.861
Num non-zero elements: 5
Test accuracy for 21: 0.793
Num non-zero elements: 5
Test accuracy for 22: 0.694
Num non-zero elements: 5
Test accuracy for 25: 0.788
Num non-zero elements: 5
Test accuracy for 26: 0.677
Num non-zero elements: 10
Test accuracy for 20: 0.879
Num non-zero elements: 10
Test accuracy for 21: 0.825
Num non-zero elements: 10
Test accuracy for 22: 0.74
Num non-zero elements: 10
Test accuracy for 25: 0.858
Num non-zero elements: 10
Test accuracy for 26: 0.729
Num non-zero elements: 20
Test accuracy for 20: 0.904
Num non-zero elements: 20
Test accuracy for 21: 0.841
Num non-zero elements: 20
Test accuracy for 22: 0.802
Num non-zero elements: 20
Test accuracy for 25: 0.897
Num non-zero elements: 20
Test accuracy for 26: 0.809
Num non-zero elements: 50
Test accuracy for 20: 0.93
Num non-zero elements: 50
Test accuracy for 21: 0.874
Num non-zero elements: 50
Test accuracy for 22: 0.876
Num non-zero elements: 50
Test accuracy for 25: 0.924
Num non-zero elements: 50
Test accuracy for 26: 0.848
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 23 epochs
Test accuracy for 20: 0.9570000171661377
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 25 epochs
Test accuracy for 21: 0.9300000667572021
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 26 epochs
Test accuracy for 22: 0.9280000329017639
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 23 epochs
Test accuracy for 25: 0.9590000510215759
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 14 epochs
Test accuracy for 26: 0.8920000195503235
Num non-zero elements: 1
Test accuracy for 20: 0.902
Num non-zero elements: 1
Test accuracy for 21: 0.8
Num non-zero elements: 1
Test accuracy for 22: 0.622
Num non-zero elements: 1
Test accuracy for 25: 0.834
Num non-zero elements: 1
Test accuracy for 26: 0.672
Num non-zero elements: 2
Test accuracy for 20: 0.915
Num non-zero elements: 2
Test accuracy for 21: 0.827
Num non-zero elements: 2
Test accuracy for 22: 0.684
Num non-zero elements: 2
Test accuracy for 25: 0.856
Num non-zero elements: 2
Test accuracy for 26: 0.7
Num non-zero elements: 5
Test accuracy for 20: 0.924
Num non-zero elements: 5
Test accuracy for 21: 0.852
Num non-zero elements: 5
Test accuracy for 22: 0.891
Num non-zero elements: 5
Test accuracy for 25: 0.909
Num non-zero elements: 5
Test accuracy for 26: 0.831
Num non-zero elements: 10
Test accuracy for 20: 0.917
Num non-zero elements: 10
Test accuracy for 21: 0.863
Num non-zero elements: 10
Test accuracy for 22: 0.889
Num non-zero elements: 10
Test accuracy for 25: 0.937
Num non-zero elements: 10
Test accuracy for 26: 0.852
Num non-zero elements: 20
Test accuracy for 20: 0.944
Num non-zero elements: 20
Test accuracy for 21: 0.852
Num non-zero elements: 20
Test accuracy for 22: 0.898
Num non-zero elements: 20
Test accuracy for 25: 0.949
Num non-zero elements: 20
Test accuracy for 26: 0.871
Num non-zero elements: 50
Test accuracy for 20: 0.936
Num non-zero elements: 50
Test accuracy for 21: 0.873
Num non-zero elements: 50
Test accuracy for 22: 0.91
Num non-zero elements: 50
Test accuracy for 25: 0.951
Num non-zero elements: 50
Test accuracy for 26: 0.873
Removing 28 from train set
Removing 0 from train set
Removing 29 from train set
Removing 31 from train set
Removing 7 from train set
Num non-zero elements: 2304
Test accuracy for 1: 0.95
Num non-zero elements: 2304
Test accuracy for 2: 0.891
Num non-zero elements: 2304
Test accuracy for 3: 0.912
Num non-zero elements: 2304
Test accuracy for 5: 0.917
Num non-zero elements: 2304
Test accuracy for 6: 0.83
Num non-zero elements: 1
Test accuracy for 1: 0.667
Num non-zero elements: 1
Test accuracy for 2: 0.6
Num non-zero elements: 1
Test accuracy for 3: 0.585
Num non-zero elements: 1
Test accuracy for 5: 0.561
Num non-zero elements: 1
Test accuracy for 6: 0.598
Num non-zero elements: 2
Test accuracy for 1: 0.742
Num non-zero elements: 2
Test accuracy for 2: 0.647
Num non-zero elements: 2
Test accuracy for 3: 0.621
Num non-zero elements: 2
Test accuracy for 5: 0.593
Num non-zero elements: 2
Test accuracy for 6: 0.616
Num non-zero elements: 5
Test accuracy for 1: 0.781
Num non-zero elements: 5
Test accuracy for 2: 0.734
Num non-zero elements: 5
Test accuracy for 3: 0.625
Num non-zero elements: 5
Test accuracy for 5: 0.689
Num non-zero elements: 5
Test accuracy for 6: 0.681
Num non-zero elements: 10
Test accuracy for 1: 0.794
Num non-zero elements: 10
Test accuracy for 2: 0.773
Num non-zero elements: 10
Test accuracy for 3: 0.744
Num non-zero elements: 10
Test accuracy for 5: 0.739
Num non-zero elements: 10
Test accuracy for 6: 0.689
Num non-zero elements: 20
Test accuracy for 1: 0.879
Num non-zero elements: 20
Test accuracy for 2: 0.848
Num non-zero elements: 20
Test accuracy for 3: 0.776
Num non-zero elements: 20
Test accuracy for 5: 0.804
Num non-zero elements: 20
Test accuracy for 6: 0.762
Num non-zero elements: 50
Test accuracy for 1: 0.919
Num non-zero elements: 50
Test accuracy for 2: 0.877
Num non-zero elements: 50
Test accuracy for 3: 0.851
Num non-zero elements: 50
Test accuracy for 5: 0.842
Num non-zero elements: 50
Test accuracy for 6: 0.791
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 24 epochs
Test accuracy for 1: 0.9410000443458557
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 19 epochs
Test accuracy for 2: 0.9420000314712524
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 18 epochs
Test accuracy for 3: 0.9180000424385071
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 18 epochs
Test accuracy for 5: 0.921000063419342
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 17 epochs
Test accuracy for 6: 0.8770000338554382
Num non-zero elements: 1
Test accuracy for 1: 0.726
Num non-zero elements: 1
Test accuracy for 2: 0.617
Num non-zero elements: 1
Test accuracy for 3: 0.603
Num non-zero elements: 1
Test accuracy for 5: 0.858
Num non-zero elements: 1
Test accuracy for 6: 0.721
Num non-zero elements: 2
Test accuracy for 1: 0.809
Num non-zero elements: 2
Test accuracy for 2: 0.721
Num non-zero elements: 2
Test accuracy for 3: 0.656
Num non-zero elements: 2
Test accuracy for 5: 0.853
Num non-zero elements: 2
Test accuracy for 6: 0.744
Num non-zero elements: 5
Test accuracy for 1: 0.902
Num non-zero elements: 5
Test accuracy for 2: 0.719
Num non-zero elements: 5
Test accuracy for 3: 0.751
Num non-zero elements: 5
Test accuracy for 5: 0.855
Num non-zero elements: 5
Test accuracy for 6: 0.797
Num non-zero elements: 10
Test accuracy for 1: 0.917
Num non-zero elements: 10
Test accuracy for 2: 0.791
Num non-zero elements: 10
Test accuracy for 3: 0.81
Num non-zero elements: 10
Test accuracy for 5: 0.879
Num non-zero elements: 10
Test accuracy for 6: 0.782
Num non-zero elements: 20
Test accuracy for 1: 0.916
Num non-zero elements: 20
Test accuracy for 2: 0.826
Num non-zero elements: 20
Test accuracy for 3: 0.857
Num non-zero elements: 20
Test accuracy for 5: 0.876
Num non-zero elements: 20
Test accuracy for 6: 0.788
Num non-zero elements: 50
Test accuracy for 1: 0.933
Num non-zero elements: 50
Test accuracy for 2: 0.891
Num non-zero elements: 50
Test accuracy for 3: 0.885
Num non-zero elements: 50
Test accuracy for 5: 0.908
Num non-zero elements: 50
Test accuracy for 6: 0.804
Num non-zero elements: 2304
Test accuracy for 1.0: 0.981
Num non-zero elements: 2304
Test accuracy for 5.0: 0.982
Num non-zero elements: 1
Test accuracy for 1.0: 0.671
Num non-zero elements: 1
Test accuracy for 5.0: 0.671
Num non-zero elements: 2
Test accuracy for 1.0: 0.724
Num non-zero elements: 2
Test accuracy for 5.0: 0.724
Num non-zero elements: 5
Test accuracy for 1.0: 0.766
Num non-zero elements: 5
Test accuracy for 5.0: 0.766
Num non-zero elements: 10
Test accuracy for 1.0: 0.826
Num non-zero elements: 10
Test accuracy for 5.0: 0.826
Num non-zero elements: 20
Test accuracy for 1.0: 0.847
Num non-zero elements: 20
Test accuracy for 5.0: 0.847
Num non-zero elements: 50
Test accuracy for 1.0: 0.933
Num non-zero elements: 50
Test accuracy for 5.0: 0.932
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 27 epochs
Test accuracy for 1.0: 0.9770000576972961
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 19 epochs
Test accuracy for 5.0: 0.9740000367164612
Num non-zero elements: 1
Test accuracy for 1.0: 0.86
Num non-zero elements: 1
Test accuracy for 5.0: 0.86
Num non-zero elements: 2
Test accuracy for 1.0: 0.868
Num non-zero elements: 2
Test accuracy for 5.0: 0.868
Num non-zero elements: 5
Test accuracy for 1.0: 0.92
Num non-zero elements: 5
Test accuracy for 5.0: 0.92
Num non-zero elements: 10
Test accuracy for 1.0: 0.944
Num non-zero elements: 10
Test accuracy for 5.0: 0.944
Num non-zero elements: 20
Test accuracy for 1.0: 0.955
Num non-zero elements: 20
Test accuracy for 5.0: 0.955
Num non-zero elements: 50
Test accuracy for 1.0: 0.965
Num non-zero elements: 50
Test accuracy for 5.0: 0.965
Loading dataset codeparrot/github-code, this usually takes ~30 seconds
Num non-zero elements: 2304
Test accuracy for C: 0.954
Num non-zero elements: 2304
Test accuracy for Python: 0.975
Num non-zero elements: 2304
Test accuracy for HTML: 0.988
Num non-zero elements: 2304
Test accuracy for Java: 0.967
Num non-zero elements: 2304
Test accuracy for PHP: 0.954
Num non-zero elements: 1
Test accuracy for C: 0.654
Num non-zero elements: 1
Test accuracy for Python: 0.643
Num non-zero elements: 1
Test accuracy for HTML: 0.792
Num non-zero elements: 1
Test accuracy for Java: 0.62
Num non-zero elements: 1
Test accuracy for PHP: 0.598
Num non-zero elements: 2
Test accuracy for C: 0.753
Num non-zero elements: 2
Test accuracy for Python: 0.676
Num non-zero elements: 2
Test accuracy for HTML: 0.784
Num non-zero elements: 2
Test accuracy for Java: 0.685
Num non-zero elements: 2
Test accuracy for PHP: 0.655
Num non-zero elements: 5
Test accuracy for C: 0.753
Num non-zero elements: 5
Test accuracy for Python: 0.738
Num non-zero elements: 5
Test accuracy for HTML: 0.906
Num non-zero elements: 5
Test accuracy for Java: 0.724
Num non-zero elements: 5
Test accuracy for PHP: 0.697
Num non-zero elements: 10
Test accuracy for C: 0.782
Num non-zero elements: 10
Test accuracy for Python: 0.74
Num non-zero elements: 10
Test accuracy for HTML: 0.953
Num non-zero elements: 10
Test accuracy for Java: 0.782
Num non-zero elements: 10
Test accuracy for PHP: 0.749
Num non-zero elements: 20
Test accuracy for C: 0.866
Num non-zero elements: 20
Test accuracy for Python: 0.858
Num non-zero elements: 20
Test accuracy for HTML: 0.961
Num non-zero elements: 20
Test accuracy for Java: 0.846
Num non-zero elements: 20
Test accuracy for PHP: 0.827
Num non-zero elements: 50
Test accuracy for C: 0.91
Num non-zero elements: 50
Test accuracy for Python: 0.954
Num non-zero elements: 50
Test accuracy for HTML: 0.962
Num non-zero elements: 50
Test accuracy for Java: 0.915
Num non-zero elements: 50
Test accuracy for PHP: 0.909
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 21 epochs
Test accuracy for C: 0.9590000510215759
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 23 epochs
Test accuracy for Python: 0.987000048160553
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 23 epochs
Test accuracy for HTML: 0.9830000400543213
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 20 epochs
Test accuracy for Java: 0.9620000720024109
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 20 epochs
Test accuracy for PHP: 0.9540000557899475
Num non-zero elements: 1
Test accuracy for C: 0.604
Num non-zero elements: 1
Test accuracy for Python: 0.563
Num non-zero elements: 1
Test accuracy for HTML: 0.609
Num non-zero elements: 1
Test accuracy for Java: 0.65
Num non-zero elements: 1
Test accuracy for PHP: 0.59
Num non-zero elements: 2
Test accuracy for C: 0.615
Num non-zero elements: 2
Test accuracy for Python: 0.595
Num non-zero elements: 2
Test accuracy for HTML: 0.601
Num non-zero elements: 2
Test accuracy for Java: 0.662
Num non-zero elements: 2
Test accuracy for PHP: 0.613
Num non-zero elements: 5
Test accuracy for C: 0.698
Num non-zero elements: 5
Test accuracy for Python: 0.606
Num non-zero elements: 5
Test accuracy for HTML: 0.733
Num non-zero elements: 5
Test accuracy for Java: 0.673
Num non-zero elements: 5
Test accuracy for PHP: 0.881
Num non-zero elements: 10
Test accuracy for C: 0.81
Num non-zero elements: 10
Test accuracy for Python: 0.914
Num non-zero elements: 10
Test accuracy for HTML: 0.937
Num non-zero elements: 10
Test accuracy for Java: 0.647
Num non-zero elements: 10
Test accuracy for PHP: 0.911
Num non-zero elements: 20
Test accuracy for C: 0.812
Num non-zero elements: 20
Test accuracy for Python: 0.929
Num non-zero elements: 20
Test accuracy for HTML: 0.947
Num non-zero elements: 20
Test accuracy for Java: 0.832
Num non-zero elements: 20
Test accuracy for PHP: 0.901
Num non-zero elements: 50
Test accuracy for C: 0.922
Num non-zero elements: 50
Test accuracy for Python: 0.954
Num non-zero elements: 50
Test accuracy for HTML: 0.963
Num non-zero elements: 50
Test accuracy for Java: 0.898
Num non-zero elements: 50
Test accuracy for PHP: 0.922
Num non-zero elements: 2304
Test accuracy for 0: 0.931
Num non-zero elements: 2304
Test accuracy for 1: 0.991
Num non-zero elements: 2304
Test accuracy for 2: 0.91
Num non-zero elements: 2304
Test accuracy for 3: 0.939
Num non-zero elements: 1
Test accuracy for 0: 0.559
Num non-zero elements: 1
Test accuracy for 1: 0.663
Num non-zero elements: 1
Test accuracy for 2: 0.662
Num non-zero elements: 1
Test accuracy for 3: 0.78
Num non-zero elements: 2
Test accuracy for 0: 0.798
Num non-zero elements: 2
Test accuracy for 1: 0.802
Num non-zero elements: 2
Test accuracy for 2: 0.684
Num non-zero elements: 2
Test accuracy for 3: 0.792
Num non-zero elements: 5
Test accuracy for 0: 0.823
Num non-zero elements: 5
Test accuracy for 1: 0.886
Num non-zero elements: 5
Test accuracy for 2: 0.749
Num non-zero elements: 5
Test accuracy for 3: 0.841
Num non-zero elements: 10
Test accuracy for 0: 0.876
Num non-zero elements: 10
Test accuracy for 1: 0.933
Num non-zero elements: 10
Test accuracy for 2: 0.782
Num non-zero elements: 10
Test accuracy for 3: 0.875
Num non-zero elements: 20
Test accuracy for 0: 0.889
Num non-zero elements: 20
Test accuracy for 1: 0.953
Num non-zero elements: 20
Test accuracy for 2: 0.873
Num non-zero elements: 20
Test accuracy for 3: 0.896
Num non-zero elements: 50
Test accuracy for 0: 0.897
Num non-zero elements: 50
Test accuracy for 1: 0.972
Num non-zero elements: 50
Test accuracy for 2: 0.905
Num non-zero elements: 50
Test accuracy for 3: 0.926
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 17 epochs
Test accuracy for 0: 0.9430000185966492
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 16 epochs
Test accuracy for 1: 0.9860000610351562
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for 2: 0.9280000329017639
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 17 epochs
Test accuracy for 3: 0.956000030040741
Num non-zero elements: 1
Test accuracy for 0: 0.774
Num non-zero elements: 1
Test accuracy for 1: 0.958
Num non-zero elements: 1
Test accuracy for 2: 0.772
Num non-zero elements: 1
Test accuracy for 3: 0.67
Num non-zero elements: 2
Test accuracy for 0: 0.869
Num non-zero elements: 2
Test accuracy for 1: 0.966
Num non-zero elements: 2
Test accuracy for 2: 0.808
Num non-zero elements: 2
Test accuracy for 3: 0.774
Num non-zero elements: 5
Test accuracy for 0: 0.878
Num non-zero elements: 5
Test accuracy for 1: 0.973
Num non-zero elements: 5
Test accuracy for 2: 0.838
Num non-zero elements: 5
Test accuracy for 3: 0.85
Num non-zero elements: 10
Test accuracy for 0: 0.89
Num non-zero elements: 10
Test accuracy for 1: 0.969
Num non-zero elements: 10
Test accuracy for 2: 0.85
Num non-zero elements: 10
Test accuracy for 3: 0.919
Num non-zero elements: 20
Test accuracy for 0: 0.907
Num non-zero elements: 20
Test accuracy for 1: 0.977
Num non-zero elements: 20
Test accuracy for 2: 0.869
Num non-zero elements: 20
Test accuracy for 3: 0.921
Num non-zero elements: 50
Test accuracy for 0: 0.906
Num non-zero elements: 50
Test accuracy for 1: 0.975
Num non-zero elements: 50
Test accuracy for 2: 0.887
Num non-zero elements: 50
Test accuracy for 3: 0.928
Loading dataset Helsinki-NLP/europarl, this usually takes ~10 seconds
Num non-zero elements: 2304
Test accuracy for en: 0.998
Num non-zero elements: 2304
Test accuracy for fr: 1.0
Num non-zero elements: 2304
Test accuracy for de: 1.0
Num non-zero elements: 2304
Test accuracy for es: 0.999
Num non-zero elements: 2304
Test accuracy for nl: 1.0
Num non-zero elements: 1
Test accuracy for en: 0.738
Num non-zero elements: 1
Test accuracy for fr: 0.575
Num non-zero elements: 1
Test accuracy for de: 0.756
Num non-zero elements: 1
Test accuracy for es: 0.502
Num non-zero elements: 1
Test accuracy for nl: 0.648
Num non-zero elements: 2
Test accuracy for en: 0.835
Num non-zero elements: 2
Test accuracy for fr: 0.59
Num non-zero elements: 2
Test accuracy for de: 0.824
Num non-zero elements: 2
Test accuracy for es: 0.898
Num non-zero elements: 2
Test accuracy for nl: 0.757
Num non-zero elements: 5
Test accuracy for en: 0.904
Num non-zero elements: 5
Test accuracy for fr: 0.923
Num non-zero elements: 5
Test accuracy for de: 0.918
Num non-zero elements: 5
Test accuracy for es: 0.98
Num non-zero elements: 5
Test accuracy for nl: 0.857
Num non-zero elements: 10
Test accuracy for en: 0.975
Num non-zero elements: 10
Test accuracy for fr: 0.974
Num non-zero elements: 10
Test accuracy for de: 0.959
Num non-zero elements: 10
Test accuracy for es: 0.994
Num non-zero elements: 10
Test accuracy for nl: 0.917
Num non-zero elements: 20
Test accuracy for en: 0.992
Num non-zero elements: 20
Test accuracy for fr: 0.989
Num non-zero elements: 20
Test accuracy for de: 0.986
Num non-zero elements: 20
Test accuracy for es: 0.996
Num non-zero elements: 20
Test accuracy for nl: 0.986
Num non-zero elements: 50
Test accuracy for en: 0.998
Num non-zero elements: 50
Test accuracy for fr: 1.0
Num non-zero elements: 50
Test accuracy for de: 1.0
Num non-zero elements: 50
Test accuracy for es: 1.0
Num non-zero elements: 50
Test accuracy for nl: 0.996
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 14 epochs
Test accuracy for en: 0.9980000257492065
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 14 epochs
Test accuracy for fr: 1.0
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for de: 0.9980000257492065
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for es: 0.999000072479248
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for nl: 1.0
Num non-zero elements: 1
Test accuracy for en: 0.999
Num non-zero elements: 1
Test accuracy for fr: 0.989
Num non-zero elements: 1
Test accuracy for de: 0.824
Num non-zero elements: 1
Test accuracy for es: 0.975
Num non-zero elements: 1
Test accuracy for nl: 0.699
Num non-zero elements: 2
Test accuracy for en: 0.999
Num non-zero elements: 2
Test accuracy for fr: 0.991
Num non-zero elements: 2
Test accuracy for de: 0.873
Num non-zero elements: 2
Test accuracy for es: 0.972
Num non-zero elements: 2
Test accuracy for nl: 0.86
Num non-zero elements: 5
Test accuracy for en: 0.998
Num non-zero elements: 5
Test accuracy for fr: 0.994
Num non-zero elements: 5
Test accuracy for de: 0.949
Num non-zero elements: 5
Test accuracy for es: 0.999
Num non-zero elements: 5
Test accuracy for nl: 0.976
Num non-zero elements: 10
Test accuracy for en: 0.998
Num non-zero elements: 10
Test accuracy for fr: 0.996
Num non-zero elements: 10
Test accuracy for de: 0.978
Num non-zero elements: 10
Test accuracy for es: 0.999
Num non-zero elements: 10
Test accuracy for nl: 0.97
Num non-zero elements: 20
Test accuracy for en: 0.999
Num non-zero elements: 20
Test accuracy for fr: 0.995
Num non-zero elements: 20
Test accuracy for de: 0.988
Num non-zero elements: 20
Test accuracy for es: 0.998
Num non-zero elements: 20
Test accuracy for nl: 0.977
Num non-zero elements: 50
Test accuracy for en: 0.998
Num non-zero elements: 50
Test accuracy for fr: 0.997
Num non-zero elements: 50
Test accuracy for de: 0.992
Num non-zero elements: 50
Test accuracy for es: 0.999
Num non-zero elements: 50
Test accuracy for nl: 0.992

Running unlearning evaluation...
Loaded pretrained model google/gemma-2-2b-it into HookedTransformer
Running evaluation for SAE: google/gemma-2-2b_layer_12_sae_custom_sae
24432 16027
1962 859
torch.Size([6378, 1024]) torch.Size([275, 1024])
Forget sparsity: [0.014126 0.001871 0.010558 ... 0.002963 0.00142  0.00191 ]
(18432,)
Retain sparsity: [0.004682 0.001597 0.012794 ... 0.001564 0.000154 0.003691]
(18432,)
Starting metrics calculation...
running on datasets: ['wmdp-bio', 'high_school_us_history', 'college_computer_science', 'high_school_geography', 'human_aging']
Calculating metrics for retain threshold: 0.001
Top features for ablation: [ 7234  8651 15607 ...  3550 14783 13324]
Calculating metrics list with parameters: {'intervention_method': 'clamp_feature_activation'} {'features_to_ablate': [array([ 7234,  8651, 15607,  9513,   178,  4566, 14838, 16825, 17456,
        2737]), array([ 7234,  8651, 15607,  9513,   178,  4566, 14838, 16825, 17456,
        2737, 16520,  1146, 14239,  4615,  1830, 17553,  5242,  8911,
       14067, 13516])], 'multiplier': [25, 50, 100, 200]}
Saving target question ids for gemma-2-2b-it on wmdp-bio...
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/wmdp-bio_correct.csv saved, with 267 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/wmdp-bio_correct.csv saved, with 267 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/wmdp-bio_correct.csv saved, with 534 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/wmdp-bio_correct-iff-question.csv saved, with 243 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/wmdp-bio_correct-iff-question.csv saved, with 244 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/wmdp-bio_correct-iff-question.csv saved, with 487 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/wmdp-bio_correct-no-tricks.csv saved, with 262 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/wmdp-bio_correct-no-tricks.csv saved, with 263 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/wmdp-bio_correct-no-tricks.csv saved, with 525 questions
Saving target question ids for gemma-2-2b-it on high_school_us_history...
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/mmlu-high-school-us-history_correct.csv saved, with 55 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/mmlu-high-school-us-history_correct.csv saved, with 55 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/mmlu-high-school-us-history_correct.csv saved, with 110 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/mmlu-high-school-us-history_correct-iff-question.csv saved, with 54 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/mmlu-high-school-us-history_correct-iff-question.csv saved, with 54 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/mmlu-high-school-us-history_correct-iff-question.csv saved, with 108 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/mmlu-high-school-us-history_correct-no-tricks.csv saved, with 55 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/mmlu-high-school-us-history_correct-no-tricks.csv saved, with 55 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/mmlu-high-school-us-history_correct-no-tricks.csv saved, with 110 questions
Saving target question ids for gemma-2-2b-it on college_computer_science...
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/mmlu-college-computer-science_correct.csv saved, with 4 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/mmlu-college-computer-science_correct.csv saved, with 5 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/mmlu-college-computer-science_correct.csv saved, with 9 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/mmlu-college-computer-science_correct-iff-question.csv saved, with 4 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/mmlu-college-computer-science_correct-iff-question.csv saved, with 5 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/mmlu-college-computer-science_correct-iff-question.csv saved, with 9 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/mmlu-college-computer-science_correct-no-tricks.csv saved, with 4 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/mmlu-college-computer-science_correct-no-tricks.csv saved, with 5 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/mmlu-college-computer-science_correct-no-tricks.csv saved, with 9 questions
Saving target question ids for gemma-2-2b-it on high_school_geography...
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/mmlu-high-school-geography_correct.csv saved, with 51 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/mmlu-high-school-geography_correct.csv saved, with 52 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/mmlu-high-school-geography_correct.csv saved, with 103 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/mmlu-high-school-geography_correct-iff-question.csv saved, with 49 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/mmlu-high-school-geography_correct-iff-question.csv saved, with 50 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/mmlu-high-school-geography_correct-iff-question.csv saved, with 99 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/mmlu-high-school-geography_correct-no-tricks.csv saved, with 51 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/mmlu-high-school-geography_correct-no-tricks.csv saved, with 52 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/mmlu-high-school-geography_correct-no-tricks.csv saved, with 103 questions
Saving target question ids for gemma-2-2b-it on human_aging...
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/mmlu-human-aging_correct.csv saved, with 42 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/mmlu-human-aging_correct.csv saved, with 42 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/mmlu-human-aging_correct.csv saved, with 84 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/mmlu-human-aging_correct-iff-question.csv saved, with 40 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/mmlu-human-aging_correct-iff-question.csv saved, with 41 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/mmlu-human-aging_correct-iff-question.csv saved, with 81 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/train/mmlu-human-aging_correct-no-tricks.csv saved, with 41 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/test/mmlu-human-aging_correct-no-tricks.csv saved, with 42 questions
artifacts/unlearning/google/gemma-2-2b-it/data/question_ids/all/mmlu-human-aging_correct-no-tricks.csv saved, with 83 questions
Calculating metrics for retain threshold: 0.01
Top features for ablation: [12497 12900 18043 ...  3550 14783 13324]
Calculating metrics list with parameters: {'intervention_method': 'clamp_feature_activation'} {'features_to_ablate': [array([12497, 12900, 18043, 11289, 11424, 15710,  7018,  2055, 15493,
        5952]), array([12497, 12900, 18043, 11289, 11424, 15710,  7018,  2055, 15493,
        5952, 10518, 17710, 14977,  7267,  4445, 15332,  2453,   264,
        1335, 17172])], 'multiplier': [25, 50, 100, 200]}
All target question ids for gemma-2-2b-it on wmdp-bio already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on high_school_us_history already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on college_computer_science already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on high_school_geography already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on human_aging already exist. No need to generate target ids.
Unlearning scores DataFrame:     wmdp-bio  high_school_us_history  ...  multiplier  all_side_effects_mcq
0   0.992509                1.000000  ...          25              1.000000
1   0.717228                0.936364  ...         200              0.947712
2   0.940075                0.981818  ...         100              0.990196
3   0.947566                0.990909  ...         200              0.960784
4   0.638577                0.927273  ...         200              0.911765
5   0.977528                1.000000  ...          50              1.000000
6   0.994382                1.000000  ...         100              0.996732
7   0.985019                1.000000  ...         100              0.993464
8   1.000000                1.000000  ...          50              1.000000
9   0.988764                1.000000  ...          50              1.000000
10  0.996255                1.000000  ...          25              1.000000
11  0.893258                0.963636  ...         100              0.980392
12  1.000000                1.000000  ...          25              1.000000
13  1.000000                1.000000  ...          25              1.000000
14  0.983146                1.000000  ...         200              0.986928
15  0.994382                1.000000  ...          50              1.000000

[16 rows x 10 columns]
coder_out: I'll help implement the hierarchical competition detection for preventing feature absorption. Let me plan out the experiments:

Experiment Plan (10 runs):

1. Runs 1-3: Test different directional competition coefficient formulas
   - Run 1: Basic asymmetric statistics (n_i|j/n_j)/(k/d)
   - Run 2: Enhanced with activation magnitude weights
   - Run 3: With exponential scaling

2. Runs 4-6: Tune hierarchical penalty weights
   - Run 4: λ_2 = 0.05 
   - Run 5: λ_2 = 0.1
   - Run 6: λ_2 = 0.2

3. Runs 7-9: Combine best settings with different sparsity levels
   - Run 7: k=280
   - Run 8: k=320 (baseline)
   - Run 9: k=360

4. Run 10: Final run with best configuration

Let's start with Run 1 - implementing basic asymmetric competition coefficients.

Here are the changes needed for Run 1:

experiment.py
```python
<<<<<<< SEARCH
    def compute_mask_intersections(self, top_indices_BK):
        """Compute normalized intersection sizes between feature masks"""
        B = top_indices_BK.size(0)
        F = self.dict_size
        
        # Convert indices to binary masks
        masks = torch.zeros((B, F), device=top_indices_BK.device)
        masks.scatter_(1, top_indices_BK, 1.0)
        
        # Compute intersections between all pairs of features
        intersections = torch.mm(masks.t(), masks)  # F x F
        
        # Normalize by minimum activation count
        counts = intersections.diag().unsqueeze(0)  # 1 x F
        min_counts = torch.min(counts, counts.t())  # F x F
        normalized = intersections / (min_counts + 1e-8)
        
        return normalized
=======
    def compute_competition_coefficients(self, top_indices_BK):
        """Compute directional competition coefficients between features"""
        B = top_indices_BK.size(0)
        F = self.dict_size
        k = self.k
        
        # Convert indices to binary masks
        masks = torch.zeros((B, F), device=top_indices_BK.device)
        masks.scatter_(1, top_indices_BK, 1.0)
        
        # Compute co-activation counts
        coact_counts = torch.mm(masks.t(), masks)  # F x F
        
        # Get individual activation counts
        act_counts = coact_counts.diag().unsqueeze(1)  # F x 1
        
        # Compute conditional probabilities n_i|j/n_j
        cond_probs = coact_counts / (act_counts.t() + 1e-8)  # F x F
        
        # Normalize by sparsity ratio k/d to get competition coefficients
        sparsity_ratio = k / F
        competition_coeffs = cond_probs / sparsity_ratio
        
        return competition_coeffs
>>>>>>> REPLACE
```

```python
<<<<<<< SEARCH
        # Compute sparsity-weighted orthogonality loss
        mask_intersections = self.ae.compute_mask_intersections(top_indices)
        feature_dots = t.einsum('bi,bj->ij', f, f) / x.size(0)  # Normalize by batch size
        ortho_loss = (mask_intersections * feature_dots.pow(2)).mean()
=======
        # Compute hierarchical competition loss
        competition_coeffs = self.ae.compute_competition_coefficients(top_indices)
        feature_dots = t.einsum('bi,bj->ij', f, f) / x.size(0)
        
        # Take max of directional coefficients to penalize both directions
        max_coeffs = torch.maximum(competition_coeffs, competition_coeffs.t())
        competition_loss = (max_coeffs * feature_dots.pow(2)).mean()
>>>>>>> REPLACE
```

```python
<<<<<<< SEARCH
        loss = l2_loss + self.auxk_alpha * auxk_loss + self.ortho_weight * ortho_loss
=======
        loss = l2_loss + self.auxk_alpha * auxk_loss + self.ortho_weight * competition_loss
>>>>>>> REPLACE
```

Let's run this first experiment:

```bash
python experiment.py --out_dir=run_1
```

This implements the basic directional competition coefficients as described in the technical details. The key changes are:

1. Replaced symmetric mask intersections with directional competition coefficients
2. Added normalization by sparsity ratio k/d
3. Modified loss to use max of directional coefficients

The competition coefficient c_ij = (n_i|j/n_j)/(k/d) captures when feature i is disproportionately active whenever feature j is active, indicating potential absorption.

Let me know how this first run goes and we can proceed with the next experiments based on the results., type: <class 'str'>
Currently on iteration 1 of run 2
Let me analyze Run 1 results and update notes.txt first:                                                                                                                                                                              

notes.txt                                                                                                                                                                                                                             

                                                                                                                                                                                                                                      
 <<<<<<< SEARCH                                                                                                                                                                                                                       
 # Title: Hierarchical Competition Detection for Preventing Feature Absorption in Sparse Autoencoders                                                                                                                                 
 # Experiment description: 1. Modify mask intersection computation for asymmetric relationships                                                                                                                                       
 2. Implement directional competition coefficients                                                                                                                                                                                    
 3. Train with optimal dictionary size (18432) on gemma-2-2b                                                                                                                                                                          
 4. Compare against symmetric adaptation                                                                                                                                                                                              
 5. Analyze reduction in feature absorption patterns                                                                                                                                                                                  
 ## Run 0: Baseline                                                                                                                                                                                                                   
 =======                                                                                                                                                                                                                              
 # Title: Hierarchical Competition Detection for Preventing Feature Absorption in Sparse Autoencoders                                                                                                                                 
 # Experiment description: 1. Modify mask intersection computation for asymmetric relationships                                                                                                                                       
 2. Implement directional competition coefficients                                                                                                                                                                                    
 3. Train with optimal dictionary size (18432) on gemma-2-2b                                                                                                                                                                          
 4. Compare against symmetric adaptation                                                                                                                                                                                              
 5. Analyze reduction in feature absorption patterns                                                                                                                                                                                  
                                                                                                                                                                                                                                      
 ## Run 0: Baseline                                                                                                                                                                                                                   
 Results: Baseline results from TopK SAE without competition loss.                                                                                                                                                                    
 Key metrics:                                                                                                                                                                                                                         
 - Absorption score: 0.0113 (lower is better)                                                                                                                                                                                         
 - KL divergence score: 0.9909 (higher is better)                                                                                                                                                                                     
 - Explained variance: 0.7773                                                                                                                                                                                                         
 - L0 sparsity: 320.0                                                                                                                                                                                                                 
                                                                                                                                                                                                                                      
 ## Run 1: Initial Competition Loss Implementation                                                                                                                                                                                    
 Description: Implemented hierarchical competition detection with:                                                                                                                                                                    
 - Competition coefficient computation using co-activation patterns                                                                                                                                                                   
 - Directional competition coefficients normalized by sparsity ratio                                                                                                                                                                  
 - Competition loss weight (ortho_weight) = 0.1                                                                                                                                                                                       
 - k = 120 features                                                                                                                                                                                                                   
                                                                                                                                                                                                                                      
 Results:                                                                                                                                                                                                                             
 - Absorption score: 0.0542 (worse than baseline)                                                                                                                                                                                     
 - KL divergence score: 0.9776 (slightly worse)                                                                                                                                                                                       
 - Explained variance: 0.6757 (worse)                                                                                                                                                                                                 
 - L0 sparsity: ~120 (as configured)                                                                                                                                                                                                  
                                                                                                                                                                                                                                      
 Analysis:                                                                                                                                                                                                                            
 The initial implementation shows some issues:                                                                                                                                                                                        
 1. Higher absorption score indicates more feature absorption                                                                                                                                                                         
 2. Lower explained variance suggests competition may be too strong                                                                                                                                                                   
 3. KL divergence relatively maintained but slightly decreased                                                                                                                                                                        
                                                                                                                                                                                                                                      
 Next steps:                                                                                                                                                                                                                          
 1. Reduce competition loss weight (ortho_weight) to 0.01 to allow better reconstruction                                                                                                                                              
 2. Keep k=120 as it maintains good sparsity                                                                                                                                                                                          
 3. Add gradient clipping to competition loss to prevent instability                                                                                                                                                                  
 >>>>>>> REPLACE                                                                                                                                                                                                                      
                                                                                                                                                                                                                                      

For Run 2, I propose reducing the competition weight and adding gradient clipping to the competition loss. Here are the changes needed:                                                                                               

experiment.py                                                                                                                                                                                                                         

                                                                                                                                                                                                                                      
 <<<<<<< SEARCH                                                                                                                                                                                                                       
         competition_loss = (max_coeffs * feature_dots.pow(2)).mean()                                                                                                                                                                 
 =======                                                                                                                                                                                                                              
         # Clip competition coefficients for stability                                                                                                                                                                                
         competition_loss = (max_coeffs.clamp(max=10.0) * feature_dots.pow(2)).mean()                                                                                                                                                 
 >>>>>>> REPLACE                                                                                                                                                                                                                      
                                                                                                                                                                                                                                      

experiment.py                                                                                                                                                                                                                         

                                                                                                                                                                                                                                      
 <<<<<<< SEARCH                                                                                                                                                                                                                       
         ortho_weight= 0.1,                                                                                                                                                                                                           
 =======                                                                                                                                                                                                                              
         ortho_weight= 0.01,  # Reduced from 0.1                                                                                                                                                                                      
 >>>>>>> REPLACE                                                                                                                                                                                                                      
                                                                                                                                                                                                                                      

Let's run the next experiment with:                                                                                                                                                                                                   

                                                                                                                                                                                                                                      
 python experiment.py --out_dir=run_2                                                                                                                                                                                                 
                                                                                                                                                                                                                                      

This should help balance the competition-reconstruction tradeoff better while maintaining stability.                                                                                                                                  

Tokens: 53k sent, 770 received. Cost: $0.17 message, $0.38 session.
Applied edit to notes.txt
Applied edit to experiment.py

python experiment.py --out_dir=run_2
Step 0: 40830.53515625
Step 100: 7375.806640625
Step 200: 5454.18798828125
Step 300: 4968.9111328125
Step 400: 4616.47021484375
Step 500: 4398.06591796875
Step 600: 4344.17236328125
Step 700: 4093.380859375
Step 800: 4038.6748046875
Step 900: 3900.999267578125
Step 1000: 3924.5595703125
Step 1100: 3786.24755859375
Step 1200: 3669.40478515625
Step 1300: 3661.771728515625
Step 1400: 3632.39208984375
Step 1500: 3648.334228515625
Step 1600: 3543.126953125
Step 1700: 3544.892822265625
Step 1800: 3444.9990234375
Step 1900: 3565.959716796875
Step 2000: 3564.72607421875
Step 2100: 3583.593505859375
Step 2200: 3450.43701171875
Step 2300: 3425.032470703125
Step 2400: 3403.99560546875

 training complete! 

all info: /gpfs/radev/project/lafferty/tl784/free_PhD_labor/results/orthogonal_continued/20250130_212318_hierarchical_orthogonal_sae/run_2/final_info.json

Running absorption evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Loading probe and training data
Training k-sparse probes
Loading validation data
Evaluating raw k-sparse probing scores
Building metadata

Running core evaluation...
Using device: cuda
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Saved evaluation results to: run_2/google_gemma-2-2b_layer_12_sae_custom_sae_eval_results.json

Running scr evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9750000238418579
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9720000624656677
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9950000643730164
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9950000643730164
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9390000700950623, scr_score: 0.4375002910385279
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9380000233650208, scr_score: 0.42187454889028175
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9340000152587891, scr_score: 0.359374374267165
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9390000700950623, scr_score: 0.4375002910385279
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9300000667572021, scr_score: 0.2968751309673376
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9260000586509705, scr_score: 0.23437495634422081
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9220000505447388, scr_score: 0.17187478172110407
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.5890000462532043, scr_score: 0.01474211549298745
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.5950000286102295, scr_score: 0.02948408453723957
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.5990000367164612, scr_score: 0.039312112716319424
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.612000048160553, scr_score: 0.07125316768614513
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.6200000047683716, scr_score: 0.09090907759556952
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.6260000467300415, scr_score: 0.10565119308855696
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.6390000581741333, scr_score: 0.13759224805838266
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9890000224113464
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9550000429153442
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9590000510215759
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9920000433921814
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9920000433921814
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8710000514984131, scr_score: 0.1844659857076143
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.878000020980835, scr_score: 0.2524268642223358
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8800000548362732, scr_score: 0.2718446714307952
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8860000371932983, scr_score: 0.3300969356842643
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8670000433921814, scr_score: 0.14563094997665002
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8650000691413879, scr_score: 0.12621372145414522
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8030000329017639, scr_score: -0.475728464346869
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.6780000329017639, scr_score: 0.10888249310703833
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.6920000314712524, scr_score: 0.14899710481947134
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.7170000076293945, scr_score: 0.2206302790249021
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.7320000529289246, scr_score: 0.26361035433511953
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.7590000629425049, scr_score: 0.34097428494916016
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.6820000410079956, scr_score: 0.12034383513729906
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.6800000071525574, scr_score: 0.1146130787286892
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9830000400543213
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.984000027179718
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9730000495910645
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9720000624656677
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.999000072479248
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.999000072479248
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9450000524520874, scr_score: 0.5555557658011382
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9500000476837158, scr_score: 0.6349207400434262
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9430000185966492, scr_score: 0.5238092084411499
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9450000524520874, scr_score: 0.5555557658011382
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9350000619888306, scr_score: 0.396825817316562
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9100000262260437, scr_score: 0.0
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.815000057220459, scr_score: -1.507935456708595
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6030000448226929, scr_score: 0.037974794330044616
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6100000143051147, scr_score: 0.055696234239288635
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6330000162124634, scr_score: 0.11392408119449507
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6410000324249268, scr_score: 0.13417728471747628
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6630000472068787, scr_score: 0.1898735189567649
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6760000586509705, scr_score: 0.22278493695715454
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6140000224113464, scr_score: 0.06582283600077923
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9940000176429749
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9940000176429749
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9690000414848328
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.968000054359436
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9970000386238098
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9980000257492065
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8650000691413879, scr_score: 0.18750034924590825
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8650000691413879, scr_score: 0.18750034924590825
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8370000123977661, scr_score: -0.03125005820765137
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8390000462532043, scr_score: -0.015624796273220196
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.831000030040741, scr_score: -0.07812491268852294
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8330000638961792, scr_score: -0.062499650754091765
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8580000400543213, scr_score: 0.1328126309672156
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.6850000619888306, scr_score: 0.08308621873453508
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.7170000076293945, scr_score: 0.1780415435515382
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.737000048160553, scr_score: 0.23738884264763468
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.7580000162124634, scr_score: 0.2997032856130665
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.7760000228881836, scr_score: 0.3531157663653655
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.6810000538825989, scr_score: 0.07121675891531577
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.6530000567436218, scr_score: -0.01186928295084368
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9440000653266907
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9520000219345093
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9960000514984131
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9970000386238098
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.815000057220459, scr_score: 0.04371592886659017
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.815000057220459, scr_score: 0.04371592886659017
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.8170000314712524, scr_score: 0.05464474822904205
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.8050000667572021, scr_score: -0.01092881936245188
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.8080000281333923, scr_score: 0.00546440968122594
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.8050000667572021, scr_score: -0.01092881936245188
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.7620000243186951, scr_score: -0.24590169273908055
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.7870000600814819, scr_score: 0.3843138373204936
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8230000138282776, scr_score: 0.525490096164477
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.843000054359436, scr_score: 0.603921610792973
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8540000319480896, scr_score: 0.6470587685309047
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8640000224113464, scr_score: 0.6862744089733254
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8640000224113464, scr_score: 0.6862744089733254
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8660000562667847, scr_score: 0.6941176773080023
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9640000462532043
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9640000462532043
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9770000576972961
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9750000238418579
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9960000514984131
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9960000514984131
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.7900000214576721, scr_score: 0.0410254200064373
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8060000538825989, scr_score: 0.12307687134902433
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8210000395774841, scr_score: 0.1999998777340575
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8260000348091125, scr_score: 0.22564087986240192
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8290000557899475, scr_score: 0.24102560340535104
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8440000414848328, scr_score: 0.3179486097903842
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8350000381469727, scr_score: 0.27179474482639304
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.734000027179718, scr_score: 0.07258066454365199
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7400000095367432, scr_score: 0.09677413927777444
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7560000419616699, scr_score: 0.16129039235714715
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7630000114440918, scr_score: 0.18951607282340924
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7760000228881836, scr_score: 0.2419354683650784
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.8030000329017639, scr_score: 0.3508064651805564
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.8280000686645508, scr_score: 0.4516130505317551
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9630000591278076
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9590000510215759
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9780000448226929
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9780000448226929
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9940000176429749
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9930000305175781
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.7740000486373901, scr_score: 0.08520176975018703
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.781000018119812, scr_score: 0.11659176883874377
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.8050000667572021, scr_score: 0.22421531016200436
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.8200000524520874, scr_score: 0.2914798230249813
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.8210000395774841, scr_score: 0.29596407042543016
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.8280000686645508, scr_score: 0.3273543367994015
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.7850000262260437, scr_score: 0.13452902572595388
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.7620000243186951, scr_score: 0.10267856311319266
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.796000063419342, scr_score: 0.25446442707572475
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.8170000314712524, scr_score: 0.3482142690835282
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.8340000510215759, scr_score: 0.4241072010647942
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.8470000624656677, scr_score: 0.48214295692740233
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.8480000495910645, scr_score: 0.4866071844340367
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.8680000305175781, scr_score: 0.5758927989352057
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.971000075340271
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.971000075340271
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9620000720024109
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9630000591278076
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9930000305175781
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9940000176429749
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7400000095367432, scr_score: 0.047210196127387125
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7380000352859497, scr_score: 0.03862661712745569
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7480000257492065, scr_score: 0.08154502375487709
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7500000596046448, scr_score: 0.09012885856869063
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.753000020980835, scr_score: 0.10300422706858779
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7540000081062317, scr_score: 0.10729601656855352
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7640000581741333, scr_score: 0.15021467900985702
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7700000405311584, scr_score: 0.042857150966616867
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7790000438690186, scr_score: 0.08571430193323373
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7830000519752502, scr_score: 0.10476195612190681
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7870000600814819, scr_score: 0.12380961031057988
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7920000553131104, scr_score: 0.14761910708852366
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.812000036239624, scr_score: 0.24285709420029883
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.8250000476837158, scr_score: 0.3047618993555888

Running tpp evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Removing 24 from test set
Removing 12 from test set
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 0: 0.9540000557899475
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 1: 0.9630000591278076
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 2: 0.9520000219345093
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 6: 0.9920000433921814
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 9: 0.9810000658035278
Removing 29 from train set
Removing 28 from train set
Removing 0 from train set
Removing 31 from train set
Removing 7 from train set
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 1: 0.9540000557899475
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 2: 0.9240000247955322
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 3: 0.9310000538825989
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 5: 0.9260000586509705
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 6: 0.8640000224113464

Running sparse_probing evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Removing 24 from test set
Removing 12 from test set
Num non-zero elements: 2304
Test accuracy for 0: 0.935
Num non-zero elements: 2304
Test accuracy for 1: 0.952
Num non-zero elements: 2304
Test accuracy for 2: 0.942
Num non-zero elements: 2304
Test accuracy for 6: 0.988
Num non-zero elements: 2304
Test accuracy for 9: 0.981
Num non-zero elements: 1
Test accuracy for 0: 0.57
Num non-zero elements: 1
Test accuracy for 1: 0.629
Num non-zero elements: 1
Test accuracy for 2: 0.686
Num non-zero elements: 1
Test accuracy for 6: 0.782
Num non-zero elements: 1
Test accuracy for 9: 0.549
Num non-zero elements: 2
Test accuracy for 0: 0.582
Num non-zero elements: 2
Test accuracy for 1: 0.661
Num non-zero elements: 2
Test accuracy for 2: 0.713
Num non-zero elements: 2
Test accuracy for 6: 0.801
Num non-zero elements: 2
Test accuracy for 9: 0.701
Num non-zero elements: 5
Test accuracy for 0: 0.721
Num non-zero elements: 5
Test accuracy for 1: 0.7
Num non-zero elements: 5
Test accuracy for 2: 0.763
Num non-zero elements: 5
Test accuracy for 6: 0.902
Num non-zero elements: 5
Test accuracy for 9: 0.87
Num non-zero elements: 10
Test accuracy for 0: 0.782
Num non-zero elements: 10
Test accuracy for 1: 0.799
Num non-zero elements: 10
Test accuracy for 2: 0.801
Num non-zero elements: 10
Test accuracy for 6: 0.886
Num non-zero elements: 10
Test accuracy for 9: 0.9
Num non-zero elements: 20
Test accuracy for 0: 0.817
Num non-zero elements: 20
Test accuracy for 1: 0.88
Num non-zero elements: 20
Test accuracy for 2: 0.879
Num non-zero elements: 20
Test accuracy for 6: 0.967
Num non-zero elements: 20
Test accuracy for 9: 0.938
Num non-zero elements: 50
Test accuracy for 0: 0.91
Num non-zero elements: 50
Test accuracy for 1: 0.925
Num non-zero elements: 50
Test accuracy for 2: 0.921
Num non-zero elements: 50
Test accuracy for 6: 0.982
Num non-zero elements: 50
Test accuracy for 9: 0.954
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for 0: 0.9510000348091125
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 17 epochs
Test accuracy for 1: 0.9610000252723694
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 19 epochs
Test accuracy for 2: 0.9470000267028809
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 13 epochs
Test accuracy for 6: 0.9900000691413879
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 20 epochs
Test accuracy for 9: 0.9700000286102295
Num non-zero elements: 1
Test accuracy for 0: 0.712
Num non-zero elements: 1
Test accuracy for 1: 0.644
Num non-zero elements: 1
Test accuracy for 2: 0.873
Num non-zero elements: 1
Test accuracy for 6: 0.984
Num non-zero elements: 1
Test accuracy for 9: 0.921
Num non-zero elements: 2
Test accuracy for 0: 0.764
Num non-zero elements: 2
Test accuracy for 1: 0.652
Num non-zero elements: 2
Test accuracy for 2: 0.874
Num non-zero elements: 2
Test accuracy for 6: 0.988
Num non-zero elements: 2
Test accuracy for 9: 0.919
Num non-zero elements: 5
Test accuracy for 0: 0.769
Num non-zero elements: 5
Test accuracy for 1: 0.772
Num non-zero elements: 5
Test accuracy for 2: 0.865
Num non-zero elements: 5
Test accuracy for 6: 0.989
Num non-zero elements: 5
Test accuracy for 9: 0.936
Num non-zero elements: 10
Test accuracy for 0: 0.871
Num non-zero elements: 10
Test accuracy for 1: 0.863
Num non-zero elements: 10
Test accuracy for 2: 0.909
Num non-zero elements: 10
Test accuracy for 6: 0.99
Num non-zero elements: 10
Test accuracy for 9: 0.96
Num non-zero elements: 20
Test accuracy for 0: 0.9
Num non-zero elements: 20
Test accuracy for 1: 0.931
Num non-zero elements: 20
Test accuracy for 2: 0.93
Num non-zero elements: 20
Test accuracy for 6: 0.992
Num non-zero elements: 20
Test accuracy for 9: 0.968
Num non-zero elements: 50
Test accuracy for 0: 0.934
Num non-zero elements: 50
Test accuracy for 1: 0.96
Num non-zero elements: 50
Test accuracy for 2: 0.945
Num non-zero elements: 50
Test accuracy for 6: 0.992
Num non-zero elements: 50
Test accuracy for 9: 0.976
Removing 24 from test set
Removing 12 from test set
Num non-zero elements: 2304
Test accuracy for 11: 0.954
Num non-zero elements: 2304
Test accuracy for 13: 0.943
Num non-zero elements: 2304
Test accuracy for 14: 0.947
Num non-zero elements: 2304
Test accuracy for 18: 0.93
Num non-zero elements: 2304
Test accuracy for 19: 0.956
Num non-zero elements: 1
Test accuracy for 11: 0.54
Num non-zero elements: 1
Test accuracy for 13: 0.675
Num non-zero elements: 1
Test accuracy for 14: 0.639
Num non-zero elements: 1
Test accuracy for 18: 0.696
Num non-zero elements: 1
Test accuracy for 19: 0.787
Num non-zero elements: 2
Test accuracy for 11: 0.772
Num non-zero elements: 2
Test accuracy for 13: 0.715
Num non-zero elements: 2
Test accuracy for 14: 0.686
Num non-zero elements: 2
Test accuracy for 18: 0.719
Num non-zero elements: 2
Test accuracy for 19: 0.759
Num non-zero elements: 5
Test accuracy for 11: 0.789
Num non-zero elements: 5
Test accuracy for 13: 0.74
Num non-zero elements: 5
Test accuracy for 14: 0.737
Num non-zero elements: 5
Test accuracy for 18: 0.73
Num non-zero elements: 5
Test accuracy for 19: 0.834
Num non-zero elements: 10
Test accuracy for 11: 0.835
Num non-zero elements: 10
Test accuracy for 13: 0.798
Num non-zero elements: 10
Test accuracy for 14: 0.785
Num non-zero elements: 10
Test accuracy for 18: 0.746
Num non-zero elements: 10
Test accuracy for 19: 0.873
Num non-zero elements: 20
Test accuracy for 11: 0.902
Num non-zero elements: 20
Test accuracy for 13: 0.886
Num non-zero elements: 20
Test accuracy for 14: 0.868
Num non-zero elements: 20
Test accuracy for 18: 0.764
Num non-zero elements: 20
Test accuracy for 19: 0.892
Num non-zero elements: 50
Test accuracy for 11: 0.947
Num non-zero elements: 50
Test accuracy for 13: 0.92
Num non-zero elements: 50
Test accuracy for 14: 0.908
Num non-zero elements: 50
Test accuracy for 18: 0.856
Num non-zero elements: 50
Test accuracy for 19: 0.925
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 13 epochs
Test accuracy for 11: 0.9620000720024109
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for 13: 0.9520000219345093
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 20 epochs
Test accuracy for 14: 0.9500000476837158
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 22 epochs
Test accuracy for 18: 0.9180000424385071
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 28 epochs
Test accuracy for 19: 0.9520000219345093
Num non-zero elements: 1
Test accuracy for 11: 0.719
Num non-zero elements: 1
Test accuracy for 13: 0.803
Num non-zero elements: 1
Test accuracy for 14: 0.864
Num non-zero elements: 1
Test accuracy for 18: 0.727
Num non-zero elements: 1
Test accuracy for 19: 0.854
Num non-zero elements: 2
Test accuracy for 11: 0.77
Num non-zero elements: 2
Test accuracy for 13: 0.811
Num non-zero elements: 2
Test accuracy for 14: 0.866
Num non-zero elements: 2
Test accuracy for 18: 0.731
Num non-zero elements: 2
Test accuracy for 19: 0.853
Num non-zero elements: 5
Test accuracy for 11: 0.913
Num non-zero elements: 5
Test accuracy for 13: 0.853
Num non-zero elements: 5
Test accuracy for 14: 0.879
Num non-zero elements: 5
Test accuracy for 18: 0.883
Num non-zero elements: 5
Test accuracy for 19: 0.918
Num non-zero elements: 10
Test accuracy for 11: 0.911
Num non-zero elements: 10
Test accuracy for 13: 0.873
Num non-zero elements: 10
Test accuracy for 14: 0.899
Num non-zero elements: 10
Test accuracy for 18: 0.903
Num non-zero elements: 10
Test accuracy for 19: 0.94
Num non-zero elements: 20
Test accuracy for 11: 0.945
Num non-zero elements: 20
Test accuracy for 13: 0.909
Num non-zero elements: 20
Test accuracy for 14: 0.913
Num non-zero elements: 20
Test accuracy for 18: 0.911
Num non-zero elements: 20
Test accuracy for 19: 0.949
Num non-zero elements: 50
Test accuracy for 11: 0.943
Num non-zero elements: 50
Test accuracy for 13: 0.933
Num non-zero elements: 50
Test accuracy for 14: 0.929
Num non-zero elements: 50
Test accuracy for 18: 0.911
Num non-zero elements: 50
Test accuracy for 19: 0.96
Removing 24 from test set
Removing 12 from test set
Num non-zero elements: 2304
Test accuracy for 20: 0.962
Num non-zero elements: 2304
Test accuracy for 21: 0.903
Num non-zero elements: 2304
Test accuracy for 22: 0.899
Num non-zero elements: 2304
Test accuracy for 25: 0.96
Num non-zero elements: 2304
Test accuracy for 26: 0.861
Num non-zero elements: 1
Test accuracy for 20: 0.694
Num non-zero elements: 1
Test accuracy for 21: 0.765
Num non-zero elements: 1
Test accuracy for 22: 0.639
Num non-zero elements: 1
Test accuracy for 25: 0.689
Num non-zero elements: 1
Test accuracy for 26: 0.62
Num non-zero elements: 2
Test accuracy for 20: 0.813
Num non-zero elements: 2
Test accuracy for 21: 0.752
Num non-zero elements: 2
Test accuracy for 22: 0.667
Num non-zero elements: 2
Test accuracy for 25: 0.767
Num non-zero elements: 2
Test accuracy for 26: 0.674
Num non-zero elements: 5
Test accuracy for 20: 0.868
Num non-zero elements: 5
Test accuracy for 21: 0.796
Num non-zero elements: 5
Test accuracy for 22: 0.729
Num non-zero elements: 5
Test accuracy for 25: 0.798
Num non-zero elements: 5
Test accuracy for 26: 0.688
Num non-zero elements: 10
Test accuracy for 20: 0.87
Num non-zero elements: 10
Test accuracy for 21: 0.814
Num non-zero elements: 10
Test accuracy for 22: 0.756
Num non-zero elements: 10
Test accuracy for 25: 0.846
Num non-zero elements: 10
Test accuracy for 26: 0.704
Num non-zero elements: 20
Test accuracy for 20: 0.9
Num non-zero elements: 20
Test accuracy for 21: 0.837
Num non-zero elements: 20
Test accuracy for 22: 0.797
Num non-zero elements: 20
Test accuracy for 25: 0.895
Num non-zero elements: 20
Test accuracy for 26: 0.824
Num non-zero elements: 50
Test accuracy for 20: 0.92
Num non-zero elements: 50
Test accuracy for 21: 0.885
Num non-zero elements: 50
Test accuracy for 22: 0.873
Num non-zero elements: 50
Test accuracy for 25: 0.934
Num non-zero elements: 50
Test accuracy for 26: 0.847
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 19 epochs
Test accuracy for 20: 0.9570000171661377
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 12 epochs
Test accuracy for 21: 0.9270000457763672
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 25 epochs
Test accuracy for 22: 0.921000063419342
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 26 epochs
Test accuracy for 25: 0.9610000252723694
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 14 epochs
Test accuracy for 26: 0.8890000581741333
Num non-zero elements: 1
Test accuracy for 20: 0.906
Num non-zero elements: 1
Test accuracy for 21: 0.798
Num non-zero elements: 1
Test accuracy for 22: 0.831
Num non-zero elements: 1
Test accuracy for 25: 0.838
Num non-zero elements: 1
Test accuracy for 26: 0.674
Num non-zero elements: 2
Test accuracy for 20: 0.916
Num non-zero elements: 2
Test accuracy for 21: 0.794
Num non-zero elements: 2
Test accuracy for 22: 0.859
Num non-zero elements: 2
Test accuracy for 25: 0.867
Num non-zero elements: 2
Test accuracy for 26: 0.702
Num non-zero elements: 5
Test accuracy for 20: 0.922
Num non-zero elements: 5
Test accuracy for 21: 0.848
Num non-zero elements: 5
Test accuracy for 22: 0.895
Num non-zero elements: 5
Test accuracy for 25: 0.916
Num non-zero elements: 5
Test accuracy for 26: 0.84
Num non-zero elements: 10
Test accuracy for 20: 0.912
Num non-zero elements: 10
Test accuracy for 21: 0.866
Num non-zero elements: 10
Test accuracy for 22: 0.885
Num non-zero elements: 10
Test accuracy for 25: 0.944
Num non-zero elements: 10
Test accuracy for 26: 0.845
Num non-zero elements: 20
Test accuracy for 20: 0.939
Num non-zero elements: 20
Test accuracy for 21: 0.855
Num non-zero elements: 20
Test accuracy for 22: 0.89
Num non-zero elements: 20
Test accuracy for 25: 0.953
Num non-zero elements: 20
Test accuracy for 26: 0.869
Num non-zero elements: 50
Test accuracy for 20: 0.943
Num non-zero elements: 50
Test accuracy for 21: 0.88
Num non-zero elements: 50
Test accuracy for 22: 0.907
Num non-zero elements: 50
Test accuracy for 25: 0.955
Num non-zero elements: 50
Test accuracy for 26: 0.871
Removing 29 from train set
Removing 28 from train set
Removing 0 from train set
Removing 31 from train set
Removing 7 from train set
Num non-zero elements: 2304
Test accuracy for 1: 0.95
Num non-zero elements: 2304
Test accuracy for 2: 0.891
Num non-zero elements: 2304
Test accuracy for 3: 0.912
Num non-zero elements: 2304
Test accuracy for 5: 0.917
Num non-zero elements: 2304
Test accuracy for 6: 0.83
Num non-zero elements: 1
Test accuracy for 1: 0.667
Num non-zero elements: 1
Test accuracy for 2: 0.6
Num non-zero elements: 1
Test accuracy for 3: 0.585
Num non-zero elements: 1
Test accuracy for 5: 0.561
Num non-zero elements: 1
Test accuracy for 6: 0.598
Num non-zero elements: 2
Test accuracy for 1: 0.742
Num non-zero elements: 2
Test accuracy for 2: 0.647
Num non-zero elements: 2
Test accuracy for 3: 0.621
Num non-zero elements: 2
Test accuracy for 5: 0.593
Num non-zero elements: 2
Test accuracy for 6: 0.616
Num non-zero elements: 5
Test accuracy for 1: 0.781
Num non-zero elements: 5
Test accuracy for 2: 0.734
Num non-zero elements: 5
Test accuracy for 3: 0.625
Num non-zero elements: 5
Test accuracy for 5: 0.689
Num non-zero elements: 5
Test accuracy for 6: 0.681
Num non-zero elements: 10
Test accuracy for 1: 0.794
Num non-zero elements: 10
Test accuracy for 2: 0.773
Num non-zero elements: 10
Test accuracy for 3: 0.744
Num non-zero elements: 10
Test accuracy for 5: 0.739
Num non-zero elements: 10
Test accuracy for 6: 0.689
Num non-zero elements: 20
Test accuracy for 1: 0.879
Num non-zero elements: 20
Test accuracy for 2: 0.848
Num non-zero elements: 20
Test accuracy for 3: 0.776
Num non-zero elements: 20
Test accuracy for 5: 0.804
Num non-zero elements: 20
Test accuracy for 6: 0.762
Num non-zero elements: 50
Test accuracy for 1: 0.919
Num non-zero elements: 50
Test accuracy for 2: 0.877
Num non-zero elements: 50
Test accuracy for 3: 0.851
Num non-zero elements: 50
Test accuracy for 5: 0.842
Num non-zero elements: 50
Test accuracy for 6: 0.791
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 17 epochs
Test accuracy for 1: 0.9420000314712524
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 19 epochs
Test accuracy for 2: 0.9330000281333923
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 20 epochs
Test accuracy for 3: 0.9180000424385071
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 23 epochs
Test accuracy for 5: 0.921000063419342
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 27 epochs
Test accuracy for 6: 0.8770000338554382
Num non-zero elements: 1
Test accuracy for 1: 0.807
Num non-zero elements: 1
Test accuracy for 2: 0.622
Num non-zero elements: 1
Test accuracy for 3: 0.603
Num non-zero elements: 1
Test accuracy for 5: 0.858
Num non-zero elements: 1
Test accuracy for 6: 0.729
Num non-zero elements: 2
Test accuracy for 1: 0.823
Num non-zero elements: 2
Test accuracy for 2: 0.704
Num non-zero elements: 2
Test accuracy for 3: 0.697
Num non-zero elements: 2
Test accuracy for 5: 0.858
Num non-zero elements: 2
Test accuracy for 6: 0.757
Num non-zero elements: 5
Test accuracy for 1: 0.901
Num non-zero elements: 5
Test accuracy for 2: 0.713
Num non-zero elements: 5
Test accuracy for 3: 0.747
Num non-zero elements: 5
Test accuracy for 5: 0.87
Num non-zero elements: 5
Test accuracy for 6: 0.752
Num non-zero elements: 10
Test accuracy for 1: 0.915
Num non-zero elements: 10
Test accuracy for 2: 0.786
Num non-zero elements: 10
Test accuracy for 3: 0.814
Num non-zero elements: 10
Test accuracy for 5: 0.894
Num non-zero elements: 10
Test accuracy for 6: 0.797
Num non-zero elements: 20
Test accuracy for 1: 0.923
Num non-zero elements: 20
Test accuracy for 2: 0.86
Num non-zero elements: 20
Test accuracy for 3: 0.867
Num non-zero elements: 20
Test accuracy for 5: 0.884
Num non-zero elements: 20
Test accuracy for 6: 0.765
Num non-zero elements: 50
Test accuracy for 1: 0.93
Num non-zero elements: 50
Test accuracy for 2: 0.894
Num non-zero elements: 50
Test accuracy for 3: 0.896
Num non-zero elements: 50
Test accuracy for 5: 0.891
Num non-zero elements: 50
Test accuracy for 6: 0.806
Num non-zero elements: 2304
Test accuracy for 1.0: 0.982
Num non-zero elements: 2304
Test accuracy for 5.0: 0.981
Num non-zero elements: 1
Test accuracy for 1.0: 0.671
Num non-zero elements: 1
Test accuracy for 5.0: 0.671
Num non-zero elements: 2
Test accuracy for 1.0: 0.724
Num non-zero elements: 2
Test accuracy for 5.0: 0.724
Num non-zero elements: 5
Test accuracy for 1.0: 0.766
Num non-zero elements: 5
Test accuracy for 5.0: 0.766
Num non-zero elements: 10
Test accuracy for 1.0: 0.826
Num non-zero elements: 10
Test accuracy for 5.0: 0.826
Num non-zero elements: 20
Test accuracy for 1.0: 0.848
Num non-zero elements: 20
Test accuracy for 5.0: 0.847
Num non-zero elements: 50
Test accuracy for 1.0: 0.933
Num non-zero elements: 50
Test accuracy for 5.0: 0.932
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 16 epochs
Test accuracy for 1.0: 0.9720000624656677
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 19 epochs
Test accuracy for 5.0: 0.9740000367164612
Num non-zero elements: 1
Test accuracy for 1.0: 0.851
Num non-zero elements: 1
Test accuracy for 5.0: 0.851
Num non-zero elements: 2
Test accuracy for 1.0: 0.883
Num non-zero elements: 2
Test accuracy for 5.0: 0.883
Num non-zero elements: 5
Test accuracy for 1.0: 0.938
Num non-zero elements: 5
Test accuracy for 5.0: 0.938
Num non-zero elements: 10
Test accuracy for 1.0: 0.939
Num non-zero elements: 10
Test accuracy for 5.0: 0.939
Num non-zero elements: 20
Test accuracy for 1.0: 0.958
Num non-zero elements: 20
Test accuracy for 5.0: 0.958
Num non-zero elements: 50
Test accuracy for 1.0: 0.966
Num non-zero elements: 50
Test accuracy for 5.0: 0.966
Loading dataset codeparrot/github-code, this usually takes ~30 seconds
Num non-zero elements: 2304
Test accuracy for C: 0.942
Num non-zero elements: 2304
Test accuracy for Python: 0.98
Num non-zero elements: 2304
Test accuracy for HTML: 0.987
Num non-zero elements: 2304
Test accuracy for Java: 0.972
Num non-zero elements: 2304
Test accuracy for PHP: 0.95
Num non-zero elements: 1
Test accuracy for C: 0.655
Num non-zero elements: 1
Test accuracy for Python: 0.645
Num non-zero elements: 1
Test accuracy for HTML: 0.778
Num non-zero elements: 1
Test accuracy for Java: 0.655
Num non-zero elements: 1
Test accuracy for PHP: 0.595
Num non-zero elements: 2
Test accuracy for C: 0.672
Num non-zero elements: 2
Test accuracy for Python: 0.675
Num non-zero elements: 2
Test accuracy for HTML: 0.793
Num non-zero elements: 2
Test accuracy for Java: 0.693
Num non-zero elements: 2
Test accuracy for PHP: 0.633
Num non-zero elements: 5
Test accuracy for C: 0.749
Num non-zero elements: 5
Test accuracy for Python: 0.731
Num non-zero elements: 5
Test accuracy for HTML: 0.936
Num non-zero elements: 5
Test accuracy for Java: 0.744
Num non-zero elements: 5
Test accuracy for PHP: 0.69
Num non-zero elements: 10
Test accuracy for C: 0.794
Num non-zero elements: 10
Test accuracy for Python: 0.721
Num non-zero elements: 10
Test accuracy for HTML: 0.95
Num non-zero elements: 10
Test accuracy for Java: 0.78
Num non-zero elements: 10
Test accuracy for PHP: 0.709
Num non-zero elements: 20
Test accuracy for C: 0.871
Num non-zero elements: 20
Test accuracy for Python: 0.854
Num non-zero elements: 20
Test accuracy for HTML: 0.956
Num non-zero elements: 20
Test accuracy for Java: 0.852
Num non-zero elements: 20
Test accuracy for PHP: 0.853
Num non-zero elements: 50
Test accuracy for C: 0.901
Num non-zero elements: 50
Test accuracy for Python: 0.961
Num non-zero elements: 50
Test accuracy for HTML: 0.968
Num non-zero elements: 50
Test accuracy for Java: 0.891
Num non-zero elements: 50
Test accuracy for PHP: 0.899
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 19 epochs
Test accuracy for C: 0.9490000605583191
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 39 epochs
Test accuracy for Python: 0.9910000562667847
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 26 epochs
Test accuracy for HTML: 0.9820000529289246
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 27 epochs
Test accuracy for Java: 0.9670000672340393
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 14 epochs
Test accuracy for PHP: 0.9500000476837158
Num non-zero elements: 1
Test accuracy for C: 0.617
Num non-zero elements: 1
Test accuracy for Python: 0.564
Num non-zero elements: 1
Test accuracy for HTML: 0.611
Num non-zero elements: 1
Test accuracy for Java: 0.631
Num non-zero elements: 1
Test accuracy for PHP: 0.904
Num non-zero elements: 2
Test accuracy for C: 0.61
Num non-zero elements: 2
Test accuracy for Python: 0.923
Num non-zero elements: 2
Test accuracy for HTML: 0.647
Num non-zero elements: 2
Test accuracy for Java: 0.645
Num non-zero elements: 2
Test accuracy for PHP: 0.903
Num non-zero elements: 5
Test accuracy for C: 0.788
Num non-zero elements: 5
Test accuracy for Python: 0.926
Num non-zero elements: 5
Test accuracy for HTML: 0.92
Num non-zero elements: 5
Test accuracy for Java: 0.671
Num non-zero elements: 5
Test accuracy for PHP: 0.911
Num non-zero elements: 10
Test accuracy for C: 0.8
Num non-zero elements: 10
Test accuracy for Python: 0.939
Num non-zero elements: 10
Test accuracy for HTML: 0.935
Num non-zero elements: 10
Test accuracy for Java: 0.809
Num non-zero elements: 10
Test accuracy for PHP: 0.906
Num non-zero elements: 20
Test accuracy for C: 0.881
Num non-zero elements: 20
Test accuracy for Python: 0.945
Num non-zero elements: 20
Test accuracy for HTML: 0.953
Num non-zero elements: 20
Test accuracy for Java: 0.816
Num non-zero elements: 20
Test accuracy for PHP: 0.909
Num non-zero elements: 50
Test accuracy for C: 0.919
Num non-zero elements: 50
Test accuracy for Python: 0.978
Num non-zero elements: 50
Test accuracy for HTML: 0.964
Num non-zero elements: 50
Test accuracy for Java: 0.934
Num non-zero elements: 50
Test accuracy for PHP: 0.94
Num non-zero elements: 2304
Test accuracy for 0: 0.925
Num non-zero elements: 2304
Test accuracy for 1: 0.987
Num non-zero elements: 2304
Test accuracy for 2: 0.91
Num non-zero elements: 2304
Test accuracy for 3: 0.933
Num non-zero elements: 1
Test accuracy for 0: 0.698
Num non-zero elements: 1
Test accuracy for 1: 0.683
Num non-zero elements: 1
Test accuracy for 2: 0.669
Num non-zero elements: 1
Test accuracy for 3: 0.647
Num non-zero elements: 2
Test accuracy for 0: 0.799
Num non-zero elements: 2
Test accuracy for 1: 0.796
Num non-zero elements: 2
Test accuracy for 2: 0.695
Num non-zero elements: 2
Test accuracy for 3: 0.747
Num non-zero elements: 5
Test accuracy for 0: 0.822
Num non-zero elements: 5
Test accuracy for 1: 0.884
Num non-zero elements: 5
Test accuracy for 2: 0.76
Num non-zero elements: 5
Test accuracy for 3: 0.834
Num non-zero elements: 10
Test accuracy for 0: 0.862
Num non-zero elements: 10
Test accuracy for 1: 0.937
Num non-zero elements: 10
Test accuracy for 2: 0.8
Num non-zero elements: 10
Test accuracy for 3: 0.886
Num non-zero elements: 20
Test accuracy for 0: 0.889
Num non-zero elements: 20
Test accuracy for 1: 0.956
Num non-zero elements: 20
Test accuracy for 2: 0.863
Num non-zero elements: 20
Test accuracy for 3: 0.887
Num non-zero elements: 50
Test accuracy for 0: 0.902
Num non-zero elements: 50
Test accuracy for 1: 0.97
Num non-zero elements: 50
Test accuracy for 2: 0.897
Num non-zero elements: 50
Test accuracy for 3: 0.936
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 28 epochs
Test accuracy for 0: 0.9420000314712524
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 17 epochs
Test accuracy for 1: 0.987000048160553
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 19 epochs
Test accuracy for 2: 0.9310000538825989
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 23 epochs
Test accuracy for 3: 0.956000030040741
Num non-zero elements: 1
Test accuracy for 0: 0.738
Num non-zero elements: 1
Test accuracy for 1: 0.959
Num non-zero elements: 1
Test accuracy for 2: 0.73
Num non-zero elements: 1
Test accuracy for 3: 0.662
Num non-zero elements: 2
Test accuracy for 0: 0.861
Num non-zero elements: 2
Test accuracy for 1: 0.967
Num non-zero elements: 2
Test accuracy for 2: 0.782
Num non-zero elements: 2
Test accuracy for 3: 0.728
Num non-zero elements: 5
Test accuracy for 0: 0.864
Num non-zero elements: 5
Test accuracy for 1: 0.969
Num non-zero elements: 5
Test accuracy for 2: 0.82
Num non-zero elements: 5
Test accuracy for 3: 0.819
Num non-zero elements: 10
Test accuracy for 0: 0.898
Num non-zero elements: 10
Test accuracy for 1: 0.975
Num non-zero elements: 10
Test accuracy for 2: 0.853
Num non-zero elements: 10
Test accuracy for 3: 0.875
Num non-zero elements: 20
Test accuracy for 0: 0.896
Num non-zero elements: 20
Test accuracy for 1: 0.974
Num non-zero elements: 20
Test accuracy for 2: 0.871
Num non-zero elements: 20
Test accuracy for 3: 0.923
Num non-zero elements: 50
Test accuracy for 0: 0.922
Num non-zero elements: 50
Test accuracy for 1: 0.975
Num non-zero elements: 50
Test accuracy for 2: 0.892
Num non-zero elements: 50
Test accuracy for 3: 0.936
Loading dataset Helsinki-NLP/europarl, this usually takes ~10 seconds
Num non-zero elements: 2304
Test accuracy for en: 0.998
Num non-zero elements: 2304
Test accuracy for fr: 1.0
Num non-zero elements: 2304
Test accuracy for de: 0.999
Num non-zero elements: 2304
Test accuracy for es: 1.0
Num non-zero elements: 2304
Test accuracy for nl: 1.0
Num non-zero elements: 1
Test accuracy for en: 0.747
Num non-zero elements: 1
Test accuracy for fr: 0.585
Num non-zero elements: 1
Test accuracy for de: 0.747
Num non-zero elements: 1
Test accuracy for es: 0.497
Num non-zero elements: 1
Test accuracy for nl: 0.626
Num non-zero elements: 2
Test accuracy for en: 0.824
Num non-zero elements: 2
Test accuracy for fr: 0.601
Num non-zero elements: 2
Test accuracy for de: 0.824
Num non-zero elements: 2
Test accuracy for es: 0.919
Num non-zero elements: 2
Test accuracy for nl: 0.739
Num non-zero elements: 5
Test accuracy for en: 0.895
Num non-zero elements: 5
Test accuracy for fr: 0.918
Num non-zero elements: 5
Test accuracy for de: 0.865
Num non-zero elements: 5
Test accuracy for es: 0.975
Num non-zero elements: 5
Test accuracy for nl: 0.867
Num non-zero elements: 10
Test accuracy for en: 0.977
Num non-zero elements: 10
Test accuracy for fr: 0.97
Num non-zero elements: 10
Test accuracy for de: 0.964
Num non-zero elements: 10
Test accuracy for es: 0.986
Num non-zero elements: 10
Test accuracy for nl: 0.918
Num non-zero elements: 20
Test accuracy for en: 0.994
Num non-zero elements: 20
Test accuracy for fr: 0.989
Num non-zero elements: 20
Test accuracy for de: 0.98
Num non-zero elements: 20
Test accuracy for es: 0.993
Num non-zero elements: 20
Test accuracy for nl: 0.985
Num non-zero elements: 50
Test accuracy for en: 0.998
Num non-zero elements: 50
Test accuracy for fr: 0.999
Num non-zero elements: 50
Test accuracy for de: 0.998
Num non-zero elements: 50
Test accuracy for es: 0.998
Num non-zero elements: 50
Test accuracy for nl: 0.994
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for en: 1.0
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 14 epochs
Test accuracy for fr: 0.999000072479248
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 23 epochs
Test accuracy for de: 1.0
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 16 epochs
Test accuracy for es: 0.9980000257492065
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 14 epochs
Test accuracy for nl: 0.9970000386238098
Num non-zero elements: 1
Test accuracy for en: 1.0
Num non-zero elements: 1
Test accuracy for fr: 0.991
Num non-zero elements: 1
Test accuracy for de: 0.803
Num non-zero elements: 1
Test accuracy for es: 0.981
Num non-zero elements: 1
Test accuracy for nl: 0.74
Num non-zero elements: 2
Test accuracy for en: 1.0
Num non-zero elements: 2
Test accuracy for fr: 0.996
Num non-zero elements: 2
Test accuracy for de: 0.973
Num non-zero elements: 2
Test accuracy for es: 0.985
Num non-zero elements: 2
Test accuracy for nl: 0.855
Num non-zero elements: 5
Test accuracy for en: 0.999
Num non-zero elements: 5
Test accuracy for fr: 0.995
Num non-zero elements: 5
Test accuracy for de: 0.984
Num non-zero elements: 5
Test accuracy for es: 0.999
Num non-zero elements: 5
Test accuracy for nl: 0.975
Num non-zero elements: 10
Test accuracy for en: 1.0
Num non-zero elements: 10
Test accuracy for fr: 0.996
Num non-zero elements: 10
Test accuracy for de: 0.993
Num non-zero elements: 10
Test accuracy for es: 0.999
Num non-zero elements: 10
Test accuracy for nl: 0.983
Num non-zero elements: 20
Test accuracy for en: 1.0
Num non-zero elements: 20
Test accuracy for fr: 0.995
Num non-zero elements: 20
Test accuracy for de: 0.996
Num non-zero elements: 20
Test accuracy for es: 1.0
Num non-zero elements: 20
Test accuracy for nl: 0.979
Num non-zero elements: 50
Test accuracy for en: 0.996
Num non-zero elements: 50
Test accuracy for fr: 0.997
Num non-zero elements: 50
Test accuracy for de: 0.998
Num non-zero elements: 50
Test accuracy for es: 1.0
Num non-zero elements: 50
Test accuracy for nl: 0.994

Running unlearning evaluation...
Loaded pretrained model google/gemma-2-2b-it into HookedTransformer
Running evaluation for SAE: google/gemma-2-2b_layer_12_sae_custom_sae
Sparsity calculation for google/gemma-2-2b_layer_12_sae_custom_sae is already done
Forget sparsity: [0.014126 0.001871 0.010558 ... 0.002963 0.00142  0.00191 ]
(18432,)
Retain sparsity: [0.004682 0.001597 0.012794 ... 0.001564 0.000154 0.003691]
(18432,)
Starting metrics calculation...
running on datasets: ['wmdp-bio', 'high_school_us_history', 'college_computer_science', 'high_school_geography', 'human_aging']
Calculating metrics for retain threshold: 0.001
Top features for ablation: [ 7234  8651 15607 ...  3550 14783 13324]
Calculating metrics list with parameters: {'intervention_method': 'clamp_feature_activation'} {'features_to_ablate': [array([ 7234,  8651, 15607,  9513,   178,  4566, 14838, 16825, 17456,
        2737]), array([ 7234,  8651, 15607,  9513,   178,  4566, 14838, 16825, 17456,
        2737, 16520,  1146, 14239,  4615,  1830, 17553,  5242,  8911,
       14067, 13516])], 'multiplier': [25, 50, 100, 200]}
All target question ids for gemma-2-2b-it on wmdp-bio already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on high_school_us_history already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on college_computer_science already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on high_school_geography already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on human_aging already exist. No need to generate target ids.
Calculating metrics for retain threshold: 0.01
Top features for ablation: [12497 12900 18043 ...  3550 14783 13324]
Calculating metrics list with parameters: {'intervention_method': 'clamp_feature_activation'} {'features_to_ablate': [array([12497, 12900, 18043, 11289, 11424, 15710,  7018,  2055, 15493,
        5952]), array([12497, 12900, 18043, 11289, 11424, 15710,  7018,  2055, 15493,
        5952, 10518, 17710, 14977,  7267,  4445, 15332,  2453,   264,
        1335, 17172])], 'multiplier': [25, 50, 100, 200]}
All target question ids for gemma-2-2b-it on wmdp-bio already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on high_school_us_history already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on college_computer_science already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on high_school_geography already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on human_aging already exist. No need to generate target ids.
Unlearning scores DataFrame:     wmdp-bio  high_school_us_history  ...  multiplier  all_side_effects_mcq
0   0.994382                1.000000  ...          25              1.000000
1   0.687266                0.963636  ...         200              0.941176
2   0.928839                0.972727  ...         100              0.990196
3   0.953184                0.990909  ...         200              0.954248
4   0.602996                0.963636  ...         200              0.924837
5   0.975655                0.990909  ...          50              0.996732
6   0.996255                1.000000  ...         100              0.996732
7   0.986891                1.000000  ...         100              0.993464
8   1.000000                1.000000  ...          50              1.000000
9   0.986891                0.990909  ...          50              0.996732
10  0.998127                1.000000  ...          25              1.000000
11  0.857678                0.972727  ...         100              0.983660
12  1.000000                1.000000  ...          25              1.000000
13  1.000000                1.000000  ...          25              1.000000
14  0.985019                1.000000  ...         200              0.973856
15  0.996255                1.000000  ...          50              1.000000

[16 rows x 10 columns]
coder_out: Let me analyze Run 1 results and update notes.txt first:

notes.txt
```python
<<<<<<< SEARCH
# Title: Hierarchical Competition Detection for Preventing Feature Absorption in Sparse Autoencoders
# Experiment description: 1. Modify mask intersection computation for asymmetric relationships
2. Implement directional competition coefficients
3. Train with optimal dictionary size (18432) on gemma-2-2b
4. Compare against symmetric adaptation
5. Analyze reduction in feature absorption patterns
## Run 0: Baseline
=======
# Title: Hierarchical Competition Detection for Preventing Feature Absorption in Sparse Autoencoders
# Experiment description: 1. Modify mask intersection computation for asymmetric relationships
2. Implement directional competition coefficients
3. Train with optimal dictionary size (18432) on gemma-2-2b
4. Compare against symmetric adaptation
5. Analyze reduction in feature absorption patterns

## Run 0: Baseline
Results: Baseline results from TopK SAE without competition loss.
Key metrics:
- Absorption score: 0.0113 (lower is better)
- KL divergence score: 0.9909 (higher is better) 
- Explained variance: 0.7773
- L0 sparsity: 320.0

## Run 1: Initial Competition Loss Implementation
Description: Implemented hierarchical competition detection with:
- Competition coefficient computation using co-activation patterns
- Directional competition coefficients normalized by sparsity ratio
- Competition loss weight (ortho_weight) = 0.1
- k = 120 features

Results:
- Absorption score: 0.0542 (worse than baseline)
- KL divergence score: 0.9776 (slightly worse)
- Explained variance: 0.6757 (worse)
- L0 sparsity: ~120 (as configured)

Analysis:
The initial implementation shows some issues:
1. Higher absorption score indicates more feature absorption
2. Lower explained variance suggests competition may be too strong
3. KL divergence relatively maintained but slightly decreased

Next steps:
1. Reduce competition loss weight (ortho_weight) to 0.01 to allow better reconstruction
2. Keep k=120 as it maintains good sparsity
3. Add gradient clipping to competition loss to prevent instability
>>>>>>> REPLACE
```

For Run 2, I propose reducing the competition weight and adding gradient clipping to the competition loss. Here are the changes needed:

experiment.py
```python
<<<<<<< SEARCH
        competition_loss = (max_coeffs * feature_dots.pow(2)).mean()
=======
        # Clip competition coefficients for stability
        competition_loss = (max_coeffs.clamp(max=10.0) * feature_dots.pow(2)).mean()
>>>>>>> REPLACE
```

experiment.py
```python
<<<<<<< SEARCH
        ortho_weight= 0.1,
=======
        ortho_weight= 0.01,  # Reduced from 0.1
>>>>>>> REPLACE
```

Let's run the next experiment with:

```bash
python experiment.py --out_dir=run_2
```

This should help balance the competition-reconstruction tradeoff better while maintaining stability., type: <class 'str'>
Currently on iteration 1 of run 3
Let me analyze Run 2's results and update the notes:                                                                                                                                                                                  

notes.txt                                                                                                                                                                                                                             

                                                                                                                                                                                                                                      
 <<<<<<< SEARCH                                                                                                                                                                                                                       
 # Title: Hierarchical Competition Detection for Preventing Feature Absorption in Sparse Autoencoders                                                                                                                                 
 # Experiment description: 1. Modify mask intersection computation for asymmetric relationships                                                                                                                                       
 2. Implement directional competition coefficients                                                                                                                                                                                    
 3. Train with optimal dictionary size (18432) on gemma-2-2b                                                                                                                                                                          
 4. Compare against symmetric adaptation                                                                                                                                                                                              
 5. Analyze reduction in feature absorption patterns                                                                                                                                                                                  
                                                                                                                                                                                                                                      
 ## Run 0: Baseline                                                                                                                                                                                                                   
 Results: Baseline results from TopK SAE without competition loss.                                                                                                                                                                    
 Key metrics:                                                                                                                                                                                                                         
 - Absorption score: 0.0113 (lower is better)                                                                                                                                                                                         
 - KL divergence score: 0.9909 (higher is better)                                                                                                                                                                                     
 - Explained variance: 0.7773                                                                                                                                                                                                         
 - L0 sparsity: 320.0                                                                                                                                                                                                                 
                                                                                                                                                                                                                                      
 ## Run 1: Initial Competition Loss Implementation                                                                                                                                                                                    
 Description: Implemented hierarchical competition detection with:                                                                                                                                                                    
 - Competition coefficient computation using co-activation patterns                                                                                                                                                                   
 - Directional competition coefficients normalized by sparsity ratio                                                                                                                                                                  
 - Competition loss weight (ortho_weight) = 0.1                                                                                                                                                                                       
 - k = 120 features                                                                                                                                                                                                                   
                                                                                                                                                                                                                                      
 Results:                                                                                                                                                                                                                             
 - Absorption score: 0.0542 (worse than baseline)                                                                                                                                                                                     
 - KL divergence score: 0.9776 (slightly worse)                                                                                                                                                                                       
 - Explained variance: 0.6757 (worse)                                                                                                                                                                                                 
 - L0 sparsity: ~120 (as configured)                                                                                                                                                                                                  
                                                                                                                                                                                                                                      
 Analysis:                                                                                                                                                                                                                            
 The initial implementation shows some issues:                                                                                                                                                                                        
 1. Higher absorption score indicates more feature absorption                                                                                                                                                                         
 2. Lower explained variance suggests competition may be too strong                                                                                                                                                                   
 3. KL divergence relatively maintained but slightly decreased                                                                                                                                                                        
                                                                                                                                                                                                                                      
 Next steps:                                                                                                                                                                                                                          
 1. Reduce competition loss weight (ortho_weight) to 0.01 to allow better reconstruction                                                                                                                                              
 2. Keep k=120 as it maintains good sparsity                                                                                                                                                                                          
 3. Add gradient clipping to competition loss to prevent instability                                                                                                                                                                  
 =======                                                                                                                                                                                                                              
 # Title: Hierarchical Competition Detection for Preventing Feature Absorption in Sparse Autoencoders                                                                                                                                 
 # Experiment description: 1. Modify mask intersection computation for asymmetric relationships                                                                                                                                       
 2. Implement directional competition coefficients                                                                                                                                                                                    
 3. Train with optimal dictionary size (18432) on gemma-2-2b                                                                                                                                                                          
 4. Compare against symmetric adaptation                                                                                                                                                                                              
 5. Analyze reduction in feature absorption patterns                                                                                                                                                                                  
                                                                                                                                                                                                                                      
 ## Run 0: Baseline                                                                                                                                                                                                                   
 Results: Baseline results from TopK SAE without competition loss.                                                                                                                                                                    
 Key metrics:                                                                                                                                                                                                                         
 - Absorption score: 0.0113 (lower is better)                                                                                                                                                                                         
 - KL divergence score: 0.9909 (higher is better)                                                                                                                                                                                     
 - Explained variance: 0.7773                                                                                                                                                                                                         
 - L0 sparsity: 320.0                                                                                                                                                                                                                 
                                                                                                                                                                                                                                      
 ## Run 1: Initial Competition Loss Implementation                                                                                                                                                                                    
 Description: Implemented hierarchical competition detection with:                                                                                                                                                                    
 - Competition coefficient computation using co-activation patterns                                                                                                                                                                   
 - Directional competition coefficients normalized by sparsity ratio                                                                                                                                                                  
 - Competition loss weight (ortho_weight) = 0.1                                                                                                                                                                                       
 - k = 120 features                                                                                                                                                                                                                   
                                                                                                                                                                                                                                      
 Results:                                                                                                                                                                                                                             
 - Absorption score: 0.0542 (worse than baseline)                                                                                                                                                                                     
 - KL divergence score: 0.9776 (slightly worse)                                                                                                                                                                                       
 - Explained variance: 0.6757 (worse)                                                                                                                                                                                                 
 - L0 sparsity: ~120 (as configured)                                                                                                                                                                                                  
                                                                                                                                                                                                                                      
 Analysis:                                                                                                                                                                                                                            
 The initial implementation shows some issues:                                                                                                                                                                                        
 1. Higher absorption score indicates more feature absorption                                                                                                                                                                         
 2. Lower explained variance suggests competition may be too strong                                                                                                                                                                   
 3. KL divergence relatively maintained but slightly decreased                                                                                                                                                                        
                                                                                                                                                                                                                                      
 ## Run 2: Reduced Competition Weight with Gradient Clipping                                                                                                                                                                          
 Description: Modified competition loss implementation with:                                                                                                                                                                          
 - Reduced competition loss weight (ortho_weight) from 0.1 to 0.01                                                                                                                                                                    
 - Added gradient clipping to competition coefficients (max=10.0)                                                                                                                                                                     
 - Maintained k=120 features                                                                                                                                                                                                          
 - Kept directional competition detection                                                                                                                                                                                             
                                                                                                                                                                                                                                      
 Results:                                                                                                                                                                                                                             
 - Absorption score: 0.0336 (better than Run 1 but still worse than baseline)                                                                                                                                                         
 - KL divergence score: 0.9817 (improved from Run 1)                                                                                                                                                                                  
 - Explained variance: 0.6953 (improved from Run 1)                                                                                                                                                                                   
 - L0 sparsity: ~120 (as configured)                                                                                                                                                                                                  
 - SCR metrics improved across thresholds                                                                                                                                                                                             
 - Sparse probing accuracy: 0.9567 (strong feature learning)                                                                                                                                                                          
                                                                                                                                                                                                                                      
 Analysis:                                                                                                                                                                                                                            
 The changes show improvement over Run 1:                                                                                                                                                                                             
 1. Reduced competition weight helped improve reconstruction                                                                                                                                                                          
 2. Gradient clipping provided more stable training                                                                                                                                                                                   
 3. KL divergence and explained variance improved                                                                                                                                                                                     
 4. Absorption score decreased but still higher than baseline                                                                                                                                                                         
 5. Strong performance on downstream tasks (SCR, sparse probing)                                                                                                                                                                      
                                                                                                                                                                                                                                      
 Next steps:                                                                                                                                                                                                                          
 1. Further reduce competition loss weight to 0.005                                                                                                                                                                                   
 2. Add warmup period for competition loss                                                                                                                                                                                            
 3. Keep gradient clipping and k=120                                                                                                                                                                                                  
 >>>>>>> REPLACE                                                                                                                                                                                                                      
                                                                                                                                                                                                                                      

Based on the results from Run 2, we see improvements in most metrics but still room for optimization. The next experiment should focus on further tuning the competition loss by:                                                     

 1 Reducing competition weight further                                                                                                                                                                                                
 2 Adding a warmup period for the competition loss                                                                                                                                                                                    

Here are the changes needed for Run 3:                                                                                                                                                                                                

experiment.py                                                                                                                                                                                                                         

                                                                                                                                                                                                                                      
 <<<<<<< SEARCH                                                                                                                                                                                                                       
         ortho_weight= 0.01,  # Reduced from 0.1                                                                                                                                                                                      
 =======                                                                                                                                                                                                                              
         ortho_weight= 0.005,  # Further reduced competition weight                                                                                                                                                                   
 >>>>>>> REPLACE                                                                                                                                                                                                                      
                                                                                                                                                                                                                                      

experiment.py                                                                                                                                                                                                                         

                                                                                                                                                                                                                                      
 <<<<<<< SEARCH                                                                                                                                                                                                                       
     def loss(self, x, step=None, logging=False):                                                                                                                                                                                     
         # Run the SAE                                                                                                                                                                                                                
         f, top_acts, top_indices = self.ae.encode(x, return_topk=True)                                                                                                                                                               
         x_hat = self.ae.decode(f)                                                                                                                                                                                                    
                                                                                                                                                                                                                                      
         # Measure goodness of reconstruction                                                                                                                                                                                         
         e = x_hat - x                                                                                                                                                                                                                
         total_variance = (x - x.mean(0)).pow(2).sum(0)                                                                                                                                                                               
 =======                                                                                                                                                                                                                              
     def loss(self, x, step=None, logging=False):                                                                                                                                                                                     
         # Run the SAE                                                                                                                                                                                                                
         f, top_acts, top_indices = self.ae.encode(x, return_topk=True)                                                                                                                                                               
         x_hat = self.ae.decode(f)                                                                                                                                                                                                    
                                                                                                                                                                                                                                      
         # Measure goodness of reconstruction                                                                                                                                                                                         
         e = x_hat - x                                                                                                                                                                                                                
         total_variance = (x - x.mean(0)).pow(2).sum(0)                                                                                                                                                                               
                                                                                                                                                                                                                                      
         # Apply competition loss warmup                                                                                                                                                                                              
         competition_weight = self.ortho_weight * min(1.0, step / 1000) if step is not None else self.ortho_weight                                                                                                                    
 >>>>>>> REPLACE                                                                                                                                                                                                                      
                                                                                                                                                                                                                                      

Let's run the next experiment with:                                                                                                                                                                                                   

                                                                                                                                                                                                                                      
 python experiment.py --out_dir=run_3                                                                                                                                                                                                 
                                                                                                                                                                                                                                      

This will test if further reducing the competition weight and adding a gradual warmup helps achieve better balance between feature disentanglement and reconstruction quality.                                                        

Tokens: 53k sent, 1.6k received. Cost: $0.18 message, $0.56 session.
Applied edit to notes.txt
Applied edit to experiment.py

python experiment.py --out_dir=run_3
Step 0: 40830.53515625
Step 100: 7376.6884765625
Step 200: 5453.4775390625
Step 300: 4966.18115234375
Step 400: 4617.7431640625
Step 500: 4402.86962890625
Step 600: 4346.71875
Step 700: 4095.531005859375
Step 800: 4041.560791015625
Step 900: 3902.292236328125
Step 1000: 3925.0078125
Step 1100: 3787.2333984375
Step 1200: 3668.567138671875
Step 1300: 3661.984619140625
Step 1400: 3632.222412109375
Step 1500: 3643.59423828125
Step 1600: 3541.508056640625
Step 1700: 3544.931640625
Step 1800: 3447.001953125
Step 1900: 3421.561279296875
Step 2000: 3564.404052734375
Step 2100: 3569.48095703125
Step 2200: 3432.900146484375
Step 2300: 3411.660400390625
Step 2400: 3386.692626953125

 training complete! 

all info: /gpfs/radev/project/lafferty/tl784/free_PhD_labor/results/orthogonal_continued/20250130_212318_hierarchical_orthogonal_sae/run_3/final_info.json

Running absorption evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Loading probe and training data
Training k-sparse probes
Loading validation data
Evaluating raw k-sparse probing scores
Building metadata

Running core evaluation...
Using device: cuda
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Saved evaluation results to: run_3/google_gemma-2-2b_layer_12_sae_custom_sae_eval_results.json

Running scr evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9750000238418579
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9720000624656677
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9950000643730164
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9950000643730164
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.940000057220459, scr_score: 0.45312510186348476
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9380000233650208, scr_score: 0.42187454889028175
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.937000036239624, scr_score: 0.4062497380653249
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9380000233650208, scr_score: 0.42187454889028175
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9270000457763672, scr_score: 0.24999976716917766
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9310000538825989, scr_score: 0.3124999417922944
dir: 1, original_acc: 0.9110000729560852, clean_acc: 0.9750000238418579, changed_acc: 0.9260000586509705, scr_score: 0.23437495634422081
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.5900000333786011, scr_score: 0.017199085925573582
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.5950000286102295, scr_score: 0.02948408453723957
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.6030000448226929, scr_score: 0.04914014089539928
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.609000027179718, scr_score: 0.0638821099396514
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.6220000386238098, scr_score: 0.09582316490947711
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.6340000033378601, scr_score: 0.12530710299798134
dir: 2, original_acc: 0.5830000042915344, clean_acc: 0.9900000691413879, changed_acc: 0.5750000476837158, scr_score: -0.019655909909424386
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9890000224113464
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9550000429153442
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9590000510215759
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9920000433921814
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9920000433921814
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8770000338554382, scr_score: 0.24271824996108338
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8840000629425049, scr_score: 0.3106797071617595
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8830000162124634, scr_score: 0.30097051421455245
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8750000596046448, scr_score: 0.22330102143857855
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8700000643730164, scr_score: 0.1747573714463619
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8650000691413879, scr_score: 0.12621372145414522
dir: 1, original_acc: 0.8520000576972961, clean_acc: 0.9550000429153442, changed_acc: 0.8080000281333923, scr_score: -0.42718481435465233
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.6830000281333923, scr_score: 0.12320912794812448
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.6990000605583191, scr_score: 0.16905449606916736
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.7120000123977661, scr_score: 0.20630364418381594
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.7360000610351562, scr_score: 0.27507169636538026
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.7620000243186951, scr_score: 0.34957016338163643
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.6840000152587891, scr_score: 0.12607442075894992
dir: 2, original_acc: 0.64000004529953, clean_acc: 0.9890000224113464, changed_acc: 0.6930000185966492, scr_score: 0.1518623976302968
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9830000400543213
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.984000027179718
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9730000495910645
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9720000624656677
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.999000072479248
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.999000072479248
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9480000734329224, scr_score: 0.6031751287885597
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9500000476837158, scr_score: 0.6349207400434262
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9460000395774841, scr_score: 0.5714285714285714
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9410000443458557, scr_score: 0.49206359718628334
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.9390000700950623, scr_score: 0.4603179859314168
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.8980000615119934, scr_score: -0.19047555973944266
dir: 1, original_acc: 0.9100000262260437, clean_acc: 0.9730000495910645, changed_acc: 0.8140000104904175, scr_score: -1.5238092084411499
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.597000002861023, scr_score: 0.022784816238899015
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6080000400543213, scr_score: 0.05063300880745302
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.625, scr_score: 0.09367087767151386
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6380000114440918, scr_score: 0.1265822956719035
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6530000567436218, scr_score: 0.1645570900019481
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6770000457763672, scr_score: 0.22531654967307232
dir: 2, original_acc: 0.5879999995231628, clean_acc: 0.9830000400543213, changed_acc: 0.6300000548362732, scr_score: 0.10632924304674166
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9940000176429749
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9940000176429749
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9690000414848328
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.968000054359436
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9970000386238098
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9980000257492065
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8740000128746033, scr_score: 0.2578123981366101
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8550000190734863, scr_score: 0.10937497089617432
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8410000205039978, scr_score: 0.0
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8390000462532043, scr_score: -0.015624796273220196
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8330000638961792, scr_score: -0.062499650754091765
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.8260000348091125, scr_score: -0.11718736903278441
dir: 1, original_acc: 0.8410000205039978, clean_acc: 0.9690000414848328, changed_acc: 0.878000020980835, scr_score: 0.2890624563442615
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.6990000605583191, scr_score: 0.1246292396676148
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.7100000381469727, scr_score: 0.15727012151918615
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.7280000448226929, scr_score: 0.21068260227148516
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.7510000467300415, scr_score: 0.2789318635807144
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.7700000405311584, scr_score: 0.33531166507072435
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.7940000295639038, scr_score: 0.4065282471176645
dir: 2, original_acc: 0.6570000052452087, clean_acc: 0.9940000176429749, changed_acc: 0.6540000438690186, scr_score: -0.008901962213132759
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9440000653266907
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9520000219345093
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9900000691413879
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9960000514984131
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9970000386238098
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.8130000233650208, scr_score: 0.03278678379574697
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.815000057220459, scr_score: 0.04371592886659017
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.8030000329017639, scr_score: -0.021857964433295084
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.7950000166893005, scr_score: -0.06557389329988525
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.8020000457763672, scr_score: -0.027322374114521025
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.8080000281333923, scr_score: 0.00546440968122594
dir: 1, original_acc: 0.8070000410079956, clean_acc: 0.9900000691413879, changed_acc: 0.7990000247955322, scr_score: -0.04371592886659017
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.7130000591278076, scr_score: 0.09411781755419522
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.7610000371932983, scr_score: 0.2823529851752762
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8160000443458557, scr_score: 0.4980392413522444
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8490000367164612, scr_score: 0.6274509483096945
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8600000143051147, scr_score: 0.6705881060476262
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8670000433921814, scr_score: 0.6980391946035135
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9440000653266907, changed_acc: 0.8750000596046448, scr_score: 0.7294118004549119
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9640000462532043
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9640000462532043
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9770000576972961
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9750000238418579
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9960000514984131
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9960000514984131
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.7900000214576721, scr_score: 0.0410254200064373
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8060000538825989, scr_score: 0.12307687134902433
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8170000314712524, scr_score: 0.17948701489841076
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8270000219345093, scr_score: 0.23076901915509954
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8280000686645508, scr_score: 0.2358974641126534
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8350000381469727, scr_score: 0.27179474482639304
dir: 1, original_acc: 0.7820000648498535, clean_acc: 0.9770000576972961, changed_acc: 0.8300000429153442, scr_score: 0.24615374269804866
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7330000400543213, scr_score: 0.06854845881151235
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7390000224113464, scr_score: 0.0927419335456348
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7500000596046448, scr_score: 0.1370969176230247
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7630000114440918, scr_score: 0.18951607282340924
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7770000100135803, scr_score: 0.24596767409721804
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.8020000457763672, scr_score: 0.3467742594484168
dir: 2, original_acc: 0.7160000205039978, clean_acc: 0.9640000462532043, changed_acc: 0.7890000343322754, scr_score: 0.2943548639067476
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.9630000591278076
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.9590000510215759
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9780000448226929
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9780000448226929
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9940000176429749
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9930000305175781
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.7740000486373901, scr_score: 0.08520176975018703
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.7830000519752502, scr_score: 0.12556053092505612
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.8080000281333923, scr_score: 0.237668052363351
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.8260000348091125, scr_score: 0.31838557471308915
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.8280000686645508, scr_score: 0.3273543367994015
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.8380000591278076, scr_score: 0.37219734537471943
dir: 1, original_acc: 0.7550000548362732, clean_acc: 0.9780000448226929, changed_acc: 0.8070000410079956, scr_score: 0.2331838049629021
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.7620000243186951, scr_score: 0.10267856311319266
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.7880000472068787, scr_score: 0.21875007483840891
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.8110000491142273, scr_score: 0.3214286379516016
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.8230000138282776, scr_score: 0.37499990021545476
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.8400000333786011, scr_score: 0.4508928321967208
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.8440000414848328, scr_score: 0.4687500083153788
dir: 2, original_acc: 0.7390000224113464, clean_acc: 0.9630000591278076, changed_acc: 0.8550000190734863, scr_score: 0.5178570430725976
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male / female: 0.971000075340271
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_data_only: 0.971000075340271
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for professor / nurse: 0.9620000720024109
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for nurse_data_only: 0.9630000591278076
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for male_professor / female_nurse: 0.9930000305175781
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for female_nurse_data_only: 0.9940000176429749
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7400000095367432, scr_score: 0.047210196127387125
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7430000305175781, scr_score: 0.060085820441166386
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7480000257492065, scr_score: 0.08154502375487709
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7560000419616699, scr_score: 0.11587985138236706
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7630000114440918, scr_score: 0.1459226336960092
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7600000500679016, scr_score: 0.13304726519611204
dir: 1, original_acc: 0.7290000319480896, clean_acc: 0.9620000720024109, changed_acc: 0.7720000147819519, scr_score: 0.18454925082346488
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7690000534057617, scr_score: 0.03809530837734615
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7750000357627869, scr_score: 0.06666664774456064
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7850000262260437, scr_score: 0.11428564130044823
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7910000085830688, scr_score: 0.14285698066766273
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7980000376701355, scr_score: 0.17619044645573817
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.7980000376701355, scr_score: 0.17619044645573817
dir: 2, original_acc: 0.7610000371932983, clean_acc: 0.971000075340271, changed_acc: 0.8270000219345093, scr_score: 0.3142855845341302

Running tpp evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Removing 24 from test set
Removing 12 from test set
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 0: 0.9540000557899475
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 1: 0.9630000591278076
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 2: 0.9520000219345093
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 6: 0.9920000433921814
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 9: 0.9810000658035278
Removing 28 from train set
Removing 0 from train set
Removing 7 from train set
Removing 29 from train set
Removing 31 from train set
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 1: 0.9540000557899475
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 2: 0.9240000247955322
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 3: 0.9310000538825989
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 5: 0.9260000586509705
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
Test accuracy for 6: 0.8640000224113464

Running sparse_probing evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Removing 24 from test set
Removing 12 from test set
Num non-zero elements: 2304
Test accuracy for 0: 0.935
Num non-zero elements: 2304
Test accuracy for 1: 0.952
Num non-zero elements: 2304
Test accuracy for 2: 0.942
Num non-zero elements: 2304
Test accuracy for 6: 0.988
Num non-zero elements: 2304
Test accuracy for 9: 0.981
Num non-zero elements: 1
Test accuracy for 0: 0.57
Num non-zero elements: 1
Test accuracy for 1: 0.629
Num non-zero elements: 1
Test accuracy for 2: 0.686
Num non-zero elements: 1
Test accuracy for 6: 0.782
Num non-zero elements: 1
Test accuracy for 9: 0.549
Num non-zero elements: 2
Test accuracy for 0: 0.582
Num non-zero elements: 2
Test accuracy for 1: 0.661
Num non-zero elements: 2
Test accuracy for 2: 0.713
Num non-zero elements: 2
Test accuracy for 6: 0.801
Num non-zero elements: 2
Test accuracy for 9: 0.701
Num non-zero elements: 5
Test accuracy for 0: 0.721
Num non-zero elements: 5
Test accuracy for 1: 0.7
Num non-zero elements: 5
Test accuracy for 2: 0.763
Num non-zero elements: 5
Test accuracy for 6: 0.902
Num non-zero elements: 5
Test accuracy for 9: 0.87
Num non-zero elements: 10
Test accuracy for 0: 0.782
Num non-zero elements: 10
Test accuracy for 1: 0.799
Num non-zero elements: 10
Test accuracy for 2: 0.801
Num non-zero elements: 10
Test accuracy for 6: 0.886
Num non-zero elements: 10
Test accuracy for 9: 0.9
Num non-zero elements: 20
Test accuracy for 0: 0.817
Num non-zero elements: 20
Test accuracy for 1: 0.88
Num non-zero elements: 20
Test accuracy for 2: 0.879
Num non-zero elements: 20
Test accuracy for 6: 0.967
Num non-zero elements: 20
Test accuracy for 9: 0.938
Num non-zero elements: 50
Test accuracy for 0: 0.91
Num non-zero elements: 50
Test accuracy for 1: 0.925
Num non-zero elements: 50
Test accuracy for 2: 0.921
Num non-zero elements: 50
Test accuracy for 6: 0.982
Num non-zero elements: 50
Test accuracy for 9: 0.954
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 22 epochs
Test accuracy for 0: 0.9530000686645508
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 25 epochs
Test accuracy for 1: 0.9630000591278076
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 17 epochs
Test accuracy for 2: 0.9490000605583191
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 27 epochs
Test accuracy for 6: 0.984000027179718
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 17 epochs
Test accuracy for 9: 0.9730000495910645
Num non-zero elements: 1
Test accuracy for 0: 0.663
Num non-zero elements: 1
Test accuracy for 1: 0.661
Num non-zero elements: 1
Test accuracy for 2: 0.867
Num non-zero elements: 1
Test accuracy for 6: 0.982
Num non-zero elements: 1
Test accuracy for 9: 0.917
Num non-zero elements: 2
Test accuracy for 0: 0.712
Num non-zero elements: 2
Test accuracy for 1: 0.656
Num non-zero elements: 2
Test accuracy for 2: 0.872
Num non-zero elements: 2
Test accuracy for 6: 0.982
Num non-zero elements: 2
Test accuracy for 9: 0.916
Num non-zero elements: 5
Test accuracy for 0: 0.775
Num non-zero elements: 5
Test accuracy for 1: 0.75
Num non-zero elements: 5
Test accuracy for 2: 0.894
Num non-zero elements: 5
Test accuracy for 6: 0.989
Num non-zero elements: 5
Test accuracy for 9: 0.949
Num non-zero elements: 10
Test accuracy for 0: 0.803
Num non-zero elements: 10
Test accuracy for 1: 0.877
Num non-zero elements: 10
Test accuracy for 2: 0.91
Num non-zero elements: 10
Test accuracy for 6: 0.988
Num non-zero elements: 10
Test accuracy for 9: 0.963
Num non-zero elements: 20
Test accuracy for 0: 0.895
Num non-zero elements: 20
Test accuracy for 1: 0.948
Num non-zero elements: 20
Test accuracy for 2: 0.922
Num non-zero elements: 20
Test accuracy for 6: 0.989
Num non-zero elements: 20
Test accuracy for 9: 0.964
Num non-zero elements: 50
Test accuracy for 0: 0.938
Num non-zero elements: 50
Test accuracy for 1: 0.962
Num non-zero elements: 50
Test accuracy for 2: 0.936
Num non-zero elements: 50
Test accuracy for 6: 0.994
Num non-zero elements: 50
Test accuracy for 9: 0.979
Removing 24 from test set
Removing 12 from test set
Num non-zero elements: 2304
Test accuracy for 11: 0.952
Num non-zero elements: 2304
Test accuracy for 13: 0.951
Num non-zero elements: 2304
Test accuracy for 14: 0.956
Num non-zero elements: 2304
Test accuracy for 18: 0.924
Num non-zero elements: 2304
Test accuracy for 19: 0.951
Num non-zero elements: 1
Test accuracy for 11: 0.568
Num non-zero elements: 1
Test accuracy for 13: 0.672
Num non-zero elements: 1
Test accuracy for 14: 0.641
Num non-zero elements: 1
Test accuracy for 18: 0.707
Num non-zero elements: 1
Test accuracy for 19: 0.788
Num non-zero elements: 2
Test accuracy for 11: 0.694
Num non-zero elements: 2
Test accuracy for 13: 0.712
Num non-zero elements: 2
Test accuracy for 14: 0.669
Num non-zero elements: 2
Test accuracy for 18: 0.722
Num non-zero elements: 2
Test accuracy for 19: 0.778
Num non-zero elements: 5
Test accuracy for 11: 0.8
Num non-zero elements: 5
Test accuracy for 13: 0.745
Num non-zero elements: 5
Test accuracy for 14: 0.717
Num non-zero elements: 5
Test accuracy for 18: 0.731
Num non-zero elements: 5
Test accuracy for 19: 0.828
Num non-zero elements: 10
Test accuracy for 11: 0.853
Num non-zero elements: 10
Test accuracy for 13: 0.792
Num non-zero elements: 10
Test accuracy for 14: 0.792
Num non-zero elements: 10
Test accuracy for 18: 0.759
Num non-zero elements: 10
Test accuracy for 19: 0.851
Num non-zero elements: 20
Test accuracy for 11: 0.905
Num non-zero elements: 20
Test accuracy for 13: 0.87
Num non-zero elements: 20
Test accuracy for 14: 0.875
Num non-zero elements: 20
Test accuracy for 18: 0.772
Num non-zero elements: 20
Test accuracy for 19: 0.897
Num non-zero elements: 50
Test accuracy for 11: 0.943
Num non-zero elements: 50
Test accuracy for 13: 0.917
Num non-zero elements: 50
Test accuracy for 14: 0.899
Num non-zero elements: 50
Test accuracy for 18: 0.843
Num non-zero elements: 50
Test accuracy for 19: 0.926
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 17 epochs
Test accuracy for 11: 0.9590000510215759
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 23 epochs
Test accuracy for 13: 0.9430000185966492
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 16 epochs
Test accuracy for 14: 0.9470000267028809
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 17 epochs
Test accuracy for 18: 0.9280000329017639
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 26 epochs
Test accuracy for 19: 0.9610000252723694
Num non-zero elements: 1
Test accuracy for 11: 0.725
Num non-zero elements: 1
Test accuracy for 13: 0.811
Num non-zero elements: 1
Test accuracy for 14: 0.857
Num non-zero elements: 1
Test accuracy for 18: 0.726
Num non-zero elements: 1
Test accuracy for 19: 0.847
Num non-zero elements: 2
Test accuracy for 11: 0.839
Num non-zero elements: 2
Test accuracy for 13: 0.817
Num non-zero elements: 2
Test accuracy for 14: 0.869
Num non-zero elements: 2
Test accuracy for 18: 0.716
Num non-zero elements: 2
Test accuracy for 19: 0.855
Num non-zero elements: 5
Test accuracy for 11: 0.899
Num non-zero elements: 5
Test accuracy for 13: 0.851
Num non-zero elements: 5
Test accuracy for 14: 0.87
Num non-zero elements: 5
Test accuracy for 18: 0.862
Num non-zero elements: 5
Test accuracy for 19: 0.887
Num non-zero elements: 10
Test accuracy for 11: 0.924
Num non-zero elements: 10
Test accuracy for 13: 0.877
Num non-zero elements: 10
Test accuracy for 14: 0.898
Num non-zero elements: 10
Test accuracy for 18: 0.899
Num non-zero elements: 10
Test accuracy for 19: 0.945
Num non-zero elements: 20
Test accuracy for 11: 0.936
Num non-zero elements: 20
Test accuracy for 13: 0.902
Num non-zero elements: 20
Test accuracy for 14: 0.914
Num non-zero elements: 20
Test accuracy for 18: 0.895
Num non-zero elements: 20
Test accuracy for 19: 0.947
Num non-zero elements: 50
Test accuracy for 11: 0.953
Num non-zero elements: 50
Test accuracy for 13: 0.921
Num non-zero elements: 50
Test accuracy for 14: 0.927
Num non-zero elements: 50
Test accuracy for 18: 0.926
Num non-zero elements: 50
Test accuracy for 19: 0.955
Removing 24 from test set
Removing 12 from test set
Num non-zero elements: 2304
Test accuracy for 20: 0.949
Num non-zero elements: 2304
Test accuracy for 21: 0.896
Num non-zero elements: 2304
Test accuracy for 22: 0.907
Num non-zero elements: 2304
Test accuracy for 25: 0.959
Num non-zero elements: 2304
Test accuracy for 26: 0.853
Num non-zero elements: 1
Test accuracy for 20: 0.706
Num non-zero elements: 1
Test accuracy for 21: 0.772
Num non-zero elements: 1
Test accuracy for 22: 0.643
Num non-zero elements: 1
Test accuracy for 25: 0.708
Num non-zero elements: 1
Test accuracy for 26: 0.613
Num non-zero elements: 2
Test accuracy for 20: 0.806
Num non-zero elements: 2
Test accuracy for 21: 0.772
Num non-zero elements: 2
Test accuracy for 22: 0.672
Num non-zero elements: 2
Test accuracy for 25: 0.753
Num non-zero elements: 2
Test accuracy for 26: 0.689
Num non-zero elements: 5
Test accuracy for 20: 0.821
Num non-zero elements: 5
Test accuracy for 21: 0.791
Num non-zero elements: 5
Test accuracy for 22: 0.718
Num non-zero elements: 5
Test accuracy for 25: 0.797
Num non-zero elements: 5
Test accuracy for 26: 0.672
Num non-zero elements: 10
Test accuracy for 20: 0.891
Num non-zero elements: 10
Test accuracy for 21: 0.827
Num non-zero elements: 10
Test accuracy for 22: 0.758
Num non-zero elements: 10
Test accuracy for 25: 0.844
Num non-zero elements: 10
Test accuracy for 26: 0.717
Num non-zero elements: 20
Test accuracy for 20: 0.91
Num non-zero elements: 20
Test accuracy for 21: 0.847
Num non-zero elements: 20
Test accuracy for 22: 0.8
Num non-zero elements: 20
Test accuracy for 25: 0.895
Num non-zero elements: 20
Test accuracy for 26: 0.818
Num non-zero elements: 50
Test accuracy for 20: 0.925
Num non-zero elements: 50
Test accuracy for 21: 0.881
Num non-zero elements: 50
Test accuracy for 22: 0.865
Num non-zero elements: 50
Test accuracy for 25: 0.936
Num non-zero elements: 50
Test accuracy for 26: 0.838
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 18 epochs
Test accuracy for 20: 0.956000030040741
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 14 epochs
Test accuracy for 21: 0.9340000152587891
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 23 epochs
Test accuracy for 22: 0.9110000729560852
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 16 epochs
Test accuracy for 25: 0.9600000381469727
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for 26: 0.8960000276565552
Num non-zero elements: 1
Test accuracy for 20: 0.909
Num non-zero elements: 1
Test accuracy for 21: 0.805
Num non-zero elements: 1
Test accuracy for 22: 0.83
Num non-zero elements: 1
Test accuracy for 25: 0.858
Num non-zero elements: 1
Test accuracy for 26: 0.679
Num non-zero elements: 2
Test accuracy for 20: 0.919
Num non-zero elements: 2
Test accuracy for 21: 0.813
Num non-zero elements: 2
Test accuracy for 22: 0.866
Num non-zero elements: 2
Test accuracy for 25: 0.858
Num non-zero elements: 2
Test accuracy for 26: 0.702
Num non-zero elements: 5
Test accuracy for 20: 0.919
Num non-zero elements: 5
Test accuracy for 21: 0.854
Num non-zero elements: 5
Test accuracy for 22: 0.883
Num non-zero elements: 5
Test accuracy for 25: 0.907
Num non-zero elements: 5
Test accuracy for 26: 0.832
Num non-zero elements: 10
Test accuracy for 20: 0.936
Num non-zero elements: 10
Test accuracy for 21: 0.852
Num non-zero elements: 10
Test accuracy for 22: 0.888
Num non-zero elements: 10
Test accuracy for 25: 0.934
Num non-zero elements: 10
Test accuracy for 26: 0.857
Num non-zero elements: 20
Test accuracy for 20: 0.934
Num non-zero elements: 20
Test accuracy for 21: 0.865
Num non-zero elements: 20
Test accuracy for 22: 0.882
Num non-zero elements: 20
Test accuracy for 25: 0.95
Num non-zero elements: 20
Test accuracy for 26: 0.877
Num non-zero elements: 50
Test accuracy for 20: 0.945
Num non-zero elements: 50
Test accuracy for 21: 0.883
Num non-zero elements: 50
Test accuracy for 22: 0.908
Num non-zero elements: 50
Test accuracy for 25: 0.961
Num non-zero elements: 50
Test accuracy for 26: 0.882
Removing 28 from train set
Removing 0 from train set
Removing 7 from train set
Removing 29 from train set
Removing 31 from train set
Num non-zero elements: 2304
Test accuracy for 1: 0.945
Num non-zero elements: 2304
Test accuracy for 2: 0.907
Num non-zero elements: 2304
Test accuracy for 3: 0.906
Num non-zero elements: 2304
Test accuracy for 5: 0.914
Num non-zero elements: 2304
Test accuracy for 6: 0.849
Num non-zero elements: 1
Test accuracy for 1: 0.667
Num non-zero elements: 1
Test accuracy for 2: 0.583
Num non-zero elements: 1
Test accuracy for 3: 0.599
Num non-zero elements: 1
Test accuracy for 5: 0.564
Num non-zero elements: 1
Test accuracy for 6: 0.602
Num non-zero elements: 2
Test accuracy for 1: 0.746
Num non-zero elements: 2
Test accuracy for 2: 0.646
Num non-zero elements: 2
Test accuracy for 3: 0.623
Num non-zero elements: 2
Test accuracy for 5: 0.627
Num non-zero elements: 2
Test accuracy for 6: 0.643
Num non-zero elements: 5
Test accuracy for 1: 0.773
Num non-zero elements: 5
Test accuracy for 2: 0.646
Num non-zero elements: 5
Test accuracy for 3: 0.656
Num non-zero elements: 5
Test accuracy for 5: 0.658
Num non-zero elements: 5
Test accuracy for 6: 0.654
Num non-zero elements: 10
Test accuracy for 1: 0.812
Num non-zero elements: 10
Test accuracy for 2: 0.777
Num non-zero elements: 10
Test accuracy for 3: 0.761
Num non-zero elements: 10
Test accuracy for 5: 0.691
Num non-zero elements: 10
Test accuracy for 6: 0.721
Num non-zero elements: 20
Test accuracy for 1: 0.874
Num non-zero elements: 20
Test accuracy for 2: 0.839
Num non-zero elements: 20
Test accuracy for 3: 0.793
Num non-zero elements: 20
Test accuracy for 5: 0.803
Num non-zero elements: 20
Test accuracy for 6: 0.757
Num non-zero elements: 50
Test accuracy for 1: 0.919
Num non-zero elements: 50
Test accuracy for 2: 0.891
Num non-zero elements: 50
Test accuracy for 3: 0.855
Num non-zero elements: 50
Test accuracy for 5: 0.853
Num non-zero elements: 50
Test accuracy for 6: 0.795
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 21 epochs
Test accuracy for 1: 0.9510000348091125
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 23 epochs
Test accuracy for 2: 0.9270000457763672
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 19 epochs
Test accuracy for 3: 0.9230000376701355
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 19 epochs
Test accuracy for 5: 0.9160000681877136
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 23 epochs
Test accuracy for 6: 0.8630000352859497
Num non-zero elements: 1
Test accuracy for 1: 0.723
Num non-zero elements: 1
Test accuracy for 2: 0.608
Num non-zero elements: 1
Test accuracy for 3: 0.615
Num non-zero elements: 1
Test accuracy for 5: 0.872
Num non-zero elements: 1
Test accuracy for 6: 0.719
Num non-zero elements: 2
Test accuracy for 1: 0.81
Num non-zero elements: 2
Test accuracy for 2: 0.717
Num non-zero elements: 2
Test accuracy for 3: 0.679
Num non-zero elements: 2
Test accuracy for 5: 0.876
Num non-zero elements: 2
Test accuracy for 6: 0.75
Num non-zero elements: 5
Test accuracy for 1: 0.909
Num non-zero elements: 5
Test accuracy for 2: 0.739
Num non-zero elements: 5
Test accuracy for 3: 0.764
Num non-zero elements: 5
Test accuracy for 5: 0.874
Num non-zero elements: 5
Test accuracy for 6: 0.769
Num non-zero elements: 10
Test accuracy for 1: 0.917
Num non-zero elements: 10
Test accuracy for 2: 0.768
Num non-zero elements: 10
Test accuracy for 3: 0.816
Num non-zero elements: 10
Test accuracy for 5: 0.881
Num non-zero elements: 10
Test accuracy for 6: 0.781
Num non-zero elements: 20
Test accuracy for 1: 0.923
Num non-zero elements: 20
Test accuracy for 2: 0.853
Num non-zero elements: 20
Test accuracy for 3: 0.855
Num non-zero elements: 20
Test accuracy for 5: 0.888
Num non-zero elements: 20
Test accuracy for 6: 0.776
Num non-zero elements: 50
Test accuracy for 1: 0.929
Num non-zero elements: 50
Test accuracy for 2: 0.904
Num non-zero elements: 50
Test accuracy for 3: 0.876
Num non-zero elements: 50
Test accuracy for 5: 0.903
Num non-zero elements: 50
Test accuracy for 6: 0.81
Num non-zero elements: 2304
Test accuracy for 1.0: 0.981
Num non-zero elements: 2304
Test accuracy for 5.0: 0.982
Num non-zero elements: 1
Test accuracy for 1.0: 0.671
Num non-zero elements: 1
Test accuracy for 5.0: 0.671
Num non-zero elements: 2
Test accuracy for 1.0: 0.724
Num non-zero elements: 2
Test accuracy for 5.0: 0.724
Num non-zero elements: 5
Test accuracy for 1.0: 0.766
Num non-zero elements: 5
Test accuracy for 5.0: 0.766
Num non-zero elements: 10
Test accuracy for 1.0: 0.826
Num non-zero elements: 10
Test accuracy for 5.0: 0.826
Num non-zero elements: 20
Test accuracy for 1.0: 0.847
Num non-zero elements: 20
Test accuracy for 5.0: 0.847
Num non-zero elements: 50
Test accuracy for 1.0: 0.933
Num non-zero elements: 50
Test accuracy for 5.0: 0.933
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 25 epochs
Test accuracy for 1.0: 0.9740000367164612
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 16 epochs
Test accuracy for 5.0: 0.9730000495910645
Num non-zero elements: 1
Test accuracy for 1.0: 0.853
Num non-zero elements: 1
Test accuracy for 5.0: 0.853
Num non-zero elements: 2
Test accuracy for 1.0: 0.916
Num non-zero elements: 2
Test accuracy for 5.0: 0.916
Num non-zero elements: 5
Test accuracy for 1.0: 0.937
Num non-zero elements: 5
Test accuracy for 5.0: 0.937
Num non-zero elements: 10
Test accuracy for 1.0: 0.946
Num non-zero elements: 10
Test accuracy for 5.0: 0.946
Num non-zero elements: 20
Test accuracy for 1.0: 0.957
Num non-zero elements: 20
Test accuracy for 5.0: 0.957
Num non-zero elements: 50
Test accuracy for 1.0: 0.963
Num non-zero elements: 50
Test accuracy for 5.0: 0.963
Loading dataset codeparrot/github-code, this usually takes ~30 seconds
Num non-zero elements: 2304
Test accuracy for C: 0.953
Num non-zero elements: 2304
Test accuracy for Python: 0.985
Num non-zero elements: 2304
Test accuracy for HTML: 0.988
Num non-zero elements: 2304
Test accuracy for Java: 0.954
Num non-zero elements: 2304
Test accuracy for PHP: 0.956
Num non-zero elements: 1
Test accuracy for C: 0.657
Num non-zero elements: 1
Test accuracy for Python: 0.641
Num non-zero elements: 1
Test accuracy for HTML: 0.787
Num non-zero elements: 1
Test accuracy for Java: 0.639
Num non-zero elements: 1
Test accuracy for PHP: 0.598
Num non-zero elements: 2
Test accuracy for C: 0.674
Num non-zero elements: 2
Test accuracy for Python: 0.675
Num non-zero elements: 2
Test accuracy for HTML: 0.803
Num non-zero elements: 2
Test accuracy for Java: 0.693
Num non-zero elements: 2
Test accuracy for PHP: 0.653
Num non-zero elements: 5
Test accuracy for C: 0.75
Num non-zero elements: 5
Test accuracy for Python: 0.724
Num non-zero elements: 5
Test accuracy for HTML: 0.897
Num non-zero elements: 5
Test accuracy for Java: 0.726
Num non-zero elements: 5
Test accuracy for PHP: 0.672
Num non-zero elements: 10
Test accuracy for C: 0.796
Num non-zero elements: 10
Test accuracy for Python: 0.734
Num non-zero elements: 10
Test accuracy for HTML: 0.951
Num non-zero elements: 10
Test accuracy for Java: 0.805
Num non-zero elements: 10
Test accuracy for PHP: 0.725
Num non-zero elements: 20
Test accuracy for C: 0.863
Num non-zero elements: 20
Test accuracy for Python: 0.849
Num non-zero elements: 20
Test accuracy for HTML: 0.959
Num non-zero elements: 20
Test accuracy for Java: 0.843
Num non-zero elements: 20
Test accuracy for PHP: 0.833
Num non-zero elements: 50
Test accuracy for C: 0.904
Num non-zero elements: 50
Test accuracy for Python: 0.953
Num non-zero elements: 50
Test accuracy for HTML: 0.972
Num non-zero elements: 50
Test accuracy for Java: 0.904
Num non-zero elements: 50
Test accuracy for PHP: 0.902
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 20 epochs
Test accuracy for C: 0.9510000348091125
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 21 epochs
Test accuracy for Python: 0.9810000658035278
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 13 epochs
Test accuracy for HTML: 0.9820000529289246
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 25 epochs
Test accuracy for Java: 0.9640000462532043
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 13 epochs
Test accuracy for PHP: 0.9520000219345093
Num non-zero elements: 1
Test accuracy for C: 0.584
Num non-zero elements: 1
Test accuracy for Python: 0.556
Num non-zero elements: 1
Test accuracy for HTML: 0.634
Num non-zero elements: 1
Test accuracy for Java: 0.609
Num non-zero elements: 1
Test accuracy for PHP: 0.905
Num non-zero elements: 2
Test accuracy for C: 0.623
Num non-zero elements: 2
Test accuracy for Python: 0.607
Num non-zero elements: 2
Test accuracy for HTML: 0.663
Num non-zero elements: 2
Test accuracy for Java: 0.64
Num non-zero elements: 2
Test accuracy for PHP: 0.906
Num non-zero elements: 5
Test accuracy for C: 0.703
Num non-zero elements: 5
Test accuracy for Python: 0.918
Num non-zero elements: 5
Test accuracy for HTML: 0.925
Num non-zero elements: 5
Test accuracy for Java: 0.654
Num non-zero elements: 5
Test accuracy for PHP: 0.91
Num non-zero elements: 10
Test accuracy for C: 0.833
Num non-zero elements: 10
Test accuracy for Python: 0.928
Num non-zero elements: 10
Test accuracy for HTML: 0.929
Num non-zero elements: 10
Test accuracy for Java: 0.804
Num non-zero elements: 10
Test accuracy for PHP: 0.916
Num non-zero elements: 20
Test accuracy for C: 0.886
Num non-zero elements: 20
Test accuracy for Python: 0.946
Num non-zero elements: 20
Test accuracy for HTML: 0.96
Num non-zero elements: 20
Test accuracy for Java: 0.849
Num non-zero elements: 20
Test accuracy for PHP: 0.92
Num non-zero elements: 50
Test accuracy for C: 0.917
Num non-zero elements: 50
Test accuracy for Python: 0.978
Num non-zero elements: 50
Test accuracy for HTML: 0.972
Num non-zero elements: 50
Test accuracy for Java: 0.919
Num non-zero elements: 50
Test accuracy for PHP: 0.922
Num non-zero elements: 2304
Test accuracy for 0: 0.926
Num non-zero elements: 2304
Test accuracy for 1: 0.986
Num non-zero elements: 2304
Test accuracy for 2: 0.895
Num non-zero elements: 2304
Test accuracy for 3: 0.946
Num non-zero elements: 1
Test accuracy for 0: 0.57
Num non-zero elements: 1
Test accuracy for 1: 0.672
Num non-zero elements: 1
Test accuracy for 2: 0.664
Num non-zero elements: 1
Test accuracy for 3: 0.772
Num non-zero elements: 2
Test accuracy for 0: 0.801
Num non-zero elements: 2
Test accuracy for 1: 0.8
Num non-zero elements: 2
Test accuracy for 2: 0.679
Num non-zero elements: 2
Test accuracy for 3: 0.81
Num non-zero elements: 5
Test accuracy for 0: 0.817
Num non-zero elements: 5
Test accuracy for 1: 0.872
Num non-zero elements: 5
Test accuracy for 2: 0.75
Num non-zero elements: 5
Test accuracy for 3: 0.841
Num non-zero elements: 10
Test accuracy for 0: 0.868
Num non-zero elements: 10
Test accuracy for 1: 0.93
Num non-zero elements: 10
Test accuracy for 2: 0.792
Num non-zero elements: 10
Test accuracy for 3: 0.888
Num non-zero elements: 20
Test accuracy for 0: 0.893
Num non-zero elements: 20
Test accuracy for 1: 0.952
Num non-zero elements: 20
Test accuracy for 2: 0.838
Num non-zero elements: 20
Test accuracy for 3: 0.893
Num non-zero elements: 50
Test accuracy for 0: 0.902
Num non-zero elements: 50
Test accuracy for 1: 0.975
Num non-zero elements: 50
Test accuracy for 2: 0.893
Num non-zero elements: 50
Test accuracy for 3: 0.924
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 22 epochs
Test accuracy for 0: 0.940000057220459
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 17 epochs
Test accuracy for 1: 0.9830000400543213
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 24 epochs
Test accuracy for 2: 0.9360000491142273
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for 3: 0.9380000233650208
Num non-zero elements: 1
Test accuracy for 0: 0.739
Num non-zero elements: 1
Test accuracy for 1: 0.954
Num non-zero elements: 1
Test accuracy for 2: 0.694
Num non-zero elements: 1
Test accuracy for 3: 0.67
Num non-zero elements: 2
Test accuracy for 0: 0.87
Num non-zero elements: 2
Test accuracy for 1: 0.971
Num non-zero elements: 2
Test accuracy for 2: 0.825
Num non-zero elements: 2
Test accuracy for 3: 0.752
Num non-zero elements: 5
Test accuracy for 0: 0.867
Num non-zero elements: 5
Test accuracy for 1: 0.973
Num non-zero elements: 5
Test accuracy for 2: 0.841
Num non-zero elements: 5
Test accuracy for 3: 0.828
Num non-zero elements: 10
Test accuracy for 0: 0.901
Num non-zero elements: 10
Test accuracy for 1: 0.968
Num non-zero elements: 10
Test accuracy for 2: 0.862
Num non-zero elements: 10
Test accuracy for 3: 0.922
Num non-zero elements: 20
Test accuracy for 0: 0.905
Num non-zero elements: 20
Test accuracy for 1: 0.978
Num non-zero elements: 20
Test accuracy for 2: 0.871
Num non-zero elements: 20
Test accuracy for 3: 0.917
Num non-zero elements: 50
Test accuracy for 0: 0.927
Num non-zero elements: 50
Test accuracy for 1: 0.971
Num non-zero elements: 50
Test accuracy for 2: 0.893
Num non-zero elements: 50
Test accuracy for 3: 0.944
Loading dataset Helsinki-NLP/europarl, this usually takes ~10 seconds
Num non-zero elements: 2304
Test accuracy for en: 0.999
Num non-zero elements: 2304
Test accuracy for fr: 1.0
Num non-zero elements: 2304
Test accuracy for de: 0.999
Num non-zero elements: 2304
Test accuracy for es: 0.999
Num non-zero elements: 2304
Test accuracy for nl: 1.0
Num non-zero elements: 1
Test accuracy for en: 0.738
Num non-zero elements: 1
Test accuracy for fr: 0.58
Num non-zero elements: 1
Test accuracy for de: 0.757
Num non-zero elements: 1
Test accuracy for es: 0.913
Num non-zero elements: 1
Test accuracy for nl: 0.634
Num non-zero elements: 2
Test accuracy for en: 0.803
Num non-zero elements: 2
Test accuracy for fr: 0.575
Num non-zero elements: 2
Test accuracy for de: 0.822
Num non-zero elements: 2
Test accuracy for es: 0.915
Num non-zero elements: 2
Test accuracy for nl: 0.756
Num non-zero elements: 5
Test accuracy for en: 0.899
Num non-zero elements: 5
Test accuracy for fr: 0.921
Num non-zero elements: 5
Test accuracy for de: 0.868
Num non-zero elements: 5
Test accuracy for es: 0.979
Num non-zero elements: 5
Test accuracy for nl: 0.86
Num non-zero elements: 10
Test accuracy for en: 0.976
Num non-zero elements: 10
Test accuracy for fr: 0.974
Num non-zero elements: 10
Test accuracy for de: 0.964
Num non-zero elements: 10
Test accuracy for es: 0.99
Num non-zero elements: 10
Test accuracy for nl: 0.919
Num non-zero elements: 20
Test accuracy for en: 0.993
Num non-zero elements: 20
Test accuracy for fr: 0.991
Num non-zero elements: 20
Test accuracy for de: 0.988
Num non-zero elements: 20
Test accuracy for es: 0.997
Num non-zero elements: 20
Test accuracy for nl: 0.976
Num non-zero elements: 50
Test accuracy for en: 0.999
Num non-zero elements: 50
Test accuracy for fr: 1.0
Num non-zero elements: 50
Test accuracy for de: 0.996
Num non-zero elements: 50
Test accuracy for es: 1.0
Num non-zero elements: 50
Test accuracy for nl: 0.995
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 17 epochs
Test accuracy for en: 0.999000072479248
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for fr: 0.999000072479248
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 18 epochs
Test accuracy for de: 1.0
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 12 epochs
Test accuracy for es: 0.999000072479248
Num non-zero elements: 18432
Training probe with dim: 18432, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 20 epochs
Test accuracy for nl: 0.9970000386238098
Num non-zero elements: 1
Test accuracy for en: 1.0
Num non-zero elements: 1
Test accuracy for fr: 0.993
Num non-zero elements: 1
Test accuracy for de: 0.818
Num non-zero elements: 1
Test accuracy for es: 0.977
Num non-zero elements: 1
Test accuracy for nl: 0.745
Num non-zero elements: 2
Test accuracy for en: 1.0
Num non-zero elements: 2
Test accuracy for fr: 0.995
Num non-zero elements: 2
Test accuracy for de: 0.875
Num non-zero elements: 2
Test accuracy for es: 0.982
Num non-zero elements: 2
Test accuracy for nl: 0.943
Num non-zero elements: 5
Test accuracy for en: 0.998
Num non-zero elements: 5
Test accuracy for fr: 0.995
Num non-zero elements: 5
Test accuracy for de: 0.978
Num non-zero elements: 5
Test accuracy for es: 0.999
Num non-zero elements: 5
Test accuracy for nl: 0.983
Num non-zero elements: 10
Test accuracy for en: 1.0
Num non-zero elements: 10
Test accuracy for fr: 0.996
Num non-zero elements: 10
Test accuracy for de: 0.996
Num non-zero elements: 10
Test accuracy for es: 0.998
Num non-zero elements: 10
Test accuracy for nl: 0.984
Num non-zero elements: 20
Test accuracy for en: 0.998
Num non-zero elements: 20
Test accuracy for fr: 0.997
Num non-zero elements: 20
Test accuracy for de: 0.998
Num non-zero elements: 20
Test accuracy for es: 0.999
Num non-zero elements: 20
Test accuracy for nl: 0.986
Num non-zero elements: 50
Test accuracy for en: 0.997
Num non-zero elements: 50
Test accuracy for fr: 0.998
Num non-zero elements: 50
Test accuracy for de: 0.998
Num non-zero elements: 50
Test accuracy for es: 0.999
Num non-zero elements: 50
Test accuracy for nl: 0.996

Running unlearning evaluation...
Loaded pretrained model google/gemma-2-2b-it into HookedTransformer
Running evaluation for SAE: google/gemma-2-2b_layer_12_sae_custom_sae
Sparsity calculation for google/gemma-2-2b_layer_12_sae_custom_sae is already done
Forget sparsity: [0.014126 0.001871 0.010558 ... 0.002963 0.00142  0.00191 ]
(18432,)
Retain sparsity: [0.004682 0.001597 0.012794 ... 0.001564 0.000154 0.003691]
(18432,)
Starting metrics calculation...
running on datasets: ['wmdp-bio', 'high_school_us_history', 'college_computer_science', 'high_school_geography', 'human_aging']
Calculating metrics for retain threshold: 0.001
Top features for ablation: [ 7234  8651 15607 ...  3550 14783 13324]
Calculating metrics list with parameters: {'intervention_method': 'clamp_feature_activation'} {'features_to_ablate': [array([ 7234,  8651, 15607,  9513,   178,  4566, 14838, 16825, 17456,
        2737]), array([ 7234,  8651, 15607,  9513,   178,  4566, 14838, 16825, 17456,
        2737, 16520,  1146, 14239,  4615,  1830, 17553,  5242,  8911,
       14067, 13516])], 'multiplier': [25, 50, 100, 200]}
All target question ids for gemma-2-2b-it on wmdp-bio already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on high_school_us_history already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on college_computer_science already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on high_school_geography already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on human_aging already exist. No need to generate target ids.
Calculating metrics for retain threshold: 0.01
Top features for ablation: [12497 12900 18043 ...  3550 14783 13324]
Calculating metrics list with parameters: {'intervention_method': 'clamp_feature_activation'} {'features_to_ablate': [array([12497, 12900, 18043, 11289, 11424, 15710,  7018,  2055, 15493,
        5952]), array([12497, 12900, 18043, 11289, 11424, 15710,  7018,  2055, 15493,
        5952, 10518, 17710, 14977,  7267,  4445, 15332,  2453,   264,
        1335, 17172])], 'multiplier': [25, 50, 100, 200]}
All target question ids for gemma-2-2b-it on wmdp-bio already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on high_school_us_history already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on college_computer_science already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on high_school_geography already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on human_aging already exist. No need to generate target ids.
Unlearning scores DataFrame:     wmdp-bio  high_school_us_history  ...  multiplier  all_side_effects_mcq
0   0.992509                1.000000  ...          25              1.000000
1   0.726592                0.963636  ...         200              0.957516
2   0.932584                0.972727  ...         100              0.986928
3   0.951311                0.990909  ...         200              0.950980
4   0.631086                0.945455  ...         200              0.937908
5   0.975655                0.990909  ...          50              0.996732
6   0.996255                1.000000  ...         100              0.993464
7   0.985019                1.000000  ...         100              0.990196
8   1.000000                1.000000  ...          50              1.000000
9   0.983146                1.000000  ...          50              1.000000
10  0.998127                1.000000  ...          25              1.000000
11  0.880150                0.972727  ...         100              0.980392
12  1.000000                1.000000  ...          25              1.000000
13  1.000000                1.000000  ...          25              1.000000
14  0.986891                1.000000  ...         200              0.980392
15  0.998127                1.000000  ...          50              1.000000

[16 rows x 10 columns]
