Model dtype: torch.float32
SAE dtype: torch.float32
Step 0: {'loss': 504623.84375, 'mse_loss': 504266.6875, 'l1_loss': 8928.7421875, 'l2_loss': 563.7000122070312}
Step 100: {'loss': 168528.875, 'mse_loss': 168209.4375, 'l1_loss': 7986.06884765625, 'l2_loss': 353.77471923828125}
Step 200: {'loss': 108510.984375, 'mse_loss': 108208.6015625, 'l1_loss': 7559.6630859375, 'l2_loss': 294.1167297363281}
Step 300: {'loss': 65573.9375, 'mse_loss': 65293.49609375, 'l1_loss': 7010.9521484375, 'l2_loss': 249.56460571289062}
Step 400: {'loss': 50024.6015625, 'mse_loss': 49751.4765625, 'l1_loss': 6828.09375, 'l2_loss': 220.64027404785156}
Step 500: {'loss': 41828.41796875, 'mse_loss': 41546.6796875, 'l1_loss': 7043.416015625, 'l2_loss': 201.08135986328125}
Step 600: {'loss': 36498.91015625, 'mse_loss': 36194.6640625, 'l1_loss': 7606.1923828125, 'l2_loss': 187.5775146484375}
Step 700: {'loss': 31029.35546875, 'mse_loss': 30688.1796875, 'l1_loss': 8529.4140625, 'l2_loss': 172.631103515625}
Step 800: {'loss': 27571.474609375, 'mse_loss': 27175.6796875, 'l1_loss': 9894.890625, 'l2_loss': 162.03573608398438}
Step 900: {'loss': 24190.666015625, 'mse_loss': 23746.3125, 'l1_loss': 11108.8359375, 'l2_loss': 151.41114807128906}
Step 1000: {'loss': 21293.205078125, 'mse_loss': 20765.4609375, 'l1_loss': 13193.5908203125, 'l2_loss': 141.48977661132812}
Step 1100: {'loss': 18804.22265625, 'mse_loss': 18233.3203125, 'l1_loss': 14272.5517578125, 'l2_loss': 132.46804809570312}
Step 1200: {'loss': 16589.681640625, 'mse_loss': 15989.87109375, 'l1_loss': 14995.2431640625, 'l2_loss': 124.07815551757812}
Step 1300: {'loss': 15401.603515625, 'mse_loss': 14740.2666015625, 'l1_loss': 16533.421875, 'l2_loss': 118.89503479003906}
Step 1400: {'loss': 13558.6689453125, 'mse_loss': 12851.748046875, 'l1_loss': 17673.0234375, 'l2_loss': 111.1470718383789}
Step 1500: {'loss': 12694.4970703125, 'mse_loss': 11965.9375, 'l1_loss': 18213.98046875, 'l2_loss': 107.04466247558594}
Step 1600: {'loss': 11657.48828125, 'mse_loss': 10894.2705078125, 'l1_loss': 19080.4453125, 'l2_loss': 102.26565551757812}
Step 1700: {'loss': 10921.859375, 'mse_loss': 10148.095703125, 'l1_loss': 19344.1015625, 'l2_loss': 98.50423431396484}
Step 1800: {'loss': 10195.25, 'mse_loss': 9391.279296875, 'l1_loss': 20099.263671875, 'l2_loss': 94.82044982910156}
Step 1900: {'loss': 9698.7021484375, 'mse_loss': 8887.7216796875, 'l1_loss': 20274.50390625, 'l2_loss': 92.2577133178711}
Step 2000: {'loss': 9172.7294921875, 'mse_loss': 8351.59375, 'l1_loss': 20528.404296875, 'l2_loss': 89.36056518554688}
Step 2100: {'loss': 8741.0654296875, 'mse_loss': 7912.30908203125, 'l1_loss': 20718.90234375, 'l2_loss': 87.0520248413086}
Step 2200: {'loss': 8312.4814453125, 'mse_loss': 7499.39453125, 'l1_loss': 20327.18359375, 'l2_loss': 84.65336608886719}
Step 2300: {'loss': 8016.24267578125, 'mse_loss': 7175.0634765625, 'l1_loss': 21029.4765625, 'l2_loss': 82.63677978515625}
Step 2400: {'loss': 7810.6103515625, 'mse_loss': 6970.3515625, 'l1_loss': 21006.47265625, 'l2_loss': 81.68488311767578}
Step 2500: {'loss': 7533.6455078125, 'mse_loss': 6692.41796875, 'l1_loss': 21030.68359375, 'l2_loss': 79.92449951171875}
Step 2600: {'loss': 7317.2646484375, 'mse_loss': 6464.40625, 'l1_loss': 21321.455078125, 'l2_loss': 78.592041015625}
Step 2700: {'loss': 7164.931640625, 'mse_loss': 6322.0302734375, 'l1_loss': 21072.53125, 'l2_loss': 77.57255554199219}
Step 2800: {'loss': 7019.9482421875, 'mse_loss': 6182.8662109375, 'l1_loss': 20927.05078125, 'l2_loss': 76.75559997558594}
Step 2900: {'loss': 6732.8486328125, 'mse_loss': 5901.80908203125, 'l1_loss': 20775.99609375, 'l2_loss': 74.87802124023438}
Step 3000: {'loss': 6694.63427734375, 'mse_loss': 5846.4267578125, 'l1_loss': 21205.1875, 'l2_loss': 74.60893249511719}
Step 3100: {'loss': 6469.62939453125, 'mse_loss': 5630.0712890625, 'l1_loss': 20988.953125, 'l2_loss': 73.20750427246094}
Step 3200: {'loss': 6388.2666015625, 'mse_loss': 5553.9658203125, 'l1_loss': 20857.515625, 'l2_loss': 72.60200500488281}
Step 3300: {'loss': 6174.08984375, 'mse_loss': 5341.56982421875, 'l1_loss': 20812.99609375, 'l2_loss': 71.24772644042969}
Step 3400: {'loss': 6087.4033203125, 'mse_loss': 5242.0751953125, 'l1_loss': 21133.203125, 'l2_loss': 70.5490951538086}
Step 3500: {'loss': 5826.169921875, 'mse_loss': 5002.74560546875, 'l1_loss': 20585.60546875, 'l2_loss': 68.93463134765625}
Step 3600: {'loss': 5865.04833984375, 'mse_loss': 5026.44091796875, 'l1_loss': 20965.18359375, 'l2_loss': 69.08102416992188}
Step 3700: {'loss': 5755.009765625, 'mse_loss': 4926.7529296875, 'l1_loss': 20706.41796875, 'l2_loss': 68.40333557128906}
Step 3800: {'loss': 5601.734375, 'mse_loss': 4775.25927734375, 'l1_loss': 20661.873046875, 'l2_loss': 67.40333557128906}
Step 3900: {'loss': 5551.103515625, 'mse_loss': 4730.15185546875, 'l1_loss': 20523.791015625, 'l2_loss': 67.06348419189453}
Step 4000: {'loss': 5451.37158203125, 'mse_loss': 4640.05078125, 'l1_loss': 20283.01953125, 'l2_loss': 66.41551208496094}
Step 4100: {'loss': 5322.8798828125, 'mse_loss': 4506.72607421875, 'l1_loss': 20403.84375, 'l2_loss': 65.42668151855469}
Step 4200: {'loss': 5220.87890625, 'mse_loss': 4396.8974609375, 'l1_loss': 20599.53125, 'l2_loss': 64.56204986572266}
Step 4300: {'loss': 5174.951171875, 'mse_loss': 4355.6708984375, 'l1_loss': 20482.013671875, 'l2_loss': 64.38850402832031}
Step 4400: {'loss': 4989.861328125, 'mse_loss': 4174.6328125, 'l1_loss': 20380.712890625, 'l2_loss': 62.931739807128906}
Step 4500: {'loss': 4939.63916015625, 'mse_loss': 4120.0810546875, 'l1_loss': 20488.95703125, 'l2_loss': 62.50993728637695}
Step 4600: {'loss': 4855.376953125, 'mse_loss': 4042.71484375, 'l1_loss': 20316.55859375, 'l2_loss': 61.948543548583984}
Step 4700: {'loss': 4778.58349609375, 'mse_loss': 3956.901123046875, 'l1_loss': 20542.0625, 'l2_loss': 61.26008605957031}
Step 4800: {'loss': 4663.26513671875, 'mse_loss': 3848.60693359375, 'l1_loss': 20366.453125, 'l2_loss': 60.54649353027344}

 training complete! 

all info: /gpfs/radev/project/lafferty/tl784/AIscientist/free_PhD_labor/templates/sae_variants/run_0/final_info.json

Running absorption evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
[PosixPath('/gpfs/radev/project/lafferty/tl784/AIscientist/free_PhD_labor/artifacts/absorption/k_sparse_probing/google/gemma-2-2b_layer_19_sae_custom_sae/layer_19_google/gemma-2-2b_layer_19_sae_custom_sae_metrics.parquet')] exist(s), loading from disk
[PosixPath('/gpfs/radev/project/lafferty/tl784/AIscientist/free_PhD_labor/artifacts/absorption/feature_absorption/google/gemma-2-2b_layer_19_sae_custom_sae/layer_19_google/gemma-2-2b_layer_19_sae_custom_sae.parquet')] exist(s), loading from disk

Running core evaluation...
Using device: cuda
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Saved evaluation results to: run_0/google_gemma-2-2b_layer_19_sae_custom_sae_eval_results.json

Running scr_and_tpp evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Loading activations from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/LabHC_bias_in_bios_class_set1_professor_nurse_activations.pt
Loading probes from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/LabHC_bias_in_bios_class_set1_professor_nurse_probes.pkl
dir: 1, original_acc: 0.8980000615119934, clean_acc: 0.9650000333786011, changed_acc: 0.8830000162124634, scr_score: -0.22388136713540846
dir: 1, original_acc: 0.8980000615119934, clean_acc: 0.9650000333786011, changed_acc: 0.8700000643730164, scr_score: -0.41791058054058766
dir: 1, original_acc: 0.8980000615119934, clean_acc: 0.9650000333786011, changed_acc: 0.8700000643730164, scr_score: -0.41791058054058766
dir: 1, original_acc: 0.8980000615119934, clean_acc: 0.9650000333786011, changed_acc: 0.8740000128746033, scr_score: -0.3582098315678786
dir: 1, original_acc: 0.8980000615119934, clean_acc: 0.9650000333786011, changed_acc: 0.843000054359436, scr_score: -0.8208959738379981
dir: 1, original_acc: 0.8980000615119934, clean_acc: 0.9650000333786011, changed_acc: 0.6370000243186951, scr_score: -3.8955245789196966
dir: 1, original_acc: 0.8980000615119934, clean_acc: 0.9650000333786011, changed_acc: 0.5, scr_score: -5.940301919893103
dir: 2, original_acc: 0.5960000157356262, clean_acc: 0.9920000433921814, changed_acc: 0.5960000157356262, scr_score: 0.0
dir: 2, original_acc: 0.5960000157356262, clean_acc: 0.9920000433921814, changed_acc: 0.6100000143051147, scr_score: 0.03535352927204973
dir: 2, original_acc: 0.5960000157356262, clean_acc: 0.9920000433921814, changed_acc: 0.612000048160553, scr_score: 0.04040411946335353
dir: 2, original_acc: 0.5960000157356262, clean_acc: 0.9920000433921814, changed_acc: 0.6130000352859497, scr_score: 0.042929339300620824
dir: 2, original_acc: 0.5960000157356262, clean_acc: 0.9920000433921814, changed_acc: 0.7090000510215759, scr_score: 0.28535360453043435
dir: 2, original_acc: 0.5960000157356262, clean_acc: 0.9920000433921814, changed_acc: 0.6210000514984131, scr_score: 0.06313139903229759
dir: 2, original_acc: 0.5960000157356262, clean_acc: 0.9920000433921814, changed_acc: 0.5, scr_score: -0.24242426522981353
Loading activations from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/LabHC_bias_in_bios_class_set1_architect_journalist_activations.pt
Loading probes from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/LabHC_bias_in_bios_class_set1_architect_journalist_probes.pkl
dir: 1, original_acc: 0.8450000286102295, clean_acc: 0.9550000429153442, changed_acc: 0.8210000395774841, scr_score: -0.21818169010573862
dir: 1, original_acc: 0.8450000286102295, clean_acc: 0.9550000429153442, changed_acc: 0.7980000376701355, scr_score: -0.4272725893446416
dir: 1, original_acc: 0.8450000286102295, clean_acc: 0.9550000429153442, changed_acc: 0.7660000324249268, scr_score: -0.7181816901057386
dir: 1, original_acc: 0.8450000286102295, clean_acc: 0.9550000429153442, changed_acc: 0.7540000081062317, scr_score: -0.8272728060887762
dir: 1, original_acc: 0.8450000286102295, clean_acc: 0.9550000429153442, changed_acc: 0.7320000529289246, scr_score: -1.0272723726005069
dir: 1, original_acc: 0.8450000286102295, clean_acc: 0.9550000429153442, changed_acc: 0.6760000586509705, scr_score: -1.5363631634673427
dir: 1, original_acc: 0.8450000286102295, clean_acc: 0.9550000429153442, changed_acc: 0.503000020980835, scr_score: -3.109090574122701
dir: 2, original_acc: 0.6490000486373901, clean_acc: 0.9900000691413879, changed_acc: 0.6490000486373901, scr_score: 0.0
dir: 2, original_acc: 0.6490000486373901, clean_acc: 0.9900000691413879, changed_acc: 0.6430000066757202, scr_score: -0.017595429914643006
dir: 2, original_acc: 0.6490000486373901, clean_acc: 0.9900000691413879, changed_acc: 0.6500000357627869, scr_score: 0.002932513387884107
dir: 2, original_acc: 0.6490000486373901, clean_acc: 0.9900000691413879, changed_acc: 0.6820000410079956, scr_score: 0.09677416535585981
dir: 2, original_acc: 0.6490000486373901, clean_acc: 0.9900000691413879, changed_acc: 0.6850000619888306, scr_score: 0.10557188031318131
dir: 2, original_acc: 0.6490000486373901, clean_acc: 0.9900000691413879, changed_acc: 0.7260000109672546, scr_score: 0.22580632756578317
dir: 2, original_acc: 0.6490000486373901, clean_acc: 0.9900000691413879, changed_acc: 0.7780000567436218, scr_score: 0.37829912125978693
Loading activations from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/LabHC_bias_in_bios_class_set1_surgeon_psychologist_activations.pt
Loading probes from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/LabHC_bias_in_bios_class_set1_surgeon_psychologist_probes.pkl
dir: 1, original_acc: 0.9160000681877136, clean_acc: 0.971000075340271, changed_acc: 0.9180000424385071, scr_score: 0.03636316346734262
dir: 1, original_acc: 0.9160000681877136, clean_acc: 0.971000075340271, changed_acc: 0.9100000262260437, scr_score: -0.10909165784337418
dir: 1, original_acc: 0.9160000681877136, clean_acc: 0.971000075340271, changed_acc: 0.8830000162124634, scr_score: -0.6000008669765385
dir: 1, original_acc: 0.9160000681877136, clean_acc: 0.971000075340271, changed_acc: 0.8100000619888306, scr_score: -1.9272725893446416
dir: 1, original_acc: 0.9160000681877136, clean_acc: 0.971000075340271, changed_acc: 0.7040000557899475, scr_score: -3.8545451786892833
dir: 1, original_acc: 0.9160000681877136, clean_acc: 0.971000075340271, changed_acc: 0.7100000381469727, scr_score: -3.745454604566582
dir: 1, original_acc: 0.9160000681877136, clean_acc: 0.971000075340271, changed_acc: 0.7010000348091125, scr_score: -3.90909100761097
dir: 2, original_acc: 0.5800000429153442, clean_acc: 0.987000048160553, changed_acc: 0.578000009059906, scr_score: -0.0049140880335695695
dir: 2, original_acc: 0.5800000429153442, clean_acc: 0.987000048160553, changed_acc: 0.578000009059906, scr_score: -0.0049140880335695695
dir: 2, original_acc: 0.5800000429153442, clean_acc: 0.987000048160553, changed_acc: 0.5900000333786011, scr_score: 0.024570000821577526
dir: 2, original_acc: 0.5800000429153442, clean_acc: 0.987000048160553, changed_acc: 0.6110000014305115, scr_score: 0.07616697325713898
dir: 2, original_acc: 0.5800000429153442, clean_acc: 0.987000048160553, changed_acc: 0.6350000500679016, scr_score: 0.13513515096743317
dir: 2, original_acc: 0.5800000429153442, clean_acc: 0.987000048160553, changed_acc: 0.593000054359436, scr_score: 0.03194105964755349
dir: 2, original_acc: 0.5800000429153442, clean_acc: 0.987000048160553, changed_acc: 0.5049999952316284, scr_score: -0.18427529905934498
Loading activations from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/LabHC_bias_in_bios_class_set1_attorney_teacher_activations.pt
Loading probes from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/LabHC_bias_in_bios_class_set1_attorney_teacher_probes.pkl
dir: 1, original_acc: 0.8400000333786011, clean_acc: 0.9690000414848328, changed_acc: 0.8220000267028809, scr_score: -0.13953492670246334
dir: 1, original_acc: 0.8400000333786011, clean_acc: 0.9690000414848328, changed_acc: 0.7740000486373901, scr_score: -0.5116277565413784
dir: 1, original_acc: 0.8400000333786011, clean_acc: 0.9690000414848328, changed_acc: 0.6960000395774841, scr_score: -1.1162789515682259
dir: 1, original_acc: 0.8400000333786011, clean_acc: 0.9690000414848328, changed_acc: 0.6450000405311584, scr_score: -1.5116277565413783
dir: 1, original_acc: 0.8400000333786011, clean_acc: 0.9690000414848328, changed_acc: 0.5630000233650208, scr_score: -2.1472867643967155
dir: 1, original_acc: 0.8400000333786011, clean_acc: 0.9690000414848328, changed_acc: 0.5220000147819519, scr_score: -2.465116268324384
dir: 1, original_acc: 0.8400000333786011, clean_acc: 0.9690000414848328, changed_acc: 0.5, scr_score: -2.6356590078553372
dir: 2, original_acc: 0.6600000262260437, clean_acc: 0.9950000643730164, changed_acc: 0.6490000486373901, scr_score: -0.03283575025692268
dir: 2, original_acc: 0.6600000262260437, clean_acc: 0.9950000643730164, changed_acc: 0.6650000214576721, scr_score: 0.014925357200809626
dir: 2, original_acc: 0.6600000262260437, clean_acc: 0.9950000643730164, changed_acc: 0.6680000424385071, scr_score: 0.023880642691012404
dir: 2, original_acc: 0.6600000262260437, clean_acc: 0.9950000643730164, changed_acc: 0.675000011920929, scr_score: 0.04477607160242888
dir: 2, original_acc: 0.6600000262260437, clean_acc: 0.9950000643730164, changed_acc: 0.7020000219345093, scr_score: 0.12537310724137637
dir: 2, original_acc: 0.6600000262260437, clean_acc: 0.9950000643730164, changed_acc: 0.7330000400543213, scr_score: 0.21791046422583005
dir: 2, original_acc: 0.6600000262260437, clean_acc: 0.9950000643730164, changed_acc: 0.812000036239624, scr_score: 0.4537313215077732
Loading activations from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/canrager_amazon_reviews_mcauley_1and5_Books_CDs_and_Vinyl_activations.pt
Loading probes from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/canrager_amazon_reviews_mcauley_1and5_Books_CDs_and_Vinyl_probes.pkl
dir: 1, original_acc: 0.8240000605583191, clean_acc: 0.9900000691413879, changed_acc: 0.8230000138282776, scr_score: -0.006024377580324436
dir: 1, original_acc: 0.8240000605583191, clean_acc: 0.9900000691413879, changed_acc: 0.8160000443458557, scr_score: -0.04819286625795596
dir: 1, original_acc: 0.8240000605583191, clean_acc: 0.9900000691413879, changed_acc: 0.7630000114440918, scr_score: -0.367470156386781
dir: 1, original_acc: 0.8240000605583191, clean_acc: 0.9900000691413879, changed_acc: 0.7300000190734863, scr_score: -0.5662652808707161
dir: 1, original_acc: 0.8240000605583191, clean_acc: 0.9900000691413879, changed_acc: 0.5250000357627869, scr_score: -1.8012048755160648
dir: 1, original_acc: 0.8240000605583191, clean_acc: 0.9900000691413879, changed_acc: 0.5, scr_score: -1.9518074928061506
dir: 1, original_acc: 0.8240000605583191, clean_acc: 0.9900000691413879, changed_acc: 0.5, scr_score: -1.9518074928061506
dir: 2, original_acc: 0.6720000505447388, clean_acc: 0.9460000395774841, changed_acc: 0.6660000085830688, scr_score: -0.021897964240257195
dir: 2, original_acc: 0.6720000505447388, clean_acc: 0.9460000395774841, changed_acc: 0.6820000410079956, scr_score: 0.03649631702015051
dir: 2, original_acc: 0.6720000505447388, clean_acc: 0.9460000395774841, changed_acc: 0.6920000314712524, scr_score: 0.07299263404030101
dir: 2, original_acc: 0.6720000505447388, clean_acc: 0.9460000395774841, changed_acc: 0.7440000176429749, scr_score: 0.2627736130662088
dir: 2, original_acc: 0.6720000505447388, clean_acc: 0.9460000395774841, changed_acc: 0.7170000076293945, scr_score: 0.16423342659067727
dir: 2, original_acc: 0.6720000505447388, clean_acc: 0.9460000395774841, changed_acc: 0.6660000085830688, scr_score: -0.021897964240257195
dir: 2, original_acc: 0.6720000505447388, clean_acc: 0.9460000395774841, changed_acc: 0.6770000457763672, scr_score: 0.018248158510075253
Loading activations from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/canrager_amazon_reviews_mcauley_1and5_Software_Electronics_activations.pt
Loading probes from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/canrager_amazon_reviews_mcauley_1and5_Software_Electronics_probes.pkl
dir: 1, original_acc: 0.8090000152587891, clean_acc: 0.9790000319480896, changed_acc: 0.8090000152587891, scr_score: 0.0
dir: 1, original_acc: 0.8090000152587891, clean_acc: 0.9790000319480896, changed_acc: 0.8180000185966492, scr_score: 0.052941190907698006
dir: 1, original_acc: 0.8090000152587891, clean_acc: 0.9790000319480896, changed_acc: 0.8220000267028809, scr_score: 0.07647064804617747
dir: 1, original_acc: 0.8090000152587891, clean_acc: 0.9790000319480896, changed_acc: 0.8250000476837158, scr_score: 0.09411782855391783
dir: 1, original_acc: 0.8090000152587891, clean_acc: 0.9790000319480896, changed_acc: 0.8370000123977661, scr_score: 0.16470584935383312
dir: 1, original_acc: 0.8090000152587891, clean_acc: 0.9790000319480896, changed_acc: 0.8570000529289246, scr_score: 0.2823531350462304
dir: 1, original_acc: 0.8090000152587891, clean_acc: 0.9790000319480896, changed_acc: 0.8850000500679016, scr_score: 0.44705898440006353
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9550000429153442, changed_acc: 0.6980000138282776, scr_score: 0.03383459489013476
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9550000429153442, changed_acc: 0.7000000476837158, scr_score: 0.04135351824215616
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9550000429153442, changed_acc: 0.7080000042915344, scr_score: 0.0714285394174879
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9550000429153442, changed_acc: 0.703000009059906, scr_score: 0.052631567153811336
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9550000429153442, changed_acc: 0.7160000205039978, scr_score: 0.10150378467040429
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9550000429153442, changed_acc: 0.7900000214576721, scr_score: 0.3796992430659191
dir: 2, original_acc: 0.6890000104904175, clean_acc: 0.9550000429153442, changed_acc: 0.6740000247955322, scr_score: -0.05639091679102973
Loading activations from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/canrager_amazon_reviews_mcauley_1and5_Pet_Supplies_Office_Products_activations.pt
Loading probes from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/canrager_amazon_reviews_mcauley_1and5_Pet_Supplies_Office_Products_probes.pkl
dir: 1, original_acc: 0.8690000176429749, clean_acc: 0.9810000658035278, changed_acc: 0.8490000367164612, scr_score: -0.1785711814859538
dir: 1, original_acc: 0.8690000176429749, clean_acc: 0.9810000658035278, changed_acc: 0.8420000672340393, scr_score: -0.24107088213239783
dir: 1, original_acc: 0.8690000176429749, clean_acc: 0.9810000658035278, changed_acc: 0.8850000500679016, scr_score: 0.14285737093604264
dir: 1, original_acc: 0.8690000176429749, clean_acc: 0.9810000658035278, changed_acc: 0.8920000195503235, scr_score: 0.20535707158248667
dir: 1, original_acc: 0.8690000176429749, clean_acc: 0.9810000658035278, changed_acc: 0.9050000309944153, scr_score: 0.32142855242199647
dir: 1, original_acc: 0.8690000176429749, clean_acc: 0.9810000658035278, changed_acc: 0.8740000128746033, scr_score: 0.04464279537148845
dir: 1, original_acc: 0.8690000176429749, clean_acc: 0.9810000658035278, changed_acc: 0.7940000295639038, scr_score: -0.6696424627564262
dir: 2, original_acc: 0.6290000081062317, clean_acc: 0.9580000638961792, changed_acc: 0.6360000371932983, scr_score: 0.021276680547239392
dir: 2, original_acc: 0.6290000081062317, clean_acc: 0.9580000638961792, changed_acc: 0.6640000343322754, scr_score: 0.10638304039799229
dir: 2, original_acc: 0.6290000081062317, clean_acc: 0.9580000638961792, changed_acc: 0.6610000133514404, scr_score: 0.09726443713930365
dir: 2, original_acc: 0.6290000081062317, clean_acc: 0.9580000638961792, changed_acc: 0.6920000314712524, scr_score: 0.19148940024874517
dir: 2, original_acc: 0.6290000081062317, clean_acc: 0.9580000638961792, changed_acc: 0.7200000286102295, scr_score: 0.27659576009949804
dir: 2, original_acc: 0.6290000081062317, clean_acc: 0.9580000638961792, changed_acc: 0.6810000538825989, scr_score: 0.15805482358205739
dir: 2, original_acc: 0.6290000081062317, clean_acc: 0.9580000638961792, changed_acc: 0.7680000066757202, scr_score: 0.42249232522390234
Loading activations from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/canrager_amazon_reviews_mcauley_1and5_Industrial_and_Scientific_Toys_and_Games_activations.pt
Loading probes from artifacts/scr/google/gemma-2-2b/blocks.19.hook_resid_post/canrager_amazon_reviews_mcauley_1and5_Industrial_and_Scientific_Toys_and_Games_probes.pkl
dir: 1, original_acc: 0.753000020980835, clean_acc: 0.9610000252723694, changed_acc: 0.7420000433921814, scr_score: -0.052884506546624445
dir: 1, original_acc: 0.753000020980835, clean_acc: 0.9610000252723694, changed_acc: 0.7390000224113464, scr_score: -0.06730768404151578
dir: 1, original_acc: 0.753000020980835, clean_acc: 0.9610000252723694, changed_acc: 0.7600000500679016, scr_score: 0.03365398530115103
dir: 1, original_acc: 0.753000020980835, clean_acc: 0.9610000252723694, changed_acc: 0.7660000324249268, scr_score: 0.06250005373014743
dir: 1, original_acc: 0.753000020980835, clean_acc: 0.9610000252723694, changed_acc: 0.7880000472068787, scr_score: 0.16826935338418259
dir: 1, original_acc: 0.753000020980835, clean_acc: 0.9610000252723694, changed_acc: 0.7560000419616699, scr_score: 0.014423177494891337
dir: 1, original_acc: 0.753000020980835, clean_acc: 0.9610000252723694, changed_acc: 0.8530000448226929, scr_score: 0.4807693354741335
dir: 2, original_acc: 0.7430000305175781, clean_acc: 0.9610000252723694, changed_acc: 0.7480000257492065, scr_score: 0.02293575849509752
dir: 2, original_acc: 0.7430000305175781, clean_acc: 0.9610000252723694, changed_acc: 0.7540000081062317, scr_score: 0.05045861400605288
dir: 2, original_acc: 0.7430000305175781, clean_acc: 0.9610000252723694, changed_acc: 0.753000020980835, scr_score: 0.04587151699019504
dir: 2, original_acc: 0.7430000305175781, clean_acc: 0.9610000252723694, changed_acc: 0.7620000243186951, scr_score: 0.08715593696453222
dir: 2, original_acc: 0.7430000305175781, clean_acc: 0.9610000252723694, changed_acc: 0.76500004529953, scr_score: 0.10091750142791406
dir: 2, original_acc: 0.7430000305175781, clean_acc: 0.9610000252723694, changed_acc: 0.7290000319480896, scr_score: -0.06422017846943472
dir: 2, original_acc: 0.7430000305175781, clean_acc: 0.9610000252723694, changed_acc: 0.5220000147819519, scr_score: -1.0137615644633817

Running sparse_probing evaluation...
Loaded pretrained model google/gemma-2-2b into HookedTransformer
Loading activations from artifacts/sparse_probing/google/gemma-2-2b/blocks.19.hook_resid_post/LabHC_bias_in_bios_class_set1_activations.pt
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 30 epochs
Test accuracy for 0: 0.9460000395774841
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 26 epochs
Test accuracy for 1: 0.9700000286102295
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 26 epochs
Test accuracy for 2: 0.9530000686645508
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 33 epochs
Test accuracy for 6: 0.9910000562667847
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 37 epochs
Test accuracy for 9: 0.9780000448226929
Num non-zero elements: 1
Test accuracy for 0: 0.725
Num non-zero elements: 1
Test accuracy for 1: 0.723
Num non-zero elements: 1
Test accuracy for 2: 0.776
Num non-zero elements: 1
Test accuracy for 6: 0.888
Num non-zero elements: 1
Test accuracy for 9: 0.882
Num non-zero elements: 2
Test accuracy for 0: 0.774
Num non-zero elements: 2
Test accuracy for 1: 0.756
Num non-zero elements: 2
Test accuracy for 2: 0.855
Num non-zero elements: 2
Test accuracy for 6: 0.913
Num non-zero elements: 2
Test accuracy for 9: 0.914
Num non-zero elements: 5
Test accuracy for 0: 0.803
Num non-zero elements: 5
Test accuracy for 1: 0.85
Num non-zero elements: 5
Test accuracy for 2: 0.866
Num non-zero elements: 5
Test accuracy for 6: 0.945
Num non-zero elements: 5
Test accuracy for 9: 0.95
Num non-zero elements: 10
Test accuracy for 0: 0.828
Num non-zero elements: 10
Test accuracy for 1: 0.882
Num non-zero elements: 10
Test accuracy for 2: 0.878
Num non-zero elements: 10
Test accuracy for 6: 0.959
Num non-zero elements: 10
Test accuracy for 9: 0.955
Num non-zero elements: 20
Test accuracy for 0: 0.876
Num non-zero elements: 20
Test accuracy for 1: 0.918
Num non-zero elements: 20
Test accuracy for 2: 0.885
Num non-zero elements: 20
Test accuracy for 6: 0.972
Num non-zero elements: 20
Test accuracy for 9: 0.957
Num non-zero elements: 50
Test accuracy for 0: 0.915
Num non-zero elements: 50
Test accuracy for 1: 0.931
Num non-zero elements: 50
Test accuracy for 2: 0.923
Num non-zero elements: 50
Test accuracy for 6: 0.981
Num non-zero elements: 50
Test accuracy for 9: 0.97
Loading activations from artifacts/sparse_probing/google/gemma-2-2b/blocks.19.hook_resid_post/LabHC_bias_in_bios_class_set2_activations.pt
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 34 epochs
Test accuracy for 11: 0.9600000381469727
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 26 epochs
Test accuracy for 13: 0.9430000185966492
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 23 epochs
Test accuracy for 14: 0.9570000171661377
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 26 epochs
Test accuracy for 18: 0.9280000329017639
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 25 epochs
Test accuracy for 19: 0.9570000171661377
Num non-zero elements: 1
Test accuracy for 11: 0.772
Num non-zero elements: 1
Test accuracy for 13: 0.711
Num non-zero elements: 1
Test accuracy for 14: 0.793
Num non-zero elements: 1
Test accuracy for 18: 0.76
Num non-zero elements: 1
Test accuracy for 19: 0.815
Num non-zero elements: 2
Test accuracy for 11: 0.846
Num non-zero elements: 2
Test accuracy for 13: 0.691
Num non-zero elements: 2
Test accuracy for 14: 0.795
Num non-zero elements: 2
Test accuracy for 18: 0.776
Num non-zero elements: 2
Test accuracy for 19: 0.802
Num non-zero elements: 5
Test accuracy for 11: 0.848
Num non-zero elements: 5
Test accuracy for 13: 0.742
Num non-zero elements: 5
Test accuracy for 14: 0.853
Num non-zero elements: 5
Test accuracy for 18: 0.766
Num non-zero elements: 5
Test accuracy for 19: 0.871
Num non-zero elements: 10
Test accuracy for 11: 0.882
Num non-zero elements: 10
Test accuracy for 13: 0.764
Num non-zero elements: 10
Test accuracy for 14: 0.874
Num non-zero elements: 10
Test accuracy for 18: 0.788
Num non-zero elements: 10
Test accuracy for 19: 0.91
Num non-zero elements: 20
Test accuracy for 11: 0.895
Num non-zero elements: 20
Test accuracy for 13: 0.818
Num non-zero elements: 20
Test accuracy for 14: 0.908
Num non-zero elements: 20
Test accuracy for 18: 0.785
Num non-zero elements: 20
Test accuracy for 19: 0.917
Num non-zero elements: 50
Test accuracy for 11: 0.941
Num non-zero elements: 50
Test accuracy for 13: 0.911
Num non-zero elements: 50
Test accuracy for 14: 0.924
Num non-zero elements: 50
Test accuracy for 18: 0.847
Num non-zero elements: 50
Test accuracy for 19: 0.93
Loading activations from artifacts/sparse_probing/google/gemma-2-2b/blocks.19.hook_resid_post/LabHC_bias_in_bios_class_set3_activations.pt
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 21 epochs
Test accuracy for 20: 0.9570000171661377
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 22 epochs
Test accuracy for 21: 0.909000039100647
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 21 epochs
Test accuracy for 22: 0.9070000648498535
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 27 epochs
Test accuracy for 25: 0.9580000638961792
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 54 epochs
Test accuracy for 26: 0.8980000615119934
Num non-zero elements: 1
Test accuracy for 20: 0.773
Num non-zero elements: 1
Test accuracy for 21: 0.714
Num non-zero elements: 1
Test accuracy for 22: 0.653
Num non-zero elements: 1
Test accuracy for 25: 0.813
Num non-zero elements: 1
Test accuracy for 26: 0.716
Num non-zero elements: 2
Test accuracy for 20: 0.857
Num non-zero elements: 2
Test accuracy for 21: 0.736
Num non-zero elements: 2
Test accuracy for 22: 0.64
Num non-zero elements: 2
Test accuracy for 25: 0.86
Num non-zero elements: 2
Test accuracy for 26: 0.735
Num non-zero elements: 5
Test accuracy for 20: 0.875
Num non-zero elements: 5
Test accuracy for 21: 0.819
Num non-zero elements: 5
Test accuracy for 22: 0.767
Num non-zero elements: 5
Test accuracy for 25: 0.899
Num non-zero elements: 5
Test accuracy for 26: 0.796
Num non-zero elements: 10
Test accuracy for 20: 0.907
Num non-zero elements: 10
Test accuracy for 21: 0.856
Num non-zero elements: 10
Test accuracy for 22: 0.812
Num non-zero elements: 10
Test accuracy for 25: 0.91
Num non-zero elements: 10
Test accuracy for 26: 0.801
Num non-zero elements: 20
Test accuracy for 20: 0.928
Num non-zero elements: 20
Test accuracy for 21: 0.854
Num non-zero elements: 20
Test accuracy for 22: 0.856
Num non-zero elements: 20
Test accuracy for 25: 0.915
Num non-zero elements: 20
Test accuracy for 26: 0.841
Num non-zero elements: 50
Test accuracy for 20: 0.931
Num non-zero elements: 50
Test accuracy for 21: 0.878
Num non-zero elements: 50
Test accuracy for 22: 0.882
Num non-zero elements: 50
Test accuracy for 25: 0.939
Num non-zero elements: 50
Test accuracy for 26: 0.857
Loading activations from artifacts/sparse_probing/google/gemma-2-2b/blocks.19.hook_resid_post/canrager_amazon_reviews_mcauley_1and5_activations.pt
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 33 epochs
Test accuracy for 1: 0.9500000476837158
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 39 epochs
Test accuracy for 2: 0.937000036239624
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 34 epochs
Test accuracy for 3: 0.9110000729560852
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 33 epochs
Test accuracy for 5: 0.9270000457763672
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 25 epochs
Test accuracy for 6: 0.8580000400543213
Num non-zero elements: 1
Test accuracy for 1: 0.751
Num non-zero elements: 1
Test accuracy for 2: 0.632
Num non-zero elements: 1
Test accuracy for 3: 0.694
Num non-zero elements: 1
Test accuracy for 5: 0.65
Num non-zero elements: 1
Test accuracy for 6: 0.66
Num non-zero elements: 2
Test accuracy for 1: 0.782
Num non-zero elements: 2
Test accuracy for 2: 0.715
Num non-zero elements: 2
Test accuracy for 3: 0.734
Num non-zero elements: 2
Test accuracy for 5: 0.709
Num non-zero elements: 2
Test accuracy for 6: 0.673
Num non-zero elements: 5
Test accuracy for 1: 0.854
Num non-zero elements: 5
Test accuracy for 2: 0.816
Num non-zero elements: 5
Test accuracy for 3: 0.795
Num non-zero elements: 5
Test accuracy for 5: 0.744
Num non-zero elements: 5
Test accuracy for 6: 0.745
Num non-zero elements: 10
Test accuracy for 1: 0.886
Num non-zero elements: 10
Test accuracy for 2: 0.869
Num non-zero elements: 10
Test accuracy for 3: 0.817
Num non-zero elements: 10
Test accuracy for 5: 0.822
Num non-zero elements: 10
Test accuracy for 6: 0.786
Num non-zero elements: 20
Test accuracy for 1: 0.92
Num non-zero elements: 20
Test accuracy for 2: 0.87
Num non-zero elements: 20
Test accuracy for 3: 0.84
Num non-zero elements: 20
Test accuracy for 5: 0.834
Num non-zero elements: 20
Test accuracy for 6: 0.791
Num non-zero elements: 50
Test accuracy for 1: 0.926
Num non-zero elements: 50
Test accuracy for 2: 0.908
Num non-zero elements: 50
Test accuracy for 3: 0.888
Num non-zero elements: 50
Test accuracy for 5: 0.876
Num non-zero elements: 50
Test accuracy for 6: 0.817
Loading activations from artifacts/sparse_probing/google/gemma-2-2b/blocks.19.hook_resid_post/canrager_amazon_reviews_mcauley_1and5_sentiment_activations.pt
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 37 epochs
Test accuracy for 1.0: 0.971000075340271
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 31 epochs
Test accuracy for 5.0: 0.9720000624656677
Num non-zero elements: 1
Test accuracy for 1.0: 0.664
Num non-zero elements: 1
Test accuracy for 5.0: 0.664
Num non-zero elements: 2
Test accuracy for 1.0: 0.713
Num non-zero elements: 2
Test accuracy for 5.0: 0.713
Num non-zero elements: 5
Test accuracy for 1.0: 0.826
Num non-zero elements: 5
Test accuracy for 5.0: 0.826
Num non-zero elements: 10
Test accuracy for 1.0: 0.855
Num non-zero elements: 10
Test accuracy for 5.0: 0.855
Num non-zero elements: 20
Test accuracy for 1.0: 0.886
Num non-zero elements: 20
Test accuracy for 5.0: 0.886
Num non-zero elements: 50
Test accuracy for 1.0: 0.926
Num non-zero elements: 50
Test accuracy for 5.0: 0.925
Loading activations from artifacts/sparse_probing/google/gemma-2-2b/blocks.19.hook_resid_post/codeparrot_github-code_activations.pt
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 24 epochs
Test accuracy for C: 0.9380000233650208
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 37 epochs
Test accuracy for Python: 0.984000027179718
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 33 epochs
Test accuracy for HTML: 0.9780000448226929
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 37 epochs
Test accuracy for Java: 0.9450000524520874
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 26 epochs
Test accuracy for PHP: 0.9430000185966492
Num non-zero elements: 1
Test accuracy for C: 0.623
Num non-zero elements: 1
Test accuracy for Python: 0.589
Num non-zero elements: 1
Test accuracy for HTML: 0.588
Num non-zero elements: 1
Test accuracy for Java: 0.638
Num non-zero elements: 1
Test accuracy for PHP: 0.566
Num non-zero elements: 2
Test accuracy for C: 0.67
Num non-zero elements: 2
Test accuracy for Python: 0.591
Num non-zero elements: 2
Test accuracy for HTML: 0.59
Num non-zero elements: 2
Test accuracy for Java: 0.649
Num non-zero elements: 2
Test accuracy for PHP: 0.585
Num non-zero elements: 5
Test accuracy for C: 0.685
Num non-zero elements: 5
Test accuracy for Python: 0.821
Num non-zero elements: 5
Test accuracy for HTML: 0.879
Num non-zero elements: 5
Test accuracy for Java: 0.713
Num non-zero elements: 5
Test accuracy for PHP: 0.662
Num non-zero elements: 10
Test accuracy for C: 0.867
Num non-zero elements: 10
Test accuracy for Python: 0.911
Num non-zero elements: 10
Test accuracy for HTML: 0.912
Num non-zero elements: 10
Test accuracy for Java: 0.794
Num non-zero elements: 10
Test accuracy for PHP: 0.876
Num non-zero elements: 20
Test accuracy for C: 0.9
Num non-zero elements: 20
Test accuracy for Python: 0.954
Num non-zero elements: 20
Test accuracy for HTML: 0.958
Num non-zero elements: 20
Test accuracy for Java: 0.872
Num non-zero elements: 20
Test accuracy for PHP: 0.88
Num non-zero elements: 50
Test accuracy for C: 0.916
Num non-zero elements: 50
Test accuracy for Python: 0.951
Num non-zero elements: 50
Test accuracy for HTML: 0.977
Num non-zero elements: 50
Test accuracy for Java: 0.926
Num non-zero elements: 50
Test accuracy for PHP: 0.929
Loading activations from artifacts/sparse_probing/google/gemma-2-2b/blocks.19.hook_resid_post/fancyzhx_ag_news_activations.pt
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 46 epochs
Test accuracy for 0: 0.9460000395774841
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 22 epochs
Test accuracy for 1: 0.984000027179718
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 24 epochs
Test accuracy for 2: 0.9340000152587891
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 34 epochs
Test accuracy for 3: 0.9480000734329224
Num non-zero elements: 1
Test accuracy for 0: 0.801
Num non-zero elements: 1
Test accuracy for 1: 0.834
Num non-zero elements: 1
Test accuracy for 2: 0.763
Num non-zero elements: 1
Test accuracy for 3: 0.778
Num non-zero elements: 2
Test accuracy for 0: 0.831
Num non-zero elements: 2
Test accuracy for 1: 0.877
Num non-zero elements: 2
Test accuracy for 2: 0.772
Num non-zero elements: 2
Test accuracy for 3: 0.827
Num non-zero elements: 5
Test accuracy for 0: 0.871
Num non-zero elements: 5
Test accuracy for 1: 0.924
Num non-zero elements: 5
Test accuracy for 2: 0.793
Num non-zero elements: 5
Test accuracy for 3: 0.876
Num non-zero elements: 10
Test accuracy for 0: 0.882
Num non-zero elements: 10
Test accuracy for 1: 0.943
Num non-zero elements: 10
Test accuracy for 2: 0.844
Num non-zero elements: 10
Test accuracy for 3: 0.871
Num non-zero elements: 20
Test accuracy for 0: 0.896
Num non-zero elements: 20
Test accuracy for 1: 0.958
Num non-zero elements: 20
Test accuracy for 2: 0.874
Num non-zero elements: 20
Test accuracy for 3: 0.892
Num non-zero elements: 50
Test accuracy for 0: 0.91
Num non-zero elements: 50
Test accuracy for 1: 0.973
Num non-zero elements: 50
Test accuracy for 2: 0.902
Num non-zero elements: 50
Test accuracy for 3: 0.899
Loading activations from artifacts/sparse_probing/google/gemma-2-2b/blocks.19.hook_resid_post/Helsinki-NLP_europarl_activations.pt
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for en: 1.0
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 24 epochs
Test accuracy for fr: 1.0
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 13 epochs
Test accuracy for de: 1.0
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 15 epochs
Test accuracy for es: 1.0
Num non-zero elements: 2304
Training probe with dim: 2304, device: cuda:0, dtype: torch.bfloat16
GPU probe training early stopping triggered after 13 epochs
Test accuracy for nl: 1.0
Num non-zero elements: 1
Test accuracy for en: 0.912
Num non-zero elements: 1
Test accuracy for fr: 0.9
Num non-zero elements: 1
Test accuracy for de: 0.881
Num non-zero elements: 1
Test accuracy for es: 0.937
Num non-zero elements: 1
Test accuracy for nl: 0.999
Num non-zero elements: 2
Test accuracy for en: 0.953
Num non-zero elements: 2
Test accuracy for fr: 0.989
Num non-zero elements: 2
Test accuracy for de: 0.943
Num non-zero elements: 2
Test accuracy for es: 0.976
Num non-zero elements: 2
Test accuracy for nl: 0.997
Num non-zero elements: 5
Test accuracy for en: 0.979
Num non-zero elements: 5
Test accuracy for fr: 0.993
Num non-zero elements: 5
Test accuracy for de: 0.983
Num non-zero elements: 5
Test accuracy for es: 0.988
Num non-zero elements: 5
Test accuracy for nl: 0.998
Num non-zero elements: 10
Test accuracy for en: 0.982
Num non-zero elements: 10
Test accuracy for fr: 0.995
Num non-zero elements: 10
Test accuracy for de: 0.992
Num non-zero elements: 10
Test accuracy for es: 0.996
Num non-zero elements: 10
Test accuracy for nl: 0.998
Num non-zero elements: 20
Test accuracy for en: 0.994
Num non-zero elements: 20
Test accuracy for fr: 0.996
Num non-zero elements: 20
Test accuracy for de: 0.996
Num non-zero elements: 20
Test accuracy for es: 0.999
Num non-zero elements: 20
Test accuracy for nl: 1.0
Num non-zero elements: 50
Test accuracy for en: 0.997
Num non-zero elements: 50
Test accuracy for fr: 1.0
Num non-zero elements: 50
Test accuracy for de: 1.0
Num non-zero elements: 50
Test accuracy for es: 1.0
Num non-zero elements: 50
Test accuracy for nl: 1.0

Running unlearning evaluation...
Loaded pretrained model google/gemma-2-2b-it into HookedTransformer
Running evaluation for SAE: google/gemma-2-2b_layer_19_sae_custom_sae
Sparsity calculation for google/gemma-2-2b_layer_19_sae_custom_sae is already done
Forget sparsity: [0.897051 0.587162 0.549825 ... 0.808562 0.831653 0.302943]
(2304,)
Retain sparsity: [0.831511 0.576512 0.59187  ... 0.777173 0.855445 0.198642]
(2304,)
Starting metrics calculation...
running on datasets: ['wmdp-bio', 'high_school_us_history', 'college_computer_science', 'high_school_geography', 'human_aging']
Calculating metrics for retain threshold: 0.001
Top features for ablation: []
Calculating metrics list with parameters: {'intervention_method': 'clamp_feature_activation'} {'features_to_ablate': [array([], dtype=int64), array([], dtype=int64)], 'multiplier': [25, 50, 100, 200]}
All target question ids for gemma-2-2b-it on wmdp-bio already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on high_school_us_history already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on college_computer_science already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on high_school_geography already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on human_aging already exist. No need to generate target ids.
Calculating metrics for retain threshold: 0.01
Top features for ablation: [398]
Calculating metrics list with parameters: {'intervention_method': 'clamp_feature_activation'} {'features_to_ablate': [array([398]), array([398])], 'multiplier': [25, 50, 100, 200]}
All target question ids for gemma-2-2b-it on wmdp-bio already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on high_school_us_history already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on college_computer_science already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on high_school_geography already exist. No need to generate target ids.
All target question ids for gemma-2-2b-it on human_aging already exist. No need to generate target ids.
Unlearning scores DataFrame:    wmdp-bio  high_school_us_history  ...  multiplier  all_side_effects_mcq
0       1.0                     1.0  ...         100                   1.0
1       1.0                     1.0  ...          25                   1.0
2       1.0                     1.0  ...         100                   1.0
3       1.0                     1.0  ...         200                   1.0
4       1.0                     1.0  ...          50                   1.0
5       1.0                     1.0  ...          50                   1.0
6       1.0                     1.0  ...         200                   1.0
7       1.0                     1.0  ...          25                   1.0

[8 rows x 10 columns]
