\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{gaoScalingEvaluatingSparse}
\citation{chaninAbsorptionStudyingFeature2024}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\newlabel{sec:intro@cref}{{[section][1][]1}{[1][1][]1}{}{}{}}
\citation{marksSparseFeatureCircuits2024}
\citation{bussmannBatchTopKSparseAutoencoders2024}
\citation{rajamanoharanJumpingAheadImproving2024}
\citation{rajamanoharanImprovingDictionaryLearning2024}
\citation{chaninAbsorptionStudyingFeature2024}
\citation{gurneeFindingNeuronsHaystack2023}
\citation{pauloAutomaticallyInterpretingMillions2024}
\citation{karvonenEvaluatingSparseAutoencoders2024}
\citation{ghilardiEfficientTrainingSparse2024a}
\citation{mudideEfficientDictionaryLearning2024a}
\citation{marksSparseFeatureCircuits2024}
\citation{Gao2024ScalingAE}
\citation{chaninAbsorptionStudyingFeature2024}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\newlabel{sec:related}{{2}{2}{Related Work}{section.2}{}}
\newlabel{sec:related@cref}{{[section][2][]2}{[1][2][]2}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{Sparsity Mechanisms}{2}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Feature Quality Assessment}{2}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Training Efficiency}{2}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Background}{2}{section.3}\protected@file@percent }
\newlabel{sec:background}{{3}{2}{Background}{section.3}{}}
\newlabel{sec:background@cref}{{[section][3][]3}{[1][2][]2}{}{}{}}
\citation{bussmannBatchTopKSparseAutoencoders2024}
\citation{rajamanoharanJumpingAheadImproving2024}
\citation{rajamanoharanImprovingDictionaryLearning2024}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Problem Setting}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Method}{3}{section.4}\protected@file@percent }
\newlabel{sec:method}{{4}{3}{Method}{section.4}{}}
\newlabel{sec:method@cref}{{[section][4][]4}{[1][3][]3}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Temporal Regularization}{3}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Dynamic Feature Resampling}{4}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Feature-wise Gradient Scaling}{4}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Setup}{4}{section.5}\protected@file@percent }
\newlabel{sec:experimental}{{5}{4}{Experimental Setup}{section.5}{}}
\newlabel{sec:experimental@cref}{{[section][5][]5}{[1][4][]4}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Baseline comparison showing key metrics}}{5}{table.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:baselines}{{1}{5}{Baseline comparison showing key metrics}{table.caption.4}{}}
\newlabel{tab:baselines@cref}{{[table][1][]1}{[1][5][]5}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Training metrics showing loss progression across different implementations. Our method (green) achieves stable convergence while maintaining strong feature interpretability.}}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:training_metrics}{{1}{5}{Training metrics showing loss progression across different implementations. Our method (green) achieves stable convergence while maintaining strong feature interpretability}{figure.caption.5}{}}
\newlabel{fig:training_metrics@cref}{{[figure][1][]1}{[1][5][]5}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{5}{section.6}\protected@file@percent }
\newlabel{sec:results}{{6}{5}{Results}{section.6}{}}
\newlabel{sec:results@cref}{{[section][6][]6}{[1][5][]5}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Baseline Comparisons}{5}{subsection.6.1}\protected@file@percent }
\newlabel{fig:absorption}{{2a}{6}{Absorption scores across variants}{figure.caption.6}{}}
\newlabel{fig:absorption@cref}{{[subfigure][1][2]2a}{[1][5][]6}{}{}{}}
\newlabel{sub@fig:absorption}{{a}{6}{Absorption scores across variants}{figure.caption.6}{}}
\newlabel{sub@fig:absorption@cref}{{[subfigure][1][2]2a}{[1][5][]6}{}{}{}}
\newlabel{fig:reconstruction}{{2b}{6}{Reconstruction metrics}{figure.caption.6}{}}
\newlabel{fig:reconstruction@cref}{{[subfigure][2][2]2b}{[1][5][]6}{}{}{}}
\newlabel{sub@fig:reconstruction}{{b}{6}{Reconstruction metrics}{figure.caption.6}{}}
\newlabel{sub@fig:reconstruction@cref}{{[subfigure][2][2]2b}{[1][5][]6}{}{}{}}
\newlabel{fig:sparsity}{{2c}{6}{L0/L1 norm progression}{figure.caption.6}{}}
\newlabel{fig:sparsity@cref}{{[subfigure][3][2]2c}{[1][5][]6}{}{}{}}
\newlabel{sub@fig:sparsity}{{c}{6}{L0/L1 norm progression}{figure.caption.6}{}}
\newlabel{sub@fig:sparsity@cref}{{[subfigure][3][2]2c}{[1][5][]6}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Key metrics across training runs showing (a) improved feature interpretability, (b) reconstruction-sparsity trade-off, and (c) natural sparsification effect.}}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig:metrics}{{2}{6}{Key metrics across training runs showing (a) improved feature interpretability, (b) reconstruction-sparsity trade-off, and (c) natural sparsification effect}{figure.caption.6}{}}
\newlabel{fig:metrics@cref}{{[figure][2][]2}{[1][5][]6}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Training Progression}{6}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Limitations}{6}{subsection.6.3}\protected@file@percent }
\bibstyle{iclr2024_conference}
\bibdata{references}
\bibcite{bussmannBatchTopKSparseAutoencoders2024}{{1}{2024}{{Bussmann et~al.}}{{Bussmann, Leask, and Nanda}}}
\bibcite{chaninAbsorptionStudyingFeature2024}{{2}{2024}{{Chanin et~al.}}{{Chanin, {Wilken-Smith}, Dulka, Bhatnagar, and Bloom}}}
\bibcite{gaoScalingEvaluatingSparse}{{3}{}{{Gao et~al.}}{{Gao, Goh, and Sutskever}}}
\bibcite{Gao2024ScalingAE}{{4}{2024}{{Gao et~al.}}{{Gao, la~Tour, Tillman, Goh, Troll, Radford, Sutskever, Leike, and Wu}}}
\bibcite{ghilardiEfficientTrainingSparse2024a}{{5}{2024}{{Ghilardi et~al.}}{{Ghilardi, Belotti, and Molinari}}}
\bibcite{gurneeFindingNeuronsHaystack2023}{{6}{2023}{{Gurnee et~al.}}{{Gurnee, Nanda, Pauly, Harvey, Troitskii, and Bertsimas}}}
\bibcite{karvonenEvaluatingSparseAutoencoders2024}{{7}{2024}{{Karvonen et~al.}}{{Karvonen, Rager, Marks, and Nanda}}}
\bibcite{marksSparseFeatureCircuits2024}{{8}{2024}{{Marks et~al.}}{{Marks, Rager, Michaud, Belinkov, Bau, and Mueller}}}
\bibcite{mudideEfficientDictionaryLearning2024a}{{9}{2024}{{Mudide et~al.}}{{Mudide, Engels, Michaud, Tegmark, and de~Witt}}}
\bibcite{pauloAutomaticallyInterpretingMillions2024}{{10}{2024}{{Paulo et~al.}}{{Paulo, Mallen, Juang, and Belrose}}}
\bibcite{rajamanoharanImprovingDictionaryLearning2024}{{11}{2024{a}}{{Rajamanoharan et~al.}}{{Rajamanoharan, Conmy, Smith, Lieberum, Varma, Kram{\'a}r, Shah, and Nanda}}}
\bibcite{rajamanoharanJumpingAheadImproving2024}{{12}{2024{b}}{{Rajamanoharan et~al.}}{{Rajamanoharan, Lieberum, Sonnerat, Conmy, Varma, Kram{\'a}r, and Nanda}}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions and Future Work}{7}{section.7}\protected@file@percent }
\newlabel{sec:conclusion}{{7}{7}{Conclusions and Future Work}{section.7}{}}
\newlabel{sec:conclusion@cref}{{[section][7][]7}{[1][6][]7}{}{}{}}
\ttl@finishall
\gdef \@abspage@last{7}
