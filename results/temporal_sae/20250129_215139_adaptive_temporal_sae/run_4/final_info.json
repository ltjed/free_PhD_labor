{
  "training results for layer 12": {
    "config": {
      "trainer_class": "JumpReLUTrainer",
      "activation_dim": 2304,
      "dict_size": 65536,
      "lr": 0.0003,
      "sparsity_penalty": 1.0,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "JumpReLUTrainer",
      "jump_coeff": 0.1,
      "target_l0": 20.0,
      "bandwidth": 0.001
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 23252.220703125,
      "layer": 12,
      "dict_size": 65536,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "733259b8-fcc0-4b17-a620-faee6faed126",
    "datetime_epoch_millis": 1738243382848,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.0,
        "mean_num_split_features": 1.0
      }
    },
    "eval_result_details": [
      {
        "first_letter": "d",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1648,
        "num_split_features": 1
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 718,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1137,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1869,
        "num_split_features": 1
      },
      {
        "first_letter": "q",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 178,
        "num_split_features": 1
      },
      {
        "first_letter": "x",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 81,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 149,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 222,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "1c64f65e68c0e3cdaf116a205182859fd51f77f7",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 65536,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "JumpReLU",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "jumprelu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null,
      "jump_coeff": 0.1
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9796195652173914,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.205078125
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9802631578947368,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 3.125,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.77734375,
        "mse": 1.40625,
        "cossim": 0.93359375
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 145.0,
        "l2_ratio": 0.96875,
        "relative_reconstruction_bias": 1.0390625
      },
      "sparsity": {
        "l0": 3187.38330078125,
        "l1": 2224.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  }
}