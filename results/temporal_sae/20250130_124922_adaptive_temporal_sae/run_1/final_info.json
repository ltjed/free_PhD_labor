{
  "training results for layer 12": {
    "config": {
      "trainer_class": "CustomTrainer",
      "activation_dim": 2304,
      "dict_size": 16384,
      "lr": 0.0005,
      "l1_penalty": 0.04,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "TemporalTrainer",
      "submodule_name": "resid_post_layer_12"
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 21046.71484375,
      "layer": 12,
      "dict_size": 16384,
      "learning_rate": 0.0005,
      "sparsity_penalty": 0.04
    }
  }
}