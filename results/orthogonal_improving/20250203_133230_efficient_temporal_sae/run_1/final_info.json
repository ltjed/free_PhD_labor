{
  "training results for layer 12": {
    "config": {
      "trainer_class": "TrainerTopK",
      "dict_class": "AutoEncoderTopK",
      "lr": 0.0003771236166328254,
      "steps": 2441,
      "seed": 42,
      "activation_dim": 2304,
      "dict_size": 4608,
      "k": 160,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "AutoEncoderTopK",
      "submodule_name": "resid_post_layer_12",
      "ortho_weight": 0.1
    },
    "final_info": {
      "training_steps": 2441,
      "final_loss": 7211.3935546875,
      "layer": 12,
      "dict_size": 4608,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  }
}