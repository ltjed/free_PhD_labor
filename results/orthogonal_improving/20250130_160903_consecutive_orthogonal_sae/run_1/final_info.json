{
  "training results for layer 12": {
    "config": {
      "trainer_class": "TrainerTopK",
      "dict_class": "AutoEncoderTopK",
      "lr": 0.0001885618083164127,
      "steps": 4882,
      "seed": 42,
      "activation_dim": 2304,
      "dict_size": 18432,
      "k": 160,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "AutoEncoderTopK",
      "submodule_name": "resid_post_layer_12",
      "ortho_weight": 0.1
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 3040.262939453125,
      "layer": 12,
      "dict_size": 18432,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "0bce6594-a77f-4e5e-b504-0283a0f16f0e",
    "datetime_epoch_millis": 1738274615908,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.01945244009279292,
        "mean_num_split_features": 1.2173913043478262
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.000779423226812159,
        "num_absorption": 2,
        "num_probe_true_positives": 2566,
        "num_split_features": 1
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.003848620910840282,
        "num_absorption": 6,
        "num_probe_true_positives": 1559,
        "num_split_features": 1
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.0017642907551164433,
        "num_absorption": 5,
        "num_probe_true_positives": 2834,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.006067961165048544,
        "num_absorption": 10,
        "num_probe_true_positives": 1648,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.004377736085053158,
        "num_absorption": 7,
        "num_probe_true_positives": 1599,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.0018264840182648401,
        "num_absorption": 2,
        "num_probe_true_positives": 1095,
        "num_split_features": 2
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.005065856129685917,
        "num_absorption": 5,
        "num_probe_true_positives": 987,
        "num_split_features": 2
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.0011976047904191617,
        "num_absorption": 2,
        "num_probe_true_positives": 1670,
        "num_split_features": 1
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.002188183807439825,
        "num_absorption": 1,
        "num_probe_true_positives": 457,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.18117854001759015,
        "num_absorption": 206,
        "num_probe_true_positives": 1137,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.005350454788657036,
        "num_absorption": 10,
        "num_probe_true_positives": 1869,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.001128668171557562,
        "num_absorption": 1,
        "num_probe_true_positives": 886,
        "num_split_features": 2
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.10516066212268745,
        "num_absorption": 108,
        "num_probe_true_positives": 1027,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.04692982456140351,
        "num_absorption": 107,
        "num_probe_true_positives": 2280,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.05017921146953405,
        "num_absorption": 84,
        "num_probe_true_positives": 1674,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 2926,
        "num_split_features": 1
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.003003003003003003,
        "num_absorption": 5,
        "num_probe_true_positives": 1665,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.002751031636863824,
        "num_absorption": 2,
        "num_probe_true_positives": 727,
        "num_split_features": 3
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.0036231884057971015,
        "num_absorption": 3,
        "num_probe_true_positives": 828,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.002967359050445104,
        "num_absorption": 2,
        "num_probe_true_positives": 674,
        "num_split_features": 1
      },
      {
        "first_letter": "x",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 81,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 149,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.018018018018018018,
        "num_absorption": 4,
        "num_probe_true_positives": 222,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "1c64f65e68c0e3cdaf116a205182859fd51f77f7",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9865100931677019,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.1357421875
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9868421052631579,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 3.0625,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.7265625,
        "mse": 1.71875,
        "cossim": 0.91796875
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 137.0,
        "l2_ratio": 0.9140625,
        "relative_reconstruction_bias": 1.0
      },
      "sparsity": {
        "l0": 160.0,
        "l1": 676.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr and tpp evaluations results": {
    "eval_type_id": "tpp",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": false,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "5548ef8c-4a98-41a7-95a3-b785a93c9ea0",
    "datetime_epoch_millis": 1738275939433,
    "eval_result_metrics": {
      "tpp_metrics": {
        "tpp_threshold_2_total_metric": 0.005199994146823882,
        "tpp_threshold_2_intended_diff_only": 0.008399993181228638,
        "tpp_threshold_2_unintended_diff_only": 0.0031999990344047545,
        "tpp_threshold_5_total_metric": 0.008624987304210664,
        "tpp_threshold_5_intended_diff_only": 0.0122999906539917,
        "tpp_threshold_5_unintended_diff_only": 0.0036750033497810366,
        "tpp_threshold_10_total_metric": 0.013825009763240814,
        "tpp_threshold_10_intended_diff_only": 0.01960000991821289,
        "tpp_threshold_10_unintended_diff_only": 0.005775000154972077,
        "tpp_threshold_20_total_metric": 0.029000005125999453,
        "tpp_threshold_20_intended_diff_only": 0.03680000901222229,
        "tpp_threshold_20_unintended_diff_only": 0.00780000388622284,
        "tpp_threshold_50_total_metric": 0.07290000915527345,
        "tpp_threshold_50_intended_diff_only": 0.08100001215934755,
        "tpp_threshold_50_unintended_diff_only": 0.008100003004074097,
        "tpp_threshold_100_total_metric": 0.14152500331401824,
        "tpp_threshold_100_intended_diff_only": 0.15110000371932983,
        "tpp_threshold_100_unintended_diff_only": 0.009575000405311585,
        "tpp_threshold_500_total_metric": 0.39182502478361125,
        "tpp_threshold_500_intended_diff_only": 0.407200026512146,
        "tpp_threshold_500_unintended_diff_only": 0.015375001728534699
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_tpp_results",
        "tpp_threshold_2_total_metric": 0.0062499970197677605,
        "tpp_threshold_2_intended_diff_only": 0.009200000762939453,
        "tpp_threshold_2_unintended_diff_only": 0.002950003743171692,
        "tpp_threshold_5_total_metric": 0.008599990606307985,
        "tpp_threshold_5_intended_diff_only": 0.011399996280670167,
        "tpp_threshold_5_unintended_diff_only": 0.002800005674362183,
        "tpp_threshold_10_total_metric": 0.01555001735687256,
        "tpp_threshold_10_intended_diff_only": 0.019000017642974855,
        "tpp_threshold_10_unintended_diff_only": 0.003450000286102295,
        "tpp_threshold_20_total_metric": 0.02935000061988831,
        "tpp_threshold_20_intended_diff_only": 0.034400010108947755,
        "tpp_threshold_20_unintended_diff_only": 0.005050009489059449,
        "tpp_threshold_50_total_metric": 0.07825000584125519,
        "tpp_threshold_50_intended_diff_only": 0.08320001363754273,
        "tpp_threshold_50_unintended_diff_only": 0.004950007796287537,
        "tpp_threshold_100_total_metric": 0.15315000712871552,
        "tpp_threshold_100_intended_diff_only": 0.1582000136375427,
        "tpp_threshold_100_unintended_diff_only": 0.00505000650882721,
        "tpp_threshold_500_total_metric": 0.4311000257730484,
        "tpp_threshold_500_intended_diff_only": 0.4392000317573547,
        "tpp_threshold_500_unintended_diff_only": 0.008100005984306335
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_tpp_results",
        "tpp_threshold_2_total_metric": 0.004149991273880005,
        "tpp_threshold_2_intended_diff_only": 0.007599985599517823,
        "tpp_threshold_2_unintended_diff_only": 0.0034499943256378176,
        "tpp_threshold_5_total_metric": 0.008649984002113342,
        "tpp_threshold_5_intended_diff_only": 0.013199985027313232,
        "tpp_threshold_5_unintended_diff_only": 0.0045500010251998905,
        "tpp_threshold_10_total_metric": 0.012100002169609068,
        "tpp_threshold_10_intended_diff_only": 0.020200002193450927,
        "tpp_threshold_10_unintended_diff_only": 0.008100000023841859,
        "tpp_threshold_20_total_metric": 0.028650009632110597,
        "tpp_threshold_20_intended_diff_only": 0.039200007915496826,
        "tpp_threshold_20_unintended_diff_only": 0.01054999828338623,
        "tpp_threshold_50_total_metric": 0.0675500124692917,
        "tpp_threshold_50_intended_diff_only": 0.07880001068115235,
        "tpp_threshold_50_unintended_diff_only": 0.011249998211860656,
        "tpp_threshold_100_total_metric": 0.129899999499321,
        "tpp_threshold_100_intended_diff_only": 0.14399999380111694,
        "tpp_threshold_100_unintended_diff_only": 0.014099994301795959,
        "tpp_threshold_500_total_metric": 0.35255002379417416,
        "tpp_threshold_500_intended_diff_only": 0.37520002126693724,
        "tpp_threshold_500_unintended_diff_only": 0.022649997472763063
      }
    ],
    "sae_bench_commit_hash": "1c64f65e68c0e3cdaf116a205182859fd51f77f7",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "9b015834-387e-4946-831f-76db89309da1",
    "datetime_epoch_millis": 1738276895132,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.9516249999999999,
        "llm_top_1_test_accuracy": 0.6635937500000001,
        "llm_top_2_test_accuracy": 0.72314375,
        "llm_top_5_test_accuracy": 0.7813375,
        "llm_top_10_test_accuracy": 0.8313875,
        "llm_top_20_test_accuracy": 0.8785624999999999,
        "llm_top_50_test_accuracy": 0.922275,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.957875046133995,
        "sae_top_1_test_accuracy": 0.8063374999999999,
        "sae_top_2_test_accuracy": 0.85916875,
        "sae_top_5_test_accuracy": 0.8937,
        "sae_top_10_test_accuracy": 0.91380625,
        "sae_top_20_test_accuracy": 0.92750625,
        "sae_top_50_test_accuracy": 0.9439124999999999,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9634000420570373,
        "sae_top_1_test_accuracy": 0.8268000000000001,
        "sae_top_2_test_accuracy": 0.8697999999999999,
        "sae_top_5_test_accuracy": 0.9102,
        "sae_top_10_test_accuracy": 0.9311999999999999,
        "sae_top_20_test_accuracy": 0.9461999999999999,
        "sae_top_50_test_accuracy": 0.9586,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9498000000000001,
        "llm_top_1_test_accuracy": 0.6738000000000001,
        "llm_top_2_test_accuracy": 0.7138,
        "llm_top_5_test_accuracy": 0.7634000000000001,
        "llm_top_10_test_accuracy": 0.8099999999999999,
        "llm_top_20_test_accuracy": 0.8714000000000001,
        "llm_top_50_test_accuracy": 0.9036000000000002,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9522000432014466,
        "sae_top_1_test_accuracy": 0.7964,
        "sae_top_2_test_accuracy": 0.8480000000000001,
        "sae_top_5_test_accuracy": 0.8800000000000001,
        "sae_top_10_test_accuracy": 0.9076000000000001,
        "sae_top_20_test_accuracy": 0.9262,
        "sae_top_50_test_accuracy": 0.943,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9161999999999999,
        "llm_top_1_test_accuracy": 0.6898000000000001,
        "llm_top_2_test_accuracy": 0.7434000000000001,
        "llm_top_5_test_accuracy": 0.7676000000000001,
        "llm_top_10_test_accuracy": 0.8006,
        "llm_top_20_test_accuracy": 0.8540000000000001,
        "llm_top_50_test_accuracy": 0.8924,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.929200041294098,
        "sae_top_1_test_accuracy": 0.8173999999999999,
        "sae_top_2_test_accuracy": 0.85,
        "sae_top_5_test_accuracy": 0.8836,
        "sae_top_10_test_accuracy": 0.8874000000000001,
        "sae_top_20_test_accuracy": 0.8931999999999999,
        "sae_top_50_test_accuracy": 0.9122,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.8981999999999999,
        "llm_top_1_test_accuracy": 0.609,
        "llm_top_2_test_accuracy": 0.6536,
        "llm_top_5_test_accuracy": 0.6674,
        "llm_top_10_test_accuracy": 0.7536,
        "llm_top_20_test_accuracy": 0.8066000000000001,
        "llm_top_50_test_accuracy": 0.8606,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9184000492095947,
        "sae_top_1_test_accuracy": 0.7754,
        "sae_top_2_test_accuracy": 0.7928000000000001,
        "sae_top_5_test_accuracy": 0.8244,
        "sae_top_10_test_accuracy": 0.8462,
        "sae_top_20_test_accuracy": 0.8640000000000001,
        "sae_top_50_test_accuracy": 0.8897999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.981,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.847,
        "llm_top_50_test_accuracy": 0.9325000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9780000448226929,
        "sae_top_1_test_accuracy": 0.889,
        "sae_top_2_test_accuracy": 0.918,
        "sae_top_5_test_accuracy": 0.931,
        "sae_top_10_test_accuracy": 0.949,
        "sae_top_20_test_accuracy": 0.961,
        "sae_top_50_test_accuracy": 0.971,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9648,
        "llm_top_1_test_accuracy": 0.6641999999999999,
        "llm_top_2_test_accuracy": 0.6978000000000001,
        "llm_top_5_test_accuracy": 0.7644,
        "llm_top_10_test_accuracy": 0.8016,
        "llm_top_20_test_accuracy": 0.8652000000000001,
        "llm_top_50_test_accuracy": 0.9308,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9678000569343567,
        "sae_top_1_test_accuracy": 0.6586000000000001,
        "sae_top_2_test_accuracy": 0.8202,
        "sae_top_5_test_accuracy": 0.8506,
        "sae_top_10_test_accuracy": 0.8809999999999999,
        "sae_top_20_test_accuracy": 0.9102,
        "sae_top_50_test_accuracy": 0.9474,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.944,
        "llm_top_1_test_accuracy": 0.63675,
        "llm_top_2_test_accuracy": 0.77375,
        "llm_top_5_test_accuracy": 0.8225,
        "llm_top_10_test_accuracy": 0.8635,
        "llm_top_20_test_accuracy": 0.8964999999999999,
        "llm_top_50_test_accuracy": 0.9225000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9550000429153442,
        "sae_top_1_test_accuracy": 0.7875,
        "sae_top_2_test_accuracy": 0.83375,
        "sae_top_5_test_accuracy": 0.881,
        "sae_top_10_test_accuracy": 0.91225,
        "sae_top_20_test_accuracy": 0.92125,
        "sae_top_50_test_accuracy": 0.9315,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9994,
        "llm_top_1_test_accuracy": 0.721,
        "llm_top_2_test_accuracy": 0.7872,
        "llm_top_5_test_accuracy": 0.9082000000000001,
        "llm_top_10_test_accuracy": 0.9621999999999999,
        "llm_top_20_test_accuracy": 0.9916,
        "llm_top_50_test_accuracy": 0.9974000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9990000486373901,
        "sae_top_1_test_accuracy": 0.8996000000000001,
        "sae_top_2_test_accuracy": 0.9408,
        "sae_top_5_test_accuracy": 0.9888,
        "sae_top_10_test_accuracy": 0.9958,
        "sae_top_20_test_accuracy": 0.998,
        "sae_top_50_test_accuracy": 0.9978,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "1c64f65e68c0e3cdaf116a205182859fd51f77f7",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "unlearning evaluation results": {
    "eval_type_id": "unlearning",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "wmdp-bio",
        "high_school_us_history",
        "college_computer_science",
        "high_school_geography",
        "human_aging"
      ],
      "intervention_method": "clamp_feature_activation",
      "retain_thresholds": [
        0.001,
        0.005,
        0.01,
        0.02
      ],
      "n_features_list": [
        10,
        100,
        1000
      ],
      "multipliers": [
        10,
        25,
        50,
        100,
        200
      ],
      "dataset_size": 1024,
      "seq_len": 1024,
      "n_batch_loss_added": 50,
      "target_metric": "correct",
      "save_metrics": true,
      "model_name": "google/gemma-2-2b-it",
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16"
    },
    "eval_id": "4f20764a-cfef-404d-b6f4-9873e45cda62",
    "datetime_epoch_millis": 1738278196884,
    "eval_result_metrics": {
      "unlearning": {
        "unlearning_score": 0.0411984920501709
      }
    },
    "eval_result_details": [],
    "sae_bench_commit_hash": "1c64f65e68c0e3cdaf116a205182859fd51f77f7",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}