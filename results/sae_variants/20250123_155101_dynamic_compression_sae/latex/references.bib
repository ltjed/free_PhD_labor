%% LaTeX2e file `references.bib'
%% generated by the `filecontents' environment
%% from source `template' on 2025/01/23.
%%

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  year={2016},
  publisher={MIT Press}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{karpathy2023nanogpt,
  title = {nanoGPT},
  author = {Karpathy, Andrej},
  year = {2023},
  journal = {URL https://github.com/karpathy/nanoGPT/tree/master},
  note = {GitHub repository}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{loshchilov2017adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@misc{gpt4,
  title={GPT-4 Technical Report},
  author={OpenAI},
  year={2024},
  eprint={2303.08774},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2303.08774},
}

@Article{Han2015DeepCC,
 author = {Song Han and Huizi Mao and W. Dally},
 booktitle = {International Conference on Learning Representations},
 journal = {arXiv: Computer Vision and Pattern Recognition},
 title = {Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding},
 year = {2015}
}


@Article{Cheng2017ASO,
 author = {Yu Cheng and Duo Wang and Pan Zhou and Zhang Tao},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {A Survey of Model Compression and Acceleration for Deep Neural Networks},
 volume = {abs/1710.09282},
 year = {2017}
}


@Article{Michel2019AreSH,
 author = {Paul Michel and Omer Levy and Graham Neubig},
 booktitle = {Neural Information Processing Systems},
 journal = {ArXiv},
 title = {Are Sixteen Heads Really Better than One?},
 volume = {abs/1905.10650},
 year = {2019}
}


@Article{Han2015LearningBW,
 author = {Song Han and Jeff Pool and J. Tran and W. Dally},
 booktitle = {Neural Information Processing Systems},
 pages = {1135-1143},
 title = {Learning both Weights and Connections for Efficient Neural Network},
 year = {2015}
}


@Article{Sarti2023InseqAI,
 author = {Gabriele Sarti and Nils Feldhus and Ludwig Sickert and Oskar van der Wal and M. Nissim and Arianna Bisazza},
 booktitle = {Annual Meeting of the Association for Computational Linguistics},
 journal = {ArXiv},
 title = {Inseq: An Interpretability Toolkit for Sequence Generation Models},
 volume = {abs/2302.13942},
 year = {2023}
}


@Article{Voita2019AnalyzingMS,
 author = {Elena Voita and David Talbot and F. Moiseev and Rico Sennrich and Ivan Titov},
 booktitle = {Annual Meeting of the Association for Computational Linguistics},
 journal = {ArXiv},
 title = {Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned},
 volume = {abs/1905.09418},
 year = {2019}
}


@Article{Tang2021ManifoldRD,
 author = {Yehui Tang and Yunhe Wang and Yixing Xu and Yiping Deng and Chao Xu and D. Tao and Chang Xu},
 booktitle = {Computer Vision and Pattern Recognition},
 journal = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
 pages = {5016-5026},
 title = {Manifold Regularized Dynamic Network Pruning},
 year = {2021}
}


@Article{Kundu2020DNRAT,
 author = {Souvik Kundu and M. Nazemi and P. Beerel and M. Pedram},
 booktitle = {Asia and South Pacific Design Automation Conference},
 journal = {2021 26th Asia and South Pacific Design Automation Conference (ASP-DAC)},
 pages = {344-350},
 title = {DNR: A Tunable Robust Pruning Framework Through Dynamic Network Rewiring of DNNs},
 year = {2020}
}


@Article{Kundu2020DNRAT,
 author = {Souvik Kundu and M. Nazemi and P. Beerel and M. Pedram},
 booktitle = {Asia and South Pacific Design Automation Conference},
 journal = {2021 26th Asia and South Pacific Design Automation Conference (ASP-DAC)},
 pages = {344-350},
 title = {DNR: A Tunable Robust Pruning Framework Through Dynamic Network Rewiring of DNNs},
 year = {2020}
}


@Conference{Sara2024ExploringDN,
 author = {Ghorab Sara and Meziani Lila and Rubin Harvey Stuart},
 booktitle = {2024 IEEE International Conference on Artificial Intelligence & Green Energy (ICAIGE)},
 journal = {2024 IEEE International Conference on Artificial Intelligence & Green Energy (ICAIGE)},
 pages = {1-6},
 title = {Exploring Deep Neural Network Compression: An Overview},
 year = {2024}
}


@Article{Guo2016DynamicNS,
 author = {Yiwen Guo and Anbang Yao and Yurong Chen},
 booktitle = {Neural Information Processing Systems},
 journal = {ArXiv},
 title = {Dynamic Network Surgery for Efficient DNNs},
 volume = {abs/1608.04493},
 year = {2016}
}


@Article{Li2020EfficientTL,
 author = {Bingbing Li and Zhenglun Kong and Tianyun Zhang and Ji Li and Z. Li and Hang Liu and Caiwen Ding},
 booktitle = {Findings},
 pages = {3187-3199},
 title = {Efficient Transformer-based Large Scale Language Representations using Hardware-friendly Block Structured Pruning},
 year = {2020}
}


@Article{Kim2022UnderstandingAI,
 author = {Minsoo Kim and Sihwa Lee and S. Hong and Duhyeuk Chang and Jungwook Choi},
 booktitle = {Conference on Empirical Methods in Natural Language Processing},
 journal = {ArXiv},
 title = {Understanding and Improving Knowledge Distillation for Quantization Aware Training of Large Transformer Encoders},
 volume = {abs/2211.11014},
 year = {2022}
}


@Article{Tang2021ManifoldRD,
 author = {Yehui Tang and Yunhe Wang and Yixing Xu and Yiping Deng and Chao Xu and D. Tao and Chang Xu},
 booktitle = {Computer Vision and Pattern Recognition},
 journal = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
 pages = {5016-5026},
 title = {Manifold Regularized Dynamic Network Pruning},
 year = {2021}
}


@Article{Glorot2010UnderstandingTD,
 author = {Xavier Glorot and Yoshua Bengio},
 booktitle = {International Conference on Artificial Intelligence and Statistics},
 pages = {249-256},
 title = {Understanding the difficulty of training deep feedforward neural networks},
 year = {2010}
}

