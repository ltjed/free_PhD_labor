{
  "training results for layer 5": {
    "training_log": {
      "step 0": {
        "loss": 281.0832214355469,
        "l1_loss": 2692.192626953125,
        "l2_loss": 172.6608123779297,
        "ortho_loss": 0.7347031235694885
      },
      "step 1": {
        "loss": 244.28550720214844,
        "l1_loss": 2632.935546875,
        "l2_loss": 138.26095581054688,
        "ortho_loss": 0.7071313858032227
      },
      "step 1220": {
        "loss": 71.98165130615234,
        "l1_loss": 171.28594970703125,
        "l2_loss": 64.48411560058594,
        "ortho_loss": 0.6460960507392883
      },
      "step 1221": {
        "loss": 72.44574737548828,
        "l1_loss": 186.46646118164062,
        "l2_loss": 64.36802673339844,
        "ortho_loss": 0.6190658211708069
      },
      "step 2440": {
        "loss": 64.06995391845703,
        "l1_loss": 193.50628662109375,
        "l2_loss": 55.94626998901367,
        "ortho_loss": 0.3834380805492401
      },
      "step 2441": {
        "loss": 63.88504409790039,
        "l1_loss": 196.73716735839844,
        "l2_loss": 55.626800537109375,
        "ortho_loss": 0.38875409960746765
      },
      "step 3660": {
        "loss": 60.8104248046875,
        "l1_loss": 217.46820068359375,
        "l2_loss": 51.757598876953125,
        "ortho_loss": 0.3541005253791809
      },
      "step 3661": {
        "loss": 61.386932373046875,
        "l1_loss": 217.97994995117188,
        "l2_loss": 52.30230712890625,
        "ortho_loss": 0.365425705909729
      }
    },
    "config": {
      "trainer_class": "OrthogonalTrainer",
      "activation_dim": 2304,
      "dict_size": 2304,
      "lr": 0.0003,
      "l1_penalty": 0.04,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 5,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "CustomTrainer",
      "submodule_name": "resid_post_layer_5"
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 58.507728576660156,
      "layer": 5,
      "dict_size": 2304,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "training results for layer 12": {
    "training_log": {
      "step 0": {
        "loss": 462.7072448730469,
        "l1_loss": 4426.9755859375,
        "l2_loss": 284.86981201171875,
        "ortho_loss": 0.758405327796936
      },
      "step 1": {
        "loss": 399.5447082519531,
        "l1_loss": 4297.7392578125,
        "l2_loss": 226.8920135498047,
        "ortho_loss": 0.7431344389915466
      },
      "step 1220": {
        "loss": 111.78135681152344,
        "l1_loss": 368.9634704589844,
        "l2_loss": 96.2739028930664,
        "ortho_loss": 0.7489156723022461
      },
      "step 1221": {
        "loss": 112.24093627929688,
        "l1_loss": 397.04095458984375,
        "l2_loss": 95.63704681396484,
        "ortho_loss": 0.7222533822059631
      },
      "step 2440": {
        "loss": 100.15731048583984,
        "l1_loss": 345.0479736328125,
        "l2_loss": 85.90701293945312,
        "ortho_loss": 0.4483819603919983
      },
      "step 2441": {
        "loss": 100.08280181884766,
        "l1_loss": 356.5145263671875,
        "l2_loss": 85.37808227539062,
        "ortho_loss": 0.44413891434669495
      },
      "step 3660": {
        "loss": 94.93890380859375,
        "l1_loss": 366.29534912109375,
        "l2_loss": 79.87738800048828,
        "ortho_loss": 0.4096972346305847
      },
      "step 3661": {
        "loss": 95.49044799804688,
        "l1_loss": 363.8693542480469,
        "l2_loss": 80.52461242675781,
        "ortho_loss": 0.41106414794921875
      }
    },
    "config": {
      "trainer_class": "OrthogonalTrainer",
      "activation_dim": 2304,
      "dict_size": 2304,
      "lr": 0.0003,
      "l1_penalty": 0.04,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "CustomTrainer",
      "submodule_name": "resid_post_layer_12"
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 91.98622131347656,
      "layer": 12,
      "dict_size": 2304,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "training results for layer 19": {
    "training_log": {
      "step 0": {
        "loss": 913.9003295898438,
        "l1_loss": 8814.16796875,
        "l2_loss": 560.615478515625,
        "ortho_loss": 0.7181362509727478
      },
      "step 1": {
        "loss": 793.6588745117188,
        "l1_loss": 8603.88671875,
        "l2_loss": 448.81964111328125,
        "ortho_loss": 0.6837527751922607
      },
      "step 1220": {
        "loss": 233.38821411132812,
        "l1_loss": 571.277587890625,
        "l2_loss": 209.66270446777344,
        "ortho_loss": 0.8743982315063477
      },
      "step 1221": {
        "loss": 234.62136840820312,
        "l1_loss": 632.4179077148438,
        "l2_loss": 208.45565795898438,
        "ortho_loss": 0.8689826130867004
      },
      "step 2440": {
        "loss": 207.41590881347656,
        "l1_loss": 567.318115234375,
        "l2_loss": 184.1509552001953,
        "ortho_loss": 0.5722382068634033
      },
      "step 2441": {
        "loss": 207.39634704589844,
        "l1_loss": 574.4530029296875,
        "l2_loss": 183.8543243408203,
        "ortho_loss": 0.5639083981513977
      },
      "step 3660": {
        "loss": 192.1455078125,
        "l1_loss": 662.4048461914062,
        "l2_loss": 165.20932006835938,
        "ortho_loss": 0.4400050938129425
      },
      "step 3661": {
        "loss": 191.97767639160156,
        "l1_loss": 661.7435302734375,
        "l2_loss": 165.0642852783203,
        "ortho_loss": 0.4436541199684143
      }
    },
    "config": {
      "trainer_class": "OrthogonalTrainer",
      "activation_dim": 2304,
      "dict_size": 2304,
      "lr": 0.0003,
      "l1_penalty": 0.04,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 19,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "CustomTrainer",
      "submodule_name": "resid_post_layer_19"
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 184.4046630859375,
      "layer": 19,
      "dict_size": 2304,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "c5d42d8f-c789-414a-b214-c0653a48476d",
    "datetime_epoch_millis": 1737914134851,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.006710192260088017,
        "mean_num_split_features": 1.4230769230769231
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.0007671653241273494,
        "num_absorption": 2,
        "num_probe_true_positives": 2607,
        "num_split_features": 3
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.01322418136020151,
        "num_absorption": 21,
        "num_probe_true_positives": 1588,
        "num_split_features": 2
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 2851,
        "num_split_features": 3
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.012582384661473937,
        "num_absorption": 21,
        "num_probe_true_positives": 1669,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.0018656716417910447,
        "num_absorption": 3,
        "num_probe_true_positives": 1608,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1255,
        "num_split_features": 2
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.004642525533890436,
        "num_absorption": 5,
        "num_probe_true_positives": 1077,
        "num_split_features": 1
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.006349206349206349,
        "num_absorption": 6,
        "num_probe_true_positives": 945,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.000612369871402327,
        "num_absorption": 1,
        "num_probe_true_positives": 1633,
        "num_split_features": 2
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.009174311926605505,
        "num_absorption": 4,
        "num_probe_true_positives": 436,
        "num_split_features": 1
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.005934718100890208,
        "num_absorption": 4,
        "num_probe_true_positives": 674,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.002437043054427295,
        "num_absorption": 3,
        "num_probe_true_positives": 1231,
        "num_split_features": 2
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.009836065573770493,
        "num_absorption": 18,
        "num_probe_true_positives": 1830,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.0035335689045936395,
        "num_absorption": 3,
        "num_probe_true_positives": 849,
        "num_split_features": 1
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.029906542056074768,
        "num_absorption": 32,
        "num_probe_true_positives": 1070,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.000423908435777872,
        "num_absorption": 1,
        "num_probe_true_positives": 2359,
        "num_split_features": 3
      },
      {
        "first_letter": "q",
        "absorption_rate": 0.01092896174863388,
        "num_absorption": 2,
        "num_probe_true_positives": 183,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.008860011813349085,
        "num_absorption": 15,
        "num_probe_true_positives": 1693,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.0010504201680672268,
        "num_absorption": 3,
        "num_probe_true_positives": 2856,
        "num_split_features": 2
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.007597895967270602,
        "num_absorption": 13,
        "num_probe_true_positives": 1711,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.014492753623188406,
        "num_absorption": 11,
        "num_probe_true_positives": 759,
        "num_split_features": 1
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.005820721769499418,
        "num_absorption": 5,
        "num_probe_true_positives": 859,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.004531722054380665,
        "num_absorption": 3,
        "num_probe_true_positives": 662,
        "num_split_features": 1
      },
      {
        "first_letter": "x",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 99,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.012345679012345678,
        "num_absorption": 2,
        "num_probe_true_positives": 162,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.007547169811320755,
        "num_absorption": 2,
        "num_probe_true_positives": 265,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "c74192deb04d33c4b7d96940ffe8d4d52d44b9a6",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_5_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 2304,
      "hook_layer": 5,
      "hook_name": "blocks.5.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "Orthogonal",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}