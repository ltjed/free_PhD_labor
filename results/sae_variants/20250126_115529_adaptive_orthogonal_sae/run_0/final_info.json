{
  "training results": {
    "training_log": {
      "step 0": {
        "loss": 913.1821899414062,
        "l1_loss": 8814.16796875,
        "l2_loss": 560.615478515625
      },
      "step 1": {
        "loss": 792.97509765625,
        "l1_loss": 8603.88671875,
        "l2_loss": 448.81964111328125
      },
      "step 2": {
        "loss": 815.9098510742188,
        "l1_loss": 8855.576171875,
        "l2_loss": 461.6867980957031
      },
      "step 3": {
        "loss": 814.262451171875,
        "l1_loss": 8842.267578125,
        "l2_loss": 460.57177734375
      },
      "step 4": {
        "loss": 822.16162109375,
        "l1_loss": 8929.091796875,
        "l2_loss": 464.99798583984375
      },
      "step 5": {
        "loss": 802.712646484375,
        "l1_loss": 8716.0068359375,
        "l2_loss": 454.0723571777344
      },
      "step 6": {
        "loss": 810.863525390625,
        "l1_loss": 8808.310546875,
        "l2_loss": 458.5311279296875
      },
      "step 7": {
        "loss": 810.8585815429688,
        "l1_loss": 8811.251953125,
        "l2_loss": 458.40850830078125
      },
      "step 8": {
        "loss": 810.8253173828125,
        "l1_loss": 8813.984375,
        "l2_loss": 458.26593017578125
      },
      "step 9": {
        "loss": 801.4393920898438,
        "l1_loss": 8709.130859375,
        "l2_loss": 453.07415771484375
      },
      "step 10": {
        "loss": 800.11328125,
        "l1_loss": 8699.029296875,
        "l2_loss": 452.152099609375
      },
      "step 2926": {
        "loss": 210.1471710205078,
        "l1_loss": 521.1864624023438,
        "l2_loss": 189.29971313476562
      },
      "step 2927": {
        "loss": 210.39854431152344,
        "l1_loss": 496.393310546875,
        "l2_loss": 190.54281616210938
      },
      "step 2928": {
        "loss": 210.80227661132812,
        "l1_loss": 487.52691650390625,
        "l2_loss": 191.30120849609375
      },
      "step 2929": {
        "loss": 211.50527954101562,
        "l1_loss": 535.2548828125,
        "l2_loss": 190.09507751464844
      },
      "step 4381": {
        "loss": 202.3007049560547,
        "l1_loss": 493.6444396972656,
        "l2_loss": 182.554931640625
      },
      "step 4382": {
        "loss": 202.8748321533203,
        "l1_loss": 507.02386474609375,
        "l2_loss": 182.5938720703125
      },
      "step 4391": {
        "loss": 201.45668029785156,
        "l1_loss": 511.1943664550781,
        "l2_loss": 181.0089111328125
      },
      "step 4392": {
        "loss": 203.9805450439453,
        "l1_loss": 540.3408203125,
        "l2_loss": 182.36691284179688
      },
      "step 4393": {
        "loss": 202.97044372558594,
        "l1_loss": 523.23193359375,
        "l2_loss": 182.04116821289062
      }
    },
    "config": {
      "trainer_class": "CustomTrainer",
      "activation_dim": 2304,
      "dict_size": 2304,
      "lr": 0.0003,
      "l1_penalty": 0.04,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 19,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "CustomTrainer",
      "submodule_name": "resid_post_layer_19"
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 200.22540283203125,
      "layer": 19,
      "dict_size": 2304,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_19_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_19_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.7950310559006211,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 2.0625
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.7894736842105263,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 4.9375,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.30859375,
        "mse": 18.75,
        "cossim": 0.76953125
      },
      "shrinkage": {
        "l2_norm_in": 308.0,
        "l2_norm_out": 221.0,
        "l2_ratio": 0.71484375,
        "relative_reconstruction_bias": 0.93359375
      },
      "sparsity": {
        "l0": 85.21243286132812,
        "l1": 458.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr and tpp evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "f91073bd-4a2d-4047-b2f7-b56525f474cf",
    "datetime_epoch_millis": 1737909513703,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.06587007579056367,
        "scr_metric_threshold_2": 0.058029774795046285,
        "scr_dir2_threshold_2": 0.058029774795046285,
        "scr_dir1_threshold_5": 0.010217662244191728,
        "scr_metric_threshold_5": 0.0844752875149297,
        "scr_dir2_threshold_5": 0.0844752875149297,
        "scr_dir1_threshold_10": -0.024891791382632943,
        "scr_metric_threshold_10": 0.10076869330279312,
        "scr_dir2_threshold_10": 0.10076869330279312,
        "scr_dir1_threshold_20": -0.03766055525206585,
        "scr_metric_threshold_20": 0.1272552577266652,
        "scr_dir2_threshold_20": 0.1272552577266652,
        "scr_dir1_threshold_50": -0.22237948394149068,
        "scr_metric_threshold_50": 0.12911556623111423,
        "scr_dir2_threshold_50": 0.12911556623111423,
        "scr_dir1_threshold_100": -0.33134406142065115,
        "scr_metric_threshold_100": 0.14392168319223805,
        "scr_dir2_threshold_100": 0.14392168319223805,
        "scr_dir1_threshold_500": -0.5233463733277888,
        "scr_metric_threshold_500": 0.10585801060064311,
        "scr_dir2_threshold_500": 0.10585801060064311
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.0,
        "scr_metric_threshold_2": 0.11111117800745299,
        "scr_dir2_threshold_2": 0.11111117800745299,
        "scr_dir1_threshold_5": -0.05970163859464643,
        "scr_metric_threshold_5": 0.0959595579503108,
        "scr_dir2_threshold_5": 0.0959595579503108,
        "scr_dir1_threshold_10": -0.08955290270293834,
        "scr_metric_threshold_10": 0.09848492830434731,
        "scr_dir2_threshold_10": 0.09848492830434731,
        "scr_dir1_threshold_20": 0.05970163859464643,
        "scr_metric_threshold_20": 0.2146465459863349,
        "scr_dir2_threshold_20": 0.2146465459863349,
        "scr_dir1_threshold_50": -1.1194041668112302,
        "scr_metric_threshold_50": 0.2474747049043481,
        "scr_dir2_threshold_50": 0.2474747049043481,
        "scr_dir1_threshold_100": -1.3134333802164095,
        "scr_metric_threshold_100": 0.27777779450186324,
        "scr_dir2_threshold_100": 0.27777779450186324,
        "scr_dir1_threshold_500": -1.671643211784288,
        "scr_metric_threshold_500": 0.27020198447329213,
        "scr_dir2_threshold_500": 0.27020198447329213
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": -0.009090790866835655,
        "scr_metric_threshold_2": -0.005865201569437397,
        "scr_dir2_threshold_2": -0.005865201569437397,
        "scr_dir1_threshold_5": 0.0363637053276792,
        "scr_metric_threshold_5": 0.043988225199269156,
        "scr_dir2_threshold_5": 0.043988225199269156,
        "scr_dir1_threshold_10": 0.09090899238902972,
        "scr_metric_threshold_10": 0.06451599370812708,
        "scr_dir2_threshold_10": 0.06451599370812708,
        "scr_dir1_threshold_20": -0.01818158173367131,
        "scr_metric_threshold_20": 0.11436942047683363,
        "scr_dir2_threshold_20": 0.11436942047683363,
        "scr_dir1_threshold_50": -0.10909057412270103,
        "scr_metric_threshold_50": 0.10557188031318131,
        "scr_dir2_threshold_50": 0.10557188031318131,
        "scr_dir1_threshold_100": -0.22727248097257427,
        "scr_metric_threshold_100": 0.10263919213162802,
        "scr_dir2_threshold_100": 0.10263919213162802,
        "scr_dir1_threshold_500": -0.3545451786892832,
        "scr_metric_threshold_500": 0.0938416519679757,
        "scr_dir2_threshold_500": 0.0938416519679757
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": -0.036364247188015786,
        "scr_metric_threshold_2": 0.027026971613983923,
        "scr_dir2_threshold_2": 0.027026971613983923,
        "scr_dir1_threshold_5": -0.036364247188015786,
        "scr_metric_threshold_5": 0.04668303085074865,
        "scr_dir2_threshold_5": 0.04668303085074865,
        "scr_dir1_threshold_10": -0.41818179847780595,
        "scr_metric_threshold_10": 0.06879606087991978,
        "scr_dir2_threshold_10": 0.06879606087991978,
        "scr_dir1_threshold_20": -0.6181824487102099,
        "scr_metric_threshold_20": 0.051596972435561446,
        "scr_dir2_threshold_20": 0.051596972435561446,
        "scr_dir1_threshold_50": -0.6000008669765385,
        "scr_metric_threshold_50": 0.07125303167232618,
        "scr_dir2_threshold_50": 0.07125303167232618,
        "scr_dir1_threshold_100": -0.4909092091331643,
        "scr_metric_threshold_100": 0.07616697325713898,
        "scr_dir2_threshold_100": 0.07616697325713898,
        "scr_dir1_threshold_500": -1.0181826654543444,
        "scr_metric_threshold_500": 0.14742015137822193,
        "scr_dir2_threshold_500": 0.14742015137822193
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": -0.03875965052274194,
        "scr_metric_threshold_2": 0.029850714401619252,
        "scr_dir2_threshold_2": 0.029850714401619252,
        "scr_dir1_threshold_5": -0.12403078926247804,
        "scr_metric_threshold_5": 0.08656710734955433,
        "scr_dir2_threshold_5": 0.08656710734955433,
        "scr_dir1_threshold_10": -0.05426332591124638,
        "scr_metric_threshold_10": 0.140298464442186,
        "scr_dir2_threshold_10": 0.140298464442186,
        "scr_dir1_threshold_20": -0.007751837694252218,
        "scr_metric_threshold_20": 0.200000071169717,
        "scr_dir2_threshold_20": 0.200000071169717,
        "scr_dir1_threshold_50": -0.3023253664876833,
        "scr_metric_threshold_50": 0.1761194284787046,
        "scr_dir2_threshold_50": 0.1761194284787046,
        "scr_dir1_threshold_100": -0.41860478010739,
        "scr_metric_threshold_100": 0.19701485739012106,
        "scr_dir2_threshold_100": 0.19701485739012106,
        "scr_dir1_threshold_500": -0.4651162683243842,
        "scr_metric_threshold_500": 0.1761194284787046,
        "scr_dir2_threshold_500": 0.1761194284787046
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.07831295883904521,
        "scr_metric_threshold_2": 0.22262770785108496,
        "scr_dir2_threshold_2": 0.22262770785108496,
        "scr_dir1_threshold_5": -0.1987954835480417,
        "scr_metric_threshold_5": 0.2408758663611602,
        "scr_dir2_threshold_5": 0.2408758663611602,
        "scr_dir1_threshold_10": -0.1987954835480417,
        "scr_metric_threshold_10": 0.24452545455613356,
        "scr_dir2_threshold_10": 0.24452545455613356,
        "scr_dir1_threshold_20": -0.1325302026773256,
        "scr_metric_threshold_20": 0.2408758663611602,
        "scr_dir2_threshold_20": 0.2408758663611602,
        "scr_dir1_threshold_50": -0.1566266358063036,
        "scr_metric_threshold_50": 0.18613139083093447,
        "scr_dir2_threshold_50": 0.18613139083093447,
        "scr_dir1_threshold_100": -0.06626528087071609,
        "scr_metric_threshold_100": 0.17518240871080587,
        "scr_dir2_threshold_100": 0.17518240871080587,
        "scr_dir1_threshold_500": -0.09638573251591193,
        "scr_metric_threshold_500": 0.047445299140279104,
        "scr_dir2_threshold_500": 0.047445299140279104
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.25882367790775096,
        "scr_metric_threshold_2": 0.04135351824215616,
        "scr_dir2_threshold_2": 0.04135351824215616,
        "scr_dir1_threshold_5": 0.27058823116922914,
        "scr_metric_threshold_5": 0.056391140868614346,
        "scr_dir2_threshold_5": 0.056391140868614346,
        "scr_dir1_threshold_10": 0.26470595453849005,
        "scr_metric_threshold_10": 0.06766918978026952,
        "scr_dir2_threshold_10": 0.06766918978026952,
        "scr_dir1_threshold_20": 0.20000021036931384,
        "scr_metric_threshold_20": 0.0902257357587491,
        "scr_dir2_threshold_20": 0.0902257357587491,
        "scr_dir1_threshold_50": 0.15882357272309403,
        "scr_metric_threshold_50": 0.026315895615697978,
        "scr_dir2_threshold_50": 0.026315895615697978,
        "scr_dir1_threshold_100": 0.18235302986157348,
        "scr_metric_threshold_100": 0.04135351824215616,
        "scr_dir2_threshold_100": 0.04135351824215616,
        "scr_dir1_threshold_500": 0.06470609478469928,
        "scr_metric_threshold_500": -0.04135329416457154,
        "scr_dir2_threshold_500": -0.04135329416457154
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.1875001663075311,
        "scr_metric_threshold_2": 0.01519755131841285,
        "scr_dir2_threshold_2": 0.01519755131841285,
        "scr_dir1_threshold_5": 0.10714302820203199,
        "scr_metric_threshold_5": 0.027355628606963597,
        "scr_dir2_threshold_5": 0.027355628606963597,
        "scr_dir1_threshold_10": 0.13392891829856485,
        "scr_metric_threshold_10": 0.07598793776116658,
        "scr_dir2_threshold_10": 0.07598793776116658,
        "scr_dir1_threshold_20": 0.13392891829856485,
        "scr_metric_threshold_20": 0.11550164365668093,
        "scr_dir2_threshold_20": 0.11550164365668093,
        "scr_dir1_threshold_50": 0.2678573044130302,
        "scr_metric_threshold_50": 0.27051681203977385,
        "scr_dir2_threshold_50": 0.27051681203977385,
        "scr_dir1_threshold_100": -0.32142802023789696,
        "scr_metric_threshold_100": 0.2674771568408094,
        "scr_dir2_threshold_100": 0.2674771568408094,
        "scr_dir1_threshold_500": -0.6696424627564262,
        "scr_metric_threshold_500": 0.20364747753729592,
        "scr_dir2_threshold_500": 0.20364747753729592
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.08653849184777547,
        "scr_metric_threshold_2": 0.02293575849509752,
        "scr_dir2_threshold_2": 0.02293575849509752,
        "scr_dir1_threshold_5": 0.08653849184777547,
        "scr_metric_threshold_5": 0.07798174293281654,
        "scr_dir2_threshold_5": 0.07798174293281654,
        "scr_dir1_threshold_10": 0.07211531435288414,
        "scr_metric_threshold_10": 0.04587151699019504,
        "scr_dir2_threshold_10": 0.04587151699019504,
        "scr_dir1_threshold_20": 0.08173086153640712,
        "scr_metric_threshold_20": -0.009174194031715687,
        "scr_dir2_threshold_20": -0.009174194031715687,
        "scr_dir1_threshold_50": 0.08173086153640712,
        "scr_metric_threshold_50": -0.05045861400605288,
        "scr_dir2_threshold_50": -0.05045861400605288,
        "scr_dir1_threshold_100": 0.004807630311368353,
        "scr_metric_threshold_100": 0.013761564463381832,
        "scr_dir2_threshold_100": 0.013761564463381832,
        "scr_dir1_threshold_500": 0.024038438117628045,
        "scr_metric_threshold_500": -0.05045861400605288,
        "scr_dir2_threshold_500": -0.05045861400605288
      }
    ],
    "sae_bench_commit_hash": "c74192deb04d33c4b7d96940ffe8d4d52d44b9a6",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_19_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 2304,
      "hook_layer": 19,
      "hook_name": "blocks.19.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "Custom",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "c6d5cffc-d2bf-4599-b283-3a392403d037",
    "datetime_epoch_millis": 1737909295184,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.008758872253182604,
        "mean_num_split_features": 1.1666666666666667
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.01015625,
        "num_absorption": 26,
        "num_probe_true_positives": 2560,
        "num_split_features": 1
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.0019329896907216496,
        "num_absorption": 3,
        "num_probe_true_positives": 1552,
        "num_split_features": 1
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.04352479486264716,
        "num_absorption": 122,
        "num_probe_true_positives": 2803,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.008706467661691543,
        "num_absorption": 14,
        "num_probe_true_positives": 1608,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.006811145510835914,
        "num_absorption": 11,
        "num_probe_true_positives": 1615,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.004914004914004914,
        "num_absorption": 6,
        "num_probe_true_positives": 1221,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.0035366931918656055,
        "num_absorption": 4,
        "num_probe_true_positives": 1131,
        "num_split_features": 1
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.00423728813559322,
        "num_absorption": 4,
        "num_probe_true_positives": 944,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.017522658610271902,
        "num_absorption": 29,
        "num_probe_true_positives": 1655,
        "num_split_features": 2
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.035164835164835165,
        "num_absorption": 16,
        "num_probe_true_positives": 455,
        "num_split_features": 1
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.00424929178470255,
        "num_absorption": 3,
        "num_probe_true_positives": 706,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.006204173716864072,
        "num_absorption": 11,
        "num_probe_true_positives": 1773,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.001226993865030675,
        "num_absorption": 1,
        "num_probe_true_positives": 815,
        "num_split_features": 1
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.013265306122448979,
        "num_absorption": 13,
        "num_probe_true_positives": 980,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.0004332755632582322,
        "num_absorption": 1,
        "num_probe_true_positives": 2308,
        "num_split_features": 2
      },
      {
        "first_letter": "q",
        "absorption_rate": 0.005405405405405406,
        "num_absorption": 1,
        "num_probe_true_positives": 185,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.015531660692951015,
        "num_absorption": 26,
        "num_probe_true_positives": 1674,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.006247703050349137,
        "num_absorption": 17,
        "num_probe_true_positives": 2721,
        "num_split_features": 1
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.0048721071863581,
        "num_absorption": 8,
        "num_probe_true_positives": 1642,
        "num_split_features": 2
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.005509641873278237,
        "num_absorption": 4,
        "num_probe_true_positives": 726,
        "num_split_features": 2
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 825,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.004470938897168405,
        "num_absorption": 3,
        "num_probe_true_positives": 671,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.006289308176100629,
        "num_absorption": 1,
        "num_probe_true_positives": 159,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 229,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "d8a9fbf2e09c6353944addaddfb5ca77a0714984",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_19_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 2304,
      "hook_layer": 19,
      "hook_name": "blocks.19.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "Custom",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "ac8a27a5-b5b7-456e-87cf-3907a425fb7b",
    "datetime_epoch_millis": 1737909579736,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.9517125,
        "llm_top_1_test_accuracy": 0.7024499999999999,
        "llm_top_2_test_accuracy": 0.7597125,
        "llm_top_5_test_accuracy": 0.81735,
        "llm_top_10_test_accuracy": 0.86769375,
        "llm_top_20_test_accuracy": 0.9023499999999998,
        "llm_top_50_test_accuracy": 0.935025,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9428437940776349,
        "sae_top_1_test_accuracy": 0.713025,
        "sae_top_2_test_accuracy": 0.7601125000000001,
        "sae_top_5_test_accuracy": 0.825225,
        "sae_top_10_test_accuracy": 0.87074375,
        "sae_top_20_test_accuracy": 0.89721875,
        "sae_top_50_test_accuracy": 0.92048125,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9606,
        "llm_top_1_test_accuracy": 0.6564,
        "llm_top_2_test_accuracy": 0.7246,
        "llm_top_5_test_accuracy": 0.8052000000000001,
        "llm_top_10_test_accuracy": 0.8672000000000001,
        "llm_top_20_test_accuracy": 0.9133999999999999,
        "llm_top_50_test_accuracy": 0.9513999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9566000580787659,
        "sae_top_1_test_accuracy": 0.759,
        "sae_top_2_test_accuracy": 0.807,
        "sae_top_5_test_accuracy": 0.8378,
        "sae_top_10_test_accuracy": 0.8942,
        "sae_top_20_test_accuracy": 0.9301999999999999,
        "sae_top_50_test_accuracy": 0.9480000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.954,
        "llm_top_1_test_accuracy": 0.6718,
        "llm_top_2_test_accuracy": 0.7018,
        "llm_top_5_test_accuracy": 0.7636,
        "llm_top_10_test_accuracy": 0.8350000000000002,
        "llm_top_20_test_accuracy": 0.8886,
        "llm_top_50_test_accuracy": 0.9254000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9386000514030457,
        "sae_top_1_test_accuracy": 0.6682,
        "sae_top_2_test_accuracy": 0.7310000000000001,
        "sae_top_5_test_accuracy": 0.805,
        "sae_top_10_test_accuracy": 0.8468,
        "sae_top_20_test_accuracy": 0.8671999999999999,
        "sae_top_50_test_accuracy": 0.9004000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.909,
        "llm_top_1_test_accuracy": 0.6813999999999999,
        "llm_top_2_test_accuracy": 0.734,
        "llm_top_5_test_accuracy": 0.7828,
        "llm_top_10_test_accuracy": 0.8324,
        "llm_top_20_test_accuracy": 0.8744,
        "llm_top_50_test_accuracy": 0.9074,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9164000391960144,
        "sae_top_1_test_accuracy": 0.7235999999999999,
        "sae_top_2_test_accuracy": 0.7911999999999999,
        "sae_top_5_test_accuracy": 0.8422000000000001,
        "sae_top_10_test_accuracy": 0.8662000000000001,
        "sae_top_20_test_accuracy": 0.8746,
        "sae_top_50_test_accuracy": 0.893,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.9145999999999999,
        "llm_top_1_test_accuracy": 0.6384000000000001,
        "llm_top_2_test_accuracy": 0.7098000000000001,
        "llm_top_5_test_accuracy": 0.7476,
        "llm_top_10_test_accuracy": 0.8,
        "llm_top_20_test_accuracy": 0.8573999999999999,
        "llm_top_50_test_accuracy": 0.8882,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.8842000365257263,
        "sae_top_1_test_accuracy": 0.6439999999999999,
        "sae_top_2_test_accuracy": 0.6738,
        "sae_top_5_test_accuracy": 0.7914,
        "sae_top_10_test_accuracy": 0.8176,
        "sae_top_20_test_accuracy": 0.8432000000000001,
        "sae_top_50_test_accuracy": 0.8591999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.971,
        "llm_top_1_test_accuracy": 0.697,
        "llm_top_2_test_accuracy": 0.743,
        "llm_top_5_test_accuracy": 0.79,
        "llm_top_10_test_accuracy": 0.86,
        "llm_top_20_test_accuracy": 0.874,
        "llm_top_50_test_accuracy": 0.942,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9460000395774841,
        "sae_top_1_test_accuracy": 0.787,
        "sae_top_2_test_accuracy": 0.791,
        "sae_top_5_test_accuracy": 0.829,
        "sae_top_10_test_accuracy": 0.852,
        "sae_top_20_test_accuracy": 0.8885000000000001,
        "sae_top_50_test_accuracy": 0.9055,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.962,
        "llm_top_1_test_accuracy": 0.638,
        "llm_top_2_test_accuracy": 0.6910000000000001,
        "llm_top_5_test_accuracy": 0.8056000000000001,
        "llm_top_10_test_accuracy": 0.877,
        "llm_top_20_test_accuracy": 0.9166000000000001,
        "llm_top_50_test_accuracy": 0.9381999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.964400053024292,
        "sae_top_1_test_accuracy": 0.7274,
        "sae_top_2_test_accuracy": 0.8102,
        "sae_top_5_test_accuracy": 0.9074,
        "sae_top_10_test_accuracy": 0.931,
        "sae_top_20_test_accuracy": 0.9494,
        "sae_top_50_test_accuracy": 0.9568000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.9435,
        "llm_top_1_test_accuracy": 0.701,
        "llm_top_2_test_accuracy": 0.7885,
        "llm_top_5_test_accuracy": 0.851,
        "llm_top_10_test_accuracy": 0.87075,
        "llm_top_20_test_accuracy": 0.895,
        "llm_top_50_test_accuracy": 0.9279999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9397500455379486,
        "sae_top_1_test_accuracy": 0.6739999999999999,
        "sae_top_2_test_accuracy": 0.7435,
        "sae_top_5_test_accuracy": 0.826,
        "sae_top_10_test_accuracy": 0.89375,
        "sae_top_20_test_accuracy": 0.90925,
        "sae_top_50_test_accuracy": 0.92775,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.999,
        "llm_top_1_test_accuracy": 0.9356,
        "llm_top_2_test_accuracy": 0.985,
        "llm_top_5_test_accuracy": 0.993,
        "llm_top_10_test_accuracy": 0.9992000000000001,
        "llm_top_20_test_accuracy": 0.9994,
        "llm_top_50_test_accuracy": 0.9996,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9968000292778015,
        "sae_top_1_test_accuracy": 0.721,
        "sae_top_2_test_accuracy": 0.7331999999999999,
        "sae_top_5_test_accuracy": 0.7630000000000001,
        "sae_top_10_test_accuracy": 0.8644000000000001,
        "sae_top_20_test_accuracy": 0.9154,
        "sae_top_50_test_accuracy": 0.9732,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "c74192deb04d33c4b7d96940ffe8d4d52d44b9a6",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_19_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 2304,
      "hook_layer": 19,
      "hook_name": "blocks.19.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "Custom",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "training results for layer 5": {
    "training_log": {
      "step 0": {
        "loss": 280.3485107421875,
        "l1_loss": 2692.192626953125,
        "l2_loss": 172.6608123779297
      },
      "step 1": {
        "loss": 243.578369140625,
        "l1_loss": 2632.935546875,
        "l2_loss": 138.26095581054688
      },
      "step 1220": {
        "loss": 71.24016571044922,
        "l1_loss": 168.2802734375,
        "l2_loss": 64.50895690917969
      },
      "step 1221": {
        "loss": 71.71453857421875,
        "l1_loss": 183.52857971191406,
        "l2_loss": 64.37339782714844
      },
      "step 2440": {
        "loss": 65.88867950439453,
        "l1_loss": 168.97921752929688,
        "l2_loss": 59.12950897216797
      },
      "step 2441": {
        "loss": 65.85481262207031,
        "l1_loss": 172.13116455078125,
        "l2_loss": 58.969566345214844
      },
      "step 3660": {
        "loss": 63.72981643676758,
        "l1_loss": 179.27920532226562,
        "l2_loss": 56.55864715576172
      },
      "step 3661": {
        "loss": 64.40095520019531,
        "l1_loss": 179.67428588867188,
        "l2_loss": 57.21398162841797
      }
    },
    "config": {
      "trainer_class": "CustomTrainer",
      "activation_dim": 2304,
      "dict_size": 2304,
      "lr": 0.0003,
      "l1_penalty": 0.04,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 5,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "CustomTrainer",
      "submodule_name": "resid_post_layer_5"
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 61.984031677246094,
      "layer": 5,
      "dict_size": 2304,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "training results for layer 12": {
    "training_log": {
      "step 0": {
        "loss": 461.9488525390625,
        "l1_loss": 4426.9755859375,
        "l2_loss": 284.86981201171875
      },
      "step 1": {
        "loss": 398.80157470703125,
        "l1_loss": 4297.7392578125,
        "l2_loss": 226.8920135498047
      },
      "step 1220": {
        "loss": 110.96922302246094,
        "l1_loss": 365.6455078125,
        "l2_loss": 96.34339904785156
      },
      "step 1221": {
        "loss": 111.44891357421875,
        "l1_loss": 394.0783996582031,
        "l2_loss": 95.68577575683594
      },
      "step 2440": {
        "loss": 102.57173919677734,
        "l1_loss": 313.1291809082031,
        "l2_loss": 90.04656982421875
      },
      "step 2441": {
        "loss": 102.70217895507812,
        "l1_loss": 324.12835693359375,
        "l2_loss": 89.73704528808594
      },
      "step 3660": {
        "loss": 99.31343841552734,
        "l1_loss": 303.0018615722656,
        "l2_loss": 87.19336700439453
      },
      "step 3661": {
        "loss": 99.67717742919922,
        "l1_loss": 300.0284118652344,
        "l2_loss": 87.67604064941406
      }
    },
    "config": {
      "trainer_class": "CustomTrainer",
      "activation_dim": 2304,
      "dict_size": 2304,
      "lr": 0.0003,
      "l1_penalty": 0.04,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "CustomTrainer",
      "submodule_name": "resid_post_layer_12"
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 96.88678741455078,
      "layer": 12,
      "dict_size": 2304,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "training results for layer 19": {
    "training_log": {
      "step 0": {
        "loss": 913.1821899414062,
        "l1_loss": 8814.16796875,
        "l2_loss": 560.615478515625
      },
      "step 1": {
        "loss": 792.97509765625,
        "l1_loss": 8603.88671875,
        "l2_loss": 448.81964111328125
      },
      "step 1220": {
        "loss": 232.52467346191406,
        "l1_loss": 571.1429443359375,
        "l2_loss": 209.678955078125
      },
      "step 1221": {
        "loss": 233.77053833007812,
        "l1_loss": 632.4195556640625,
        "l2_loss": 208.4737548828125
      },
      "step 2440": {
        "loss": 214.23690795898438,
        "l1_loss": 502.8707580566406,
        "l2_loss": 194.1220703125
      },
      "step 2441": {
        "loss": 214.14248657226562,
        "l1_loss": 508.6922912597656,
        "l2_loss": 193.7947998046875
      },
      "step 3660": {
        "loss": 206.41171264648438,
        "l1_loss": 514.4593505859375,
        "l2_loss": 185.83334350585938
      },
      "step 3661": {
        "loss": 206.8395233154297,
        "l1_loss": 515.376708984375,
        "l2_loss": 186.22445678710938
      }
    },
    "config": {
      "trainer_class": "CustomTrainer",
      "activation_dim": 2304,
      "dict_size": 2304,
      "lr": 0.0003,
      "l1_penalty": 0.04,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 19,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "CustomTrainer",
      "submodule_name": "resid_post_layer_19"
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 200.22540283203125,
      "layer": 19,
      "dict_size": 2304,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  }
}