{
  "training results for layer 5": {
    "training_log": {
      "step 0": {
        "loss": 281.0832214355469,
        "l1_loss": 2692.192626953125,
        "l2_loss": 172.6608123779297,
        "ortho_loss": 0.7347031235694885
      },
      "step 1": {
        "loss": 244.28158569335938,
        "l1_loss": 2632.935546875,
        "l2_loss": 138.26095581054688,
        "ortho_loss": 0.7032171487808228
      },
      "step 1220": {
        "loss": 71.86112213134766,
        "l1_loss": 170.97914123535156,
        "l2_loss": 64.47850036621094,
        "ortho_loss": 0.5434563159942627
      },
      "step 1221": {
        "loss": 72.2920150756836,
        "l1_loss": 186.13876342773438,
        "l2_loss": 64.33442687988281,
        "ortho_loss": 0.5120376348495483
      },
      "step 2440": {
        "loss": 63.997833251953125,
        "l1_loss": 192.73257446289062,
        "l2_loss": 56.009010314941406,
        "ortho_loss": 0.2795169949531555
      },
      "step 2441": {
        "loss": 63.96873474121094,
        "l1_loss": 195.67160034179688,
        "l2_loss": 55.85227584838867,
        "ortho_loss": 0.28959691524505615
      },
      "step 3660": {
        "loss": 60.7346076965332,
        "l1_loss": 217.28866577148438,
        "l2_loss": 51.7845344543457,
        "ortho_loss": 0.2585268020629883
      },
      "step 3661": {
        "loss": 61.36616134643555,
        "l1_loss": 217.98301696777344,
        "l2_loss": 52.38612365722656,
        "ortho_loss": 0.26071682572364807
      }
    },
    "config": {
      "trainer_class": "OrthogonalTrainer",
      "activation_dim": 2304,
      "dict_size": 2304,
      "lr": 0.0003,
      "l1_penalty": 0.04,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 5,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "CustomTrainer",
      "submodule_name": "resid_post_layer_5"
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 58.404544830322266,
      "layer": 5,
      "dict_size": 2304,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "training results for layer 12": {
    "training_log": {
      "step 0": {
        "loss": 462.7072448730469,
        "l1_loss": 4426.9755859375,
        "l2_loss": 284.86981201171875,
        "ortho_loss": 0.758405327796936
      },
      "step 1": {
        "loss": 399.5401611328125,
        "l1_loss": 4297.7392578125,
        "l2_loss": 226.8920135498047,
        "ortho_loss": 0.7385805249214172
      },
      "step 1220": {
        "loss": 111.7159652709961,
        "l1_loss": 369.0711669921875,
        "l2_loss": 96.30489349365234,
        "ortho_loss": 0.6482222080230713
      },
      "step 1221": {
        "loss": 112.21276092529297,
        "l1_loss": 397.26904296875,
        "l2_loss": 95.69296264648438,
        "ortho_loss": 0.6290384531021118
      },
      "step 2440": {
        "loss": 100.192626953125,
        "l1_loss": 344.2295227050781,
        "l2_loss": 86.05743408203125,
        "ortho_loss": 0.3660103678703308
      },
      "step 2441": {
        "loss": 100.15087127685547,
        "l1_loss": 355.8314208984375,
        "l2_loss": 85.56201171875,
        "ortho_loss": 0.3556060492992401
      },
      "step 3660": {
        "loss": 94.8901596069336,
        "l1_loss": 365.2125244140625,
        "l2_loss": 79.97498321533203,
        "ortho_loss": 0.30667734146118164
      },
      "step 3661": {
        "loss": 95.39730072021484,
        "l1_loss": 362.717529296875,
        "l2_loss": 80.5822982788086,
        "ortho_loss": 0.30630823969841003
      }
    },
    "config": {
      "trainer_class": "OrthogonalTrainer",
      "activation_dim": 2304,
      "dict_size": 2304,
      "lr": 0.0003,
      "l1_penalty": 0.04,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "CustomTrainer",
      "submodule_name": "resid_post_layer_12"
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 91.96614837646484,
      "layer": 12,
      "dict_size": 2304,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "training results for layer 19": {
    "training_log": {
      "step 0": {
        "loss": 913.9003295898438,
        "l1_loss": 8814.16796875,
        "l2_loss": 560.615478515625,
        "ortho_loss": 0.7181362509727478
      },
      "step 1": {
        "loss": 793.6553955078125,
        "l1_loss": 8603.88671875,
        "l2_loss": 448.81964111328125,
        "ortho_loss": 0.6803209781646729
      },
      "step 1220": {
        "loss": 233.23387145996094,
        "l1_loss": 571.0858154296875,
        "l2_loss": 209.616455078125,
        "ortho_loss": 0.7739883661270142
      },
      "step 1221": {
        "loss": 234.44558715820312,
        "l1_loss": 632.128173828125,
        "l2_loss": 208.39337158203125,
        "ortho_loss": 0.7670946717262268
      },
      "step 2440": {
        "loss": 206.9493865966797,
        "l1_loss": 568.371337890625,
        "l2_loss": 183.74571228027344,
        "ortho_loss": 0.46882471442222595
      },
      "step 2441": {
        "loss": 206.74237060546875,
        "l1_loss": 575.7809448242188,
        "l2_loss": 183.25311279296875,
        "ortho_loss": 0.4580265283584595
      },
      "step 3660": {
        "loss": 192.28057861328125,
        "l1_loss": 656.0709228515625,
        "l2_loss": 165.69085693359375,
        "ortho_loss": 0.34688806533813477
      },
      "step 3661": {
        "loss": 192.26243591308594,
        "l1_loss": 657.0574951171875,
        "l2_loss": 165.6599578857422,
        "ortho_loss": 0.32017654180526733
      }
    },
    "config": {
      "trainer_class": "OrthogonalTrainer",
      "activation_dim": 2304,
      "dict_size": 2304,
      "lr": 0.0003,
      "l1_penalty": 0.04,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 19,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "CustomTrainer",
      "submodule_name": "resid_post_layer_19"
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 184.6689910888672,
      "layer": 19,
      "dict_size": 2304,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "8484447d-daeb-4f48-a7cf-9675ae41741f",
    "datetime_epoch_millis": 1737912486214,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.008758872253182604,
        "mean_num_split_features": 1.1666666666666667
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.01015625,
        "num_absorption": 26,
        "num_probe_true_positives": 2560,
        "num_split_features": 1
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.0019329896907216496,
        "num_absorption": 3,
        "num_probe_true_positives": 1552,
        "num_split_features": 1
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.04352479486264716,
        "num_absorption": 122,
        "num_probe_true_positives": 2803,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.008706467661691543,
        "num_absorption": 14,
        "num_probe_true_positives": 1608,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.006811145510835914,
        "num_absorption": 11,
        "num_probe_true_positives": 1615,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.004914004914004914,
        "num_absorption": 6,
        "num_probe_true_positives": 1221,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.0035366931918656055,
        "num_absorption": 4,
        "num_probe_true_positives": 1131,
        "num_split_features": 1
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.00423728813559322,
        "num_absorption": 4,
        "num_probe_true_positives": 944,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.017522658610271902,
        "num_absorption": 29,
        "num_probe_true_positives": 1655,
        "num_split_features": 2
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.035164835164835165,
        "num_absorption": 16,
        "num_probe_true_positives": 455,
        "num_split_features": 1
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.00424929178470255,
        "num_absorption": 3,
        "num_probe_true_positives": 706,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.006204173716864072,
        "num_absorption": 11,
        "num_probe_true_positives": 1773,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.001226993865030675,
        "num_absorption": 1,
        "num_probe_true_positives": 815,
        "num_split_features": 1
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.013265306122448979,
        "num_absorption": 13,
        "num_probe_true_positives": 980,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.0004332755632582322,
        "num_absorption": 1,
        "num_probe_true_positives": 2308,
        "num_split_features": 2
      },
      {
        "first_letter": "q",
        "absorption_rate": 0.005405405405405406,
        "num_absorption": 1,
        "num_probe_true_positives": 185,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.015531660692951015,
        "num_absorption": 26,
        "num_probe_true_positives": 1674,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.006247703050349137,
        "num_absorption": 17,
        "num_probe_true_positives": 2721,
        "num_split_features": 1
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.0048721071863581,
        "num_absorption": 8,
        "num_probe_true_positives": 1642,
        "num_split_features": 2
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.005509641873278237,
        "num_absorption": 4,
        "num_probe_true_positives": 726,
        "num_split_features": 2
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 825,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.004470938897168405,
        "num_absorption": 3,
        "num_probe_true_positives": 671,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.006289308176100629,
        "num_absorption": 1,
        "num_probe_true_positives": 159,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 229,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "c74192deb04d33c4b7d96940ffe8d4d52d44b9a6",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_19_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 2304,
      "hook_layer": 19,
      "hook_name": "blocks.19.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "Orthogonal",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_19_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_19_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.8788819875776398,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 1.21875
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.8782894736842105,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 4.09375,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.443359375,
        "mse": 15.0625,
        "cossim": 0.8203125
      },
      "shrinkage": {
        "l2_norm_in": 308.0,
        "l2_norm_out": 234.0,
        "l2_ratio": 0.7578125,
        "relative_reconstruction_bias": 0.9296875
      },
      "sparsity": {
        "l0": 99.30024719238281,
        "l1": 632.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr and tpp evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "acf7f8cd-49df-485c-b9cf-29bba19c84b4",
    "datetime_epoch_millis": 1737912723835,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.031051850528903517,
        "scr_metric_threshold_2": 0.1779892293955015,
        "scr_dir2_threshold_2": 0.1779892293955015,
        "scr_dir1_threshold_5": -0.02408025408627858,
        "scr_metric_threshold_5": 0.22971831015435468,
        "scr_dir2_threshold_5": 0.22971831015435468,
        "scr_dir1_threshold_10": -0.1138600225277417,
        "scr_metric_threshold_10": 0.27062248838139613,
        "scr_dir2_threshold_10": 0.27062248838139613,
        "scr_dir1_threshold_20": -0.12958365001770722,
        "scr_metric_threshold_20": 0.30398568676243115,
        "scr_dir2_threshold_20": 0.30398568676243115,
        "scr_dir1_threshold_50": -0.28589277050577716,
        "scr_metric_threshold_50": 0.3136876427990092,
        "scr_dir2_threshold_50": 0.3136876427990092,
        "scr_dir1_threshold_100": -0.46717046578558935,
        "scr_metric_threshold_100": 0.349375609040497,
        "scr_dir2_threshold_100": 0.349375609040497,
        "scr_dir1_threshold_500": -0.8782416175393579,
        "scr_metric_threshold_500": 0.2806347274687658,
        "scr_dir2_threshold_500": 0.2806347274687658
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": -0.05970163859464643,
        "scr_metric_threshold_2": 0.050505149329191916,
        "scr_dir2_threshold_2": 0.050505149329191916,
        "scr_dir1_threshold_5": -0.014926076865114633,
        "scr_metric_threshold_5": 0.21212117563229838,
        "scr_dir2_threshold_5": 0.21212117563229838,
        "scr_dir1_threshold_10": 0.0,
        "scr_metric_threshold_10": 0.23232323536397514,
        "scr_dir2_threshold_10": 0.23232323536397514,
        "scr_dir1_threshold_20": -0.014926076865114633,
        "scr_metric_threshold_20": 0.25757573477018647,
        "scr_dir2_threshold_20": 0.25757573477018647,
        "scr_dir1_threshold_50": -0.9701496255136455,
        "scr_metric_threshold_50": 0.2626263249614903,
        "scr_dir2_threshold_50": 0.2626263249614903,
        "scr_dir1_threshold_100": -1.2537326312437003,
        "scr_metric_threshold_100": 0.32070713380248406,
        "scr_dir2_threshold_100": 0.32070713380248406,
        "scr_dir1_threshold_500": -1.761195224865289,
        "scr_metric_threshold_500": 0.3434344133714281,
        "scr_dir2_threshold_500": 0.3434344133714281
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.0,
        "scr_metric_threshold_2": 0.2639295259892841,
        "scr_dir2_threshold_2": 0.2639295259892841,
        "scr_dir1_threshold_5": 0.009090790866835655,
        "scr_metric_threshold_5": 0.28738998267969534,
        "scr_dir2_threshold_5": 0.28738998267969534,
        "scr_dir1_threshold_10": 0.009090790866835655,
        "scr_metric_threshold_10": 0.30498523780066916,
        "scr_dir2_threshold_10": 0.30498523780066916,
        "scr_dir1_threshold_20": 0.04545449619451486,
        "scr_metric_threshold_20": 0.3489734629999383,
        "scr_dir2_threshold_20": 0.3489734629999383,
        "scr_dir1_threshold_50": -0.027272372600506963,
        "scr_metric_threshold_50": 0.38709666142343924,
        "scr_dir2_threshold_50": 0.38709666142343924,
        "scr_dir1_threshold_100": -1.081818201522194,
        "scr_metric_threshold_100": 0.38709666142343924,
        "scr_dir2_threshold_100": 0.38709666142343924,
        "scr_dir1_threshold_500": -1.127272697716709,
        "scr_metric_threshold_500": 0.34604094961205417,
        "scr_dir2_threshold_500": 0.34604094961205417
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": -0.09090899238902972,
        "scr_metric_threshold_2": 0.0958230324939037,
        "scr_dir2_threshold_2": 0.0958230324939037,
        "scr_dir1_threshold_5": -0.036364247188015786,
        "scr_metric_threshold_5": 0.1253071213490508,
        "scr_dir2_threshold_5": 0.1253071213490508,
        "scr_dir1_threshold_10": -0.7454546045665822,
        "scr_metric_threshold_10": 0.14004909255224596,
        "scr_dir2_threshold_10": 0.14004909255224596,
        "scr_dir1_threshold_20": -0.9090910076109703,
        "scr_metric_threshold_20": 0.13513515096743317,
        "scr_dir2_threshold_20": 0.13513515096743317,
        "scr_dir1_threshold_50": -1.1818190684987326,
        "scr_metric_threshold_50": 0.18181818181818182,
        "scr_dir2_threshold_50": 0.18181818181818182,
        "scr_dir1_threshold_100": -1.2363638136997466,
        "scr_metric_threshold_100": 0.20638818263975933,
        "scr_dir2_threshold_100": 0.20638818263975933,
        "scr_dir1_threshold_500": -1.6181824487102099,
        "scr_metric_threshold_500": 0.19656015302137697,
        "scr_dir2_threshold_500": 0.19656015302137697
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": -0.05426332591124638,
        "scr_metric_threshold_2": 0.10447767832995988,
        "scr_dir2_threshold_2": 0.10447767832995988,
        "scr_dir1_threshold_5": -0.04651148821699416,
        "scr_metric_threshold_5": 0.17014917884380523,
        "scr_dir2_threshold_5": 0.17014917884380523,
        "scr_dir1_threshold_10": -0.3255813416219208,
        "scr_metric_threshold_10": 0.24179110691684247,
        "scr_dir2_threshold_10": 0.24179110691684247,
        "scr_dir1_threshold_20": -0.3255813416219208,
        "scr_metric_threshold_20": 0.28955221437457473,
        "scr_dir2_threshold_20": 0.28955221437457473,
        "scr_dir1_threshold_50": -0.09302297643398832,
        "scr_metric_threshold_50": 0.379104535503725,
        "scr_dir2_threshold_50": 0.379104535503725,
        "scr_dir1_threshold_100": -0.16279043978521998,
        "scr_metric_threshold_100": 0.379104535503725,
        "scr_dir2_threshold_100": 0.379104535503725,
        "scr_dir1_threshold_500": -0.961240349477258,
        "scr_metric_threshold_500": 0.4238806071061539,
        "scr_dir2_threshold_500": 0.4238806071061539
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.0,
        "scr_metric_threshold_2": 0.5839415073928252,
        "scr_dir2_threshold_2": 0.5839415073928252,
        "scr_dir1_threshold_5": -0.7951808569998471,
        "scr_metric_threshold_5": 0.6021896659029006,
        "scr_dir2_threshold_5": 0.6021896659029006,
        "scr_dir1_threshold_10": -0.6024097510321298,
        "scr_metric_threshold_10": 0.6058394716330825,
        "scr_dir2_threshold_10": 0.6058394716330825,
        "scr_dir1_threshold_20": -0.5481928662579559,
        "scr_metric_threshold_20": 0.6167882362180025,
        "scr_dir2_threshold_20": 0.6167882362180025,
        "scr_dir1_threshold_50": -0.5481928662579559,
        "scr_metric_threshold_50": 0.642335788653233,
        "scr_dir2_threshold_50": 0.642335788653233,
        "scr_dir1_threshold_100": -0.5783133179031518,
        "scr_metric_threshold_100": 0.6094890598280558,
        "scr_dir2_threshold_100": 0.6094890598280558,
        "scr_dir1_threshold_500": -0.9156626635806303,
        "scr_metric_threshold_500": 0.5218978554726529,
        "scr_dir2_threshold_500": 0.5218978554726529
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.13529411558461457,
        "scr_metric_threshold_2": 0.14661665254977885,
        "scr_dir2_threshold_2": 0.14661665254977885,
        "scr_dir1_threshold_5": 0.2235296675077933,
        "scr_metric_threshold_5": 0.184210597077132,
        "scr_dir2_threshold_5": 0.184210597077132,
        "scr_dir1_threshold_10": 0.32352942207692714,
        "scr_metric_threshold_10": 0.19924821970359016,
        "scr_dir2_threshold_10": 0.19924821970359016,
        "scr_dir1_threshold_20": 0.36470605972314696,
        "scr_metric_threshold_20": 0.2443608635053801,
        "scr_dir2_threshold_20": 0.2443608635053801,
        "scr_dir1_threshold_50": 0.18235302986157348,
        "scr_metric_threshold_50": 0.22556389124170353,
        "scr_dir2_threshold_50": 0.22556389124170353,
        "scr_dir1_threshold_100": 0.2411764974000106,
        "scr_metric_threshold_100": 0.3496242218905874,
        "scr_dir2_threshold_100": 0.3496242218905874,
        "scr_dir1_threshold_500": 0.017647180507740362,
        "scr_metric_threshold_500": 0.13157902992332066,
        "scr_dir2_threshold_500": 0.13157902992332066
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.24107141431649734,
        "scr_metric_threshold_2": 0.04559283512434088,
        "scr_dir2_threshold_2": 0.04559283512434088,
        "scr_dir1_threshold_5": 0.29464319450956306,
        "scr_metric_threshold_5": 0.08206688582089079,
        "scr_dir2_threshold_5": 0.08206688582089079,
        "scr_dir1_threshold_10": 0.34821444251852934,
        "scr_metric_threshold_10": 0.18844992621888307,
        "scr_dir2_threshold_10": 0.18844992621888307,
        "scr_dir1_threshold_20": 0.24999986695397514,
        "scr_metric_threshold_20": 0.2917933114179109,
        "scr_dir2_threshold_20": 0.2917933114179109,
        "scr_dir1_threshold_50": 0.31250009978451865,
        "scr_metric_threshold_50": 0.28875383738804883,
        "scr_dir2_threshold_50": 0.28875383738804883,
        "scr_dir1_threshold_100": 0.276785757050508,
        "scr_metric_threshold_100": 0.28571436335818673,
        "scr_dir2_threshold_100": 0.28571436335818673,
        "scr_dir1_threshold_500": -0.6071422299258827,
        "scr_metric_threshold_500": 0.1945288742786073,
        "scr_dir2_threshold_500": 0.1945288742786073
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.07692323122503876,
        "scr_metric_threshold_2": 0.13302745395472726,
        "scr_dir2_threshold_2": 0.13302745395472726,
        "scr_dir1_threshold_5": 0.17307698369555094,
        "scr_metric_threshold_5": 0.17431187392906444,
        "scr_dir2_threshold_5": 0.17431187392906444,
        "scr_dir1_threshold_10": 0.08173086153640712,
        "scr_metric_threshold_10": 0.252293616861881,
        "scr_dir2_threshold_10": 0.252293616861881,
        "scr_dir1_threshold_20": 0.10096166934266682,
        "scr_metric_threshold_20": 0.24770651984602315,
        "scr_dir2_threshold_20": 0.24770651984602315,
        "scr_dir1_threshold_50": 0.03846161561251938,
        "scr_metric_threshold_50": 0.14220192140225124,
        "scr_dir2_threshold_50": 0.14220192140225124,
        "scr_dir1_threshold_100": 0.057692423418779074,
        "scr_metric_threshold_100": 0.25688071387773886,
        "scr_dir2_threshold_100": 0.25688071387773886,
        "scr_dir1_threshold_500": -0.052884506546624445,
        "scr_metric_threshold_500": 0.08715593696453222,
        "scr_dir2_threshold_500": 0.08715593696453222
      }
    ],
    "sae_bench_commit_hash": "c74192deb04d33c4b7d96940ffe8d4d52d44b9a6",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_19_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 2304,
      "hook_layer": 19,
      "hook_name": "blocks.19.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "Orthogonal",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "03858648-5e6b-46de-8f47-c7539abc416c",
    "datetime_epoch_millis": 1737912785579,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.9517125,
        "llm_top_1_test_accuracy": 0.7024499999999999,
        "llm_top_2_test_accuracy": 0.7597125,
        "llm_top_5_test_accuracy": 0.81735,
        "llm_top_10_test_accuracy": 0.86769375,
        "llm_top_20_test_accuracy": 0.9023499999999998,
        "llm_top_50_test_accuracy": 0.935025,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9496812973171472,
        "sae_top_1_test_accuracy": 0.7814875,
        "sae_top_2_test_accuracy": 0.84541875,
        "sae_top_5_test_accuracy": 0.8833375,
        "sae_top_10_test_accuracy": 0.9122125,
        "sae_top_20_test_accuracy": 0.9273562500000002,
        "sae_top_50_test_accuracy": 0.93839375,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9606,
        "llm_top_1_test_accuracy": 0.6564,
        "llm_top_2_test_accuracy": 0.7246,
        "llm_top_5_test_accuracy": 0.8052000000000001,
        "llm_top_10_test_accuracy": 0.8672000000000001,
        "llm_top_20_test_accuracy": 0.9133999999999999,
        "llm_top_50_test_accuracy": 0.9513999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9586000561714172,
        "sae_top_1_test_accuracy": 0.7614,
        "sae_top_2_test_accuracy": 0.8375999999999999,
        "sae_top_5_test_accuracy": 0.8809999999999999,
        "sae_top_10_test_accuracy": 0.9198000000000001,
        "sae_top_20_test_accuracy": 0.9448000000000001,
        "sae_top_50_test_accuracy": 0.9516,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.954,
        "llm_top_1_test_accuracy": 0.6718,
        "llm_top_2_test_accuracy": 0.7018,
        "llm_top_5_test_accuracy": 0.7636,
        "llm_top_10_test_accuracy": 0.8350000000000002,
        "llm_top_20_test_accuracy": 0.8886,
        "llm_top_50_test_accuracy": 0.9254000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9456000447273254,
        "sae_top_1_test_accuracy": 0.6684000000000001,
        "sae_top_2_test_accuracy": 0.7886,
        "sae_top_5_test_accuracy": 0.86,
        "sae_top_10_test_accuracy": 0.8914,
        "sae_top_20_test_accuracy": 0.9208000000000001,
        "sae_top_50_test_accuracy": 0.9276,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.909,
        "llm_top_1_test_accuracy": 0.6813999999999999,
        "llm_top_2_test_accuracy": 0.734,
        "llm_top_5_test_accuracy": 0.7828,
        "llm_top_10_test_accuracy": 0.8324,
        "llm_top_20_test_accuracy": 0.8744,
        "llm_top_50_test_accuracy": 0.9074,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9160000443458557,
        "sae_top_1_test_accuracy": 0.7385999999999999,
        "sae_top_2_test_accuracy": 0.8054,
        "sae_top_5_test_accuracy": 0.8474,
        "sae_top_10_test_accuracy": 0.8795999999999999,
        "sae_top_20_test_accuracy": 0.8952,
        "sae_top_50_test_accuracy": 0.9048,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.9145999999999999,
        "llm_top_1_test_accuracy": 0.6384000000000001,
        "llm_top_2_test_accuracy": 0.7098000000000001,
        "llm_top_5_test_accuracy": 0.7476,
        "llm_top_10_test_accuracy": 0.8,
        "llm_top_20_test_accuracy": 0.8573999999999999,
        "llm_top_50_test_accuracy": 0.8882,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.912000048160553,
        "sae_top_1_test_accuracy": 0.7935999999999999,
        "sae_top_2_test_accuracy": 0.804,
        "sae_top_5_test_accuracy": 0.8314,
        "sae_top_10_test_accuracy": 0.8704000000000001,
        "sae_top_20_test_accuracy": 0.8788,
        "sae_top_50_test_accuracy": 0.9040000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.971,
        "llm_top_1_test_accuracy": 0.697,
        "llm_top_2_test_accuracy": 0.743,
        "llm_top_5_test_accuracy": 0.79,
        "llm_top_10_test_accuracy": 0.86,
        "llm_top_20_test_accuracy": 0.874,
        "llm_top_50_test_accuracy": 0.942,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9535000622272491,
        "sae_top_1_test_accuracy": 0.887,
        "sae_top_2_test_accuracy": 0.884,
        "sae_top_5_test_accuracy": 0.885,
        "sae_top_10_test_accuracy": 0.927,
        "sae_top_20_test_accuracy": 0.9325000000000001,
        "sae_top_50_test_accuracy": 0.934,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.962,
        "llm_top_1_test_accuracy": 0.638,
        "llm_top_2_test_accuracy": 0.6910000000000001,
        "llm_top_5_test_accuracy": 0.8056000000000001,
        "llm_top_10_test_accuracy": 0.877,
        "llm_top_20_test_accuracy": 0.9166000000000001,
        "llm_top_50_test_accuracy": 0.9381999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9674000382423401,
        "sae_top_1_test_accuracy": 0.718,
        "sae_top_2_test_accuracy": 0.8712,
        "sae_top_5_test_accuracy": 0.9186,
        "sae_top_10_test_accuracy": 0.9386000000000001,
        "sae_top_20_test_accuracy": 0.9534,
        "sae_top_50_test_accuracy": 0.9602,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.9435,
        "llm_top_1_test_accuracy": 0.701,
        "llm_top_2_test_accuracy": 0.7885,
        "llm_top_5_test_accuracy": 0.851,
        "llm_top_10_test_accuracy": 0.87075,
        "llm_top_20_test_accuracy": 0.895,
        "llm_top_50_test_accuracy": 0.9279999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9447500556707382,
        "sae_top_1_test_accuracy": 0.8075,
        "sae_top_2_test_accuracy": 0.82275,
        "sae_top_5_test_accuracy": 0.8825,
        "sae_top_10_test_accuracy": 0.9025,
        "sae_top_20_test_accuracy": 0.9167500000000001,
        "sae_top_50_test_accuracy": 0.92875,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.999,
        "llm_top_1_test_accuracy": 0.9356,
        "llm_top_2_test_accuracy": 0.985,
        "llm_top_5_test_accuracy": 0.993,
        "llm_top_10_test_accuracy": 0.9992000000000001,
        "llm_top_20_test_accuracy": 0.9994,
        "llm_top_50_test_accuracy": 0.9996,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9996000289916992,
        "sae_top_1_test_accuracy": 0.8774000000000001,
        "sae_top_2_test_accuracy": 0.9498,
        "sae_top_5_test_accuracy": 0.9608000000000001,
        "sae_top_10_test_accuracy": 0.9684000000000001,
        "sae_top_20_test_accuracy": 0.9766,
        "sae_top_50_test_accuracy": 0.9962,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "c74192deb04d33c4b7d96940ffe8d4d52d44b9a6",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_19_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 2304,
      "hook_layer": 19,
      "hook_name": "blocks.19.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "Orthogonal",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}