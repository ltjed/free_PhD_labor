\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{gpt4}
\citation{Cunningham2023SparseAF}
\citation{Makelov2024TowardsPE}
\citation{Mu2020CompositionalEO}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\newlabel{sec:intro@cref}{{[section][1][]1}{[1][1][]1}{}{}{}}
\citation{Cunningham2023SparseAF}
\citation{Makelov2024TowardsPE}
\citation{Kissane2024InterpretingAL}
\citation{vaswani2017attention}
\citation{Park2024MonetMO}
\citation{Burgess2018UnderstandingDI}
\citation{Narayanaswamy2017LearningDR}
\citation{radford2019language}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\newlabel{sec:related}{{2}{2}{Related Work}{section.2}{}}
\newlabel{sec:related@cref}{{[section][2][]2}{[1][2][]2}{}{}{}}
\citation{Bengio2007LearningDA}
\citation{Mu2020CompositionalEO}
\@writefile{toc}{\contentsline {section}{\numberline {3}Background}{3}{section.3}\protected@file@percent }
\newlabel{sec:background}{{3}{3}{Background}{section.3}{}}
\newlabel{sec:background@cref}{{[section][3][]3}{[1][2][]3}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Sparse Autoencoders for Neural Interpretation}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Problem Setting}{3}{subsection.3.2}\protected@file@percent }
\newlabel{subsec:problem}{{3.2}{3}{Problem Setting}{subsection.3.2}{}}
\newlabel{subsec:problem@cref}{{[subsection][2][3]3.2}{[1][3][]3}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Method}{3}{section.4}\protected@file@percent }
\newlabel{sec:method}{{4}{3}{Method}{section.4}{}}
\newlabel{sec:method@cref}{{[section][4][]4}{[1][3][]3}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Temporal Feature Integration}{3}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Dynamic Margin Adaptation}{4}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Attribution-Guided Training}{4}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Combined Training Objective}{4}{subsection.4.4}\protected@file@percent }
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Setup}{5}{section.5}\protected@file@percent }
\newlabel{sec:experimental}{{5}{5}{Experimental Setup}{section.5}{}}
\newlabel{sec:experimental@cref}{{[section][5][]5}{[1][4][]5}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Implementation Details}{5}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Evaluation Protocol}{5}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Temporal-Aware Feature Extraction}{5}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Dynamic Margin Adaptation}{5}{subsection.5.4}\protected@file@percent }
\citation{kingma2014adam}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Attribution-Guided Training}{6}{subsection.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Training Objective}{6}{subsection.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{6}{section.6}\protected@file@percent }
\newlabel{sec:results}{{6}{6}{Results}{section.6}{}}
\newlabel{sec:results@cref}{{[section][6][]6}{[1][6][]6}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Training Dynamics and Feature Organization}{6}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Architectural Ablation Studies}{6}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Unlearning Performance}{7}{subsection.6.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:training_curves}{{1a}{7}{Training loss convergence across architectural variants, showing stable dynamics but similar final performance}{figure.caption.1}{}}
\newlabel{fig:training_curves@cref}{{[subfigure][1][1]1a}{[1][7][]7}{}{}{}}
\newlabel{sub@fig:training_curves}{{a}{7}{Training loss convergence across architectural variants, showing stable dynamics but similar final performance}{figure.caption.1}{}}
\newlabel{sub@fig:training_curves@cref}{{[subfigure][1][1]1a}{[1][7][]7}{}{}{}}
\newlabel{fig:feature_statistics}{{1b}{7}{Feature activation statistics across hierarchical levels, demonstrating successful organization but limited impact on unlearning}{figure.caption.1}{}}
\newlabel{fig:feature_statistics@cref}{{[subfigure][2][1]1b}{[1][7][]7}{}{}{}}
\newlabel{sub@fig:feature_statistics}{{b}{7}{Feature activation statistics across hierarchical levels, demonstrating successful organization but limited impact on unlearning}{figure.caption.1}{}}
\newlabel{sub@fig:feature_statistics@cref}{{[subfigure][2][1]1b}{[1][7][]7}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Training dynamics and feature organization patterns across architectural variants.}}{7}{figure.caption.1}\protected@file@percent }
\newlabel{fig:first_figure}{{1}{7}{Training dynamics and feature organization patterns across architectural variants}{figure.caption.1}{}}
\newlabel{fig:first_figure@cref}{{[figure][1][]1}{[1][7][]7}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{7}{section.7}\protected@file@percent }
\newlabel{sec:conclusion}{{7}{7}{Conclusions}{section.7}{}}
\newlabel{sec:conclusion@cref}{{[section][7][]7}{[1][7][]7}{}{}{}}
\bibstyle{iclr2024_conference}
\bibdata{references}
\bibcite{Bengio2007LearningDA}{{1}{2007}{{Bengio}}{{}}}
\bibcite{Burgess2018UnderstandingDI}{{2}{2018}{{Burgess et~al.}}{{Burgess, Higgins, Pal, Matthey, Watters, Desjardins, and Lerchner}}}
\bibcite{Cunningham2023SparseAF}{{3}{2023}{{Cunningham et~al.}}{{Cunningham, Ewart, Riggs, Huben, and Sharkey}}}
\bibcite{kingma2014adam}{{4}{2014}{{Kingma \& Ba}}{{Kingma and Ba}}}
\bibcite{Kissane2024InterpretingAL}{{5}{2024}{{Kissane et~al.}}{{Kissane, Krzyzanowski, Bloom, Conmy, and Nanda}}}
\bibcite{Makelov2024TowardsPE}{{6}{2024}{{Makelov et~al.}}{{Makelov, Lange, and Nanda}}}
\bibcite{Mu2020CompositionalEO}{{7}{2020}{{Mu \& Andreas}}{{Mu and Andreas}}}
\bibcite{Narayanaswamy2017LearningDR}{{8}{2017}{{Narayanaswamy et~al.}}{{Narayanaswamy, Paige, van~de Meent, Desmaison, Goodman, Kohli, Wood, and Torr}}}
\bibcite{gpt4}{{9}{2024}{{OpenAI}}{{}}}
\bibcite{Park2024MonetMO}{{10}{2024}{{Park et~al.}}{{Park, Ahn, Kim, and Kang}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Unlearning performance across SAE variants, showing consistent baseline scores (0.0) despite architectural innovations.}}{8}{figure.caption.2}\protected@file@percent }
\newlabel{fig:unlearning_scores}{{2}{8}{Unlearning performance across SAE variants, showing consistent baseline scores (0.0) despite architectural innovations}{figure.caption.2}{}}
\newlabel{fig:unlearning_scores@cref}{{[figure][2][]2}{[1][7][]8}{}{}{}}
\bibcite{radford2019language}{{11}{2019}{{Radford et~al.}}{{Radford, Wu, Child, Luan, Amodei, and Sutskever}}}
\bibcite{vaswani2017attention}{{12}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\ttl@finishall
\gdef \@abspage@last{9}
