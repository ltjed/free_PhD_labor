{
  "training results for layer 19": {
    "config": {
      "trainer_class": "JumpReLUTrainer",
      "activation_dim": 2304,
      "dict_size": 2304,
      "lr": 0.0003,
      "sparsity_penalty": 1.0,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 19,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "JumpReLUTrainer",
      "jump_coeff": 0.1,
      "target_l0": 20.0,
      "bandwidth": 0.001
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 15402.853515625,
      "layer": 19,
      "dict_size": 2304,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "b290221a-a359-4db2-a68d-3714fcd95d1e",
    "datetime_epoch_millis": 1738090040207,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.009173980180944308,
        "mean_num_split_features": 1.0
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.01179245283018868,
        "num_absorption": 30,
        "num_probe_true_positives": 2544,
        "num_split_features": 1
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.007462686567164179,
        "num_absorption": 12,
        "num_probe_true_positives": 1608,
        "num_split_features": 1
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 2773,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.0018450184501845018,
        "num_absorption": 3,
        "num_probe_true_positives": 1626,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.018397626112759646,
        "num_absorption": 31,
        "num_probe_true_positives": 1685,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.00938566552901024,
        "num_absorption": 11,
        "num_probe_true_positives": 1172,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.00676818950930626,
        "num_absorption": 8,
        "num_probe_true_positives": 1182,
        "num_split_features": 1
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.016983016983016984,
        "num_absorption": 17,
        "num_probe_true_positives": 1001,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.025730994152046785,
        "num_absorption": 44,
        "num_probe_true_positives": 1710,
        "num_split_features": 1
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.01366742596810934,
        "num_absorption": 6,
        "num_probe_true_positives": 439,
        "num_split_features": 1
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.009538950715421303,
        "num_absorption": 6,
        "num_probe_true_positives": 629,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.002512562814070352,
        "num_absorption": 3,
        "num_probe_true_positives": 1194,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1756,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.006150061500615006,
        "num_absorption": 5,
        "num_probe_true_positives": 813,
        "num_split_features": 1
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.03185328185328185,
        "num_absorption": 33,
        "num_probe_true_positives": 1036,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.005531914893617021,
        "num_absorption": 13,
        "num_probe_true_positives": 2350,
        "num_split_features": 1
      },
      {
        "first_letter": "q",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 168,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.012987012987012988,
        "num_absorption": 22,
        "num_probe_true_positives": 1694,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.0007168458781362007,
        "num_absorption": 2,
        "num_probe_true_positives": 2790,
        "num_split_features": 1
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.0036231884057971015,
        "num_absorption": 6,
        "num_probe_true_positives": 1656,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.002509410288582183,
        "num_absorption": 2,
        "num_probe_true_positives": 797,
        "num_split_features": 1
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.015402843601895734,
        "num_absorption": 13,
        "num_probe_true_positives": 844,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.031818181818181815,
        "num_absorption": 21,
        "num_probe_true_positives": 660,
        "num_split_features": 1
      },
      {
        "first_letter": "x",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 102,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 153,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.0038461538461538464,
        "num_absorption": 1,
        "num_probe_true_positives": 260,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "d1f3769ef4beaca30726e58f8d3a9c1a4baf5910",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 65536,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "JumpReLU",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "jumprelu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null,
      "jump_coeff": 0.1
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9792313664596274,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.208984375
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9802631578947368,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 3.125,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.76953125,
        "mse": 1.4765625,
        "cossim": 0.93359375
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 152.0,
        "l2_ratio": 1.015625,
        "relative_reconstruction_bias": 1.0859375
      },
      "sparsity": {
        "l0": 3349.723388671875,
        "l1": 2384.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr and tpp evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "e827aa82-6c49-4c04-ae00-e4839002dcbc",
    "datetime_epoch_millis": 1738090827369,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.02163248562962354,
        "scr_metric_threshold_2": 0.013775576175600678,
        "scr_dir2_threshold_2": 0.011747162721208801,
        "scr_dir1_threshold_5": 0.00797513200245279,
        "scr_metric_threshold_5": 0.012243467722626217,
        "scr_dir2_threshold_5": 0.01581488514352803,
        "scr_dir1_threshold_10": 0.005620844078476961,
        "scr_metric_threshold_10": 0.021725976871906364,
        "scr_dir2_threshold_10": 0.0254149430440832,
        "scr_dir1_threshold_20": -0.0042442461395118146,
        "scr_metric_threshold_20": 0.02798841060137652,
        "scr_dir2_threshold_20": 0.03114087110932238,
        "scr_dir1_threshold_50": -0.037368683077093755,
        "scr_metric_threshold_50": 0.03933976502243071,
        "scr_dir2_threshold_50": 0.04725410359859606,
        "scr_dir1_threshold_100": -0.041929115762227756,
        "scr_metric_threshold_100": 0.04968711624808444,
        "scr_dir2_threshold_100": 0.058850707586679374,
        "scr_dir1_threshold_500": -0.061147481563771526,
        "scr_metric_threshold_500": 0.1546941453598473,
        "scr_dir2_threshold_500": 0.15686816891559102
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.10937460709798731,
        "scr_metric_threshold_2": -0.0024569704325861324,
        "scr_dir2_threshold_2": -0.0024569704325861324,
        "scr_dir1_threshold_5": 0.10937460709798731,
        "scr_metric_threshold_5": 0.0024571168813214595,
        "scr_dir2_threshold_5": 0.0024571168813214595,
        "scr_dir1_threshold_10": 0.10937460709798731,
        "scr_metric_threshold_10": 0.007371057746493725,
        "scr_dir2_threshold_10": 0.007371057746493725,
        "scr_dir1_threshold_20": 0.12499941792294417,
        "scr_metric_threshold_20": 0.017199085925573582,
        "scr_dir2_threshold_20": 0.017199085925573582,
        "scr_dir1_threshold_50": 0.1562499708961472,
        "scr_metric_threshold_50": 0.02948408453723957,
        "scr_dir2_threshold_50": 0.02948408453723957,
        "scr_dir1_threshold_100": 0.17187478172110407,
        "scr_metric_threshold_100": 0.039312112716319424,
        "scr_dir2_threshold_100": 0.039312112716319424,
        "scr_dir1_threshold_500": 0.21875014551926394,
        "scr_metric_threshold_500": 0.10565119308855696,
        "scr_dir2_threshold_500": 0.10565119308855696
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.009708614261252404,
        "scr_metric_threshold_2": 0.005730585621650868,
        "scr_dir2_threshold_2": 0.005730585621650868,
        "scr_dir1_threshold_5": -0.05825284293942373,
        "scr_metric_threshold_5": -0.005730756408609849,
        "scr_dir2_threshold_5": -0.005730756408609849,
        "scr_dir1_threshold_10": -0.06796145720067613,
        "scr_metric_threshold_10": 0.011461342030260717,
        "scr_dir2_threshold_10": 0.011461342030260717,
        "scr_dir1_threshold_20": -0.06796145720067613,
        "scr_metric_threshold_20": 0.017191927651911583,
        "scr_dir2_threshold_20": 0.017191927651911583,
        "scr_dir1_threshold_50": -0.23300963569983096,
        "scr_metric_threshold_50": 0.02005722046273702,
        "scr_dir2_threshold_50": 0.02005722046273702,
        "scr_dir1_threshold_100": -0.3495147428927238,
        "scr_metric_threshold_100": 0.06876788139460532,
        "scr_dir2_threshold_100": 0.06876788139460532,
        "scr_dir1_threshold_500": -0.7572817500389166,
        "scr_metric_threshold_500": 0.19484230215355525,
        "scr_dir2_threshold_500": 0.19484230215355525
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.0634921686148548,
        "scr_metric_threshold_2": -0.0025316127159178037,
        "scr_dir2_threshold_2": -0.0025316127159178037,
        "scr_dir1_threshold_5": 0.015873751732555005,
        "scr_metric_threshold_5": 0.0,
        "scr_dir2_threshold_5": 0.0,
        "scr_dir1_threshold_10": 0.0,
        "scr_metric_threshold_10": -0.0025316127159178037,
        "scr_dir2_threshold_10": -0.0025316127159178037,
        "scr_dir1_threshold_20": -0.04761841688229979,
        "scr_metric_threshold_20": -0.0025316127159178037,
        "scr_dir2_threshold_20": -0.0025316127159178037,
        "scr_dir1_threshold_50": -0.1111105854971546,
        "scr_metric_threshold_50": 0.010126601761490606,
        "scr_dir2_threshold_50": 0.010126601761490606,
        "scr_dir1_threshold_100": -0.1111105854971546,
        "scr_metric_threshold_100": 0.02025320352298121,
        "scr_dir2_threshold_100": 0.02025320352298121,
        "scr_dir1_threshold_500": -0.1111105854971546,
        "scr_metric_threshold_500": 0.07594943776226984,
        "scr_dir2_threshold_500": 0.07594943776226984
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": -0.015624796273220196,
        "scr_metric_threshold_2": 0.005934818343797456,
        "scr_dir2_threshold_2": 0.005934818343797456,
        "scr_dir1_threshold_5": -0.03125005820765137,
        "scr_metric_threshold_5": 0.014836957425305832,
        "scr_dir2_threshold_5": 0.014836957425305832,
        "scr_dir1_threshold_10": -0.046874854480871565,
        "scr_metric_threshold_10": 0.011869459819219295,
        "scr_dir2_threshold_10": 0.011869459819219295,
        "scr_dir1_threshold_20": -0.12499976716939451,
        "scr_metric_threshold_20": 0.020771598900727672,
        "scr_dir2_threshold_20": 0.020771598900727672,
        "scr_dir1_threshold_50": -0.22656233992895872,
        "scr_metric_threshold_50": 0.011869459819219295,
        "scr_dir2_threshold_50": 0.011869459819219295,
        "scr_dir1_threshold_100": -0.2890624563442615,
        "scr_metric_threshold_100": -0.023738742770062975,
        "scr_dir2_threshold_100": -0.023738742770062975,
        "scr_dir1_threshold_500": -0.5937497089617432,
        "scr_metric_threshold_500": 0.07715140039073762,
        "scr_dir2_threshold_500": 0.07715140039073762
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": -0.027322374114521025,
        "scr_metric_threshold_2": 0.03529412314690952,
        "scr_dir2_threshold_2": 0.03529412314690952,
        "scr_dir1_threshold_5": -0.04371592886659017,
        "scr_metric_threshold_5": 0.03137260585139841,
        "scr_dir2_threshold_5": 0.03137260585139841,
        "scr_dir1_threshold_10": -0.03825151918536423,
        "scr_metric_threshold_10": 0.06274521170279682,
        "scr_dir2_threshold_10": 0.06274521170279682,
        "scr_dir1_threshold_20": -0.03825151918536423,
        "scr_metric_threshold_20": 0.06666672899830793,
        "scr_dir2_threshold_20": 0.06666672899830793,
        "scr_dir1_threshold_50": -0.07103830298111119,
        "scr_metric_threshold_50": 0.05490194336811984,
        "scr_dir2_threshold_50": 0.05490194336811984,
        "scr_dir1_threshold_100": -0.00546440968122594,
        "scr_metric_threshold_100": 0.06274521170279682,
        "scr_dir2_threshold_100": 0.06274521170279682,
        "scr_dir1_threshold_500": 0.13661187057260513,
        "scr_metric_threshold_500": 0.23921582743734443,
        "scr_dir2_threshold_500": 0.23921582743734443
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": -0.010256584250251485,
        "scr_metric_threshold_2": 0.020161269001982816,
        "scr_dir2_threshold_2": 0.020161269001982816,
        "scr_dir1_threshold_5": 0.03589728071373967,
        "scr_metric_threshold_5": 0.028225920807546715,
        "scr_dir2_threshold_5": 0.028225920807546715,
        "scr_dir1_threshold_10": 0.03076914142104203,
        "scr_metric_threshold_10": 0.056451601273808806,
        "scr_dir2_threshold_10": 0.056451601273808806,
        "scr_dir1_threshold_20": 0.03076914142104203,
        "scr_metric_threshold_20": 0.060483807005948444,
        "scr_dir2_threshold_20": 0.060483807005948444,
        "scr_dir1_threshold_50": 0.06153828284208406,
        "scr_metric_threshold_50": 0.11290320254761761,
        "scr_dir2_threshold_50": 0.11290320254761761,
        "scr_dir1_threshold_100": 0.08717928497042846,
        "scr_metric_threshold_100": 0.1370969176230247,
        "scr_dir2_threshold_100": 0.1370969176230247,
        "scr_dir1_threshold_500": 0.18974359914866223,
        "scr_metric_threshold_500": 0.18951607282340924,
        "scr_dir2_threshold_500": 0.18951607282340924
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.0179372568872101,
        "scr_metric_threshold_2": 0.02232140362529227,
        "scr_dir2_threshold_2": 0.02232140362529227,
        "scr_dir1_threshold_5": 0.03587424648900561,
        "scr_metric_threshold_5": 0.02678589722404717,
        "scr_dir2_threshold_5": 0.02678589722404717,
        "scr_dir1_threshold_10": 0.049327255975766836,
        "scr_metric_threshold_10": 0.017857176118657926,
        "scr_dir2_threshold_10": 0.017857176118657926,
        "scr_dir1_threshold_20": 0.0762330076638747,
        "scr_metric_threshold_20": 0.03125012473068151,
        "scr_dir2_threshold_20": 0.03125012473068151,
        "scr_dir1_threshold_50": 0.11210752143829489,
        "scr_metric_threshold_50": 0.062499983369242465,
        "scr_dir2_threshold_50": 0.062499983369242465,
        "scr_dir1_threshold_100": 0.14349778781226621,
        "scr_metric_threshold_100": 0.07589293198126605,
        "scr_dir2_threshold_100": 0.07589293198126605,
        "scr_dir1_threshold_500": 0.26905831873732233,
        "scr_metric_threshold_500": 0.19642867121311663,
        "scr_dir2_threshold_500": 0.19642867121311663
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.025750992813676425,
        "scr_metric_threshold_2": 0.025750992813676425,
        "scr_dir2_threshold_2": 0.009523685178541423,
        "scr_dir1_threshold_5": 0.0,
        "scr_metric_threshold_5": 0.0,
        "scr_dir2_threshold_5": 0.0285713393672145,
        "scr_dir1_threshold_10": 0.008583578999931441,
        "scr_metric_threshold_10": 0.008583578999931441,
        "scr_dir2_threshold_10": 0.03809530837734615,
        "scr_dir1_threshold_20": 0.012875624313779262,
        "scr_metric_threshold_20": 0.012875624313779262,
        "scr_dir2_threshold_20": 0.03809530837734615,
        "scr_dir1_threshold_50": 0.012875624313779262,
        "scr_metric_threshold_50": 0.012875624313779262,
        "scr_dir2_threshold_50": 0.07619033292310208,
        "scr_dir1_threshold_100": 0.01716741381374498,
        "scr_metric_threshold_100": 0.01716741381374498,
        "scr_dir2_threshold_100": 0.09047614452250444,
        "scr_dir1_threshold_500": 0.15879825800978847,
        "scr_metric_threshold_500": 0.15879825800978847,
        "scr_dir2_threshold_500": 0.17619044645573817
      }
    ],
    "sae_bench_commit_hash": "d1f3769ef4beaca30726e58f8d3a9c1a4baf5910",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 65536,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "JumpReLU",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "jumprelu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null,
      "jump_coeff": 0.1
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "da8f01f4-bbb1-4af1-bb65-de44406de7a0",
    "datetime_epoch_millis": 1738091240717,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.9510624999999999,
        "llm_top_1_test_accuracy": 0.65735625,
        "llm_top_2_test_accuracy": 0.71594375,
        "llm_top_5_test_accuracy": 0.78363125,
        "llm_top_10_test_accuracy": 0.8313937499999998,
        "llm_top_20_test_accuracy": 0.8782375000000001,
        "llm_top_50_test_accuracy": 0.92224375,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9607187896966934,
        "sae_top_1_test_accuracy": 0.69455,
        "sae_top_2_test_accuracy": 0.7592937500000001,
        "sae_top_5_test_accuracy": 0.8112749999999999,
        "sae_top_10_test_accuracy": 0.8424062499999999,
        "sae_top_20_test_accuracy": 0.872875,
        "sae_top_50_test_accuracy": 0.9135125000000001,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9718000292778015,
        "sae_top_1_test_accuracy": 0.7718,
        "sae_top_2_test_accuracy": 0.8228,
        "sae_top_5_test_accuracy": 0.8405999999999999,
        "sae_top_10_test_accuracy": 0.8656,
        "sae_top_20_test_accuracy": 0.8977999999999999,
        "sae_top_50_test_accuracy": 0.9192,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9490000000000001,
        "llm_top_1_test_accuracy": 0.6716000000000001,
        "llm_top_2_test_accuracy": 0.7148,
        "llm_top_5_test_accuracy": 0.76,
        "llm_top_10_test_accuracy": 0.8009999999999999,
        "llm_top_20_test_accuracy": 0.8664,
        "llm_top_50_test_accuracy": 0.898,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9550000548362731,
        "sae_top_1_test_accuracy": 0.7142,
        "sae_top_2_test_accuracy": 0.74,
        "sae_top_5_test_accuracy": 0.79,
        "sae_top_10_test_accuracy": 0.8175999999999999,
        "sae_top_20_test_accuracy": 0.8464,
        "sae_top_50_test_accuracy": 0.9141999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9182,
        "llm_top_1_test_accuracy": 0.6828000000000001,
        "llm_top_2_test_accuracy": 0.7375999999999999,
        "llm_top_5_test_accuracy": 0.7627999999999999,
        "llm_top_10_test_accuracy": 0.7978,
        "llm_top_20_test_accuracy": 0.8573999999999999,
        "llm_top_50_test_accuracy": 0.8939999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.934000039100647,
        "sae_top_1_test_accuracy": 0.6686,
        "sae_top_2_test_accuracy": 0.7183999999999999,
        "sae_top_5_test_accuracy": 0.8074,
        "sae_top_10_test_accuracy": 0.8382,
        "sae_top_20_test_accuracy": 0.859,
        "sae_top_50_test_accuracy": 0.8878,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.8976,
        "llm_top_1_test_accuracy": 0.608,
        "llm_top_2_test_accuracy": 0.6472,
        "llm_top_5_test_accuracy": 0.6806000000000001,
        "llm_top_10_test_accuracy": 0.7525999999999999,
        "llm_top_20_test_accuracy": 0.8051999999999999,
        "llm_top_50_test_accuracy": 0.86,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9202000379562378,
        "sae_top_1_test_accuracy": 0.6498,
        "sae_top_2_test_accuracy": 0.6978000000000001,
        "sae_top_5_test_accuracy": 0.7552,
        "sae_top_10_test_accuracy": 0.7956,
        "sae_top_20_test_accuracy": 0.8182,
        "sae_top_50_test_accuracy": 0.8512000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.981,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.8474999999999999,
        "llm_top_50_test_accuracy": 0.933,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9785000383853912,
        "sae_top_1_test_accuracy": 0.689,
        "sae_top_2_test_accuracy": 0.772,
        "sae_top_5_test_accuracy": 0.83,
        "sae_top_10_test_accuracy": 0.855,
        "sae_top_20_test_accuracy": 0.891,
        "sae_top_50_test_accuracy": 0.948,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9645999999999999,
        "llm_top_1_test_accuracy": 0.6446,
        "llm_top_2_test_accuracy": 0.6886,
        "llm_top_5_test_accuracy": 0.7615999999999999,
        "llm_top_10_test_accuracy": 0.8012,
        "llm_top_20_test_accuracy": 0.8661999999999999,
        "llm_top_50_test_accuracy": 0.931,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9708000421524048,
        "sae_top_1_test_accuracy": 0.5912000000000001,
        "sae_top_2_test_accuracy": 0.6966,
        "sae_top_5_test_accuracy": 0.7409999999999999,
        "sae_top_10_test_accuracy": 0.7931999999999999,
        "sae_top_20_test_accuracy": 0.8522000000000001,
        "sae_top_50_test_accuracy": 0.9132,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.9395,
        "llm_top_1_test_accuracy": 0.69625,
        "llm_top_2_test_accuracy": 0.74175,
        "llm_top_5_test_accuracy": 0.8312499999999999,
        "llm_top_10_test_accuracy": 0.87575,
        "llm_top_20_test_accuracy": 0.897,
        "llm_top_50_test_accuracy": 0.92675,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9562500417232513,
        "sae_top_1_test_accuracy": 0.763,
        "sae_top_2_test_accuracy": 0.80975,
        "sae_top_5_test_accuracy": 0.873,
        "sae_top_10_test_accuracy": 0.89225,
        "sae_top_20_test_accuracy": 0.9079999999999999,
        "sae_top_50_test_accuracy": 0.9205000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.999,
        "llm_top_1_test_accuracy": 0.6414,
        "llm_top_2_test_accuracy": 0.7819999999999999,
        "llm_top_5_test_accuracy": 0.9156000000000001,
        "llm_top_10_test_accuracy": 0.9632,
        "llm_top_20_test_accuracy": 0.99,
        "llm_top_50_test_accuracy": 0.9968,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9992000341415406,
        "sae_top_1_test_accuracy": 0.7088,
        "sae_top_2_test_accuracy": 0.817,
        "sae_top_5_test_accuracy": 0.853,
        "sae_top_10_test_accuracy": 0.8817999999999999,
        "sae_top_20_test_accuracy": 0.9104000000000001,
        "sae_top_50_test_accuracy": 0.954,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "d1f3769ef4beaca30726e58f8d3a9c1a4baf5910",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 65536,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "JumpReLU",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "jumprelu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null,
      "jump_coeff": 0.1
    },
    "eval_result_unstructured": null
  },
  "unlearning evaluation results": {
    "eval_type_id": "unlearning",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "wmdp-bio",
        "high_school_us_history",
        "college_computer_science",
        "high_school_geography",
        "human_aging"
      ],
      "intervention_method": "clamp_feature_activation",
      "retain_thresholds": [
        0.001,
        0.01
      ],
      "n_features_list": [
        10,
        20
      ],
      "multipliers": [
        25,
        50,
        100,
        200
      ],
      "dataset_size": 1024,
      "seq_len": 1024,
      "n_batch_loss_added": 50,
      "target_metric": "correct",
      "save_metrics": true,
      "model_name": "google/gemma-2-2b-it",
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16"
    },
    "eval_id": "fe40985a-74aa-44a7-85c9-7e9b5e4aee01",
    "datetime_epoch_millis": 1738091445585,
    "eval_result_metrics": {
      "unlearning": {
        "unlearning_score": 0.018726587295532227
      }
    },
    "eval_result_details": [],
    "sae_bench_commit_hash": "d1f3769ef4beaca30726e58f8d3a9c1a4baf5910",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 65536,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "JumpReLU",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "jumprelu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null,
      "jump_coeff": 0.1
    },
    "eval_result_unstructured": null
  },
  "training results for layer 12": {
    "config": {
      "trainer_class": "JumpReLUTrainer",
      "activation_dim": 2304,
      "dict_size": 65536,
      "lr": 0.0003,
      "sparsity_penalty": 1.0,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "JumpReLUTrainer",
      "jump_coeff": 0.1,
      "target_l0": 20.0,
      "bandwidth": 0.001
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 26473.599609375,
      "layer": 12,
      "dict_size": 65536,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  }
}