{
  "training results for layer 19": {
    "config": {
      "trainer_class": "ProgressiveTrainer",
      "activation_dim": 2304,
      "dict_size": 2304,
      "lr": 0.0003,
      "l1_penalty": 0.04,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 19,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "CustomTrainer",
      "submodule_name": "resid_post_layer_19"
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 201.87400817871094,
      "layer": 19,
      "dict_size": 2304,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "974e6efd-3357-4242-814d-8d6fca7a01ca",
    "datetime_epoch_millis": 1738008011529,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.010124895517470242,
        "mean_num_split_features": 1.2
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.00986971969996052,
        "num_absorption": 25,
        "num_probe_true_positives": 2533,
        "num_split_features": 1
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.005050505050505051,
        "num_absorption": 8,
        "num_probe_true_positives": 1584,
        "num_split_features": 1
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.02792890823358723,
        "num_absorption": 77,
        "num_probe_true_positives": 2757,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.008631319358816275,
        "num_absorption": 14,
        "num_probe_true_positives": 1622,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.002523659305993691,
        "num_absorption": 4,
        "num_probe_true_positives": 1585,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.004942339373970346,
        "num_absorption": 6,
        "num_probe_true_positives": 1214,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.0026362038664323375,
        "num_absorption": 3,
        "num_probe_true_positives": 1138,
        "num_split_features": 1
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.08004158004158005,
        "num_absorption": 77,
        "num_probe_true_positives": 962,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.007402837754472548,
        "num_absorption": 12,
        "num_probe_true_positives": 1621,
        "num_split_features": 2
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.03546099290780142,
        "num_absorption": 15,
        "num_probe_true_positives": 423,
        "num_split_features": 1
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.001557632398753894,
        "num_absorption": 1,
        "num_probe_true_positives": 642,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1196,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.0060406370126304225,
        "num_absorption": 11,
        "num_probe_true_positives": 1821,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 845,
        "num_split_features": 1
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.007070707070707071,
        "num_absorption": 7,
        "num_probe_true_positives": 990,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.0004332755632582322,
        "num_absorption": 1,
        "num_probe_true_positives": 2308,
        "num_split_features": 2
      },
      {
        "first_letter": "q",
        "absorption_rate": 0.011428571428571429,
        "num_absorption": 2,
        "num_probe_true_positives": 175,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.006053268765133172,
        "num_absorption": 10,
        "num_probe_true_positives": 1652,
        "num_split_features": 2
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.005263157894736842,
        "num_absorption": 15,
        "num_probe_true_positives": 2850,
        "num_split_features": 1
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.00357355568790947,
        "num_absorption": 6,
        "num_probe_true_positives": 1679,
        "num_split_features": 2
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.0013297872340425532,
        "num_absorption": 1,
        "num_probe_true_positives": 752,
        "num_split_features": 2
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.0012738853503184713,
        "num_absorption": 1,
        "num_probe_true_positives": 785,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.004201680672268907,
        "num_absorption": 3,
        "num_probe_true_positives": 714,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.02040816326530612,
        "num_absorption": 3,
        "num_probe_true_positives": 147,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 230,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "88c9225ec5f48485e1b632cf29a8e11e4d49547c",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_19_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 2304,
      "hook_layer": 19,
      "hook_name": "blocks.19.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "Custom",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_19_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_19_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.782608695652174,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 2.1875
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.7763157894736842,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 5.0625,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.29296875,
        "mse": 19.25,
        "cossim": 0.76171875
      },
      "shrinkage": {
        "l2_norm_in": 308.0,
        "l2_norm_out": 220.0,
        "l2_ratio": 0.70703125,
        "relative_reconstruction_bias": 0.93359375
      },
      "sparsity": {
        "l0": 83.5626449584961,
        "l1": 442.1119384765625
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr and tpp evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "119fb4a4-5ce8-4e4a-9d7d-f7513aa38592",
    "datetime_epoch_millis": 1738008246407,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": -0.07855336268641425,
        "scr_metric_threshold_2": 0.1031589604713476,
        "scr_dir2_threshold_2": 0.1031589604713476,
        "scr_dir1_threshold_5": -0.02359048422412521,
        "scr_metric_threshold_5": 0.09964248898820677,
        "scr_dir2_threshold_5": 0.09964248898820677,
        "scr_dir1_threshold_10": -0.04542285778152336,
        "scr_metric_threshold_10": 0.11807910930770278,
        "scr_dir2_threshold_10": 0.11807910930770278,
        "scr_dir1_threshold_20": -0.085792508638599,
        "scr_metric_threshold_20": 0.14208644024634395,
        "scr_dir2_threshold_20": 0.14208644024634395,
        "scr_dir1_threshold_50": -0.1692421901186405,
        "scr_metric_threshold_50": 0.14538904231446526,
        "scr_dir2_threshold_50": 0.14538904231446526,
        "scr_dir1_threshold_100": -0.19302028872148588,
        "scr_metric_threshold_100": 0.1375415992851397,
        "scr_dir2_threshold_100": 0.1375415992851397,
        "scr_dir1_threshold_500": -0.46219113812493173,
        "scr_metric_threshold_500": 0.10451731391091235,
        "scr_dir2_threshold_500": 0.10451731391091235
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.0447755617295318,
        "scr_metric_threshold_2": 0.2020202962832292,
        "scr_dir2_threshold_2": 0.2020202962832292,
        "scr_dir1_threshold_5": 0.1194023875673555,
        "scr_metric_threshold_5": 0.21969698566086945,
        "scr_dir2_threshold_5": 0.21969698566086945,
        "scr_dir1_threshold_10": 0.1194023875673555,
        "scr_metric_threshold_10": 0.22979801552670784,
        "scr_dir2_threshold_10": 0.22979801552670784,
        "scr_dir1_threshold_20": -0.4477618446488796,
        "scr_metric_threshold_20": 0.2651515447987576,
        "scr_dir2_threshold_20": 0.2651515447987576,
        "scr_dir1_threshold_50": -0.8656724251894672,
        "scr_metric_threshold_50": 0.2904040442049689,
        "scr_dir2_threshold_50": 0.2904040442049689,
        "scr_dir1_threshold_100": -0.940299251027291,
        "scr_metric_threshold_100": 0.31060610393664567,
        "scr_dir2_threshold_100": 0.31060610393664567,
        "scr_dir1_threshold_500": -1.3731350188110558,
        "scr_metric_threshold_500": 0.23232323536397514,
        "scr_dir2_threshold_500": 0.23232323536397514
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": -0.008928457389060843,
        "scr_metric_threshold_2": 0.04081631589136039,
        "scr_dir2_threshold_2": 0.04081631589136039,
        "scr_dir1_threshold_5": 0.0,
        "scr_metric_threshold_5": 0.07580180398728945,
        "scr_dir2_threshold_5": 0.07580180398728945,
        "scr_dir1_threshold_10": -0.0892856382593739,
        "scr_metric_threshold_10": 0.09620987504574613,
        "scr_dir2_threshold_10": 0.09620987504574613,
        "scr_dir1_threshold_20": -0.08035718087031306,
        "scr_metric_threshold_20": 0.12244894767408115,
        "scr_dir2_threshold_20": 0.12244894767408115,
        "scr_dir1_threshold_50": -0.2321425530374956,
        "scr_metric_threshold_50": 0.1195335337763655,
        "scr_dir2_threshold_50": 0.1195335337763655,
        "scr_dir1_threshold_100": -0.34821409564843475,
        "scr_metric_threshold_100": 0.13411077703939084,
        "scr_dir2_threshold_100": 0.13411077703939084,
        "scr_dir1_threshold_500": -0.4821430852218783,
        "scr_metric_threshold_500": 0.1399417786092692,
        "scr_dir2_threshold_500": 0.1399417786092692
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": -0.7115378443311448,
        "scr_metric_threshold_2": 0.07785889101138782,
        "scr_dir2_threshold_2": 0.07785889101138782,
        "scr_dir1_threshold_5": -0.42307683490444925,
        "scr_metric_threshold_5": 0.0802919496316114,
        "scr_dir2_threshold_5": 0.0802919496316114,
        "scr_dir1_threshold_10": -0.32692201885339106,
        "scr_metric_threshold_10": 0.05352801476222823,
        "scr_dir2_threshold_10": 0.05352801476222823,
        "scr_dir1_threshold_20": -0.2884610094266955,
        "scr_metric_threshold_20": 0.05596107338245181,
        "scr_dir2_threshold_20": 0.05596107338245181,
        "scr_dir1_threshold_50": -0.442307339617797,
        "scr_metric_threshold_50": 0.07055957012725518,
        "scr_dir2_threshold_50": 0.07055957012725518,
        "scr_dir1_threshold_100": -0.3076915141400433,
        "scr_metric_threshold_100": 0.07299277377094067,
        "scr_dir2_threshold_100": 0.07299277377094067,
        "scr_dir1_threshold_500": -0.8076915141400433,
        "scr_metric_threshold_500": 0.0924573877561912,
        "scr_dir2_threshold_500": 0.0924573877561912
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": -0.13846159489197346,
        "scr_metric_threshold_2": 0.10606067174064686,
        "scr_dir2_threshold_2": 0.10606067174064686,
        "scr_dir1_threshold_5": -0.22307681021605308,
        "scr_metric_threshold_5": 0.1272726977167089,
        "scr_dir2_threshold_5": 0.1272726977167089,
        "scr_dir1_threshold_10": -0.1692308891454436,
        "scr_metric_threshold_10": 0.12424243409443037,
        "scr_dir2_threshold_10": 0.12424243409443037,
        "scr_dir1_threshold_20": -0.15384601277006638,
        "scr_metric_threshold_20": 0.14848490431288316,
        "scr_dir2_threshold_20": 0.14848490431288316,
        "scr_dir1_threshold_50": -0.16153868020639714,
        "scr_metric_threshold_50": 0.19696966412967656,
        "scr_dir2_threshold_50": 0.19696966412967656,
        "scr_dir1_threshold_100": -0.10769230063850332,
        "scr_metric_threshold_100": 0.21212116286118152,
        "scr_dir2_threshold_100": 0.21212116286118152,
        "scr_dir1_threshold_500": -0.6076923006385033,
        "scr_metric_threshold_500": 0.22727266159268647,
        "scr_dir2_threshold_500": 0.22727266159268647
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.156069388060262,
        "scr_metric_threshold_2": 0.25490195620110373,
        "scr_dir2_threshold_2": 0.25490195620110373,
        "scr_dir1_threshold_5": 0.22543367537663753,
        "scr_metric_threshold_5": 0.12941173720662244,
        "scr_dir2_threshold_5": 0.12941173720662244,
        "scr_dir1_threshold_10": 0.1329479589548035,
        "scr_metric_threshold_10": 0.14509804379889626,
        "scr_dir2_threshold_10": 0.14509804379889626,
        "scr_dir1_threshold_20": 0.02312142910545851,
        "scr_metric_threshold_20": 0.1568625984353196,
        "scr_dir2_threshold_20": 0.1568625984353196,
        "scr_dir1_threshold_50": -0.02890170024796216,
        "scr_metric_threshold_50": 0.15294108022317848,
        "scr_dir2_threshold_50": 0.15294108022317848,
        "scr_dir1_threshold_100": -0.13872823009730714,
        "scr_metric_threshold_100": 0.11372543061434859,
        "scr_dir2_threshold_100": 0.11372543061434859,
        "scr_dir1_threshold_500": -0.08670510074388647,
        "scr_metric_threshold_500": 0.05098020424525325,
        "scr_dir2_threshold_500": 0.05098020424525325
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.03225828159854488,
        "scr_metric_threshold_2": 0.06349218363242483,
        "scr_dir2_threshold_2": 0.06349218363242483,
        "scr_dir1_threshold_5": 0.0591399692940024,
        "scr_metric_threshold_5": 0.07142858832330974,
        "scr_dir2_threshold_5": 0.07142858832330974,
        "scr_dir1_threshold_10": 0.08602165698945992,
        "scr_metric_threshold_10": 0.13888897430117703,
        "scr_dir2_threshold_10": 0.13888897430117703,
        "scr_dir1_threshold_20": 0.12903248548418988,
        "scr_metric_threshold_20": 0.15079381786384077,
        "scr_dir2_threshold_20": 0.15079381786384077,
        "scr_dir1_threshold_50": 0.10215047733373753,
        "scr_metric_threshold_50": 0.14285717664661948,
        "scr_dir2_threshold_50": 0.14285717664661948,
        "scr_dir1_threshold_100": 0.08064538354136737,
        "scr_metric_threshold_100": 0.09920647779407969,
        "scr_dir2_threshold_100": 0.09920647779407969,
        "scr_dir1_threshold_500": -0.06989219573519266,
        "scr_metric_threshold_500": 0.051587340069761074,
        "scr_dir2_threshold_500": 0.051587340069761074
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": -0.029629237171208758,
        "scr_metric_threshold_2": 0.08852462091935374,
        "scr_dir2_threshold_2": 0.08852462091935374,
        "scr_dir1_threshold_5": -0.02222192787840657,
        "scr_metric_threshold_5": 0.1016394012879684,
        "scr_dir2_threshold_5": 0.1016394012879684,
        "scr_dir1_threshold_10": 0.02962967868693224,
        "scr_metric_threshold_10": 0.14426238862970098,
        "scr_dir2_threshold_10": 0.14426238862970098,
        "scr_dir1_threshold_20": 0.14814839343466119,
        "scr_metric_threshold_20": 0.2327870095490547,
        "scr_dir2_threshold_20": 0.2327870095490547,
        "scr_dir1_threshold_50": 0.15555570272746339,
        "scr_metric_threshold_50": 0.23606565578494332,
        "scr_dir2_threshold_50": 0.23606565578494332,
        "scr_dir1_threshold_100": 0.12592602404053113,
        "scr_metric_threshold_100": 0.21639358294455147,
        "scr_dir2_threshold_100": 0.21639358294455147,
        "scr_dir1_threshold_500": -0.39999955848427654,
        "scr_metric_threshold_500": 0.15081968110147817,
        "scr_dir2_threshold_500": 0.15081968110147817
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.027027000903735277,
        "scr_metric_threshold_2": -0.008403251908725769,
        "scr_dir2_threshold_2": -0.008403251908725769,
        "scr_dir1_threshold_5": 0.07567566696791175,
        "scr_metric_threshold_5": -0.008403251908725769,
        "scr_dir2_threshold_5": -0.008403251908725769,
        "scr_dir1_threshold_10": -0.14594599819252943,
        "scr_metric_threshold_10": 0.012605128302735451,
        "scr_dir2_threshold_10": 0.012605128302735451,
        "scr_dir1_threshold_20": -0.016216329417147127,
        "scr_metric_threshold_20": 0.004201625954362884,
        "scr_dir2_threshold_20": 0.004201625954362884,
        "scr_dir1_threshold_50": 0.11891899728879417,
        "scr_metric_threshold_50": -0.04621838637728532,
        "scr_dir2_threshold_50": -0.04621838637728532,
        "scr_dir1_threshold_100": 0.09189167419779398,
        "scr_metric_threshold_100": -0.058823514680020776,
        "scr_dir2_threshold_100": -0.058823514680020776,
        "scr_dir1_threshold_500": 0.1297296687753823,
        "scr_metric_threshold_500": -0.10924377745131579,
        "scr_dir2_threshold_500": -0.10924377745131579
      }
    ],
    "sae_bench_commit_hash": "88c9225ec5f48485e1b632cf29a8e11e4d49547c",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_19_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 2304,
      "hook_layer": 19,
      "hook_name": "blocks.19.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "Custom",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}