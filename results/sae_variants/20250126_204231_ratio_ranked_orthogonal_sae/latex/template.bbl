\begin{thebibliography}{17}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Arora et~al.(2015)Arora, Ge, Ma, and Moitra]{Arora2015SimpleEA}
Sanjeev Arora, Rong Ge, Tengyu Ma, and Ankur Moitra.
\newblock Simple, efficient, and neural algorithms for sparse coding.
\newblock pp.\  113--149, 2015.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Bengio(2007)]{Bengio2007LearningDA}
Yoshua Bengio.
\newblock Learning deep architectures for ai.
\newblock \emph{Found. Trends Mach. Learn.}, 2:\penalty0 1--127, 2007.

\bibitem[Chen et~al.(2016)Chen, Duan, Houthooft, Schulman, Sutskever, and
  Abbeel]{Chen2016InfoGANIR}
Xi~Chen, Yan Duan, Rein Houthooft, John Schulman, I.~Sutskever, and P.~Abbeel.
\newblock Infogan: Interpretable representation learning by information
  maximizing generative adversarial nets.
\newblock pp.\  2172--2180, 2016.

\bibitem[Flesch et~al.(2021)Flesch, Juechems, Dumbalska, Saxe, and
  Summerfield]{Flesch2021RichAL}
Timo Flesch, Keno Juechems, T.~Dumbalska, Andrew~M. Saxe, and C.~Summerfield.
\newblock Rich and lazy learning of task representations in brains and neural
  networks.
\newblock \emph{bioRxiv}, 2021.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, Courville, and
  Bengio]{goodfellow2016deep}
Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio.
\newblock \emph{Deep learning}, volume~1.
\newblock MIT Press, 2016.

\bibitem[Higgins et~al.(2017)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{Higgins2017betaVAELB}
Irina Higgins, L.~Matthey, Arka Pal, Christopher~P. Burgess, Xavier Glorot,
  Matthew~M. Botvinick, Shakir Mohamed, and Alexander Lerchner.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock 2017.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Lan et~al.(2024)Lan, Torr, Meek, Khakzar, Krueger, and
  Barez]{Lan2024SparseAR}
Michael Lan, Philip Torr, Austin Meek, Ashkan Khakzar, David Krueger, and Fazl
  Barez.
\newblock Sparse autoencoders reveal universal feature spaces across large
  language models.
\newblock \emph{ArXiv}, abs/2410.06981, 2024.

\bibitem[Makelov et~al.(2024)Makelov, Lange, and Nanda]{Makelov2024TowardsPE}
Aleksandar Makelov, Georg Lange, and Neel Nanda.
\newblock Towards principled evaluations of sparse autoencoders for
  interpretability and control.
\newblock \emph{ArXiv}, abs/2405.08366, 2024.

\bibitem[Olshausen \& Field(1996)Olshausen and Field]{Olshausen1996EmergenceOS}
B.~Olshausen and D.~Field.
\newblock Emergence of simple-cell receptive field properties by learning a
  sparse code for natural images.
\newblock \emph{Nature}, 381:\penalty0 607--609, 1996.

\bibitem[OpenAI(2024)]{gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2024.
\newblock URL \url{https://arxiv.org/abs/2303.08774}.

\bibitem[Salimans \& Kingma(2016)Salimans and Kingma]{Salimans2016WeightNA}
Tim Salimans and Diederik~P. Kingma.
\newblock Weight normalization: A simple reparameterization to accelerate
  training of deep neural networks.
\newblock \emph{ArXiv}, abs/1602.07868, 2016.

\bibitem[Sirosh(1995)]{Sirosh1995ASN}
Joseph Sirosh.
\newblock A self-organizing neural network model of the primary visual cortex.
\newblock pp.\  815--818, 1995.

\bibitem[Suteu \& Guo(2019)Suteu and Guo]{Suteu2019RegularizingDM}
Mihai Suteu and Yike Guo.
\newblock Regularizing deep multi-task networks using orthogonal gradients.
\newblock \emph{ArXiv}, abs/1912.06844, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Zhou et~al.(2024)Zhou, Zhou, Liu, Gao, and Wang]{Zhou2024MitigatingFG}
Nuoyan Zhou, Dawei Zhou, Decheng Liu, Xinbo Gao, and Nannan Wang.
\newblock Mitigating feature gap for adversarial robustness by feature
  disentanglement.
\newblock \emph{ArXiv}, abs/2401.14707, 2024.

\end{thebibliography}
