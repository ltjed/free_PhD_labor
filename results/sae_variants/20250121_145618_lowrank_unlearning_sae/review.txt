{
    "Summary": "The paper presents FactorSAE, a memory-efficient sparse autoencoder architecture designed to enable memory-efficient knowledge editing in large language models through low-rank matrix factorization and block-diagonal feature isolation. The method aims to reduce memory requirements significantly while maintaining model functionality. The authors evaluate the approach on five specialized datasets and report stable training dynamics and memory efficiency. However, the method fails to achieve effective knowledge removal, as evidenced by unlearning scores of 0.0 across all configurations.",
    "Strengths": [
        "Addresses a significant issue in maintaining and updating large language models.",
        "Proposes a novel combination of low-rank matrix factorization and block-diagonal constraints for memory efficiency.",
        "Demonstrates significant memory reduction (90%) while maintaining model functionality."
    ],
    "Weaknesses": [
        "Fails to achieve the primary objective of effective knowledge removal, with unlearning scores of 0.0 across all configurations.",
        "Lacks clarity in the description of the autoencoder aggregator and feature attribution mechanism.",
        "Experimental results do not demonstrate the practical utility of the approach in real-world scenarios.",
        "The assumptions and motivations for the block-diagonal structure and rank-128 approximation are not well-justified.",
        "The paper does not provide sufficient empirical validation for the proposed assumptions."
    ],
    "Originality": 2,
    "Quality": 2,
    "Clarity": 2,
    "Significance": 2,
    "Questions": [
        "Can you provide more details on the autoencoder aggregator and its role in the architecture?",
        "How do you justify the choice of a rank-128 approximation and block-diagonal structure?",
        "What are the potential reasons for the failure to achieve effective knowledge removal?",
        "Can you provide more empirical evidence to support the assumptions made in the paper?"
    ],
    "Limitations": [
        "The paper fails to address the fundamental challenge of effective knowledge removal, which is the primary objective of the proposed method.",
        "The assumptions regarding the block-diagonal structure and rank-128 approximation are not well-justified and lack empirical validation."
    ],
    "Ethical Concerns": false,
    "Soundness": 1,
    "Presentation": 2,
    "Contribution": 2,
    "Overall": 3,
    "Confidence": 4,
    "Decision": "Reject"
}