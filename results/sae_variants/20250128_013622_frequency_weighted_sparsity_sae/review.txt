{
    "Summary": "The paper introduces frequency-weighted sparse autoencoders (FreqSAEs) to address the problem of feature absorption in traditional sparse autoencoders (SAEs). The proposed method dynamically adjusts sparsity penalties based on feature activation patterns tracked through exponential smoothing, which aims to prevent dominant features from absorbing others and encourages balanced feature specialization. The paper presents experimental results on the Gemma-2-2B language model, showing significant improvements in model behavior preservation, reconstruction quality, and training stability.",
    "Strengths": [
        "Addresses a significant problem in the field of sparse autoencoders: feature absorption.",
        "The proposed frequency-weighted regularization method shows promising results in preventing feature absorption and improving reconstruction quality and training stability.",
        "Comprehensive experimental results are presented, demonstrating significant improvements over standard SAEs.",
        "The method is computationally efficient, adding only O(n) operations per batch."
    ],
    "Weaknesses": [
        "The novelty of the approach is somewhat limited, as adaptive regularization is not entirely new.",
        "The paper lacks details on hyperparameter tuning and provides limited sensitivity analysis.",
        "Only one dataset (Gemma-2-2B) is used for evaluation, raising concerns about the generalizability of the results.",
        "Some sections of the paper, particularly the methodology, could be clearer and more detailed.",
        "The paper lacks a detailed ablation study to isolate the effects of different components of the proposed method.",
        "Limited comparison with other advanced methods beyond the standard SAE baseline, such as BatchTopK and Switch SAEs."
    ],
    "Originality": 3,
    "Quality": 3,
    "Clarity": 2,
    "Significance": 3,
    "Questions": [
        "Can the authors provide more details on the hyperparameter tuning process?",
        "How does the proposed method perform on other datasets or models?",
        "Can the authors provide more details on the implementation of the frequency-weighted regularization mechanism?",
        "How does the proposed method compare with BatchTopK and Switch SAEs in terms of feature absorption and other metrics?",
        "Can the authors include ablation studies to isolate the effects of different components of their method, such as the exponential smoothing factor and the frequency penalty coefficient?",
        "Is the method applicable to other types of models or domains beyond the Gemma-2-2B language model?"
    ],
    "Limitations": [
        "The paper does not provide sufficient details on the hyperparameter tuning process and offers limited sensitivity analysis.",
        "The evaluation is limited to a single dataset, raising concerns about generalizability.",
        "The method has some sensitivity to hyperparameter choices and incurs memory overhead, which could impact scalability. A more detailed discussion on these aspects would be beneficial."
    ],
    "Ethical Concerns": false,
    "Soundness": 3,
    "Presentation": 2,
    "Contribution": 3,
    "Overall": 5,
    "Confidence": 4,
    "Decision": "Reject"
}