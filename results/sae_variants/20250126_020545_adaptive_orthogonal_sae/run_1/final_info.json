{
  "training results": {
    "training_log": {
      "step 0": {
        "loss": 280.4226379394531,
        "l1_loss": 2692.192626953125,
        "l2_loss": 172.6608123779297,
        "ortho_loss": 0.741286039352417
      },
      "step 1": {
        "loss": 243.64956665039062,
        "l1_loss": 2632.935546875,
        "l2_loss": 138.26095581054688,
        "ortho_loss": 0.7119743227958679
      },
      "step 2": {
        "loss": 249.94200134277344,
        "l1_loss": 2702.074462890625,
        "l2_loss": 141.78500366210938,
        "ortho_loss": 0.7402211427688599
      },
      "step 3": {
        "loss": 249.8802947998047,
        "l1_loss": 2702.37548828125,
        "l2_loss": 141.71153259277344,
        "ortho_loss": 0.7374298572540283
      },
      "step 4": {
        "loss": 252.72512817382812,
        "l1_loss": 2733.4248046875,
        "l2_loss": 143.3136749267578,
        "ortho_loss": 0.7446606755256653
      },
      "step 5": {
        "loss": 244.97096252441406,
        "l1_loss": 2648.0673828125,
        "l2_loss": 138.97555541992188,
        "ortho_loss": 0.727008044719696
      },
      "step 6": {
        "loss": 247.56333923339844,
        "l1_loss": 2678.136962890625,
        "l2_loss": 140.36439514160156,
        "ortho_loss": 0.7346583604812622
      },
      "step 7": {
        "loss": 250.39816284179688,
        "l1_loss": 2709.99560546875,
        "l2_loss": 141.92401123046875,
        "ortho_loss": 0.7433661818504333
      },
      "step 8": {
        "loss": 247.76629638671875,
        "l1_loss": 2682.0224609375,
        "l2_loss": 140.41152954101562,
        "ortho_loss": 0.7387134432792664
      },
      "step 9": {
        "loss": 246.90866088867188,
        "l1_loss": 2673.4326171875,
        "l2_loss": 139.89877319335938,
        "ortho_loss": 0.7259096503257751
      },
      "step 10": {
        "loss": 245.66683959960938,
        "l1_loss": 2660.15087890625,
        "l2_loss": 139.1881866455078,
        "ortho_loss": 0.7261750102043152
      },
      "step 11": {
        "loss": 250.2109375,
        "l1_loss": 2711.39306640625,
        "l2_loss": 141.68130493164062,
        "ortho_loss": 0.7390769124031067
      },
      "step 12": {
        "loss": 247.05673217773438,
        "l1_loss": 2678.1611328125,
        "l2_loss": 139.85678100585938,
        "ortho_loss": 0.73517906665802
      },
      "step 13": {
        "loss": 242.24099731445312,
        "l1_loss": 2626.711669921875,
        "l2_loss": 137.10018920898438,
        "ortho_loss": 0.723397970199585
      },
      "step 14": {
        "loss": 249.46047973632812,
        "l1_loss": 2708.19580078125,
        "l2_loss": 141.0580596923828,
        "ortho_loss": 0.745859682559967
      },
      "step 15": {
        "loss": 240.19912719726562,
        "l1_loss": 2606.272705078125,
        "l2_loss": 135.87765502929688,
        "ortho_loss": 0.7055355906486511
      },
      "step 16": {
        "loss": 247.05169677734375,
        "l1_loss": 2684.575439453125,
        "l2_loss": 139.59527587890625,
        "ortho_loss": 0.7338883876800537
      },
      "step 17": {
        "loss": 246.51649475097656,
        "l1_loss": 2679.739013671875,
        "l2_loss": 139.25314331054688,
        "ortho_loss": 0.7378892302513123
      },
      "step 18": {
        "loss": 253.02630615234375,
        "l1_loss": 2753.6337890625,
        "l2_loss": 142.80564880371094,
        "ortho_loss": 0.7532190680503845
      },
      "step 19": {
        "loss": 238.01571655273438,
        "l1_loss": 2588.939453125,
        "l2_loss": 134.38735961914062,
        "ortho_loss": 0.7077009677886963
      },
      "step 20": {
        "loss": 243.52752685546875,
        "l1_loss": 2651.21337890625,
        "l2_loss": 137.40643310546875,
        "ortho_loss": 0.7257665991783142
      },
      "step 21": {
        "loss": 238.75816345214844,
        "l1_loss": 2601.4892578125,
        "l2_loss": 134.62606811523438,
        "ortho_loss": 0.7252346873283386
      },
      "step 22": {
        "loss": 244.79006958007812,
        "l1_loss": 2670.92236328125,
        "l2_loss": 137.8794708251953,
        "ortho_loss": 0.7370133996009827
      },
      "step 23": {
        "loss": 240.28932189941406,
        "l1_loss": 2623.88916015625,
        "l2_loss": 135.26055908203125,
        "ortho_loss": 0.7319428324699402
      },
      "step 24": {
        "loss": 238.23704528808594,
        "l1_loss": 2600.95654296875,
        "l2_loss": 134.12693786621094,
        "ortho_loss": 0.7184776067733765
      },
      "step 25": {
        "loss": 236.91366577148438,
        "l1_loss": 2589.65869140625,
        "l2_loss": 133.2553253173828,
        "ortho_loss": 0.7199111580848694
      },
      "step 26": {
        "loss": 232.6258087158203,
        "l1_loss": 2542.3388671875,
        "l2_loss": 130.86300659179688,
        "ortho_loss": 0.6926239728927612
      },
      "step 27": {
        "loss": 237.8189697265625,
        "l1_loss": 2601.419677734375,
        "l2_loss": 133.68984985351562,
        "ortho_loss": 0.7232376337051392
      },
      "step 28": {
        "loss": 237.57713317871094,
        "l1_loss": 2602.43994140625,
        "l2_loss": 133.4066162109375,
        "ortho_loss": 0.729162335395813
      },
      "step 29": {
        "loss": 242.7565155029297,
        "l1_loss": 2662.431640625,
        "l2_loss": 136.18527221679688,
        "ortho_loss": 0.7398430109024048
      },
      "step 30": {
        "loss": 245.08242797851562,
        "l1_loss": 2690.78857421875,
        "l2_loss": 137.3761444091797,
        "ortho_loss": 0.7474198341369629
      },
      "step 31": {
        "loss": 240.726806640625,
        "l1_loss": 2642.801025390625,
        "l2_loss": 134.94058227539062,
        "ortho_loss": 0.7419010400772095
      },
      "step 32": {
        "loss": 230.81826782226562,
        "l1_loss": 2533.2236328125,
        "l2_loss": 129.4184112548828,
        "ortho_loss": 0.7092053294181824
      },
      "step 33": {
        "loss": 237.1571044921875,
        "l1_loss": 2607.9833984375,
        "l2_loss": 132.76385498046875,
        "ortho_loss": 0.7391289472579956
      },
      "step 34": {
        "loss": 244.7565460205078,
        "l1_loss": 2695.02880859375,
        "l2_loss": 136.8802490234375,
        "ortho_loss": 0.7514708042144775
      },
      "step 35": {
        "loss": 239.08070373535156,
        "l1_loss": 2633.613525390625,
        "l2_loss": 133.6617431640625,
        "ortho_loss": 0.7441507577896118
      },
      "step 36": {
        "loss": 234.55653381347656,
        "l1_loss": 2585.5703125,
        "l2_loss": 131.06053161621094,
        "ortho_loss": 0.7319550514221191
      },
      "step 37": {
        "loss": 238.45541381835938,
        "l1_loss": 2630.9248046875,
        "l2_loss": 133.14398193359375,
        "ortho_loss": 0.7442959547042847
      },
      "step 38": {
        "loss": 235.7006072998047,
        "l1_loss": 2602.454833984375,
        "l2_loss": 131.52813720703125,
        "ortho_loss": 0.7428222894668579
      },
      "step 39": {
        "loss": 228.70021057128906,
        "l1_loss": 2522.714111328125,
        "l2_loss": 127.7196044921875,
        "ortho_loss": 0.7204386591911316
      },
      "step 40": {
        "loss": 233.1739044189453,
        "l1_loss": 2578.727783203125,
        "l2_loss": 129.95045471191406,
        "ortho_loss": 0.7434669137001038
      },
      "step 41": {
        "loss": 238.66818237304688,
        "l1_loss": 2643.217041015625,
        "l2_loss": 132.8639678955078,
        "ortho_loss": 0.7553638815879822
      },
      "step 42": {
        "loss": 234.54322814941406,
        "l1_loss": 2595.01416015625,
        "l2_loss": 130.66818237304688,
        "ortho_loss": 0.7447076439857483
      },
      "step 43": {
        "loss": 232.9159698486328,
        "l1_loss": 2577.806396484375,
        "l2_loss": 129.72946166992188,
        "ortho_loss": 0.742580235004425
      },
      "step 44": {
        "loss": 228.0931396484375,
        "l1_loss": 2527.2685546875,
        "l2_loss": 126.9285659790039,
        "ortho_loss": 0.7384253740310669
      },
      "step 45": {
        "loss": 228.68746948242188,
        "l1_loss": 2532.59033203125,
        "l2_loss": 127.3100814819336,
        "ortho_loss": 0.7377504706382751
      },
      "step 46": {
        "loss": 223.48129272460938,
        "l1_loss": 2473.064453125,
        "l2_loss": 124.48710632324219,
        "ortho_loss": 0.7160372138023376
      },
      "step 47": {
        "loss": 226.34759521484375,
        "l1_loss": 2510.073974609375,
        "l2_loss": 125.87117004394531,
        "ortho_loss": 0.7347190976142883
      },
      "step 48": {
        "loss": 232.85475158691406,
        "l1_loss": 2586.4580078125,
        "l2_loss": 129.32113647460938,
        "ortho_loss": 0.7530929446220398
      },
      "step 49": {
        "loss": 223.4406280517578,
        "l1_loss": 2478.9541015625,
        "l2_loss": 124.2097396850586,
        "ortho_loss": 0.7272464036941528
      },
      "step 50": {
        "loss": 221.43878173828125,
        "l1_loss": 2453.6259765625,
        "l2_loss": 123.22137451171875,
        "ortho_loss": 0.7236605286598206
      },
      "step 51": {
        "loss": 220.23081970214844,
        "l1_loss": 2441.002197265625,
        "l2_loss": 122.51905822753906,
        "ortho_loss": 0.7167724370956421
      },
      "step 52": {
        "loss": 221.03672790527344,
        "l1_loss": 2450.5712890625,
        "l2_loss": 122.9405517578125,
        "ortho_loss": 0.7331335544586182
      },
      "step 53": {
        "loss": 222.68618774414062,
        "l1_loss": 2471.015625,
        "l2_loss": 123.77204895019531,
        "ortho_loss": 0.7352144122123718
      },
      "step 54": {
        "loss": 225.66668701171875,
        "l1_loss": 2506.217529296875,
        "l2_loss": 125.34355163574219,
        "ortho_loss": 0.7442582845687866
      },
      "step 55": {
        "loss": 216.75059509277344,
        "l1_loss": 2401.36279296875,
        "l2_loss": 120.62413787841797,
        "ortho_loss": 0.7194793224334717
      },
      "step 56": {
        "loss": 225.71878051757812,
        "l1_loss": 2505.9228515625,
        "l2_loss": 125.40721130371094,
        "ortho_loss": 0.7464945316314697
      },
      "step 57": {
        "loss": 220.24839782714844,
        "l1_loss": 2443.627685546875,
        "l2_loss": 122.4297103881836,
        "ortho_loss": 0.7359863519668579
      },
      "step 58": {
        "loss": 218.81846618652344,
        "l1_loss": 2424.3447265625,
        "l2_loss": 121.77135467529297,
        "ortho_loss": 0.7331494092941284
      },
      "step 59": {
        "loss": 211.3588409423828,
        "l1_loss": 2338.658203125,
        "l2_loss": 117.74166870117188,
        "ortho_loss": 0.7083967924118042
      },
      "step 60": {
        "loss": 217.23936462402344,
        "l1_loss": 2408.2470703125,
        "l2_loss": 120.83574676513672,
        "ortho_loss": 0.7374202609062195
      },
      "step 61": {
        "loss": 212.96592712402344,
        "l1_loss": 2355.7109375,
        "l2_loss": 118.66557312011719,
        "ortho_loss": 0.7192133665084839
      },
      "step 62": {
        "loss": 211.70806884765625,
        "l1_loss": 2341.85205078125,
        "l2_loss": 117.96173858642578,
        "ortho_loss": 0.7225437760353088
      },
      "step 63": {
        "loss": 217.58714294433594,
        "l1_loss": 2410.138671875,
        "l2_loss": 121.10757446289062,
        "ortho_loss": 0.7401907444000244
      },
      "step 64": {
        "loss": 210.3202667236328,
        "l1_loss": 2322.209716796875,
        "l2_loss": 117.36028289794922,
        "ortho_loss": 0.7158788442611694
      },
      "step 65": {
        "loss": 208.7689208984375,
        "l1_loss": 2306.69775390625,
        "l2_loss": 116.42930603027344,
        "ortho_loss": 0.7171633839607239
      },
      "step 66": {
        "loss": 207.98837280273438,
        "l1_loss": 2294.69921875,
        "l2_loss": 116.12875366210938,
        "ortho_loss": 0.7165841460227966
      },
      "step 67": {
        "loss": 213.34744262695312,
        "l1_loss": 2358.11279296875,
        "l2_loss": 118.94868469238281,
        "ortho_loss": 0.742555558681488
      },
      "step 68": {
        "loss": 214.51107788085938,
        "l1_loss": 2373.478515625,
        "l2_loss": 119.49714660644531,
        "ortho_loss": 0.7479819655418396
      },
      "step 69": {
        "loss": 211.56419372558594,
        "l1_loss": 2336.4404296875,
        "l2_loss": 118.03251647949219,
        "ortho_loss": 0.7404434084892273
      },
      "step 70": {
        "loss": 208.39137268066406,
        "l1_loss": 2293.9990234375,
        "l2_loss": 116.55857849121094,
        "ortho_loss": 0.7283511161804199
      },
      "step 71": {
        "loss": 216.06076049804688,
        "l1_loss": 2387.287841796875,
        "l2_loss": 120.4940185546875,
        "ortho_loss": 0.752213180065155
      },
      "step 72": {
        "loss": 214.5456085205078,
        "l1_loss": 2364.639892578125,
        "l2_loss": 119.88505554199219,
        "ortho_loss": 0.7497228980064392
      },
      "step 73": {
        "loss": 202.9757843017578,
        "l1_loss": 2224.546630859375,
        "l2_loss": 113.92274475097656,
        "ortho_loss": 0.711788535118103
      },
      "step 74": {
        "loss": 207.8695831298828,
        "l1_loss": 2283.554931640625,
        "l2_loss": 116.4537353515625,
        "ortho_loss": 0.7365679740905762
      },
      "step 75": {
        "loss": 203.67514038085938,
        "l1_loss": 2231.40087890625,
        "l2_loss": 114.34608459472656,
        "ortho_loss": 0.7303354144096375
      },
      "step 76": {
        "loss": 206.29376220703125,
        "l1_loss": 2259.517578125,
        "l2_loss": 115.83934020996094,
        "ortho_loss": 0.7373195290565491
      },
      "step 77": {
        "loss": 213.2047882080078,
        "l1_loss": 2346.5791015625,
        "l2_loss": 119.265869140625,
        "ortho_loss": 0.7576013803482056
      },
      "step 78": {
        "loss": 200.3704833984375,
        "l1_loss": 2182.42822265625,
        "l2_loss": 113.0018539428711,
        "ortho_loss": 0.7149560451507568
      },
      "step 79": {
        "loss": 202.54148864746094,
        "l1_loss": 2207.83837890625,
        "l2_loss": 114.15548706054688,
        "ortho_loss": 0.7246122360229492
      },
      "step 80": {
        "loss": 198.76760864257812,
        "l1_loss": 2157.396484375,
        "l2_loss": 112.4002685546875,
        "ortho_loss": 0.7147903442382812
      },
      "step 81": {
        "loss": 207.17259216308594,
        "l1_loss": 2261.64404296875,
        "l2_loss": 116.63207244873047,
        "ortho_loss": 0.7474617958068848
      },
      "step 82": {
        "loss": 206.3424530029297,
        "l1_loss": 2250.58837890625,
        "l2_loss": 116.24380493164062,
        "ortho_loss": 0.7512246370315552
      },
      "step 83": {
        "loss": 200.14817810058594,
        "l1_loss": 2170.81396484375,
        "l2_loss": 113.24249267578125,
        "ortho_loss": 0.7313368320465088
      },
      "step 84": {
        "loss": 199.44126892089844,
        "l1_loss": 2161.5576171875,
        "l2_loss": 112.90577697753906,
        "ortho_loss": 0.7319550514221191
      },
      "step 85": {
        "loss": 198.1798858642578,
        "l1_loss": 2138.1552734375,
        "l2_loss": 112.58154296875,
        "ortho_loss": 0.7212342023849487
      },
      "step 86": {
        "loss": 206.89013671875,
        "l1_loss": 2246.79345703125,
        "l2_loss": 116.94261169433594,
        "ortho_loss": 0.7578361630439758
      },
      "step 87": {
        "loss": 201.591552734375,
        "l1_loss": 2180.5908203125,
        "l2_loss": 114.2931900024414,
        "ortho_loss": 0.7473919987678528
      },
      "step 88": {
        "loss": 193.26942443847656,
        "l1_loss": 2072.85693359375,
        "l2_loss": 110.28406524658203,
        "ortho_loss": 0.7109222412109375
      },
      "step 89": {
        "loss": 198.78970336914062,
        "l1_loss": 2143.701171875,
        "l2_loss": 112.96685028076172,
        "ortho_loss": 0.7479338049888611
      },
      "step 90": {
        "loss": 196.67559814453125,
        "l1_loss": 2109.171875,
        "l2_loss": 112.23493957519531,
        "ortho_loss": 0.7378881573677063
      },
      "step 91": {
        "loss": 200.97027587890625,
        "l1_loss": 2162.90869140625,
        "l2_loss": 114.37861633300781,
        "ortho_loss": 0.7531633377075195
      },
      "step 92": {
        "loss": 188.03421020507812,
        "l1_loss": 1994.86474609375,
        "l2_loss": 108.17155456542969,
        "ortho_loss": 0.6807690262794495
      },
      "step 93": {
        "loss": 201.39720153808594,
        "l1_loss": 2163.15576171875,
        "l2_loss": 114.79493713378906,
        "ortho_loss": 0.7602874040603638
      },
      "step 94": {
        "loss": 197.0018768310547,
        "l1_loss": 2106.27978515625,
        "l2_loss": 112.67546081542969,
        "ortho_loss": 0.7521945238113403
      },
      "step 95": {
        "loss": 193.16358947753906,
        "l1_loss": 2054.724365234375,
        "l2_loss": 110.90057373046875,
        "ortho_loss": 0.7405133843421936
      },
      "step 96": {
        "loss": 196.25938415527344,
        "l1_loss": 2092.12890625,
        "l2_loss": 112.49893951416016,
        "ortho_loss": 0.7529374361038208
      },
      "step 97": {
        "loss": 190.85394287109375,
        "l1_loss": 2015.516845703125,
        "l2_loss": 110.1595458984375,
        "ortho_loss": 0.7373802065849304
      },
      "step 98": {
        "loss": 195.09422302246094,
        "l1_loss": 2069.8408203125,
        "l2_loss": 112.22530364990234,
        "ortho_loss": 0.7528849244117737
      },
      "step 99": {
        "loss": 195.74154663085938,
        "l1_loss": 2081.06982421875,
        "l2_loss": 112.4229507446289,
        "ortho_loss": 0.7580689787864685
      },
      "step 100": {
        "loss": 188.45413208007812,
        "l1_loss": 1980.8299560546875,
        "l2_loss": 109.14702606201172,
        "ortho_loss": 0.7391270995140076
      },
      "step 101": {
        "loss": 185.2833709716797,
        "l1_loss": 1938.6337890625,
        "l2_loss": 107.66555786132812,
        "ortho_loss": 0.724714994430542
      },
      "step 102": {
        "loss": 191.55563354492188,
        "l1_loss": 2017.1357421875,
        "l2_loss": 110.79466247558594,
        "ortho_loss": 0.7554016709327698
      },
      "step 103": {
        "loss": 193.46261596679688,
        "l1_loss": 2037.514404296875,
        "l2_loss": 111.88617706298828,
        "ortho_loss": 0.7587155103683472
      },
      "step 104": {
        "loss": 185.4759521484375,
        "l1_loss": 1929.302734375,
        "l2_loss": 108.2302017211914,
        "ortho_loss": 0.736341655254364
      },
      "step 105": {
        "loss": 192.67759704589844,
        "l1_loss": 2019.90380859375,
        "l2_loss": 111.80546569824219,
        "ortho_loss": 0.7596908211708069
      },
      "step 106": {
        "loss": 191.44525146484375,
        "l1_loss": 2001.906005859375,
        "l2_loss": 111.29273986816406,
        "ortho_loss": 0.7626199722290039
      },
      "step 107": {
        "loss": 182.86056518554688,
        "l1_loss": 1886.633544921875,
        "l2_loss": 107.32188415527344,
        "ortho_loss": 0.7333546280860901
      },
      "step 108": {
        "loss": 190.37396240234375,
        "l1_loss": 1983.4320068359375,
        "l2_loss": 110.96066284179688,
        "ortho_loss": 0.7601974606513977
      },
      "step 109": {
        "loss": 181.1084442138672,
        "l1_loss": 1859.3504638671875,
        "l2_loss": 106.66091918945312,
        "ortho_loss": 0.7349866628646851
      },
      "step 110": {
        "loss": 193.89353942871094,
        "l1_loss": 2016.122314453125,
        "l2_loss": 113.1720199584961,
        "ortho_loss": 0.7662636637687683
      },
      "step 111": {
        "loss": 187.05239868164062,
        "l1_loss": 1930.886474609375,
        "l2_loss": 109.74089050292969,
        "ortho_loss": 0.7604967355728149
      },
      "step 112": {
        "loss": 185.16722106933594,
        "l1_loss": 1904.10986328125,
        "l2_loss": 108.92733764648438,
        "ortho_loss": 0.7549224495887756
      },
      "step 113": {
        "loss": 181.8105926513672,
        "l1_loss": 1851.320556640625,
        "l2_loss": 107.68344116210938,
        "ortho_loss": 0.7433164715766907
      },
      "step 114": {
        "loss": 177.646484375,
        "l1_loss": 1795.561767578125,
        "l2_loss": 105.75090026855469,
        "ortho_loss": 0.7311629056930542
      },
      "step 115": {
        "loss": 175.68106079101562,
        "l1_loss": 1763.843017578125,
        "l2_loss": 105.05570220947266,
        "ortho_loss": 0.7164139747619629
      },
      "step 116": {
        "loss": 180.92813110351562,
        "l1_loss": 1833.727783203125,
        "l2_loss": 107.50389099121094,
        "ortho_loss": 0.7513193488121033
      },
      "step 117": {
        "loss": 183.52920532226562,
        "l1_loss": 1862.53759765625,
        "l2_loss": 108.95185089111328,
        "ortho_loss": 0.7585135102272034
      },
      "step 118": {
        "loss": 177.06854248046875,
        "l1_loss": 1771.2979736328125,
        "l2_loss": 106.1427993774414,
        "ortho_loss": 0.7381662130355835
      },
      "step 119": {
        "loss": 179.65101623535156,
        "l1_loss": 1809.91162109375,
        "l2_loss": 107.17893981933594,
        "ortho_loss": 0.756016194820404
      },
      "step 120": {
        "loss": 182.39129638671875,
        "l1_loss": 1832.797607421875,
        "l2_loss": 109.00338745117188,
        "ortho_loss": 0.7600319981575012
      },
      "step 121": {
        "loss": 174.326171875,
        "l1_loss": 1729.7158203125,
        "l2_loss": 105.06370544433594,
        "ortho_loss": 0.7383919358253479
      },
      "step 122": {
        "loss": 173.8316192626953,
        "l1_loss": 1720.75244140625,
        "l2_loss": 104.92760467529297,
        "ortho_loss": 0.7393339276313782
      },
      "step 123": {
        "loss": 175.08969116210938,
        "l1_loss": 1737.1605224609375,
        "l2_loss": 105.52808380126953,
        "ortho_loss": 0.7519876956939697
      },
      "step 124": {
        "loss": 180.1658935546875,
        "l1_loss": 1800.682861328125,
        "l2_loss": 108.06204223632812,
        "ortho_loss": 0.765382707118988
      },
      "step 125": {
        "loss": 181.2781219482422,
        "l1_loss": 1812.0078125,
        "l2_loss": 108.72087097167969,
        "ortho_loss": 0.7694556713104248
      },
      "step 126": {
        "loss": 171.83889770507812,
        "l1_loss": 1680.12841796875,
        "l2_loss": 104.5591812133789,
        "ortho_loss": 0.7458224296569824
      },
      "step 127": {
        "loss": 175.52896118164062,
        "l1_loss": 1728.02587890625,
        "l2_loss": 106.33187866210938,
        "ortho_loss": 0.7605591416358948
      },
      "step 128": {
        "loss": 172.82632446289062,
        "l1_loss": 1685.9434814453125,
        "l2_loss": 105.3131103515625,
        "ortho_loss": 0.7547513842582703
      },
      "step 129": {
        "loss": 180.85031127929688,
        "l1_loss": 1792.0406494140625,
        "l2_loss": 109.09152221679688,
        "ortho_loss": 0.7716070413589478
      },
      "step 130": {
        "loss": 174.9434051513672,
        "l1_loss": 1709.7001953125,
        "l2_loss": 106.47904968261719,
        "ortho_loss": 0.763373076915741
      },
      "step 131": {
        "loss": 177.35812377929688,
        "l1_loss": 1733.255126953125,
        "l2_loss": 107.95127868652344,
        "ortho_loss": 0.7664904594421387
      },
      "step 132": {
        "loss": 170.79827880859375,
        "l1_loss": 1643.084228515625,
        "l2_loss": 104.99938201904297,
        "ortho_loss": 0.7552736401557922
      },
      "step 133": {
        "loss": 167.51239013671875,
        "l1_loss": 1598.8016357421875,
        "l2_loss": 103.48587036132812,
        "ortho_loss": 0.7445821166038513
      },
      "step 134": {
        "loss": 162.50796508789062,
        "l1_loss": 1533.5107421875,
        "l2_loss": 101.09542846679688,
        "ortho_loss": 0.7210888266563416
      },
      "step 135": {
        "loss": 164.96153259277344,
        "l1_loss": 1560.59619140625,
        "l2_loss": 102.46344757080078,
        "ortho_loss": 0.7423651218414307
      },
      "step 136": {
        "loss": 168.69712829589844,
        "l1_loss": 1603.379638671875,
        "l2_loss": 104.48587799072266,
        "ortho_loss": 0.7606008052825928
      },
      "step 137": {
        "loss": 171.6077880859375,
        "l1_loss": 1639.1634521484375,
        "l2_loss": 105.96442413330078,
        "ortho_loss": 0.7682163715362549
      },
      "step 138": {
        "loss": 164.49679565429688,
        "l1_loss": 1542.135498046875,
        "l2_loss": 102.73619079589844,
        "ortho_loss": 0.7518805861473083
      },
      "step 139": {
        "loss": 167.76040649414062,
        "l1_loss": 1582.858154296875,
        "l2_loss": 104.36969757080078,
        "ortho_loss": 0.763795018196106
      },
      "step 140": {
        "loss": 167.85116577148438,
        "l1_loss": 1577.323486328125,
        "l2_loss": 104.68193054199219,
        "ortho_loss": 0.7629363536834717
      },
      "step 141": {
        "loss": 168.334716796875,
        "l1_loss": 1581.914794921875,
        "l2_loss": 104.98157501220703,
        "ortho_loss": 0.7655006051063538
      },
      "step 142": {
        "loss": 163.5529022216797,
        "l1_loss": 1513.6246337890625,
        "l2_loss": 102.9322280883789,
        "ortho_loss": 0.7569162249565125
      },
      "step 143": {
        "loss": 165.36929321289062,
        "l1_loss": 1541.1182861328125,
        "l2_loss": 103.64781188964844,
        "ortho_loss": 0.7674531936645508
      },
      "step 144": {
        "loss": 166.83775329589844,
        "l1_loss": 1548.374267578125,
        "l2_loss": 104.82621765136719,
        "ortho_loss": 0.7657154202461243
      },
      "step 145": {
        "loss": 158.38851928710938,
        "l1_loss": 1436.940185546875,
        "l2_loss": 100.83670043945312,
        "ortho_loss": 0.7421738505363464
      },
      "step 146": {
        "loss": 165.66180419921875,
        "l1_loss": 1529.23193359375,
        "l2_loss": 104.41581726074219,
        "ortho_loss": 0.7670445442199707
      },
      "step 147": {
        "loss": 159.38812255859375,
        "l1_loss": 1441.0931396484375,
        "l2_loss": 101.66877746582031,
        "ortho_loss": 0.7562930583953857
      },
      "step 148": {
        "loss": 159.0232696533203,
        "l1_loss": 1430.359619140625,
        "l2_loss": 101.73363494873047,
        "ortho_loss": 0.7525804042816162
      },
      "step 149": {
        "loss": 155.49412536621094,
        "l1_loss": 1385.03662109375,
        "l2_loss": 100.01808166503906,
        "ortho_loss": 0.7459051609039307
      },
      "step 150": {
        "loss": 161.5020294189453,
        "l1_loss": 1453.81005859375,
        "l2_loss": 103.27315521240234,
        "ortho_loss": 0.7648032307624817
      },
      "step 151": {
        "loss": 162.23109436035156,
        "l1_loss": 1465.151611328125,
        "l2_loss": 103.54817199707031,
        "ortho_loss": 0.7685394287109375
      },
      "step 152": {
        "loss": 167.59263610839844,
        "l1_loss": 1536.8994140625,
        "l2_loss": 106.03899383544922,
        "ortho_loss": 0.77662593126297
      },
      "step 153": {
        "loss": 152.58233642578125,
        "l1_loss": 1330.04833984375,
        "l2_loss": 99.30619812011719,
        "ortho_loss": 0.7420524954795837
      },
      "step 154": {
        "loss": 159.98220825195312,
        "l1_loss": 1429.33984375,
        "l2_loss": 102.73155212402344,
        "ortho_loss": 0.7706295847892761
      },
      "step 155": {
        "loss": 159.33262634277344,
        "l1_loss": 1414.0087890625,
        "l2_loss": 102.6954574584961,
        "ortho_loss": 0.7683093547821045
      },
      "step 156": {
        "loss": 160.49745178222656,
        "l1_loss": 1427.146728515625,
        "l2_loss": 103.33439636230469,
        "ortho_loss": 0.7719878554344177
      },
      "step 157": {
        "loss": 154.60987854003906,
        "l1_loss": 1342.96630859375,
        "l2_loss": 100.81488037109375,
        "ortho_loss": 0.7634531855583191
      },
      "step 158": {
        "loss": 165.16419982910156,
        "l1_loss": 1486.1668701171875,
        "l2_loss": 105.63954162597656,
        "ortho_loss": 0.7799127101898193
      },
      "step 159": {
        "loss": 157.9299774169922,
        "l1_loss": 1389.717529296875,
        "l2_loss": 102.26395416259766,
        "ortho_loss": 0.7732043862342834
      },
      "step 160": {
        "loss": 158.13760375976562,
        "l1_loss": 1381.914306640625,
        "l2_loss": 102.78351593017578,
        "ortho_loss": 0.7751931548118591
      },
      "step 161": {
        "loss": 158.552490234375,
        "l1_loss": 1382.12744140625,
        "l2_loss": 103.18987274169922,
        "ortho_loss": 0.7750874161720276
      },
      "step 162": {
        "loss": 153.15167236328125,
        "l1_loss": 1310.240966796875,
        "l2_loss": 100.66532135009766,
        "ortho_loss": 0.7672111988067627
      },
      "step 163": {
        "loss": 156.51641845703125,
        "l1_loss": 1344.631103515625,
        "l2_loss": 102.65376281738281,
        "ortho_loss": 0.7741408944129944
      },
      "step 164": {
        "loss": 148.73211669921875,
        "l1_loss": 1242.997314453125,
        "l2_loss": 98.93606567382812,
        "ortho_loss": 0.7616183161735535
      },
      "step 165": {
        "loss": 156.04258728027344,
        "l1_loss": 1336.123291015625,
        "l2_loss": 102.52000427246094,
        "ortho_loss": 0.7764810919761658
      },
      "step 166": {
        "loss": 150.97659301757812,
        "l1_loss": 1266.5550537109375,
        "l2_loss": 100.23750305175781,
        "ortho_loss": 0.7688680291175842
      },
      "step 167": {
        "loss": 153.321533203125,
        "l1_loss": 1294.6624755859375,
        "l2_loss": 101.45741271972656,
        "ortho_loss": 0.7762615084648132
      },
      "step 168": {
        "loss": 152.05807495117188,
        "l1_loss": 1274.08740234375,
        "l2_loss": 101.01710510253906,
        "ortho_loss": 0.7748410701751709
      },
      "step 169": {
        "loss": 148.0838623046875,
        "l1_loss": 1215.510009765625,
        "l2_loss": 99.38697814941406,
        "ortho_loss": 0.7648128867149353
      },
      "step 170": {
        "loss": 147.3543701171875,
        "l1_loss": 1209.3251953125,
        "l2_loss": 98.90451049804688,
        "ortho_loss": 0.7685971856117249
      },
      "step 171": {
        "loss": 152.85755920410156,
        "l1_loss": 1280.62158203125,
        "l2_loss": 101.5548095703125,
        "ortho_loss": 0.7789120078086853
      },
      "step 172": {
        "loss": 152.05673217773438,
        "l1_loss": 1262.3973388671875,
        "l2_loss": 101.48306274414062,
        "ortho_loss": 0.7778115272521973
      },
      "step 173": {
        "loss": 151.15382385253906,
        "l1_loss": 1249.96826171875,
        "l2_loss": 101.07719421386719,
        "ortho_loss": 0.7789228558540344
      },
      "step 174": {
        "loss": 149.2609100341797,
        "l1_loss": 1214.4342041015625,
        "l2_loss": 100.60589599609375,
        "ortho_loss": 0.7765786647796631
      },
      "step 175": {
        "loss": 146.47763061523438,
        "l1_loss": 1174.996337890625,
        "l2_loss": 99.40058898925781,
        "ortho_loss": 0.771938681602478
      },
      "step 176": {
        "loss": 154.36868286132812,
        "l1_loss": 1281.2874755859375,
        "l2_loss": 103.03895568847656,
        "ortho_loss": 0.7823521494865417
      },
      "step 177": {
        "loss": 143.76480102539062,
        "l1_loss": 1130.0499267578125,
        "l2_loss": 98.48597717285156,
        "ortho_loss": 0.7683311700820923
      },
      "step 178": {
        "loss": 148.15768432617188,
        "l1_loss": 1184.97998046875,
        "l2_loss": 100.68073272705078,
        "ortho_loss": 0.7775956988334656
      },
      "step 179": {
        "loss": 143.5626220703125,
        "l1_loss": 1128.390625,
        "l2_loss": 98.34955596923828,
        "ortho_loss": 0.7743321657180786
      },
      "step 180": {
        "loss": 142.8838348388672,
        "l1_loss": 1115.451171875,
        "l2_loss": 98.18859100341797,
        "ortho_loss": 0.7718948721885681
      },
      "step 181": {
        "loss": 145.3431396484375,
        "l1_loss": 1145.14794921875,
        "l2_loss": 99.45954895019531,
        "ortho_loss": 0.7766262888908386
      },
      "step 182": {
        "loss": 143.25286865234375,
        "l1_loss": 1104.8651123046875,
        "l2_loss": 98.98086547851562,
        "ortho_loss": 0.7739042639732361
      },
      "step 183": {
        "loss": 139.33193969726562,
        "l1_loss": 1056.4937744140625,
        "l2_loss": 96.99534606933594,
        "ortho_loss": 0.7684615254402161
      },
      "step 184": {
        "loss": 144.2487030029297,
        "l1_loss": 1116.797119140625,
        "l2_loss": 99.49893951416016,
        "ortho_loss": 0.7788555026054382
      },
      "step 185": {
        "loss": 142.2022705078125,
        "l1_loss": 1088.2501220703125,
        "l2_loss": 98.5946044921875,
        "ortho_loss": 0.776744544506073
      },
      "step 186": {
        "loss": 143.2920684814453,
        "l1_loss": 1097.7098388671875,
        "l2_loss": 99.30570983886719,
        "ortho_loss": 0.7795040011405945
      },
      "step 187": {
        "loss": 139.82318115234375,
        "l1_loss": 1044.0692138671875,
        "l2_loss": 97.98296356201172,
        "ortho_loss": 0.7745504379272461
      },
      "step 188": {
        "loss": 143.00167846679688,
        "l1_loss": 1090.1728515625,
        "l2_loss": 99.31661224365234,
        "ortho_loss": 0.7815488576889038
      },
      "step 189": {
        "loss": 136.2490692138672,
        "l1_loss": 995.1671142578125,
        "l2_loss": 96.36561584472656,
        "ortho_loss": 0.7676798105239868
      },
      "step 190": {
        "loss": 136.67771911621094,
        "l1_loss": 993.0005493164062,
        "l2_loss": 96.88057708740234,
        "ortho_loss": 0.7711392045021057
      },
      "step 191": {
        "loss": 136.46853637695312,
        "l1_loss": 987.0201416015625,
        "l2_loss": 96.91050720214844,
        "ortho_loss": 0.7723103761672974
      },
      "step 192": {
        "loss": 147.28204345703125,
        "l1_loss": 1139.72802734375,
        "l2_loss": 101.6142349243164,
        "ortho_loss": 0.7869564294815063
      },
      "step 193": {
        "loss": 138.06466674804688,
        "l1_loss": 1008.8146362304688,
        "l2_loss": 97.63432312011719,
        "ortho_loss": 0.7775368690490723
      },
      "step 194": {
        "loss": 140.52650451660156,
        "l1_loss": 1036.7391357421875,
        "l2_loss": 98.97864532470703,
        "ortho_loss": 0.7829474806785583
      },
      "step 195": {
        "loss": 139.45089721679688,
        "l1_loss": 1019.7549438476562,
        "l2_loss": 98.58256530761719,
        "ortho_loss": 0.7814128994941711
      },
      "step 196": {
        "loss": 137.54647827148438,
        "l1_loss": 994.1756591796875,
        "l2_loss": 97.70132446289062,
        "ortho_loss": 0.7811994552612305
      },
      "step 197": {
        "loss": 141.2228546142578,
        "l1_loss": 1045.8389892578125,
        "l2_loss": 99.31073760986328,
        "ortho_loss": 0.7857155799865723
      },
      "step 198": {
        "loss": 135.2294158935547,
        "l1_loss": 953.4273681640625,
        "l2_loss": 97.01458740234375,
        "ortho_loss": 0.7773897647857666
      },
      "step 199": {
        "loss": 137.388671875,
        "l1_loss": 983.7816772460938,
        "l2_loss": 97.95909118652344,
        "ortho_loss": 0.7830865383148193
      },
      "step 200": {
        "loss": 136.09983825683594,
        "l1_loss": 956.1481323242188,
        "l2_loss": 97.77580261230469,
        "ortho_loss": 0.7810372114181519
      },
      "step 201": {
        "loss": 143.74667358398438,
        "l1_loss": 1059.4991455078125,
        "l2_loss": 101.28794860839844,
        "ortho_loss": 0.7875882387161255
      },
      "step 202": {
        "loss": 135.4368896484375,
        "l1_loss": 948.26171875,
        "l2_loss": 97.42815399169922,
        "ortho_loss": 0.7826696634292603
      },
      "step 203": {
        "loss": 134.77133178710938,
        "l1_loss": 942.4976806640625,
        "l2_loss": 96.99314880371094,
        "ortho_loss": 0.7827830910682678
      },
      "step 204": {
        "loss": 132.31723022460938,
        "l1_loss": 901.9425048828125,
        "l2_loss": 96.16157531738281,
        "ortho_loss": 0.7795881032943726
      },
      "step 205": {
        "loss": 140.98609924316406,
        "l1_loss": 1017.3001708984375,
        "l2_loss": 100.21522521972656,
        "ortho_loss": 0.7887096405029297
      },
      "step 206": {
        "loss": 138.39732360839844,
        "l1_loss": 985.3892211914062,
        "l2_loss": 98.9029541015625,
        "ortho_loss": 0.7880008220672607
      },
      "step 207": {
        "loss": 133.4365997314453,
        "l1_loss": 911.2843017578125,
        "l2_loss": 96.90684509277344,
        "ortho_loss": 0.7838611006736755
      },
      "step 208": {
        "loss": 131.47341918945312,
        "l1_loss": 881.1705932617188,
        "l2_loss": 96.14826202392578,
        "ortho_loss": 0.783393144607544
      },
      "step 209": {
        "loss": 130.84620666503906,
        "l1_loss": 860.467041015625,
        "l2_loss": 96.34944152832031,
        "ortho_loss": 0.7808592319488525
      },
      "step 210": {
        "loss": 136.33203125,
        "l1_loss": 937.4998168945312,
        "l2_loss": 98.75331115722656,
        "ortho_loss": 0.7873980402946472
      },
      "step 211": {
        "loss": 131.48129272460938,
        "l1_loss": 870.3193359375,
        "l2_loss": 96.5902328491211,
        "ortho_loss": 0.7829959392547607
      },
      "step 212": {
        "loss": 129.25807189941406,
        "l1_loss": 836.005859375,
        "l2_loss": 95.73966979980469,
        "ortho_loss": 0.7816441059112549
      },
      "step 213": {
        "loss": 131.3902587890625,
        "l1_loss": 857.4200439453125,
        "l2_loss": 97.0149154663086,
        "ortho_loss": 0.7853488326072693
      },
      "step 214": {
        "loss": 123.77832794189453,
        "l1_loss": 750.8702392578125,
        "l2_loss": 93.66653442382812,
        "ortho_loss": 0.7698836326599121
      },
      "step 215": {
        "loss": 128.531005859375,
        "l1_loss": 823.3509521484375,
        "l2_loss": 95.51860046386719,
        "ortho_loss": 0.7837015390396118
      },
      "step 216": {
        "loss": 125.78893280029297,
        "l1_loss": 777.5531616210938,
        "l2_loss": 94.60887145996094,
        "ortho_loss": 0.7793728113174438
      },
      "step 217": {
        "loss": 130.25926208496094,
        "l1_loss": 838.8887939453125,
        "l2_loss": 96.62512969970703,
        "ortho_loss": 0.7858601212501526
      },
      "step 218": {
        "loss": 131.1542205810547,
        "l1_loss": 837.5166625976562,
        "l2_loss": 97.57484436035156,
        "ortho_loss": 0.7870773673057556
      },
      "step 219": {
        "loss": 131.84664916992188,
        "l1_loss": 850.3109130859375,
        "l2_loss": 97.75538635253906,
        "ortho_loss": 0.7883432507514954
      },
      "step 220": {
        "loss": 124.80338287353516,
        "l1_loss": 753.3172607421875,
        "l2_loss": 94.59259796142578,
        "ortho_loss": 0.7809470295906067
      },
      "step 221": {
        "loss": 127.4715347290039,
        "l1_loss": 783.7523193359375,
        "l2_loss": 96.04296875,
        "ortho_loss": 0.7847844362258911
      },
      "step 222": {
        "loss": 127.91665649414062,
        "l1_loss": 795.3179931640625,
        "l2_loss": 96.02523803710938,
        "ortho_loss": 0.7869939804077148
      },
      "step 223": {
        "loss": 127.19609832763672,
        "l1_loss": 780.9276123046875,
        "l2_loss": 95.88035583496094,
        "ortho_loss": 0.7863370776176453
      },
      "step 224": {
        "loss": 125.73271179199219,
        "l1_loss": 763.9515991210938,
        "l2_loss": 95.09596252441406,
        "ortho_loss": 0.7869334816932678
      },
      "step 225": {
        "loss": 127.86461639404297,
        "l1_loss": 787.6773681640625,
        "l2_loss": 96.27873992919922,
        "ortho_loss": 0.7877967953681946
      },
      "step 226": {
        "loss": 122.64315032958984,
        "l1_loss": 710.141357421875,
        "l2_loss": 94.15921783447266,
        "ortho_loss": 0.7827959060668945
      },
      "step 227": {
        "loss": 126.42645263671875,
        "l1_loss": 761.9635009765625,
        "l2_loss": 95.8691177368164,
        "ortho_loss": 0.7879754900932312
      },
      "step 228": {
        "loss": 128.0265350341797,
        "l1_loss": 775.530029296875,
        "l2_loss": 96.9263687133789,
        "ortho_loss": 0.7896527051925659
      },
      "step 229": {
        "loss": 127.16508483886719,
        "l1_loss": 768.7273559570312,
        "l2_loss": 96.337158203125,
        "ortho_loss": 0.7883725166320801
      },
      "step 230": {
        "loss": 123.47671508789062,
        "l1_loss": 719.9254150390625,
        "l2_loss": 94.60099029541016,
        "ortho_loss": 0.787034809589386
      },
      "step 231": {
        "loss": 128.49642944335938,
        "l1_loss": 783.2551879882812,
        "l2_loss": 97.087158203125,
        "ortho_loss": 0.7906475067138672
      },
      "step 232": {
        "loss": 123.38723754882812,
        "l1_loss": 701.421630859375,
        "l2_loss": 95.25164031982422,
        "ortho_loss": 0.7873162627220154
      },
      "step 233": {
        "loss": 121.57071685791016,
        "l1_loss": 672.8286743164062,
        "l2_loss": 94.57904052734375,
        "ortho_loss": 0.785312294960022
      },
      "step 234": {
        "loss": 120.94120788574219,
        "l1_loss": 669.7470703125,
        "l2_loss": 94.07273864746094,
        "ortho_loss": 0.7858296036720276
      },
      "step 235": {
        "loss": 129.4496612548828,
        "l1_loss": 793.3687744140625,
        "l2_loss": 97.63568115234375,
        "ortho_loss": 0.7922595739364624
      },
      "step 236": {
        "loss": 126.6148910522461,
        "l1_loss": 748.3368530273438,
        "l2_loss": 96.60225677490234,
        "ortho_loss": 0.7916346788406372
      },
      "step 237": {
        "loss": 128.19284057617188,
        "l1_loss": 756.2882690429688,
        "l2_loss": 97.86213684082031,
        "ortho_loss": 0.7918116450309753
      },
      "step 238": {
        "loss": 121.28035736083984,
        "l1_loss": 665.9805908203125,
        "l2_loss": 94.56243896484375,
        "ortho_loss": 0.7869540452957153
      },
      "step 239": {
        "loss": 117.27854919433594,
        "l1_loss": 609.5211791992188,
        "l2_loss": 92.81928253173828,
        "ortho_loss": 0.7841981649398804
      },
      "step 240": {
        "loss": 115.54153442382812,
        "l1_loss": 582.94189453125,
        "l2_loss": 92.14598846435547,
        "ortho_loss": 0.7787609100341797
      },
      "step 241": {
        "loss": 126.29167175292969,
        "l1_loss": 728.2588500976562,
        "l2_loss": 97.0821304321289,
        "ortho_loss": 0.7918640971183777
      },
      "step 242": {
        "loss": 117.07369232177734,
        "l1_loss": 598.20361328125,
        "l2_loss": 93.06700897216797,
        "ortho_loss": 0.7853608727455139
      },
      "step 243": {
        "loss": 120.54344940185547,
        "l1_loss": 642.9138793945312,
        "l2_loss": 94.74798583984375,
        "ortho_loss": 0.7890992760658264
      },
      "step 244": {
        "loss": 120.5137710571289,
        "l1_loss": 649.5856323242188,
        "l2_loss": 94.45135498046875,
        "ortho_loss": 0.7898778319358826
      },
      "step 245": {
        "loss": 121.53109741210938,
        "l1_loss": 657.303466796875,
        "l2_loss": 95.15994262695312,
        "ortho_loss": 0.7901647686958313
      },
      "step 246": {
        "loss": 123.06881713867188,
        "l1_loss": 676.3138427734375,
        "l2_loss": 95.93704986572266,
        "ortho_loss": 0.7921499013900757
      },
      "step 247": {
        "loss": 117.75949096679688,
        "l1_loss": 603.6173095703125,
        "l2_loss": 93.53602600097656,
        "ortho_loss": 0.7877647876739502
      },
      "step 248": {
        "loss": 123.02552032470703,
        "l1_loss": 662.7152099609375,
        "l2_loss": 96.43771362304688,
        "ortho_loss": 0.7919793128967285
      },
      "step 249": {
        "loss": 120.10810852050781,
        "l1_loss": 628.44677734375,
        "l2_loss": 94.8912353515625,
        "ortho_loss": 0.7900484204292297
      },
      "step 250": {
        "loss": 118.73880767822266,
        "l1_loss": 606.537109375,
        "l2_loss": 94.39830017089844,
        "ortho_loss": 0.790260374546051
      },
      "step 251": {
        "loss": 126.098388671875,
        "l1_loss": 713.1430053710938,
        "l2_loss": 97.4932632446289,
        "ortho_loss": 0.7940356731414795
      },
      "step 252": {
        "loss": 122.71489715576172,
        "l1_loss": 659.815185546875,
        "l2_loss": 96.24299621582031,
        "ortho_loss": 0.7928917407989502
      },
      "step 253": {
        "loss": 121.63671112060547,
        "l1_loss": 637.0404052734375,
        "l2_loss": 96.07583618164062,
        "ortho_loss": 0.7925814986228943
      },
      "step 254": {
        "loss": 117.1408920288086,
        "l1_loss": 567.7578735351562,
        "l2_loss": 94.3516845703125,
        "ortho_loss": 0.7889434099197388
      },
      "step 255": {
        "loss": 116.87842559814453,
        "l1_loss": 568.0323486328125,
        "l2_loss": 94.0781478881836,
        "ortho_loss": 0.7898472547531128
      },
      "step 256": {
        "loss": 117.54501342773438,
        "l1_loss": 573.4207763671875,
        "l2_loss": 94.52911376953125,
        "ortho_loss": 0.7907010912895203
      },
      "step 257": {
        "loss": 121.20276641845703,
        "l1_loss": 636.7652587890625,
        "l2_loss": 95.65280151367188,
        "ortho_loss": 0.7935646176338196
      },
      "step 258": {
        "loss": 117.52747344970703,
        "l1_loss": 576.2427368164062,
        "l2_loss": 94.39861297607422,
        "ortho_loss": 0.7915335297584534
      },
      "step 259": {
        "loss": 118.28643035888672,
        "l1_loss": 587.8914794921875,
        "l2_loss": 94.69149780273438,
        "ortho_loss": 0.7927969098091125
      },
      "step 260": {
        "loss": 117.1314697265625,
        "l1_loss": 558.614501953125,
        "l2_loss": 94.70771789550781,
        "ortho_loss": 0.7917265892028809
      },
      "step 261": {
        "loss": 115.16793060302734,
        "l1_loss": 532.0810546875,
        "l2_loss": 93.80570983886719,
        "ortho_loss": 0.7897756695747375
      },
      "step 262": {
        "loss": 114.77437591552734,
        "l1_loss": 524.7017822265625,
        "l2_loss": 93.70726013183594,
        "ortho_loss": 0.7904801964759827
      },
      "step 263": {
        "loss": 116.20997619628906,
        "l1_loss": 540.4276123046875,
        "l2_loss": 94.51368713378906,
        "ortho_loss": 0.7918841242790222
      },
      "step 264": {
        "loss": 119.1286849975586,
        "l1_loss": 589.0609130859375,
        "l2_loss": 95.48684692382812,
        "ortho_loss": 0.794022262096405
      },
      "step 265": {
        "loss": 115.73199462890625,
        "l1_loss": 530.3971557617188,
        "l2_loss": 94.43695068359375,
        "ortho_loss": 0.7916334867477417
      },
      "step 266": {
        "loss": 119.07801818847656,
        "l1_loss": 585.5020751953125,
        "l2_loss": 95.57853698730469,
        "ortho_loss": 0.7939983010292053
      },
      "step 267": {
        "loss": 113.32862854003906,
        "l1_loss": 495.66717529296875,
        "l2_loss": 93.42292785644531,
        "ortho_loss": 0.7901272773742676
      },
      "step 268": {
        "loss": 119.478759765625,
        "l1_loss": 587.554931640625,
        "l2_loss": 95.8971176147461,
        "ortho_loss": 0.7944479584693909
      },
      "step 269": {
        "loss": 113.75450134277344,
        "l1_loss": 502.3911437988281,
        "l2_loss": 93.57963562011719,
        "ortho_loss": 0.7922700047492981
      },
      "step 270": {
        "loss": 113.14005279541016,
        "l1_loss": 480.7701416015625,
        "l2_loss": 93.8301773071289,
        "ortho_loss": 0.7907472848892212
      },
      "step 271": {
        "loss": 115.04722595214844,
        "l1_loss": 516.9368896484375,
        "l2_loss": 94.29043579101562,
        "ortho_loss": 0.7931775450706482
      },
      "step 272": {
        "loss": 119.06527709960938,
        "l1_loss": 572.0655517578125,
        "l2_loss": 96.10317993164062,
        "ortho_loss": 0.794767439365387
      },
      "step 273": {
        "loss": 118.4392318725586,
        "l1_loss": 561.7698974609375,
        "l2_loss": 95.88899230957031,
        "ortho_loss": 0.7944477796554565
      },
      "step 274": {
        "loss": 115.76549530029297,
        "l1_loss": 528.2264404296875,
        "l2_loss": 94.5570297241211,
        "ortho_loss": 0.7940367460250854
      },
      "step 275": {
        "loss": 115.40176391601562,
        "l1_loss": 516.5042114257812,
        "l2_loss": 94.66221618652344,
        "ortho_loss": 0.7937590479850769
      },
      "step 276": {
        "loss": 115.6840591430664,
        "l1_loss": 520.8582153320312,
        "l2_loss": 94.77029418945312,
        "ortho_loss": 0.7943388223648071
      },
      "step 277": {
        "loss": 115.82918548583984,
        "l1_loss": 525.6846313476562,
        "l2_loss": 94.7223129272461,
        "ortho_loss": 0.7948843240737915
      },
      "step 278": {
        "loss": 110.05487823486328,
        "l1_loss": 426.4148254394531,
        "l2_loss": 92.91929626464844,
        "ortho_loss": 0.7898606061935425
      },
      "step 279": {
        "loss": 111.26141357421875,
        "l1_loss": 454.93853759765625,
        "l2_loss": 92.984619140625,
        "ortho_loss": 0.7925150394439697
      },
      "step 280": {
        "loss": 111.82952117919922,
        "l1_loss": 451.5946044921875,
        "l2_loss": 93.6865005493164,
        "ortho_loss": 0.7923654317855835
      },
      "step 281": {
        "loss": 111.93710327148438,
        "l1_loss": 457.6450500488281,
        "l2_loss": 93.55198669433594,
        "ortho_loss": 0.7931202054023743
      },
      "step 282": {
        "loss": 109.62052917480469,
        "l1_loss": 423.68780517578125,
        "l2_loss": 92.59391784667969,
        "ortho_loss": 0.7910334467887878
      },
      "step 283": {
        "loss": 111.18807983398438,
        "l1_loss": 439.4596862792969,
        "l2_loss": 93.53041076660156,
        "ortho_loss": 0.7928643822669983
      },
      "step 284": {
        "loss": 116.09971618652344,
        "l1_loss": 513.4136962890625,
        "l2_loss": 95.48361206054688,
        "ortho_loss": 0.7955703735351562
      },
      "step 285": {
        "loss": 112.83121490478516,
        "l1_loss": 455.0870666503906,
        "l2_loss": 94.54833984375,
        "ortho_loss": 0.7939243912696838
      },
      "step 286": {
        "loss": 109.75527954101562,
        "l1_loss": 418.4099426269531,
        "l2_loss": 92.9395751953125,
        "ortho_loss": 0.7930544018745422
      },
      "step 287": {
        "loss": 110.9482192993164,
        "l1_loss": 443.1839599609375,
        "l2_loss": 93.14152526855469,
        "ortho_loss": 0.7933759689331055
      },
      "step 288": {
        "loss": 112.98858642578125,
        "l1_loss": 469.3084716796875,
        "l2_loss": 94.13674926757812,
        "ortho_loss": 0.7949662208557129
      },
      "step 289": {
        "loss": 109.75981903076172,
        "l1_loss": 427.9656982421875,
        "l2_loss": 92.5617904663086,
        "ortho_loss": 0.7939539551734924
      },
      "step 290": {
        "loss": 112.6360092163086,
        "l1_loss": 456.41644287109375,
        "l2_loss": 94.29985046386719,
        "ortho_loss": 0.7950690984725952
      },
      "step 291": {
        "loss": 107.81625366210938,
        "l1_loss": 384.3115234375,
        "l2_loss": 92.3646240234375,
        "ortho_loss": 0.7916787266731262
      },
      "step 292": {
        "loss": 114.77818298339844,
        "l1_loss": 498.50677490234375,
        "l2_loss": 94.75830841064453,
        "ortho_loss": 0.7960649132728577
      },
      "step 293": {
        "loss": 111.1434326171875,
        "l1_loss": 432.6529541015625,
        "l2_loss": 93.75782775878906,
        "ortho_loss": 0.7948121428489685
      },
      "step 294": {
        "loss": 111.11634063720703,
        "l1_loss": 426.28704833984375,
        "l2_loss": 93.98539733886719,
        "ortho_loss": 0.7946087121963501
      },
      "step 295": {
        "loss": 111.34468078613281,
        "l1_loss": 439.9142150878906,
        "l2_loss": 93.66857147216797,
        "ortho_loss": 0.7954691052436829
      },
      "step 296": {
        "loss": 112.68448638916016,
        "l1_loss": 462.0836181640625,
        "l2_loss": 94.12153625488281,
        "ortho_loss": 0.7960327863693237
      },
      "step 297": {
        "loss": 109.65081787109375,
        "l1_loss": 408.08734130859375,
        "l2_loss": 93.24785614013672,
        "ortho_loss": 0.7947016358375549
      },
      "step 298": {
        "loss": 115.68655395507812,
        "l1_loss": 505.82647705078125,
        "l2_loss": 95.37379455566406,
        "ortho_loss": 0.7969561815261841
      },
      "step 299": {
        "loss": 111.48635864257812,
        "l1_loss": 435.3133544921875,
        "l2_loss": 93.9942626953125,
        "ortho_loss": 0.7955619096755981
      },
      "step 300": {
        "loss": 110.39004516601562,
        "l1_loss": 423.24554443359375,
        "l2_loss": 93.38069915771484,
        "ortho_loss": 0.7952724695205688
      },
      "step 301": {
        "loss": 108.66627502441406,
        "l1_loss": 381.0389404296875,
        "l2_loss": 93.34526062011719,
        "ortho_loss": 0.7946220636367798
      },
      "step 302": {
        "loss": 106.93791198730469,
        "l1_loss": 357.94329833984375,
        "l2_loss": 92.54080200195312,
        "ortho_loss": 0.7937748432159424
      },
      "step 303": {
        "loss": 110.10504150390625,
        "l1_loss": 409.29730224609375,
        "l2_loss": 93.65357971191406,
        "ortho_loss": 0.7957634925842285
      },
      "step 304": {
        "loss": 110.52625274658203,
        "l1_loss": 416.6813049316406,
        "l2_loss": 93.77938842773438,
        "ortho_loss": 0.7961111068725586
      },
      "step 305": {
        "loss": 115.87767791748047,
        "l1_loss": 501.0545349121094,
        "l2_loss": 95.75576782226562,
        "ortho_loss": 0.7972670197486877
      },
      "step 306": {
        "loss": 115.09196472167969,
        "l1_loss": 489.1177978515625,
        "l2_loss": 95.4475326538086,
        "ortho_loss": 0.7971976399421692
      },
      "step 307": {
        "loss": 109.73945617675781,
        "l1_loss": 399.1894226074219,
        "l2_loss": 93.69229888916016,
        "ortho_loss": 0.7957983016967773
      },
      "step 308": {
        "loss": 110.82282257080078,
        "l1_loss": 417.6307067871094,
        "l2_loss": 94.03794860839844,
        "ortho_loss": 0.7964616417884827
      },
      "step 309": {
        "loss": 106.12425231933594,
        "l1_loss": 348.2637939453125,
        "l2_loss": 92.11429595947266,
        "ortho_loss": 0.7941033840179443
      },
      "step 310": {
        "loss": 107.17079162597656,
        "l1_loss": 358.66204833984375,
        "l2_loss": 92.74479675292969,
        "ortho_loss": 0.7951198220252991
      },
      "step 311": {
        "loss": 107.0848159790039,
        "l1_loss": 359.19207763671875,
        "l2_loss": 92.63762664794922,
        "ortho_loss": 0.7950258255004883
      },
      "step 312": {
        "loss": 105.88426208496094,
        "l1_loss": 336.6426696777344,
        "l2_loss": 92.33911895751953,
        "ortho_loss": 0.7943578362464905
      },
      "step 313": {
        "loss": 112.43649291992188,
        "l1_loss": 430.321044921875,
        "l2_loss": 95.14396667480469,
        "ortho_loss": 0.7968083620071411
      },
      "step 314": {
        "loss": 110.28162384033203,
        "l1_loss": 403.17474365234375,
        "l2_loss": 94.07495880126953,
        "ortho_loss": 0.7967601418495178
      },
      "step 315": {
        "loss": 106.93079376220703,
        "l1_loss": 354.14678955078125,
        "l2_loss": 92.68540954589844,
        "ortho_loss": 0.795127809047699
      },
      "step 316": {
        "loss": 110.4864501953125,
        "l1_loss": 411.34930419921875,
        "l2_loss": 93.95278930664062,
        "ortho_loss": 0.7968584299087524
      },
      "step 317": {
        "loss": 108.69268798828125,
        "l1_loss": 369.08746337890625,
        "l2_loss": 93.84957885742188,
        "ortho_loss": 0.7960948944091797
      },
      "step 318": {
        "loss": 112.8586196899414,
        "l1_loss": 446.8337707519531,
        "l2_loss": 94.90552520751953,
        "ortho_loss": 0.7974607348442078
      },
      "step 319": {
        "loss": 109.76705932617188,
        "l1_loss": 389.63018798828125,
        "l2_loss": 94.10214233398438,
        "ortho_loss": 0.7971165776252747
      },
      "step 320": {
        "loss": 113.50308990478516,
        "l1_loss": 451.7769775390625,
        "l2_loss": 95.35222625732422,
        "ortho_loss": 0.7978252172470093
      },
      "step 321": {
        "loss": 106.16312408447266,
        "l1_loss": 337.51458740234375,
        "l2_loss": 92.58296203613281,
        "ortho_loss": 0.7958505749702454
      },
      "step 322": {
        "loss": 108.68048858642578,
        "l1_loss": 375.8908996582031,
        "l2_loss": 93.56517791748047,
        "ortho_loss": 0.7967445850372314
      },
      "step 323": {
        "loss": 110.15148162841797,
        "l1_loss": 398.250244140625,
        "l2_loss": 94.14176940917969,
        "ortho_loss": 0.7970390915870667
      },
      "step 324": {
        "loss": 106.5763931274414,
        "l1_loss": 341.7461242675781,
        "l2_loss": 92.82691955566406,
        "ortho_loss": 0.7962810397148132
      },
      "step 325": {
        "loss": 106.0411148071289,
        "l1_loss": 340.0469970703125,
        "l2_loss": 92.35957336425781,
        "ortho_loss": 0.7965617179870605
      },
      "step 326": {
        "loss": 106.28787994384766,
        "l1_loss": 328.2503967285156,
        "l2_loss": 93.07825469970703,
        "ortho_loss": 0.796136200428009
      },
      "step 327": {
        "loss": 105.98640441894531,
        "l1_loss": 335.39532470703125,
        "l2_loss": 92.490966796875,
        "ortho_loss": 0.7963125109672546
      },
      "step 328": {
        "loss": 108.38095092773438,
        "l1_loss": 375.78314208984375,
        "l2_loss": 93.26990509033203,
        "ortho_loss": 0.7972017526626587
      },
      "step 329": {
        "loss": 107.62578582763672,
        "l1_loss": 341.1541442871094,
        "l2_loss": 93.89996337890625,
        "ortho_loss": 0.7965587973594666
      },
      "step 330": {
        "loss": 104.70189666748047,
        "l1_loss": 305.5462341308594,
        "l2_loss": 92.40043640136719,
        "ortho_loss": 0.7961235046386719
      },
      "step 331": {
        "loss": 112.65538024902344,
        "l1_loss": 420.3020935058594,
        "l2_loss": 95.76350402832031,
        "ortho_loss": 0.797846794128418
      },
      "step 332": {
        "loss": 108.7423095703125,
        "l1_loss": 369.78875732421875,
        "l2_loss": 93.87104034423828,
        "ortho_loss": 0.7971954345703125
      },
      "step 333": {
        "loss": 108.6608657836914,
        "l1_loss": 373.68670654296875,
        "l2_loss": 93.63365173339844,
        "ortho_loss": 0.7975265383720398
      },
      "step 334": {
        "loss": 112.79646301269531,
        "l1_loss": 437.27490234375,
        "l2_loss": 95.22566223144531,
        "ortho_loss": 0.7980189323425293
      },
      "step 335": {
        "loss": 105.51964569091797,
        "l1_loss": 318.79437255859375,
        "l2_loss": 92.68817901611328,
        "ortho_loss": 0.796876847743988
      },
      "step 336": {
        "loss": 107.60633087158203,
        "l1_loss": 347.0163269042969,
        "l2_loss": 93.64592742919922,
        "ortho_loss": 0.7974866032600403
      },
      "step 337": {
        "loss": 103.54632568359375,
        "l1_loss": 285.1545104980469,
        "l2_loss": 92.060546875,
        "ortho_loss": 0.7959471940994263
      },
      "step 338": {
        "loss": 105.40401458740234,
        "l1_loss": 321.86767578125,
        "l2_loss": 92.44956970214844,
        "ortho_loss": 0.7973772287368774
      },
      "step 339": {
        "loss": 106.06475067138672,
        "l1_loss": 314.187255859375,
        "l2_loss": 93.41757202148438,
        "ortho_loss": 0.7968772053718567
      },
      "step 340": {
        "loss": 102.4796142578125,
        "l1_loss": 272.32696533203125,
        "l2_loss": 91.5069580078125,
        "ortho_loss": 0.7957661151885986
      },
      "step 341": {
        "loss": 107.98199462890625,
        "l1_loss": 348.38983154296875,
        "l2_loss": 93.96664428710938,
        "ortho_loss": 0.7975988388061523
      },
      "step 342": {
        "loss": 109.39067077636719,
        "l1_loss": 383.86981201171875,
        "l2_loss": 93.95606994628906,
        "ortho_loss": 0.7981430888175964
      },
      "step 343": {
        "loss": 106.62859344482422,
        "l1_loss": 327.10186767578125,
        "l2_loss": 93.46478271484375,
        "ortho_loss": 0.7973233461380005
      },
      "step 344": {
        "loss": 106.20818328857422,
        "l1_loss": 324.5677185058594,
        "l2_loss": 93.14572143554688,
        "ortho_loss": 0.7974817752838135
      },
      "step 345": {
        "loss": 106.78113555908203,
        "l1_loss": 333.9178771972656,
        "l2_loss": 93.34465026855469,
        "ortho_loss": 0.7977225184440613
      },
      "step 346": {
        "loss": 103.21311950683594,
        "l1_loss": 280.0174560546875,
        "l2_loss": 91.93274688720703,
        "ortho_loss": 0.7967283725738525
      },
      "step 347": {
        "loss": 114.4992446899414,
        "l1_loss": 450.9613342285156,
        "l2_loss": 96.38092803955078,
        "ortho_loss": 0.7986562848091125
      },
      "step 348": {
        "loss": 106.5076904296875,
        "l1_loss": 321.177734375,
        "l2_loss": 93.58084106445312,
        "ortho_loss": 0.7974410057067871
      },
      "step 349": {
        "loss": 106.4517822265625,
        "l1_loss": 327.66693115234375,
        "l2_loss": 93.26533508300781,
        "ortho_loss": 0.7976930141448975
      },
      "step 350": {
        "loss": 108.67140197753906,
        "l1_loss": 372.456298828125,
        "l2_loss": 93.69331359863281,
        "ortho_loss": 0.7983334064483643
      },
      "step 351": {
        "loss": 104.86709594726562,
        "l1_loss": 300.8155822753906,
        "l2_loss": 92.75471496582031,
        "ortho_loss": 0.7976062297821045
      },
      "step 352": {
        "loss": 112.38849639892578,
        "l1_loss": 429.4228210449219,
        "l2_loss": 95.13170623779297,
        "ortho_loss": 0.7987754940986633
      },
      "step 353": {
        "loss": 105.12694549560547,
        "l1_loss": 310.1777038574219,
        "l2_loss": 92.64006042480469,
        "ortho_loss": 0.7977879643440247
      },
      "step 354": {
        "loss": 105.93928527832031,
        "l1_loss": 318.04827880859375,
        "l2_loss": 93.13755798339844,
        "ortho_loss": 0.7979678511619568
      },
      "step 355": {
        "loss": 106.56002807617188,
        "l1_loss": 326.91070556640625,
        "l2_loss": 93.40377807617188,
        "ortho_loss": 0.7981696724891663
      },
      "step 356": {
        "loss": 109.00093841552734,
        "l1_loss": 366.5531005859375,
        "l2_loss": 94.25897216796875,
        "ortho_loss": 0.7984192371368408
      },
      "step 357": {
        "loss": 99.91466522216797,
        "l1_loss": 219.5687255859375,
        "l2_loss": 91.05238342285156,
        "ortho_loss": 0.7953417897224426
      },
      "step 358": {
        "loss": 105.48027801513672,
        "l1_loss": 311.24652099609375,
        "l2_loss": 92.95060729980469,
        "ortho_loss": 0.7981249690055847
      },
      "step 359": {
        "loss": 110.33773040771484,
        "l1_loss": 388.36444091796875,
        "l2_loss": 94.72328186035156,
        "ortho_loss": 0.798750638961792
      },
      "step 360": {
        "loss": 107.00116729736328,
        "l1_loss": 329.512451171875,
        "l2_loss": 93.7408447265625,
        "ortho_loss": 0.7982906699180603
      },
      "step 361": {
        "loss": 106.0544662475586,
        "l1_loss": 310.76690673828125,
        "l2_loss": 93.5439682006836,
        "ortho_loss": 0.7981515526771545
      },
      "step 362": {
        "loss": 103.09434509277344,
        "l1_loss": 269.1945495605469,
        "l2_loss": 92.2468032836914,
        "ortho_loss": 0.7976012229919434
      },
      "step 363": {
        "loss": 106.08135986328125,
        "l1_loss": 316.4752502441406,
        "l2_loss": 93.34251403808594,
        "ortho_loss": 0.7983134388923645
      },
      "step 364": {
        "loss": 102.79657745361328,
        "l1_loss": 264.9813537597656,
        "l2_loss": 92.11753845214844,
        "ortho_loss": 0.7978845834732056
      },
      "step 365": {
        "loss": 110.90160369873047,
        "l1_loss": 400.0026550292969,
        "l2_loss": 94.82160186767578,
        "ortho_loss": 0.798913300037384
      },
      "step 366": {
        "loss": 107.16002655029297,
        "l1_loss": 330.6288757324219,
        "l2_loss": 93.85502624511719,
        "ortho_loss": 0.7984369397163391
      },
      "step 367": {
        "loss": 103.21469116210938,
        "l1_loss": 271.47015380859375,
        "l2_loss": 92.27609252929688,
        "ortho_loss": 0.7979689836502075
      },
      "step 368": {
        "loss": 103.61563110351562,
        "l1_loss": 289.85601806640625,
        "l2_loss": 91.94157409667969,
        "ortho_loss": 0.7981950044631958
      },
      "step 369": {
        "loss": 108.29035186767578,
        "l1_loss": 346.9141845703125,
        "l2_loss": 94.33392333984375,
        "ortho_loss": 0.7986593246459961
      },
      "step 370": {
        "loss": 106.07354736328125,
        "l1_loss": 317.3048095703125,
        "l2_loss": 93.30150604248047,
        "ortho_loss": 0.7984777092933655
      },
      "step 371": {
        "loss": 104.71155548095703,
        "l1_loss": 303.9747619628906,
        "l2_loss": 92.47271728515625,
        "ortho_loss": 0.7985042929649353
      },
      "step 372": {
        "loss": 110.17091369628906,
        "l1_loss": 379.9417419433594,
        "l2_loss": 94.89334869384766,
        "ortho_loss": 0.7989398241043091
      },
      "step 373": {
        "loss": 103.72618103027344,
        "l1_loss": 272.92608642578125,
        "l2_loss": 92.72931671142578,
        "ortho_loss": 0.7981721758842468
      },
      "step 374": {
        "loss": 104.58415222167969,
        "l1_loss": 301.0480041503906,
        "l2_loss": 92.46237182617188,
        "ortho_loss": 0.7986215949058533
      },
      "step 375": {
        "loss": 101.26197814941406,
        "l1_loss": 236.32362365722656,
        "l2_loss": 91.7292709350586,
        "ortho_loss": 0.7976222038269043
      },
      "step 376": {
        "loss": 101.63785552978516,
        "l1_loss": 236.63877868652344,
        "l2_loss": 92.09255981445312,
        "ortho_loss": 0.7974317073822021
      },
      "step 377": {
        "loss": 107.21855163574219,
        "l1_loss": 335.87359619140625,
        "l2_loss": 93.70372009277344,
        "ortho_loss": 0.7988559007644653
      },
      "step 378": {
        "loss": 104.18260192871094,
        "l1_loss": 289.0025634765625,
        "l2_loss": 92.54265594482422,
        "ortho_loss": 0.7984530329704285
      },
      "step 379": {
        "loss": 100.46542358398438,
        "l1_loss": 228.01519775390625,
        "l2_loss": 91.26502990722656,
        "ortho_loss": 0.7978461980819702
      },
      "step 380": {
        "loss": 107.2984390258789,
        "l1_loss": 342.64306640625,
        "l2_loss": 93.51283264160156,
        "ortho_loss": 0.7988432049751282
      },
      "step 381": {
        "loss": 104.32825469970703,
        "l1_loss": 274.8555603027344,
        "l2_loss": 93.25418090820312,
        "ortho_loss": 0.7985273599624634
      },
      "step 382": {
        "loss": 101.35762786865234,
        "l1_loss": 237.68099975585938,
        "l2_loss": 91.77058410644531,
        "ortho_loss": 0.7980391979217529
      },
      "step 383": {
        "loss": 100.54635620117188,
        "l1_loss": 226.73977661132812,
        "l2_loss": 91.39698791503906,
        "ortho_loss": 0.7978439331054688
      },
      "step 384": {
        "loss": 101.7844009399414,
        "l1_loss": 243.48919677734375,
        "l2_loss": 91.96501159667969,
        "ortho_loss": 0.7982078790664673
      },
      "step 385": {
        "loss": 107.50941467285156,
        "l1_loss": 337.650146484375,
        "l2_loss": 93.92351531982422,
        "ortho_loss": 0.7989197969436646
      },
      "step 386": {
        "loss": 104.0838851928711,
        "l1_loss": 282.9296875,
        "l2_loss": 92.68683624267578,
        "ortho_loss": 0.7986114025115967
      },
      "step 387": {
        "loss": 103.42381286621094,
        "l1_loss": 264.45428466796875,
        "l2_loss": 92.76580810546875,
        "ortho_loss": 0.7983718514442444
      },
      "step 388": {
        "loss": 106.6408462524414,
        "l1_loss": 324.0714111328125,
        "l2_loss": 93.59809112548828,
        "ortho_loss": 0.7989991903305054
      },
      "step 389": {
        "loss": 103.90843963623047,
        "l1_loss": 276.9677734375,
        "l2_loss": 92.74984741210938,
        "ortho_loss": 0.7987677454948425
      },
      "step 390": {
        "loss": 105.50684356689453,
        "l1_loss": 302.23236083984375,
        "l2_loss": 93.33766174316406,
        "ortho_loss": 0.7988912463188171
      },
      "step 391": {
        "loss": 101.15848541259766,
        "l1_loss": 241.2441864013672,
        "l2_loss": 91.42889404296875,
        "ortho_loss": 0.7982717156410217
      },
      "step 392": {
        "loss": 103.5576400756836,
        "l1_loss": 282.3631591796875,
        "l2_loss": 92.18323516845703,
        "ortho_loss": 0.7988021373748779
      },
      "step 393": {
        "loss": 103.78157806396484,
        "l1_loss": 276.4954833984375,
        "l2_loss": 92.64189147949219,
        "ortho_loss": 0.7986687421798706
      },
      "step 394": {
        "loss": 105.73917388916016,
        "l1_loss": 312.35711669921875,
        "l2_loss": 93.16499328613281,
        "ortho_loss": 0.7989680171012878
      },
      "step 395": {
        "loss": 102.01484680175781,
        "l1_loss": 255.1651153564453,
        "l2_loss": 91.72838592529297,
        "ortho_loss": 0.7985743284225464
      },
      "step 396": {
        "loss": 101.7677993774414,
        "l1_loss": 251.81582641601562,
        "l2_loss": 91.61529541015625,
        "ortho_loss": 0.798691987991333
      },
      "step 397": {
        "loss": 101.3851318359375,
        "l1_loss": 233.8252410888672,
        "l2_loss": 91.9522705078125,
        "ortho_loss": 0.7984715104103088
      },
      "step 398": {
        "loss": 105.72972106933594,
        "l1_loss": 321.83551025390625,
        "l2_loss": 92.77638244628906,
        "ortho_loss": 0.7991897463798523
      },
      "step 399": {
        "loss": 103.09209442138672,
        "l1_loss": 279.1685791015625,
        "l2_loss": 91.845458984375,
        "ortho_loss": 0.7989323139190674
      },
      "step 400": {
        "loss": 102.64456176757812,
        "l1_loss": 258.440185546875,
        "l2_loss": 92.2270736694336,
        "ortho_loss": 0.7987712621688843
      },
      "step 401": {
        "loss": 103.4046401977539,
        "l1_loss": 277.50128173828125,
        "l2_loss": 92.22469329833984,
        "ortho_loss": 0.7989545464515686
      },
      "step 402": {
        "loss": 101.5807113647461,
        "l1_loss": 255.6643829345703,
        "l2_loss": 91.27424621582031,
        "ortho_loss": 0.7988998293876648
      },
      "step 403": {
        "loss": 104.32038116455078,
        "l1_loss": 293.1702575683594,
        "l2_loss": 92.513671875,
        "ortho_loss": 0.7990455031394958
      },
      "step 404": {
        "loss": 101.97876739501953,
        "l1_loss": 252.9647216796875,
        "l2_loss": 91.78028869628906,
        "ortho_loss": 0.7988860607147217
      },
      "step 405": {
        "loss": 105.53707885742188,
        "l1_loss": 320.62725830078125,
        "l2_loss": 92.63207244873047,
        "ortho_loss": 0.7991766929626465
      },
      "step 406": {
        "loss": 105.92807006835938,
        "l1_loss": 325.81494140625,
        "l2_loss": 92.81554412841797,
        "ortho_loss": 0.7992523312568665
      },
      "step 407": {
        "loss": 105.44241333007812,
        "l1_loss": 315.41943359375,
        "l2_loss": 92.74571228027344,
        "ortho_loss": 0.7992264032363892
      }
    },
    "config": {
      "trainer_class": "CustomTrainer",
      "activation_dim": 2304,
      "dict_size": 2304,
      "lr": 0.0003,
      "l1_penalty": 0.04,
      "warmup_steps": 1000,
      "resample_steps": null,
      "device": "cuda",
      "layer": 5,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "CustomTrainer",
      "submodule_name": "resid_post_layer_5"
    },
    "final_info": {
      "training_steps": 488,
      "final_loss": 94.71179962158203,
      "layer": 5,
      "dict_size": 2304,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "dee137ba-368b-412b-97e4-5bfe76fd25e1",
    "datetime_epoch_millis": 1737875504722,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.006710192260088017,
        "mean_num_split_features": 1.4230769230769231
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.0007671653241273494,
        "num_absorption": 2,
        "num_probe_true_positives": 2607,
        "num_split_features": 3
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.01322418136020151,
        "num_absorption": 21,
        "num_probe_true_positives": 1588,
        "num_split_features": 2
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 2851,
        "num_split_features": 3
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.012582384661473937,
        "num_absorption": 21,
        "num_probe_true_positives": 1669,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.0018656716417910447,
        "num_absorption": 3,
        "num_probe_true_positives": 1608,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1255,
        "num_split_features": 2
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.004642525533890436,
        "num_absorption": 5,
        "num_probe_true_positives": 1077,
        "num_split_features": 1
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.006349206349206349,
        "num_absorption": 6,
        "num_probe_true_positives": 945,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.000612369871402327,
        "num_absorption": 1,
        "num_probe_true_positives": 1633,
        "num_split_features": 2
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.009174311926605505,
        "num_absorption": 4,
        "num_probe_true_positives": 436,
        "num_split_features": 1
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.005934718100890208,
        "num_absorption": 4,
        "num_probe_true_positives": 674,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.002437043054427295,
        "num_absorption": 3,
        "num_probe_true_positives": 1231,
        "num_split_features": 2
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.009836065573770493,
        "num_absorption": 18,
        "num_probe_true_positives": 1830,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.0035335689045936395,
        "num_absorption": 3,
        "num_probe_true_positives": 849,
        "num_split_features": 1
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.029906542056074768,
        "num_absorption": 32,
        "num_probe_true_positives": 1070,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.000423908435777872,
        "num_absorption": 1,
        "num_probe_true_positives": 2359,
        "num_split_features": 3
      },
      {
        "first_letter": "q",
        "absorption_rate": 0.01092896174863388,
        "num_absorption": 2,
        "num_probe_true_positives": 183,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.008860011813349085,
        "num_absorption": 15,
        "num_probe_true_positives": 1693,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.0010504201680672268,
        "num_absorption": 3,
        "num_probe_true_positives": 2856,
        "num_split_features": 2
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.007597895967270602,
        "num_absorption": 13,
        "num_probe_true_positives": 1711,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.014492753623188406,
        "num_absorption": 11,
        "num_probe_true_positives": 759,
        "num_split_features": 1
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.005820721769499418,
        "num_absorption": 5,
        "num_probe_true_positives": 859,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.004531722054380665,
        "num_absorption": 3,
        "num_probe_true_positives": 662,
        "num_split_features": 1
      },
      {
        "first_letter": "x",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 99,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.012345679012345678,
        "num_absorption": 2,
        "num_probe_true_positives": 162,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.007547169811320755,
        "num_absorption": 2,
        "num_probe_true_positives": 265,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "d8a9fbf2e09c6353944addaddfb5ca77a0714984",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_5_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 2304,
      "hook_layer": 5,
      "hook_name": "blocks.5.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "AdaptiveOrthogonal",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "l2",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_5_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_5_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.2857142857142857,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 7.1875
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.26973684210526316,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 9.875,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": -0.26171875,
        "mse": 3.5,
        "cossim": 0.4140625
      },
      "shrinkage": {
        "l2_norm_in": 90.0,
        "l2_norm_out": 23.0,
        "l2_ratio": 0.259765625,
        "relative_reconstruction_bias": 0.63671875
      },
      "sparsity": {
        "l0": 109.07015991210938,
        "l1": 133.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr and tpp evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "df746bea-03e9-4eb5-b227-21f9bef59d26",
    "datetime_epoch_millis": 1737875811153,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": -0.01694974317603434,
        "scr_metric_threshold_2": 0.006875199029461961,
        "scr_dir2_threshold_2": 0.006875199029461961,
        "scr_dir1_threshold_5": -0.054922298437173674,
        "scr_metric_threshold_5": 0.009282916965858567,
        "scr_dir2_threshold_5": 0.009282916965858567,
        "scr_dir1_threshold_10": -0.0827346961681783,
        "scr_metric_threshold_10": 0.013762328932450503,
        "scr_dir2_threshold_10": 0.013762328932450503,
        "scr_dir1_threshold_20": -0.13310879394037597,
        "scr_metric_threshold_20": 0.01570339920888572,
        "scr_dir2_threshold_20": 0.01570339920888572,
        "scr_dir1_threshold_50": -0.11568516638963813,
        "scr_metric_threshold_50": 0.020368975113422262,
        "scr_dir2_threshold_50": 0.020368975113422262,
        "scr_dir1_threshold_100": -0.12666760554333115,
        "scr_metric_threshold_100": 0.01840113403452378,
        "scr_dir2_threshold_100": 0.01840113403452378,
        "scr_dir1_threshold_500": -0.24027169703290607,
        "scr_metric_threshold_500": 0.01682777237967878,
        "scr_dir2_threshold_500": 0.01682777237967878
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": -0.3103451110805095,
        "scr_metric_threshold_2": 0.018779380822471343,
        "scr_dir2_threshold_2": 0.018779380822471343,
        "scr_dir1_threshold_5": -0.37930977783898107,
        "scr_metric_threshold_5": 0.021126768446028555,
        "scr_dir2_threshold_5": 0.021126768446028555,
        "scr_dir1_threshold_10": -0.37930977783898107,
        "scr_metric_threshold_10": 0.018779380822471343,
        "scr_dir2_threshold_10": 0.018779380822471343,
        "scr_dir1_threshold_20": -0.8275862777701274,
        "scr_metric_threshold_20": 0.021126768446028555,
        "scr_dir2_threshold_20": 0.021126768446028555,
        "scr_dir1_threshold_50": -0.9655176666207642,
        "scr_metric_threshold_50": 0.05399061492684999,
        "scr_dir2_threshold_50": 0.05399061492684999,
        "scr_dir1_threshold_100": -1.0344843887129296,
        "scr_metric_threshold_100": 0.06103291771452845,
        "scr_dir2_threshold_100": 0.06103291771452845,
        "scr_dir1_threshold_500": -1.7586216110116557,
        "scr_metric_threshold_500": 0.07981215861999297,
        "scr_dir2_threshold_500": 0.07981215861999297
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.029850374486354535,
        "scr_metric_threshold_2": -0.002590640371648879,
        "scr_dir2_threshold_2": -0.002590640371648879,
        "scr_dir1_threshold_5": -0.34328375470276395,
        "scr_metric_threshold_5": -0.005181435159484898,
        "scr_dir2_threshold_5": -0.005181435159484898,
        "scr_dir1_threshold_10": -0.41791058054058766,
        "scr_metric_threshold_10": 0.010362715902782657,
        "scr_dir2_threshold_10": 0.010362715902782657,
        "scr_dir1_threshold_20": -0.46268703189205684,
        "scr_metric_threshold_20": -0.002590640371648879,
        "scr_dir2_threshold_20": -0.002590640371648879,
        "scr_dir1_threshold_50": -0.20895529027029383,
        "scr_metric_threshold_50": 0.0077719211149466375,
        "scr_dir2_threshold_50": 0.0077719211149466375,
        "scr_dir1_threshold_100": -0.13432846443247012,
        "scr_metric_threshold_100": 0.0077719211149466375,
        "scr_dir2_threshold_100": 0.0077719211149466375,
        "scr_dir1_threshold_500": -0.20895529027029383,
        "scr_metric_threshold_500": 0.005181280743297758,
        "scr_dir2_threshold_500": 0.005181280743297758
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.023256877745449607,
        "scr_metric_threshold_2": -0.005089144583879204,
        "scr_dir2_threshold_2": -0.005089144583879204,
        "scr_dir1_threshold_5": 0.0,
        "scr_metric_threshold_5": -0.005089144583879204,
        "scr_dir2_threshold_5": -0.005089144583879204,
        "scr_dir1_threshold_10": -0.0930233525223136,
        "scr_metric_threshold_10": -0.005089144583879204,
        "scr_dir2_threshold_10": -0.005089144583879204,
        "scr_dir1_threshold_20": -0.0930233525223136,
        "scr_metric_threshold_20": -0.002544648124819707,
        "scr_dir2_threshold_20": -0.002544648124819707,
        "scr_dir1_threshold_50": -0.046510983184576,
        "scr_metric_threshold_50": -0.0076336410429387,
        "scr_dir2_threshold_50": -0.0076336410429387,
        "scr_dir1_threshold_100": -0.046510983184576,
        "scr_metric_threshold_100": 0.0,
        "scr_dir2_threshold_100": 0.0,
        "scr_dir1_threshold_500": -0.1162788441146016,
        "scr_metric_threshold_500": 0.010178137501998197,
        "scr_dir2_threshold_500": 0.010178137501998197
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": -0.01234551548800365,
        "scr_metric_threshold_2": -0.03225796631216327,
        "scr_dir2_threshold_2": -0.03225796631216327,
        "scr_dir1_threshold_5": 0.1728394244106685,
        "scr_metric_threshold_5": 0.0,
        "scr_dir2_threshold_5": 0.0,
        "scr_dir1_threshold_10": 0.20987670673421857,
        "scr_metric_threshold_10": -0.002688137154759759,
        "scr_dir2_threshold_10": -0.002688137154759759,
        "scr_dir1_threshold_20": 0.23456773771022588,
        "scr_metric_threshold_20": 0.0,
        "scr_dir2_threshold_20": 0.0,
        "scr_dir1_threshold_50": 0.2222222222222222,
        "scr_metric_threshold_50": 0.005376434537042601,
        "scr_dir2_threshold_50": 0.005376434537042601,
        "scr_dir1_threshold_100": 0.20987670673421857,
        "scr_metric_threshold_100": -0.008064411464279277,
        "scr_dir2_threshold_100": -0.008064411464279277,
        "scr_dir1_threshold_500": 0.2222222222222222,
        "scr_metric_threshold_500": -0.04301067515872539,
        "scr_dir2_threshold_500": -0.04301067515872539
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.051428586998763286,
        "scr_metric_threshold_2": 0.05936078776117859,
        "scr_dir2_threshold_2": 0.05936078776117859,
        "scr_dir1_threshold_5": 0.04571437524288891,
        "scr_metric_threshold_5": 0.06392693939649612,
        "scr_dir2_threshold_5": 0.06392693939649612,
        "scr_dir1_threshold_10": 0.051428586998763286,
        "scr_metric_threshold_10": 0.07305924266713117,
        "scr_dir2_threshold_10": 0.07305924266713117,
        "scr_dir1_threshold_20": 0.051428586998763286,
        "scr_metric_threshold_20": 0.06849309103181364,
        "scr_dir2_threshold_20": 0.06849309103181364,
        "scr_dir1_threshold_50": 0.04000016348701453,
        "scr_metric_threshold_50": 0.050228212323193286,
        "scr_dir2_threshold_50": 0.050228212323193286,
        "scr_dir1_threshold_100": 0.04571437524288891,
        "scr_metric_threshold_100": 0.06849309103181364,
        "scr_dir2_threshold_100": 0.06849309103181364,
        "scr_dir1_threshold_500": 0.04571437524288891,
        "scr_metric_threshold_500": 0.04566206068787576,
        "scr_dir2_threshold_500": 0.04566206068787576
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.007692208939046454,
        "scr_metric_threshold_2": -0.0323887323562997,
        "scr_dir2_threshold_2": -0.0323887323562997,
        "scr_dir1_threshold_5": -0.015384876375377228,
        "scr_metric_threshold_5": -0.028340201140355195,
        "scr_dir2_threshold_5": -0.028340201140355195,
        "scr_dir1_threshold_10": -0.023077085314423682,
        "scr_metric_threshold_10": -0.012145834962205343,
        "scr_dir2_threshold_10": -0.012145834962205343,
        "scr_dir1_threshold_20": 0.015384417878092908,
        "scr_metric_threshold_20": 0.004048531215944509,
        "scr_dir2_threshold_20": 0.004048531215944509,
        "scr_dir1_threshold_50": 0.038461503192516594,
        "scr_metric_threshold_50": -0.020243138708466175,
        "scr_dir2_threshold_50": -0.020243138708466175,
        "scr_dir1_threshold_100": 0.053845921070609495,
        "scr_metric_threshold_100": -0.04048603610256054,
        "scr_dir2_threshold_100": -0.04048603610256054,
        "scr_dir1_threshold_500": 0.046153712131563045,
        "scr_metric_threshold_500": -0.0323887323562997,
        "scr_dir2_threshold_500": -0.0323887323562997
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.08522750170939969,
        "scr_metric_threshold_2": 0.03418809950102767,
        "scr_dir2_threshold_2": 0.03418809950102767,
        "scr_dir1_threshold_5": 0.08522750170939969,
        "scr_metric_threshold_5": 0.012820600993054022,
        "scr_dir2_threshold_5": 0.012820600993054022,
        "scr_dir1_threshold_10": 0.005682081799897114,
        "scr_metric_threshold_10": 0.012820600993054022,
        "scr_dir2_threshold_10": 0.012820600993054022,
        "scr_dir1_threshold_20": 0.017045568074408247,
        "scr_metric_threshold_20": 0.017094049750513835,
        "scr_dir2_threshold_20": 0.017094049750513835,
        "scr_dir1_threshold_50": 0.0,
        "scr_metric_threshold_50": 0.03846154825848749,
        "scr_dir2_threshold_50": 0.03846154825848749,
        "scr_dir1_threshold_100": -0.10227273112116639,
        "scr_metric_threshold_100": 0.03846154825848749,
        "scr_dir2_threshold_100": 0.03846154825848749,
        "scr_dir1_threshold_500": -0.14204527174459688,
        "scr_metric_threshold_500": 0.03418809950102767,
        "scr_dir2_threshold_500": 0.03418809950102767
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": -0.010362868718775122,
        "scr_metric_threshold_2": 0.014999807775009142,
        "scr_dir2_threshold_2": 0.014999807775009142,
        "scr_dir1_threshold_5": -0.005181279943224265,
        "scr_metric_threshold_5": 0.014999807775009142,
        "scr_dir2_threshold_5": 0.014999807775009142,
        "scr_dir1_threshold_10": -0.015544148661999387,
        "scr_metric_threshold_10": 0.014999807775009142,
        "scr_dir2_threshold_10": 0.014999807775009142,
        "scr_dir1_threshold_20": 0.0,
        "scr_metric_threshold_20": 0.020000041723253828,
        "scr_dir2_threshold_20": 0.020000041723253828,
        "scr_dir1_threshold_50": -0.005181279943224265,
        "scr_metric_threshold_50": 0.03499984949826297,
        "scr_dir2_threshold_50": 0.03499984949826297,
        "scr_dir1_threshold_100": -0.005181279943224265,
        "scr_metric_threshold_100": 0.020000041723253828,
        "scr_dir2_threshold_100": 0.020000041723253828,
        "scr_dir1_threshold_500": -0.010362868718775122,
        "scr_metric_threshold_500": 0.03499984949826297,
        "scr_dir2_threshold_500": 0.03499984949826297
      }
    ],
    "sae_bench_commit_hash": "d8a9fbf2e09c6353944addaddfb5ca77a0714984",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_5_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 2304,
      "hook_layer": 5,
      "hook_name": "blocks.5.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "AdaptiveOrthogonal",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "l2",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "955ab908-512f-418b-b162-0e71ae7c349c",
    "datetime_epoch_millis": 1737875856655,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.940025,
        "llm_top_1_test_accuracy": 0.67890625,
        "llm_top_2_test_accuracy": 0.72346875,
        "llm_top_5_test_accuracy": 0.77423125,
        "llm_top_10_test_accuracy": 0.8231812500000001,
        "llm_top_20_test_accuracy": 0.8601937500000001,
        "llm_top_50_test_accuracy": 0.8994062500000001,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.93446254581213,
        "sae_top_1_test_accuracy": 0.6378125,
        "sae_top_2_test_accuracy": 0.6729624999999999,
        "sae_top_5_test_accuracy": 0.719125,
        "sae_top_10_test_accuracy": 0.77038125,
        "sae_top_20_test_accuracy": 0.81631875,
        "sae_top_50_test_accuracy": 0.8694999999999999,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.958,
        "llm_top_1_test_accuracy": 0.6641999999999999,
        "llm_top_2_test_accuracy": 0.6843999999999999,
        "llm_top_5_test_accuracy": 0.7469999999999999,
        "llm_top_10_test_accuracy": 0.8282,
        "llm_top_20_test_accuracy": 0.8606,
        "llm_top_50_test_accuracy": 0.9118,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9488000392913818,
        "sae_top_1_test_accuracy": 0.643,
        "sae_top_2_test_accuracy": 0.6836,
        "sae_top_5_test_accuracy": 0.7154,
        "sae_top_10_test_accuracy": 0.7786,
        "sae_top_20_test_accuracy": 0.8308,
        "sae_top_50_test_accuracy": 0.8836,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9396000000000001,
        "llm_top_1_test_accuracy": 0.6714,
        "llm_top_2_test_accuracy": 0.7222000000000001,
        "llm_top_5_test_accuracy": 0.7607999999999999,
        "llm_top_10_test_accuracy": 0.8038000000000001,
        "llm_top_20_test_accuracy": 0.8455999999999999,
        "llm_top_50_test_accuracy": 0.8880000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9264000535011292,
        "sae_top_1_test_accuracy": 0.6442,
        "sae_top_2_test_accuracy": 0.6679999999999999,
        "sae_top_5_test_accuracy": 0.7196,
        "sae_top_10_test_accuracy": 0.7634000000000001,
        "sae_top_20_test_accuracy": 0.8071999999999999,
        "sae_top_50_test_accuracy": 0.8592000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.909,
        "llm_top_1_test_accuracy": 0.6814,
        "llm_top_2_test_accuracy": 0.705,
        "llm_top_5_test_accuracy": 0.751,
        "llm_top_10_test_accuracy": 0.7966,
        "llm_top_20_test_accuracy": 0.8251999999999999,
        "llm_top_50_test_accuracy": 0.8625999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9106000661849976,
        "sae_top_1_test_accuracy": 0.629,
        "sae_top_2_test_accuracy": 0.6382,
        "sae_top_5_test_accuracy": 0.6906000000000001,
        "sae_top_10_test_accuracy": 0.7651999999999999,
        "sae_top_20_test_accuracy": 0.8089999999999999,
        "sae_top_50_test_accuracy": 0.844,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.8888,
        "llm_top_1_test_accuracy": 0.6068,
        "llm_top_2_test_accuracy": 0.6407999999999999,
        "llm_top_5_test_accuracy": 0.6763999999999999,
        "llm_top_10_test_accuracy": 0.719,
        "llm_top_20_test_accuracy": 0.772,
        "llm_top_50_test_accuracy": 0.8290000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.8760000348091126,
        "sae_top_1_test_accuracy": 0.5906,
        "sae_top_2_test_accuracy": 0.611,
        "sae_top_5_test_accuracy": 0.6432,
        "sae_top_10_test_accuracy": 0.6792,
        "sae_top_20_test_accuracy": 0.741,
        "sae_top_50_test_accuracy": 0.7862,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.9245000000000001,
        "llm_top_1_test_accuracy": 0.628,
        "llm_top_2_test_accuracy": 0.686,
        "llm_top_5_test_accuracy": 0.738,
        "llm_top_10_test_accuracy": 0.767,
        "llm_top_20_test_accuracy": 0.8,
        "llm_top_50_test_accuracy": 0.8545,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9130000472068787,
        "sae_top_1_test_accuracy": 0.617,
        "sae_top_2_test_accuracy": 0.677,
        "sae_top_5_test_accuracy": 0.72,
        "sae_top_10_test_accuracy": 0.74,
        "sae_top_20_test_accuracy": 0.7545,
        "sae_top_50_test_accuracy": 0.845,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9663999999999999,
        "llm_top_1_test_accuracy": 0.6626,
        "llm_top_2_test_accuracy": 0.706,
        "llm_top_5_test_accuracy": 0.7719999999999999,
        "llm_top_10_test_accuracy": 0.8426,
        "llm_top_20_test_accuracy": 0.8924,
        "llm_top_50_test_accuracy": 0.9362,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9638000369071961,
        "sae_top_1_test_accuracy": 0.662,
        "sae_top_2_test_accuracy": 0.688,
        "sae_top_5_test_accuracy": 0.7505999999999998,
        "sae_top_10_test_accuracy": 0.783,
        "sae_top_20_test_accuracy": 0.8371999999999999,
        "sae_top_50_test_accuracy": 0.8926000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.9345000000000001,
        "llm_top_1_test_accuracy": 0.7082499999999999,
        "llm_top_2_test_accuracy": 0.75075,
        "llm_top_5_test_accuracy": 0.80625,
        "llm_top_10_test_accuracy": 0.8482500000000001,
        "llm_top_20_test_accuracy": 0.89275,
        "llm_top_50_test_accuracy": 0.91475,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9375000596046448,
        "sae_top_1_test_accuracy": 0.6415,
        "sae_top_2_test_accuracy": 0.6845,
        "sae_top_5_test_accuracy": 0.7110000000000001,
        "sae_top_10_test_accuracy": 0.77725,
        "sae_top_20_test_accuracy": 0.8162499999999999,
        "sae_top_50_test_accuracy": 0.872,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9994,
        "llm_top_1_test_accuracy": 0.8086,
        "llm_top_2_test_accuracy": 0.8925999999999998,
        "llm_top_5_test_accuracy": 0.9423999999999999,
        "llm_top_10_test_accuracy": 0.9800000000000001,
        "llm_top_20_test_accuracy": 0.993,
        "llm_top_50_test_accuracy": 0.9984,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9996000289916992,
        "sae_top_1_test_accuracy": 0.6752,
        "sae_top_2_test_accuracy": 0.7333999999999999,
        "sae_top_5_test_accuracy": 0.8026,
        "sae_top_10_test_accuracy": 0.8764,
        "sae_top_20_test_accuracy": 0.9346,
        "sae_top_50_test_accuracy": 0.9734,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "d8a9fbf2e09c6353944addaddfb5ca77a0714984",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_5_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 2304,
      "hook_layer": 5,
      "hook_name": "blocks.5.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "AdaptiveOrthogonal",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "l2",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}