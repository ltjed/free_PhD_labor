\begin{thebibliography}{12}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Casper et~al.(2023)Casper, Li, Li, Bu, Zhang, and
  Hadfield-Menell]{Casper2023BenchmarkingIT}
Stephen Casper, Yuxiao Li, Jiawei Li, Tong Bu, Kevin Zhang, and Dylan
  Hadfield-Menell.
\newblock Benchmarking interpretability tools for deep neural networks.
\newblock \emph{ArXiv}, abs/2302.10894, 2023.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, Courville, and
  Bengio]{goodfellow2016deep}
Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio.
\newblock \emph{Deep learning}, volume~1.
\newblock MIT Press, 2016.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[OpenAI(2024)]{gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2024.
\newblock URL \url{https://arxiv.org/abs/2303.08774}.

\bibitem[Oyedotun et~al.(2020)Oyedotun, Aouada, and
  Ottersten]{Oyedotun2020StructuredCO}
O.~Oyedotun, D.~Aouada, and B.~Ottersten.
\newblock Structured compression of deep neural networks with debiased elastic
  group lasso.
\newblock \emph{2020 IEEE Winter Conference on Applications of Computer Vision
  (WACV)}, pp.\  2266--2275, 2020.

\bibitem[Pandit \& Banday(2023)Pandit and Banday]{Pandit2023VarianceGuidedSS}
Mohammad~Khalid Pandit and Mahroosh Banday.
\newblock Variance-guided structured sparsity in deep neural networks.
\newblock \emph{IEEE Transactions on Artificial Intelligence}, 4:\penalty0
  1714--1723, 2023.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Rangamani et~al.(2023)Rangamani, Lindegaard, Galanti, and
  Poggio]{Rangamani2023FeatureLI}
Akshay Rangamani, Marius Lindegaard, Tomer Galanti, and T.~Poggio.
\newblock Feature learning in deep classifiers through intermediate neural
  collapse.
\newblock pp.\  28729--28745, 2023.

\bibitem[Sulam et~al.(2017)Sulam, Papyan, Romano, and
  Elad]{Sulam2017MultilayerCS}
Jeremias Sulam, V.~Papyan, Yaniv Romano, and Michael Elad.
\newblock Multilayer convolutional sparse modeling: Pursuit and dictionary
  learning.
\newblock \emph{IEEE Transactions on Signal Processing}, 66:\penalty0
  4090--4104, 2017.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Yaras et~al.(2022)Yaras, Wang, Zhu, Balzano, and
  Qu]{Yaras2022NeuralCW}
Can Yaras, Peng Wang, Zhihui Zhu, L.~Balzano, and Qing Qu.
\newblock Neural collapse with normalized features: A geometric analysis over
  the riemannian manifold.
\newblock \emph{ArXiv}, abs/2209.09211, 2022.

\bibitem[Zeiler \& Fergus(2013)Zeiler and Fergus]{Zeiler2013VisualizingAU}
Matthew~D. Zeiler and R.~Fergus.
\newblock Visualizing and understanding convolutional networks.
\newblock \emph{ArXiv}, abs/1311.2901, 2013.

\end{thebibliography}
