\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{goodfellow2016deep}
\citation{vaswani2017attention}
\citation{karpathy2023nanogpt}
\citation{ba2016layer}
\citation{kingma2014adam,loshchilov2017adamw}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\newlabel{sec:intro@cref}{{[section][1][]1}{[1][1][]1}{}{}{}}
\citation{paszke2019pytorch}
\citation{gpt4}
\citation{goodfellow2016deep}
\citation{Dunefsky2024TranscodersFI}
\citation{vaswani2017attention}
\citation{bahdanau2014neural}
\citation{radford2019language}
\citation{kingma2014adam}
\citation{loshchilov2017adamw}
\citation{ba2016layer}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\newlabel{sec:related}{{2}{2}{Related Work}{section.2}{}}
\newlabel{sec:related@cref}{{[section][2][]2}{[1][2][]2}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Sparse Autoencoders for Interpretability}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Position-Invariant Feature Learning}{2}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Optimization and Training}{2}{subsection.2.3}\protected@file@percent }
\citation{goodfellow2016deep}
\citation{vaswani2017attention}
\citation{vaswani2017attention}
\citation{karpathy2023nanogpt}
\citation{ba2016layer}
\citation{kingma2014adam,loshchilov2017adamw}
\@writefile{toc}{\contentsline {section}{\numberline {3}Background}{3}{section.3}\protected@file@percent }
\newlabel{sec:background}{{3}{3}{Background}{section.3}{}}
\newlabel{sec:background@cref}{{[section][3][]3}{[1][3][]3}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Problem Setting}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Method}{3}{section.4}\protected@file@percent }
\newlabel{sec:method}{{4}{3}{Method}{section.4}{}}
\newlabel{sec:method@cref}{{[section][4][]4}{[1][3][]3}{}{}{}}
\citation{loshchilov2017adamw}
\citation{ba2016layer}
\citation{paszke2019pytorch}
\citation{vaswani2017attention}
\citation{karpathy2023nanogpt}
\citation{karpathy2023nanogpt}
\citation{paszke2019pytorch}
\citation{ba2016layer}
\citation{loshchilov2017adamw}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces TemporalSAE Training}}{4}{algorithm.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:training}{{1}{4}{TemporalSAE Training}{algorithm.1}{}}
\newlabel{alg:training@cref}{{[algorithm][1][]1}{[1][4][]4}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Setup}{4}{section.5}\protected@file@percent }
\newlabel{sec:experimental}{{5}{4}{Experimental Setup}{section.5}{}}
\newlabel{sec:experimental@cref}{{[section][5][]5}{[1][4][]4}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{5}{section.6}\protected@file@percent }
\newlabel{sec:results}{{6}{5}{Results}{section.6}{}}
\newlabel{sec:results@cref}{{[section][6][]6}{[1][5][]5}{}{}{}}
\newlabel{fig:training_curves}{{1a}{5}{Training loss over time for baseline SAE (blue), TemporalSAE without temporal loss (orange), and full TemporalSAE (green)}{figure.caption.1}{}}
\newlabel{fig:training_curves@cref}{{[subfigure][1][1]1a}{[1][5][]5}{}{}{}}
\newlabel{sub@fig:training_curves}{{a}{5}{Training loss over time for baseline SAE (blue), TemporalSAE without temporal loss (orange), and full TemporalSAE (green)}{figure.caption.1}{}}
\newlabel{sub@fig:training_curves@cref}{{[subfigure][1][1]1a}{[1][5][]5}{}{}{}}
\newlabel{fig:explained_variance}{{1b}{5}{Explained variance comparison across model variants}{figure.caption.1}{}}
\newlabel{fig:explained_variance@cref}{{[subfigure][2][1]1b}{[1][5][]5}{}{}{}}
\newlabel{sub@fig:explained_variance}{{b}{5}{Explained variance comparison across model variants}{figure.caption.1}{}}
\newlabel{sub@fig:explained_variance@cref}{{[subfigure][2][1]1b}{[1][5][]5}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Training dynamics and reconstruction quality metrics}}{5}{figure.caption.1}\protected@file@percent }
\newlabel{fig:training_results}{{1}{5}{Training dynamics and reconstruction quality metrics}{figure.caption.1}{}}
\newlabel{fig:training_results@cref}{{[figure][1][]1}{[1][5][]5}{}{}{}}
\newlabel{fig:cossim}{{2a}{6}{Cosine similarity between original and reconstructed activations}{figure.caption.2}{}}
\newlabel{fig:cossim@cref}{{[subfigure][1][2]2a}{[1][5][]6}{}{}{}}
\newlabel{sub@fig:cossim}{{a}{6}{Cosine similarity between original and reconstructed activations}{figure.caption.2}{}}
\newlabel{sub@fig:cossim@cref}{{[subfigure][1][2]2a}{[1][5][]6}{}{}{}}
\newlabel{fig:ce_loss}{{2b}{6}{Cross-entropy loss impact on model performance}{figure.caption.2}{}}
\newlabel{fig:ce_loss@cref}{{[subfigure][2][2]2b}{[1][5][]6}{}{}{}}
\newlabel{sub@fig:ce_loss}{{b}{6}{Cross-entropy loss impact on model performance}{figure.caption.2}{}}
\newlabel{sub@fig:ce_loss@cref}{{[subfigure][2][2]2b}{[1][5][]6}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Feature consistency and model performance preservation metrics}}{6}{figure.caption.2}\protected@file@percent }
\newlabel{fig:consistency_results}{{2}{6}{Feature consistency and model performance preservation metrics}{figure.caption.2}{}}
\newlabel{fig:consistency_results@cref}{{[figure][2][]2}{[1][5][]6}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Quantitative comparison of model variants}}{6}{table.caption.3}\protected@file@percent }
\newlabel{tab:results}{{1}{6}{Quantitative comparison of model variants}{table.caption.3}{}}
\newlabel{tab:results@cref}{{[table][1][]1}{[1][5][]6}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{6}{section.7}\protected@file@percent }
\newlabel{sec:conclusion}{{7}{6}{Conclusions}{section.7}{}}
\newlabel{sec:conclusion@cref}{{[section][7][]7}{[1][6][]6}{}{}{}}
\bibstyle{iclr2024_conference}
\bibdata{references}
\bibcite{ba2016layer}{{1}{2016}{{Ba et~al.}}{{Ba, Kiros, and Hinton}}}
\bibcite{bahdanau2014neural}{{2}{2014}{{Bahdanau et~al.}}{{Bahdanau, Cho, and Bengio}}}
\bibcite{Dunefsky2024TranscodersFI}{{3}{2024}{{Dunefsky et~al.}}{{Dunefsky, Chlenski, and Nanda}}}
\bibcite{goodfellow2016deep}{{4}{2016}{{Goodfellow et~al.}}{{Goodfellow, Bengio, Courville, and Bengio}}}
\bibcite{karpathy2023nanogpt}{{5}{2023}{{Karpathy}}{{}}}
\bibcite{kingma2014adam}{{6}{2014}{{Kingma \& Ba}}{{Kingma and Ba}}}
\bibcite{loshchilov2017adamw}{{7}{2017}{{Loshchilov \& Hutter}}{{Loshchilov and Hutter}}}
\bibcite{gpt4}{{8}{2024}{{OpenAI}}{{}}}
