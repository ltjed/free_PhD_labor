# Title: Learning Position-Invariant Features with Temporal Consistency Sparse Autoencoders

## Experiment Description
This experiment investigates the effectiveness of Temporal Consistency Sparse Autoencoders (TemporalSAE) in learning position-invariant features from language model activations. The key innovation is the addition of temporal consistency loss that encourages features to maintain consistent activation patterns across different positions in the input sequence.

## Key Figures and Analysis

### training_curves.png
Shows the training loss over time for three different model configurations:
1. Baseline SAE (blue): Standard sparse autoencoder without temporal consistency
2. TemporalSAE (No Temp Loss) (orange): TemporalSAE architecture but without temporal consistency loss
3. TemporalSAE (Full) (green): Complete TemporalSAE with temporal consistency loss

Key observations:
- Baseline shows stable but slow convergence
- TemporalSAE (No Temp Loss) exhibits instability early in training
- TemporalSAE (Full) demonstrates faster initial convergence but higher final loss

### explained_variance_comparison.png
Compares the explained variance metric across models:
- Higher values indicate better reconstruction quality
- TemporalSAE (Full) shows improved variance over baseline
- TemporalSAE (No Temp Loss) performs worst due to instability

### mse_comparison.png
Displays mean squared error (MSE) of reconstructions:
- Lower values indicate better reconstruction
- TemporalSAE (Full) achieves lowest MSE
- Baseline shows moderate performance
- TemporalSAE (No Temp Loss) has highest error

### cossim_comparison.png
Shows cosine similarity between original and reconstructed activations:
- Values closer to 1 indicate better reconstruction
- TemporalSAE (Full) maintains highest similarity
- Baseline shows moderate performance
- TemporalSAE (No Temp Loss) has lowest similarity

### l0_comparison.png
Compares L0 sparsity (number of active features):
- Lower values indicate sparser representations
- TemporalSAE (Full) achieves best sparsity
- Baseline shows moderate sparsity
- TemporalSAE (No Temp Loss) has highest activation

### l1_comparison.png
Shows L1 sparsity (magnitude of activations):
- Lower values indicate more compact representations
- TemporalSAE (Full) achieves best compactness
- Baseline shows moderate performance
- TemporalSAE (No Temp Loss) has highest activation magnitudes

### ce_loss_score_comparison.png
Compares cross-entropy loss impact:
- Lower values indicate better preservation of model performance
- TemporalSAE (Full) shows best preservation
- Baseline has moderate impact
- TemporalSAE (No Temp Loss) has highest performance degradation

### l2_ratio_comparison.png
Shows L2 norm ratio (input vs output):
- Values closer to 1 indicate better preservation of activation magnitudes
- TemporalSAE (Full) maintains best ratio
- Baseline shows moderate performance
- TemporalSAE (No Temp Loss) has lowest ratio

## Key Findings
1. Temporal consistency loss improves reconstruction quality while maintaining sparsity
2. The full TemporalSAE achieves better feature consistency across positions
3. Without temporal loss, the model becomes unstable and performs worse than baseline
4. Temporal consistency helps preserve model performance (lower CE loss impact)
5. The approach shows promise for learning position-invariant features

## Future Work
1. Investigate different window sizes for temporal consistency
2. Explore adaptive weighting of temporal loss
3. Analyze feature specialization patterns
4. Test on larger language models
5. Evaluate on downstream tasks requiring position invariance
