{
    "Summary": "The paper 'OrthogonalLens: Dynamic Feature Disentanglement for Interpretable Language Model Analysis' introduces a method to improve feature disentanglement in large language models (LLMs) using selective orthogonality constraints combined with dynamic feature grouping. The approach aims to enhance interpretability by separating related features while maintaining model performance. The method is evaluated on layer 19 of the Gemma-2b model, showing improvements in feature separation with minimal performance trade-offs.",
    "Strengths": [
        "Addresses a significant problem of feature entanglement in LLMs, which is crucial for interpretability and safe deployment.",
        "Proposes a novel combination of selective orthogonality and dynamic feature grouping to achieve cleaner feature separation.",
        "Provides comprehensive experimental results, including core performance metrics and task-specific performance on various benchmarks."
    ],
    "Weaknesses": [
        "The explanation of key components, such as the dynamic feature grouping mechanism and the orthogonality constraints, lacks depth and clarity, making it difficult to fully understand the implementation details.",
        "The ablation studies provided are minimal and do not explore the sensitivity of the model to hyperparameters or alternative configurations sufficiently.",
        "The evaluation is limited to a single layer of a specific model (Gemma-2b), raising questions about the generalizability of the results to other layers and models.",
        "The paper does not adequately discuss the potential limitations and negative societal impacts of the proposed method, such as computational overhead and the need for specialized hardware (e.g., GPUs).",
        "There is a noted 3.6% accuracy drop compared to the baseline model, which needs more justification and analysis."
    ],
    "Originality": 3,
    "Quality": 2,
    "Clarity": 3,
    "Significance": 4,
    "Questions": [
        "Can you provide more details on the implementation of the dynamic feature grouping mechanism?",
        "How does the method perform on layers other than layer 19 of the Gemma-2b model?",
        "What are the computational costs associated with the selective orthogonality technique?",
        "Can the authors provide more detailed explanations about the autoencoder aggregator and the dynamic feature grouping mechanism?",
        "What is the performance of the proposed model when different types of aggregators are used?",
        "Can the authors include more visualizations for qualitative analysis to strengthen their claims?"
    ],
    "Limitations": [
        "The paper does not thoroughly address the limitations of the approach, such as the increased computational complexity and the requirement for specialized hardware.",
        "Potential negative societal impacts, like the environmental cost of increased GPU usage, are not discussed.",
        "The experimental validation is limited to a specific model and layer, which may reduce the generalizability of the results.",
        "The trade-off in task performance (3.6% accuracy drop) needs more justification and analysis."
    ],
    "Ethical Concerns": false,
    "Soundness": 2,
    "Presentation": 3,
    "Contribution": 3,
    "Overall": 4,
    "Confidence": 4,
    "Decision": "Reject"
}