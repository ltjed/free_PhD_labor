\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{gpt4}
\citation{goodfellow2016deep}
\citation{vaswani2017attention}
\citation{kingma2014adam}
\citation{ba2016layer}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\newlabel{sec:intro@cref}{{[section][1][]1}{[1][1][]1}{}{}{}}
\citation{vaswani2017attention}
\citation{kingma2014adam,ba2016layer}
\citation{goodfellow2016deep}
\citation{bahdanau2014neural,radford2019language}
\citation{goodfellow2016deep}
\citation{vaswani2017attention}
\citation{ba2016layer}
\citation{kingma2014adam}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\newlabel{sec:related}{{2}{2}{Related Work}{section.2}{}}
\newlabel{sec:related@cref}{{[section][2][]2}{[1][2][]2}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Background}{2}{section.3}\protected@file@percent }
\newlabel{sec:background}{{3}{2}{Background}{section.3}{}}
\newlabel{sec:background@cref}{{[section][3][]3}{[1][2][]2}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Problem Setting}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Method}{3}{section.4}\protected@file@percent }
\newlabel{sec:method}{{4}{3}{Method}{section.4}{}}
\newlabel{sec:method@cref}{{[section][4][]4}{[1][3][]3}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Setup}{4}{section.5}\protected@file@percent }
\newlabel{sec:experimental}{{5}{4}{Experimental Setup}{section.5}{}}
\newlabel{sec:experimental@cref}{{[section][5][]5}{[1][3][]4}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{4}{section.6}\protected@file@percent }
\newlabel{sec:results}{{6}{4}{Results}{section.6}{}}
\newlabel{sec:results@cref}{{[section][6][]6}{[1][4][]4}{}{}{}}
\citation{vaswani2017attention}
\bibstyle{iclr2024_conference}
\bibdata{references}
\bibcite{ba2016layer}{{1}{2016}{{Ba et~al.}}{{Ba, Kiros, and Hinton}}}
\bibcite{bahdanau2014neural}{{2}{2014}{{Bahdanau et~al.}}{{Bahdanau, Cho, and Bengio}}}
\bibcite{goodfellow2016deep}{{3}{2016}{{Goodfellow et~al.}}{{Goodfellow, Bengio, Courville, and Bengio}}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:training}{{1a}{5}{Training convergence showing HSAE's faster initial learning but higher plateau}{figure.caption.1}{}}
\newlabel{fig:training@cref}{{[subfigure][1][1]1a}{[1][4][]5}{}{}{}}
\newlabel{sub@fig:training}{{a}{5}{Training convergence showing HSAE's faster initial learning but higher plateau}{figure.caption.1}{}}
\newlabel{sub@fig:training@cref}{{[subfigure][1][1]1a}{[1][4][]5}{}{}{}}
\newlabel{fig:sparsity}{{1b}{5}{Feature sparsity comparison across model variants}{figure.caption.1}{}}
\newlabel{fig:sparsity@cref}{{[subfigure][2][1]1b}{[1][4][]5}{}{}{}}
\newlabel{sub@fig:sparsity}{{b}{5}{Feature sparsity comparison across model variants}{figure.caption.1}{}}
\newlabel{sub@fig:sparsity@cref}{{[subfigure][2][1]1b}{[1][4][]5}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Performance evaluation showing (a) training dynamics and (b) achieved sparsity levels. Results from runs with evaluation IDs: 1a043892 (HSAE), 7a2164d7 (No Feature Separation), 6e0dffb5 (Single-Scale), and e4ece415 (Adaptive).}}{5}{figure.caption.1}\protected@file@percent }
\newlabel{fig:results}{{1}{5}{Performance evaluation showing (a) training dynamics and (b) achieved sparsity levels. Results from runs with evaluation IDs: 1a043892 (HSAE), 7a2164d7 (No Feature Separation), 6e0dffb5 (Single-Scale), and e4ece415 (Adaptive)}{figure.caption.1}{}}
\newlabel{fig:results@cref}{{[figure][1][]1}{[1][4][]5}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Cross-domain evaluation using sequence length 1024 and batch size 32, showing consistent performance limitations across knowledge domains. Training times relative to baseline SAE.}}{5}{table.caption.2}\protected@file@percent }
\newlabel{tab:domain_results}{{1}{5}{Cross-domain evaluation using sequence length 1024 and batch size 32, showing consistent performance limitations across knowledge domains. Training times relative to baseline SAE}{table.caption.2}{}}
\newlabel{tab:domain_results@cref}{{[table][1][]1}{[1][4][]5}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{5}{section.7}\protected@file@percent }
\newlabel{sec:conclusion}{{7}{5}{Conclusions}{section.7}{}}
\newlabel{sec:conclusion@cref}{{[section][7][]7}{[1][4][]5}{}{}{}}
\bibcite{kingma2014adam}{{4}{2014}{{Kingma \& Ba}}{{Kingma and Ba}}}
\bibcite{gpt4}{{5}{2024}{{OpenAI}}{{}}}
\bibcite{radford2019language}{{6}{2019}{{Radford et~al.}}{{Radford, Wu, Child, Luan, Amodei, and Sutskever}}}
\bibcite{vaswani2017attention}{{7}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\ttl@finishall
\gdef \@abspage@last{6}
