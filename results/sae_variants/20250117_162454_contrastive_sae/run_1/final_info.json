{
  "eval_type_id": "sparse_probing",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "LabHC/bias_in_bios_class_set2",
      "LabHC/bias_in_bios_class_set3",
      "canrager/amazon_reviews_mcauley_1and5",
      "canrager/amazon_reviews_mcauley_1and5_sentiment",
      "codeparrot/github-code",
      "fancyzhx/ag_news",
      "Helsinki-NLP/europarl"
    ],
    "probe_train_set_size": 4000,
    "probe_test_set_size": 1000,
    "context_length": 128,
    "sae_batch_size": 125,
    "llm_batch_size": 32,
    "llm_dtype": "bfloat16",
    "model_name": "google/gemma-2-2b",
    "k_values": [
      1,
      2,
      5,
      10,
      20,
      50
    ],
    "lower_vram_usage": false
  },
  "eval_id": "24f1aca2-e016-460f-9ff4-bd51af2dbd5e",
  "datetime_epoch_millis": 1737152007947,
  "eval_result_metrics": {
    "llm": {
      "llm_test_accuracy": 0.95074375,
      "llm_top_1_test_accuracy": 0.70171875,
      "llm_top_2_test_accuracy": 0.7558624999999999,
      "llm_top_5_test_accuracy": 0.8177312499999999,
      "llm_top_10_test_accuracy": 0.8704125000000001,
      "llm_top_20_test_accuracy": 0.9015937500000001,
      "llm_top_50_test_accuracy": 0.9322125,
      "llm_top_100_test_accuracy": null
    },
    "sae": {
      "sae_test_accuracy": 0.5,
      "sae_top_1_test_accuracy": 0.5,
      "sae_top_2_test_accuracy": 0.5,
      "sae_top_5_test_accuracy": 0.5,
      "sae_top_10_test_accuracy": 0.5,
      "sae_top_20_test_accuracy": 0.5,
      "sae_top_50_test_accuracy": 0.5,
      "sae_top_100_test_accuracy": null
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_results",
      "llm_test_accuracy": 0.9612,
      "llm_top_1_test_accuracy": 0.6562000000000001,
      "llm_top_2_test_accuracy": 0.7243999999999999,
      "llm_top_5_test_accuracy": 0.8043999999999999,
      "llm_top_10_test_accuracy": 0.8676,
      "llm_top_20_test_accuracy": 0.913,
      "llm_top_50_test_accuracy": 0.952,
      "llm_top_100_test_accuracy": null,
      "sae_test_accuracy": 0.5,
      "sae_top_1_test_accuracy": 0.5,
      "sae_top_2_test_accuracy": 0.5,
      "sae_top_5_test_accuracy": 0.5,
      "sae_top_10_test_accuracy": 0.5,
      "sae_top_20_test_accuracy": 0.5,
      "sae_top_50_test_accuracy": 0.5,
      "sae_top_100_test_accuracy": null
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set2_results",
      "llm_test_accuracy": 0.9447999999999999,
      "llm_top_1_test_accuracy": 0.6746000000000001,
      "llm_top_2_test_accuracy": 0.7018,
      "llm_top_5_test_accuracy": 0.7739999999999999,
      "llm_top_10_test_accuracy": 0.8274000000000001,
      "llm_top_20_test_accuracy": 0.8804000000000001,
      "llm_top_50_test_accuracy": 0.915,
      "llm_top_100_test_accuracy": null,
      "sae_test_accuracy": 0.5,
      "sae_top_1_test_accuracy": 0.5,
      "sae_top_2_test_accuracy": 0.5,
      "sae_top_5_test_accuracy": 0.5,
      "sae_top_10_test_accuracy": 0.5,
      "sae_top_20_test_accuracy": 0.5,
      "sae_top_50_test_accuracy": 0.5,
      "sae_top_100_test_accuracy": null
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set3_results",
      "llm_test_accuracy": 0.9141999999999999,
      "llm_top_1_test_accuracy": 0.6898,
      "llm_top_2_test_accuracy": 0.7121999999999999,
      "llm_top_5_test_accuracy": 0.7788000000000002,
      "llm_top_10_test_accuracy": 0.8444,
      "llm_top_20_test_accuracy": 0.8688,
      "llm_top_50_test_accuracy": 0.9084,
      "llm_top_100_test_accuracy": null,
      "sae_test_accuracy": 0.5,
      "sae_top_1_test_accuracy": 0.5,
      "sae_top_2_test_accuracy": 0.5,
      "sae_top_5_test_accuracy": 0.5,
      "sae_top_10_test_accuracy": 0.5,
      "sae_top_20_test_accuracy": 0.5,
      "sae_top_50_test_accuracy": 0.5,
      "sae_top_100_test_accuracy": null
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
      "llm_test_accuracy": 0.9098,
      "llm_top_1_test_accuracy": 0.6292,
      "llm_top_2_test_accuracy": 0.6984,
      "llm_top_5_test_accuracy": 0.7568,
      "llm_top_10_test_accuracy": 0.818,
      "llm_top_20_test_accuracy": 0.858,
      "llm_top_50_test_accuracy": 0.881,
      "llm_top_100_test_accuracy": null,
      "sae_test_accuracy": 0.5,
      "sae_top_1_test_accuracy": 0.5,
      "sae_top_2_test_accuracy": 0.5,
      "sae_top_5_test_accuracy": 0.5,
      "sae_top_10_test_accuracy": 0.5,
      "sae_top_20_test_accuracy": 0.5,
      "sae_top_50_test_accuracy": 0.5,
      "sae_top_100_test_accuracy": null
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
      "llm_test_accuracy": 0.9695,
      "llm_top_1_test_accuracy": 0.697,
      "llm_top_2_test_accuracy": 0.743,
      "llm_top_5_test_accuracy": 0.791,
      "llm_top_10_test_accuracy": 0.86,
      "llm_top_20_test_accuracy": 0.875,
      "llm_top_50_test_accuracy": 0.942,
      "llm_top_100_test_accuracy": null,
      "sae_test_accuracy": 0.5,
      "sae_top_1_test_accuracy": 0.5,
      "sae_top_2_test_accuracy": 0.5,
      "sae_top_5_test_accuracy": 0.5,
      "sae_top_10_test_accuracy": 0.5,
      "sae_top_20_test_accuracy": 0.5,
      "sae_top_50_test_accuracy": 0.5,
      "sae_top_100_test_accuracy": null
    },
    {
      "dataset_name": "codeparrot/github-code_results",
      "llm_test_accuracy": 0.9648,
      "llm_top_1_test_accuracy": 0.6284,
      "llm_top_2_test_accuracy": 0.6910000000000001,
      "llm_top_5_test_accuracy": 0.8074,
      "llm_top_10_test_accuracy": 0.8756,
      "llm_top_20_test_accuracy": 0.9164,
      "llm_top_50_test_accuracy": 0.9374,
      "llm_top_100_test_accuracy": null,
      "sae_test_accuracy": 0.5,
      "sae_top_1_test_accuracy": 0.5,
      "sae_top_2_test_accuracy": 0.5,
      "sae_top_5_test_accuracy": 0.5,
      "sae_top_10_test_accuracy": 0.5,
      "sae_top_20_test_accuracy": 0.5,
      "sae_top_50_test_accuracy": 0.5,
      "sae_top_100_test_accuracy": null
    },
    {
      "dataset_name": "fancyzhx/ag_news_results",
      "llm_test_accuracy": 0.94225,
      "llm_top_1_test_accuracy": 0.69875,
      "llm_top_2_test_accuracy": 0.7905,
      "llm_top_5_test_accuracy": 0.8382499999999999,
      "llm_top_10_test_accuracy": 0.8714999999999999,
      "llm_top_20_test_accuracy": 0.90175,
      "llm_top_50_test_accuracy": 0.9225,
      "llm_top_100_test_accuracy": null,
      "sae_test_accuracy": 0.5,
      "sae_top_1_test_accuracy": 0.5,
      "sae_top_2_test_accuracy": 0.5,
      "sae_top_5_test_accuracy": 0.5,
      "sae_top_10_test_accuracy": 0.5,
      "sae_top_20_test_accuracy": 0.5,
      "sae_top_50_test_accuracy": 0.5,
      "sae_top_100_test_accuracy": null
    },
    {
      "dataset_name": "Helsinki-NLP/europarl_results",
      "llm_test_accuracy": 0.9994,
      "llm_top_1_test_accuracy": 0.9398,
      "llm_top_2_test_accuracy": 0.9856000000000001,
      "llm_top_5_test_accuracy": 0.9911999999999999,
      "llm_top_10_test_accuracy": 0.9987999999999999,
      "llm_top_20_test_accuracy": 0.9994,
      "llm_top_50_test_accuracy": 0.9994,
      "llm_top_100_test_accuracy": null,
      "sae_test_accuracy": 0.5,
      "sae_top_1_test_accuracy": 0.5,
      "sae_top_2_test_accuracy": 0.5,
      "sae_top_5_test_accuracy": 0.5,
      "sae_top_10_test_accuracy": 0.5,
      "sae_top_20_test_accuracy": 0.5,
      "sae_top_50_test_accuracy": 0.5,
      "sae_top_100_test_accuracy": null
    }
  ],
  "sae_bench_commit_hash": "bcb003afd6045deaee4be8dd883ae42863da9163",
  "sae_lens_id": "custom_sae",
  "sae_lens_release_id": "google/gemma-2-2b_layer_19_sae",
  "sae_lens_version": "5.3.0",
  "sae_cfg_dict": {
    "model_name": "google/gemma-2-2b",
    "d_in": 2304,
    "d_sae": 2304,
    "hook_layer": 19,
    "hook_name": "blocks.19.hook_resid_post",
    "context_size": null,
    "hook_head_index": null,
    "architecture": "Custom",
    "apply_b_dec_to_input": true,
    "finetuning_scaling_factor": null,
    "activation_fn_str": "relu",
    "prepend_bos": true,
    "normalize_activations": "none",
    "dtype": "bfloat16",
    "device": "",
    "dataset_path": "",
    "dataset_trust_remote_code": true,
    "seqpos_slice": [
      null
    ],
    "training_tokens": -100000,
    "sae_lens_training_version": null,
    "neuronpedia_id": null
  },
  "eval_result_unstructured": null
}