{
    "Summary": "The paper proposes Temporal Consistency Sparse Autoencoders (TC-SAE) to address position-dependence in transformer models by incorporating temporal consistency constraints. The method aims to achieve stable feature activations across sequential positions while maintaining sparsity, using a sliding window mechanism and gradient clipping. Evaluations on the Gemma-2B model show better feature clustering and more stable training dynamics compared to baseline SAEs. However, significant issues with reconstruction quality and sparsity remain.",
    "Strengths": [
        "The paper addresses a relevant problem in the field of neural interpretability, specifically the challenge of position-dependent features in transformer models.",
        "The proposed temporal consistency constraint is a novel approach to enforce position-invariant feature learning.",
        "The experimental setup is rigorous, with a large dataset (Gemma-2B) and a detailed analysis of training dynamics and feature correlations."
    ],
    "Weaknesses": [
        "The reconstruction quality and sparsity achievements are poor (MSE: 47.25, L0: 0.0), questioning the effectiveness of the proposed method.",
        "The paper lacks comparisons with other baseline methods beyond standard sparse autoencoders, limiting the context of the results.",
        "Several sections, including the detailed explanation of the autoencoder aggregator and the rationale behind hyperparameter choices, lack clarity.",
        "The empirical determination of key hyperparameters (e.g., \u03bb = 0.5, window size = 8) without a systematic search raises concerns about the robustness of the results.",
        "The paper does not sufficiently explore the impact of varying the temporal consistency weight and window size on the results."
    ],
    "Originality": 2,
    "Quality": 2,
    "Clarity": 2,
    "Significance": 2,
    "Questions": [
        "Can the authors provide more details about the autoencoder aggregator and the rationale behind the choice of hyperparameters?",
        "How does the proposed method compare with other advanced baseline methods that address temporal consistency or position-invariant features?",
        "Can the authors provide a clearer motivation for the problem they are addressing?",
        "How does the proposed method compare with existing methods in terms of reconstruction quality and feature stability?",
        "Can the authors provide more detailed ablation studies to analyze the impact of different components of TC-SAE?",
        "What methods were considered for determining the hyperparameters (\u03bb and window size) beyond empirical validation?",
        "Can the authors provide a more detailed mathematical formulation of the temporal consistency loss and how it is integrated with the sparse autoencoder?",
        "Can the authors provide results on additional datasets to demonstrate the generalization capability of the proposed method?"
    ],
    "Limitations": [
        "The paper acknowledges the poor reconstruction quality and sparsity achievements but does not offer a concrete plan to address these issues.",
        "The empirical determination of hyperparameters without solid justification is a significant concern.",
        "The primary limitations are poor reconstruction quality and failure to achieve sparsity, which are critical for the practical application of the proposed method.",
        "Experiments should include additional datasets to validate the generalization of the proposed method."
    ],
    "Ethical Concerns": false,
    "Soundness": 2,
    "Presentation": 2,
    "Contribution": 2,
    "Overall": 3,
    "Confidence": 4,
    "Decision": "Reject"
}