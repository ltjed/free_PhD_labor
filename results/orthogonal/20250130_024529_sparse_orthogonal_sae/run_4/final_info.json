{
  "training results for layer 12": {
    "config": {
      "trainer_class": "TrainerTopK",
      "dict_class": "AutoEncoderTopK",
      "lr": 0.0001885618083164127,
      "steps": 4882,
      "seed": 42,
      "activation_dim": 2304,
      "dict_size": 18432,
      "k": 320,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "AutoEncoderTopK",
      "submodule_name": "resid_post_layer_12",
      "ortho_weight": 0.075
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 2481.916748046875,
      "layer": 12,
      "dict_size": 18432,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "54e7ea40-d566-4885-b524-2c09d61c4107",
    "datetime_epoch_millis": 1738247235777,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.02514253894543604,
        "mean_num_split_features": 1.1428571428571428
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 2663,
        "num_split_features": 2
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.0037998733375554147,
        "num_absorption": 6,
        "num_probe_true_positives": 1579,
        "num_split_features": 1
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.0014378145219266715,
        "num_absorption": 4,
        "num_probe_true_positives": 2782,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.0018773466833541927,
        "num_absorption": 3,
        "num_probe_true_positives": 1598,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.19504643962848298,
        "num_absorption": 315,
        "num_probe_true_positives": 1615,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.0008771929824561404,
        "num_absorption": 1,
        "num_probe_true_positives": 1140,
        "num_split_features": 1
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 970,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.001154068090017311,
        "num_absorption": 2,
        "num_probe_true_positives": 1733,
        "num_split_features": 1
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.0026041666666666665,
        "num_absorption": 1,
        "num_probe_true_positives": 384,
        "num_split_features": 2
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.16323529411764706,
        "num_absorption": 111,
        "num_probe_true_positives": 680,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.0016384489350081922,
        "num_absorption": 3,
        "num_probe_true_positives": 1831,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.0011976047904191617,
        "num_absorption": 1,
        "num_probe_true_positives": 835,
        "num_split_features": 1
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.1023696682464455,
        "num_absorption": 108,
        "num_probe_true_positives": 1055,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.000434593654932638,
        "num_absorption": 1,
        "num_probe_true_positives": 2301,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.0010615711252653928,
        "num_absorption": 3,
        "num_probe_true_positives": 2826,
        "num_split_features": 2
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.02414860681114551,
        "num_absorption": 39,
        "num_probe_true_positives": 1615,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.0012594458438287153,
        "num_absorption": 1,
        "num_probe_true_positives": 794,
        "num_split_features": 1
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.0012315270935960591,
        "num_absorption": 1,
        "num_probe_true_positives": 812,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.0014705882352941176,
        "num_absorption": 1,
        "num_probe_true_positives": 680,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.005681818181818182,
        "num_absorption": 1,
        "num_probe_true_positives": 176,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.017467248908296942,
        "num_absorption": 4,
        "num_probe_true_positives": 229,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9910714285714286,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.08984375
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9917763157894737,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 3.015625,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.77734375,
        "mse": 1.4140625,
        "cossim": 0.93359375
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 139.0,
        "l2_ratio": 0.9296875,
        "relative_reconstruction_bias": 1.0
      },
      "sparsity": {
        "l0": 320.0,
        "l1": 952.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr and tpp evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "09950683-7a14-4d03-9e72-8ed4732475de",
    "datetime_epoch_millis": 1738247484518,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.17170776510876695,
        "scr_metric_threshold_2": 0.1257028995603569,
        "scr_dir2_threshold_2": 0.12700322002461376,
        "scr_dir1_threshold_5": 0.24921394804313338,
        "scr_metric_threshold_5": 0.16554870098555544,
        "scr_dir2_threshold_5": 0.1673191135202796,
        "scr_dir1_threshold_10": 0.2907813594301737,
        "scr_metric_threshold_10": 0.20020349046475033,
        "scr_dir2_threshold_10": 0.20029800088753963,
        "scr_dir1_threshold_20": 0.28861431352627237,
        "scr_metric_threshold_20": 0.23453251705738248,
        "scr_dir2_threshold_20": 0.240042927987162,
        "scr_dir1_threshold_50": 0.254579088976688,
        "scr_metric_threshold_50": 0.29498540871676,
        "scr_dir2_threshold_50": 0.29155960139721004,
        "scr_dir1_threshold_100": 0.2151411951067132,
        "scr_metric_threshold_100": 0.2898271780779527,
        "scr_dir2_threshold_100": 0.2868203311735722,
        "scr_dir1_threshold_500": 0.07897402100759396,
        "scr_metric_threshold_500": 0.27443642648012456,
        "scr_dir2_threshold_500": 0.2718919472329267
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.4062497380653249,
        "scr_metric_threshold_2": 0.01474211549298745,
        "scr_dir2_threshold_2": 0.01474211549298745,
        "scr_dir1_threshold_5": 0.46874991268844163,
        "scr_metric_threshold_5": 0.019656056358159712,
        "scr_dir2_threshold_5": 0.019656056358159712,
        "scr_dir1_threshold_10": 0.5624997089614721,
        "scr_metric_threshold_10": 0.024570143672067307,
        "scr_dir2_threshold_10": 0.024570143672067307,
        "scr_dir1_threshold_20": 0.4843747235133985,
        "scr_metric_threshold_20": 0.05651105219315768,
        "scr_dir2_threshold_20": 0.05651105219315768,
        "scr_dir1_threshold_50": 0.4843747235133985,
        "scr_metric_threshold_50": 0.1031940762072355,
        "scr_dir2_threshold_50": 0.1031940762072355,
        "scr_dir1_threshold_100": 0.390624927240368,
        "scr_metric_threshold_100": 0.11793619170022296,
        "scr_dir2_threshold_100": 0.11793619170022296,
        "scr_dir1_threshold_500": 0.37500011641541114,
        "scr_metric_threshold_500": 0.13022119031188895,
        "scr_dir2_threshold_500": 0.13022119031188895
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.04854364999221667,
        "scr_metric_threshold_2": 0.1518623976302968,
        "scr_dir2_threshold_2": 0.1518623976302968,
        "scr_dir1_threshold_5": 0.22330102143857855,
        "scr_metric_threshold_5": 0.18624642372107894,
        "scr_dir2_threshold_5": 0.18624642372107894,
        "scr_dir1_threshold_10": 0.22330102143857855,
        "scr_metric_threshold_10": 0.20916910778160036,
        "scr_dir2_threshold_10": 0.20916910778160036,
        "scr_dir1_threshold_20": 0.26213605716954286,
        "scr_metric_threshold_20": 0.2779369891762057,
        "scr_dir2_threshold_20": 0.2779369891762057,
        "scr_dir1_threshold_50": 0.07766949277597389,
        "scr_metric_threshold_50": 0.33237823572972486,
        "scr_dir2_threshold_50": 0.33237823572972486,
        "scr_dir1_threshold_100": 0.1747573714463619,
        "scr_metric_threshold_100": 0.1146130787286892,
        "scr_dir2_threshold_100": 0.1146130787286892,
        "scr_dir1_threshold_500": -0.5728157643313023,
        "scr_metric_threshold_500": 0.0573065393643446,
        "scr_dir2_threshold_500": 0.0573065393643446
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.49206359718628334,
        "scr_metric_threshold_2": 0.030379805284471813,
        "scr_dir2_threshold_2": 0.030379805284471813,
        "scr_dir1_threshold_5": 0.5873013770560047,
        "scr_metric_threshold_5": 0.055696234239288635,
        "scr_dir2_threshold_5": 0.055696234239288635,
        "scr_dir1_threshold_10": 0.6507935456708595,
        "scr_metric_threshold_10": 0.08860765223967824,
        "scr_dir2_threshold_10": 0.08860765223967824,
        "scr_dir1_threshold_20": 0.5396829601737049,
        "scr_metric_threshold_20": 0.10126586671708666,
        "scr_dir2_threshold_20": 0.10126586671708666,
        "scr_dir1_threshold_50": 0.4444442341988618,
        "scr_metric_threshold_50": 0.1594937136722931,
        "scr_dir2_threshold_50": 0.1594937136722931,
        "scr_dir1_threshold_100": 0.20634931147199764,
        "scr_metric_threshold_100": 0.1873419062408471,
        "scr_dir2_threshold_100": 0.1873419062408471,
        "scr_dir1_threshold_500": 0.03174655735998827,
        "scr_metric_threshold_500": 0.04556963247779803,
        "scr_dir2_threshold_500": 0.04556963247779803
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": 0.14062502910382568,
        "scr_metric_threshold_2": 0.044510518539166266,
        "scr_dir2_threshold_2": 0.044510518539166266,
        "scr_dir1_threshold_5": 0.2343752037267798,
        "scr_metric_threshold_5": 0.08308621873453508,
        "scr_dir2_threshold_5": 0.08308621873453508,
        "scr_dir1_threshold_10": 0.15625029103825686,
        "scr_metric_threshold_10": 0.1127597798483955,
        "scr_dir2_threshold_10": 0.1127597798483955,
        "scr_dir1_threshold_20": 0.1328126309672156,
        "scr_metric_threshold_20": 0.1513353031753887,
        "scr_dir2_threshold_20": 0.1513353031753887,
        "scr_dir1_threshold_50": 0.007812863797821078,
        "scr_metric_threshold_50": 0.23738884264763468,
        "scr_dir2_threshold_50": 0.23738884264763468,
        "scr_dir1_threshold_100": 0.1171878346939954,
        "scr_metric_threshold_100": 0.29376864413764464,
        "scr_dir2_threshold_100": 0.29376864413764464,
        "scr_dir1_threshold_500": 0.28125005820765137,
        "scr_metric_threshold_500": 0.008902139081508376,
        "scr_dir2_threshold_500": 0.008902139081508376
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.04371592886659017,
        "scr_metric_threshold_2": 0.5843137905717627,
        "scr_dir2_threshold_2": 0.5843137905717627,
        "scr_dir1_threshold_5": 0.021857964433295084,
        "scr_metric_threshold_5": 0.6274509483096945,
        "scr_dir2_threshold_5": 0.6274509483096945,
        "scr_dir1_threshold_10": 0.04371592886659017,
        "scr_metric_threshold_10": 0.6549020368655817,
        "scr_dir2_threshold_10": 0.6549020368655817,
        "scr_dir1_threshold_20": 0.06010915791026799,
        "scr_metric_threshold_20": 0.674509857086792,
        "scr_dir2_threshold_20": 0.674509857086792,
        "scr_dir1_threshold_50": 0.08743153202478901,
        "scr_metric_threshold_50": 0.6941176773080023,
        "scr_dir2_threshold_50": 0.6941176773080023,
        "scr_dir1_threshold_100": -0.13661187057260513,
        "scr_metric_threshold_100": 0.6901961600124913,
        "scr_dir2_threshold_100": 0.6901961600124913,
        "scr_dir1_threshold_500": -0.36612033426800783,
        "scr_metric_threshold_500": 0.7372548350459341,
        "scr_dir2_threshold_500": 0.7372548350459341
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.09230742426312609,
        "scr_metric_threshold_2": 0.05241939554166917,
        "scr_dir2_threshold_2": 0.05241939554166917,
        "scr_dir1_threshold_5": 0.14358973418467108,
        "scr_metric_threshold_5": 0.09677413927777444,
        "scr_dir2_threshold_5": 0.09677413927777444,
        "scr_dir1_threshold_10": 0.22051274056970427,
        "scr_metric_threshold_10": 0.1733872498948507,
        "scr_dir2_threshold_10": 0.1733872498948507,
        "scr_dir1_threshold_20": 0.23076901915509954,
        "scr_metric_threshold_20": 0.20967734182539205,
        "scr_dir2_threshold_20": 0.20967734182539205,
        "scr_dir1_threshold_50": 0.29743574695473746,
        "scr_metric_threshold_50": 0.2782258006369044,
        "scr_dir2_threshold_50": 0.2782258006369044,
        "scr_dir1_threshold_100": 0.34871775121142623,
        "scr_metric_threshold_100": 0.3145161329087304,
        "scr_dir2_threshold_100": 0.3145161329087304,
        "scr_dir1_threshold_500": 0.369230614047073,
        "scr_metric_threshold_500": 0.4717743195337379,
        "scr_dir2_threshold_500": 0.4717743195337379
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.09865451195153367,
        "scr_metric_threshold_2": 0.07589293198126605,
        "scr_dir2_threshold_2": 0.07589293198126605,
        "scr_dir1_threshold_5": 0.22869955756245325,
        "scr_metric_threshold_5": 0.16964277398906946,
        "scr_dir2_threshold_5": 0.16964277398906946,
        "scr_dir1_threshold_10": 0.33183858419985035,
        "scr_metric_threshold_10": 0.20089289871975097,
        "scr_dir2_threshold_10": 0.20089289871975097,
        "scr_dir1_threshold_20": 0.4573991151249065,
        "scr_metric_threshold_20": 0.2633928820889934,
        "scr_dir2_threshold_20": 0.2633928820889934,
        "scr_dir1_threshold_50": 0.4529148677244576,
        "scr_metric_threshold_50": 0.37053567270882043,
        "scr_dir2_threshold_50": 0.37053567270882043,
        "scr_dir1_threshold_100": 0.44843035303859413,
        "scr_metric_threshold_100": 0.42857142857142855,
        "scr_dir2_threshold_100": 0.42857142857142855,
        "scr_dir1_threshold_500": 0.26457380405145886,
        "scr_metric_threshold_500": 0.4955356394473054,
        "scr_dir2_threshold_500": 0.4955356394473054
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.05150224144123495,
        "scr_metric_threshold_2": 0.05150224144123495,
        "scr_dir2_threshold_2": 0.06190480515528994,
        "scr_dir1_threshold_5": 0.08583681325484281,
        "scr_metric_threshold_5": 0.08583681325484281,
        "scr_dir2_threshold_5": 0.10000011353263609,
        "scr_dir1_threshold_10": 0.13733905469607777,
        "scr_metric_threshold_10": 0.13733905469607777,
        "scr_dir2_threshold_10": 0.13809513807839202,
        "scr_dir1_threshold_20": 0.1416308441960435,
        "scr_metric_threshold_20": 0.1416308441960435,
        "scr_dir2_threshold_20": 0.18571413163427958,
        "scr_dir1_threshold_50": 0.18454925082346488,
        "scr_metric_threshold_50": 0.18454925082346488,
        "scr_dir2_threshold_50": 0.1571427922670651,
        "scr_dir1_threshold_100": 0.17167388232356773,
        "scr_metric_threshold_100": 0.17167388232356773,
        "scr_dir2_threshold_100": 0.14761910708852366,
        "scr_dir1_threshold_500": 0.2489271165784791,
        "scr_metric_threshold_500": 0.2489271165784791,
        "scr_dir2_threshold_500": 0.22857128260089646
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "9af18d87-1297-4e3c-9ef9-acfadc9b8bdc",
    "datetime_epoch_millis": 1738247870597,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.9501312499999999,
        "llm_top_1_test_accuracy": 0.6502249999999999,
        "llm_top_2_test_accuracy": 0.72083125,
        "llm_top_5_test_accuracy": 0.78338125,
        "llm_top_10_test_accuracy": 0.83066875,
        "llm_top_20_test_accuracy": 0.876675,
        "llm_top_50_test_accuracy": 0.9209999999999999,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9606750480830669,
        "sae_top_1_test_accuracy": 0.804225,
        "sae_top_2_test_accuracy": 0.8431875,
        "sae_top_5_test_accuracy": 0.88376875,
        "sae_top_10_test_accuracy": 0.9092312499999999,
        "sae_top_20_test_accuracy": 0.9253874999999999,
        "sae_top_50_test_accuracy": 0.9386062499999999,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9682000398635864,
        "sae_top_1_test_accuracy": 0.8213999999999999,
        "sae_top_2_test_accuracy": 0.8644000000000001,
        "sae_top_5_test_accuracy": 0.8948,
        "sae_top_10_test_accuracy": 0.9207999999999998,
        "sae_top_20_test_accuracy": 0.9410000000000001,
        "sae_top_50_test_accuracy": 0.9528000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9471999999999999,
        "llm_top_1_test_accuracy": 0.6699999999999999,
        "llm_top_2_test_accuracy": 0.7154,
        "llm_top_5_test_accuracy": 0.7639999999999999,
        "llm_top_10_test_accuracy": 0.8030000000000002,
        "llm_top_20_test_accuracy": 0.865,
        "llm_top_50_test_accuracy": 0.9056,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9568000555038452,
        "sae_top_1_test_accuracy": 0.7898,
        "sae_top_2_test_accuracy": 0.8169999999999998,
        "sae_top_5_test_accuracy": 0.8704000000000001,
        "sae_top_10_test_accuracy": 0.8984,
        "sae_top_20_test_accuracy": 0.9238,
        "sae_top_50_test_accuracy": 0.9301999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9149999999999998,
        "llm_top_1_test_accuracy": 0.6838,
        "llm_top_2_test_accuracy": 0.732,
        "llm_top_5_test_accuracy": 0.7639999999999999,
        "llm_top_10_test_accuracy": 0.7994,
        "llm_top_20_test_accuracy": 0.8460000000000001,
        "llm_top_50_test_accuracy": 0.8874000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9344000339508056,
        "sae_top_1_test_accuracy": 0.7878,
        "sae_top_2_test_accuracy": 0.8294,
        "sae_top_5_test_accuracy": 0.8562,
        "sae_top_10_test_accuracy": 0.8766,
        "sae_top_20_test_accuracy": 0.8939999999999999,
        "sae_top_50_test_accuracy": 0.9018,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.8976,
        "llm_top_1_test_accuracy": 0.5973999999999999,
        "llm_top_2_test_accuracy": 0.6428,
        "llm_top_5_test_accuracy": 0.6796000000000001,
        "llm_top_10_test_accuracy": 0.7486,
        "llm_top_20_test_accuracy": 0.8004,
        "llm_top_50_test_accuracy": 0.8592000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9212000489234924,
        "sae_top_1_test_accuracy": 0.76,
        "sae_top_2_test_accuracy": 0.7856,
        "sae_top_5_test_accuracy": 0.8232000000000002,
        "sae_top_10_test_accuracy": 0.8422000000000001,
        "sae_top_20_test_accuracy": 0.8634000000000001,
        "sae_top_50_test_accuracy": 0.8868,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.9815,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.847,
        "llm_top_50_test_accuracy": 0.933,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9800000488758087,
        "sae_top_1_test_accuracy": 0.897,
        "sae_top_2_test_accuracy": 0.92,
        "sae_top_5_test_accuracy": 0.938,
        "sae_top_10_test_accuracy": 0.951,
        "sae_top_20_test_accuracy": 0.963,
        "sae_top_50_test_accuracy": 0.966,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9630000000000001,
        "llm_top_1_test_accuracy": 0.6522,
        "llm_top_2_test_accuracy": 0.6986,
        "llm_top_5_test_accuracy": 0.7718,
        "llm_top_10_test_accuracy": 0.8042,
        "llm_top_20_test_accuracy": 0.8682000000000001,
        "llm_top_50_test_accuracy": 0.9254,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9716000437736512,
        "sae_top_1_test_accuracy": 0.6274,
        "sae_top_2_test_accuracy": 0.7306,
        "sae_top_5_test_accuracy": 0.812,
        "sae_top_10_test_accuracy": 0.8802,
        "sae_top_20_test_accuracy": 0.8954000000000001,
        "sae_top_50_test_accuracy": 0.9391999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.9377500000000001,
        "llm_top_1_test_accuracy": 0.637,
        "llm_top_2_test_accuracy": 0.77525,
        "llm_top_5_test_accuracy": 0.82425,
        "llm_top_10_test_accuracy": 0.8667500000000001,
        "llm_top_20_test_accuracy": 0.8999999999999999,
        "llm_top_50_test_accuracy": 0.922,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9540000557899475,
        "sae_top_1_test_accuracy": 0.811,
        "sae_top_2_test_accuracy": 0.8565,
        "sae_top_5_test_accuracy": 0.9047499999999999,
        "sae_top_10_test_accuracy": 0.91325,
        "sae_top_20_test_accuracy": 0.9285,
        "sae_top_50_test_accuracy": 0.93425,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9994,
        "llm_top_1_test_accuracy": 0.6472,
        "llm_top_2_test_accuracy": 0.7870000000000001,
        "llm_top_5_test_accuracy": 0.9061999999999999,
        "llm_top_10_test_accuracy": 0.9638,
        "llm_top_20_test_accuracy": 0.9905999999999999,
        "llm_top_50_test_accuracy": 0.9970000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9992000579833984,
        "sae_top_1_test_accuracy": 0.9394,
        "sae_top_2_test_accuracy": 0.942,
        "sae_top_5_test_accuracy": 0.9708,
        "sae_top_10_test_accuracy": 0.9914,
        "sae_top_20_test_accuracy": 0.994,
        "sae_top_50_test_accuracy": 0.9978,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}