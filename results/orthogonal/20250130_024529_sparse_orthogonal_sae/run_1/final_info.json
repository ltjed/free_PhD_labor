{
  "training results for layer 12": {
    "config": {
      "trainer_class": "TrainerTopK",
      "dict_class": "AutoEncoderTopK",
      "lr": 0.0001885618083164127,
      "steps": 4882,
      "seed": 42,
      "activation_dim": 2304,
      "dict_size": 18432,
      "k": 320,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "AutoEncoderTopK",
      "submodule_name": "resid_post_layer_12",
      "ortho_weight": 0.01
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 2485.0302734375,
      "layer": 12,
      "dict_size": 18432,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "1a362f7d-d383-4a93-9368-efb96c13815b",
    "datetime_epoch_millis": 1738224545964,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.019294392770806086,
        "mean_num_split_features": 1.3181818181818181
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.0003755163349605708,
        "num_absorption": 1,
        "num_probe_true_positives": 2663,
        "num_split_features": 2
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.0031665611146295125,
        "num_absorption": 5,
        "num_probe_true_positives": 1579,
        "num_split_features": 1
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.002875629043853343,
        "num_absorption": 8,
        "num_probe_true_positives": 2782,
        "num_split_features": 2
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.0025031289111389237,
        "num_absorption": 4,
        "num_probe_true_positives": 1598,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.018575851393188854,
        "num_absorption": 30,
        "num_probe_true_positives": 1615,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1140,
        "num_split_features": 1
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.003092783505154639,
        "num_absorption": 3,
        "num_probe_true_positives": 970,
        "num_split_features": 2
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.004039238315060588,
        "num_absorption": 7,
        "num_probe_true_positives": 1733,
        "num_split_features": 1
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.0026041666666666665,
        "num_absorption": 1,
        "num_probe_true_positives": 384,
        "num_split_features": 2
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1227,
        "num_split_features": 2
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.002184598580010923,
        "num_absorption": 4,
        "num_probe_true_positives": 1831,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 835,
        "num_split_features": 1
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.33649289099526064,
        "num_absorption": 355,
        "num_probe_true_positives": 1055,
        "num_split_features": 2
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 2301,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.000628140703517588,
        "num_absorption": 1,
        "num_probe_true_positives": 1592,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.00035385704175513094,
        "num_absorption": 1,
        "num_probe_true_positives": 2826,
        "num_split_features": 1
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.0018575851393188853,
        "num_absorption": 3,
        "num_probe_true_positives": 1615,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.0025188916876574307,
        "num_absorption": 2,
        "num_probe_true_positives": 794,
        "num_split_features": 1
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.0012315270935960591,
        "num_absorption": 1,
        "num_probe_true_positives": 812,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.004411764705882353,
        "num_absorption": 3,
        "num_probe_true_positives": 680,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.011363636363636364,
        "num_absorption": 2,
        "num_probe_true_positives": 176,
        "num_split_features": 2
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.026200873362445413,
        "num_absorption": 6,
        "num_probe_true_positives": 229,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9910229037267081,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.09033203125
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9917763157894737,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 3.015625,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.77734375,
        "mse": 1.4140625,
        "cossim": 0.9296875
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 139.0,
        "l2_ratio": 0.9296875,
        "relative_reconstruction_bias": 1.0
      },
      "sparsity": {
        "l0": 320.0,
        "l1": 952.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr and tpp evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "276690d0-6fd1-44ae-a8c6-a701028077c3",
    "datetime_epoch_millis": 1738225212182,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.1955425822094086,
        "scr_metric_threshold_2": 0.11970401073894583,
        "scr_dir2_threshold_2": 0.12213606719109253,
        "scr_dir1_threshold_5": 0.23408098260211205,
        "scr_metric_threshold_5": 0.1578280435237722,
        "scr_dir2_threshold_5": 0.16132539039330973,
        "scr_dir1_threshold_10": 0.27579798467138245,
        "scr_metric_threshold_10": 0.19285017396835,
        "scr_dir2_threshold_10": 0.19931605097752997,
        "scr_dir1_threshold_20": 0.26185449280265366,
        "scr_metric_threshold_20": 0.22151772152030752,
        "scr_dir2_threshold_20": 0.2346563767797726,
        "scr_dir1_threshold_50": 0.2108871487180114,
        "scr_metric_threshold_50": 0.2886734030973625,
        "scr_dir2_threshold_50": 0.2957855781320286,
        "scr_dir1_threshold_100": 0.16623939280095515,
        "scr_metric_threshold_100": 0.2851695496843647,
        "scr_dir2_threshold_100": 0.28203752904784385,
        "scr_dir1_threshold_500": 0.0668684409382995,
        "scr_metric_threshold_500": 0.26438794908812524,
        "scr_dir2_threshold_500": 0.2683323851785931
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.4375002910385279,
        "scr_metric_threshold_2": 0.012284998611665989,
        "scr_dir2_threshold_2": 0.012284998611665989,
        "scr_dir1_threshold_5": 0.45312510186348476,
        "scr_metric_threshold_5": 0.01474211549298745,
        "scr_dir2_threshold_5": 0.01474211549298745,
        "scr_dir1_threshold_10": 0.4843747235133985,
        "scr_metric_threshold_10": 0.027027114104653437,
        "scr_dir2_threshold_10": 0.027027114104653437,
        "scr_dir1_threshold_20": 0.42187454889028175,
        "scr_metric_threshold_20": 0.05896816907447914,
        "scr_dir2_threshold_20": 0.05896816907447914,
        "scr_dir1_threshold_50": 0.4062497380653249,
        "scr_metric_threshold_50": 0.09090907759556952,
        "scr_dir2_threshold_50": 0.09090907759556952,
        "scr_dir1_threshold_100": 0.390624927240368,
        "scr_metric_threshold_100": 0.10565119308855696,
        "scr_dir2_threshold_100": 0.10565119308855696,
        "scr_dir1_threshold_500": 0.42187454889028175,
        "scr_metric_threshold_500": 0.0024571168813214595,
        "scr_dir2_threshold_500": 0.0024571168813214595
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.1359223357153976,
        "scr_metric_threshold_2": 0.13180517716755977,
        "scr_dir2_threshold_2": 0.13180517716755977,
        "scr_dir1_threshold_5": 0.12621372145414522,
        "scr_metric_threshold_5": 0.16045844684973207,
        "scr_dir2_threshold_5": 0.16045844684973207,
        "scr_dir1_threshold_10": 0.2524268642223358,
        "scr_metric_threshold_10": 0.1719197888799928,
        "scr_dir2_threshold_10": 0.1719197888799928,
        "scr_dir1_threshold_20": 0.19417459996886668,
        "scr_metric_threshold_20": 0.2521490123048588,
        "scr_dir2_threshold_20": 0.2521490123048588,
        "scr_dir1_threshold_50": -0.019417807208459464,
        "scr_metric_threshold_50": 0.33237823572972486,
        "scr_dir2_threshold_50": 0.33237823572972486,
        "scr_dir1_threshold_100": 0.0,
        "scr_metric_threshold_100": 0.12893988435673434,
        "scr_dir2_threshold_100": 0.12893988435673434,
        "scr_dir1_threshold_500": -0.6116508000622666,
        "scr_metric_threshold_500": 0.09169056545512676,
        "scr_dir2_threshold_500": 0.09169056545512676
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.5079364028137167,
        "scr_metric_threshold_2": 0.037974794330044616,
        "scr_dir2_threshold_2": 0.037974794330044616,
        "scr_dir1_threshold_5": 0.6031751287885597,
        "scr_metric_threshold_5": 0.06075961056894363,
        "scr_dir2_threshold_5": 0.06075961056894363,
        "scr_dir1_threshold_10": 0.5873013770560047,
        "scr_metric_threshold_10": 0.09113926495559606,
        "scr_dir2_threshold_10": 0.09113926495559606,
        "scr_dir1_threshold_20": 0.5714285714285714,
        "scr_metric_threshold_20": 0.09367087767151386,
        "scr_dir2_threshold_20": 0.09367087767151386,
        "scr_dir1_threshold_50": 0.3492064543291405,
        "scr_metric_threshold_50": 0.1620253263882109,
        "scr_dir2_threshold_50": 0.1620253263882109,
        "scr_dir1_threshold_100": 0.20634931147199764,
        "scr_metric_threshold_100": 0.2050633461500911,
        "scr_dir2_threshold_100": 0.2050633461500911,
        "scr_dir1_threshold_500": -0.1587299484845761,
        "scr_metric_threshold_500": 0.08354442680784264,
        "scr_dir2_threshold_500": 0.08354442680784264
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": 0.15625029103825686,
        "scr_metric_threshold_2": 0.041543020933079725,
        "scr_dir2_threshold_2": 0.041543020933079725,
        "scr_dir1_threshold_5": 0.21093754365573852,
        "scr_metric_threshold_5": 0.07715140039073762,
        "scr_dir2_threshold_5": 0.07715140039073762,
        "scr_dir1_threshold_10": 0.17968748544808716,
        "scr_metric_threshold_10": 0.13056388114303663,
        "scr_dir2_threshold_10": 0.13056388114303663,
        "scr_dir1_threshold_20": 0.08593777648634401,
        "scr_metric_threshold_20": 0.1513353031753887,
        "scr_dir2_threshold_20": 0.1513353031753887,
        "scr_dir1_threshold_50": -0.07812491268852294,
        "scr_metric_threshold_50": 0.20474778392768772,
        "scr_dir2_threshold_50": 0.20474778392768772,
        "scr_dir1_threshold_100": 0.06250011641530274,
        "scr_metric_threshold_100": 0.249258302466854,
        "scr_dir2_threshold_100": 0.249258302466854,
        "scr_dir1_threshold_500": 0.4062502910382569,
        "scr_metric_threshold_500": 0.04747783927687718,
        "scr_dir2_threshold_500": 0.04747783927687718
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.04371592886659017,
        "scr_metric_threshold_2": 0.5294118472036429,
        "scr_dir2_threshold_2": 0.5294118472036429,
        "scr_dir1_threshold_5": 0.016393554752069144,
        "scr_metric_threshold_5": 0.596078342458296,
        "scr_dir2_threshold_5": 0.596078342458296,
        "scr_dir1_threshold_10": 0.04371592886659017,
        "scr_metric_threshold_10": 0.6431372512353937,
        "scr_dir2_threshold_10": 0.6431372512353937,
        "scr_dir1_threshold_20": 0.05464474822904205,
        "scr_metric_threshold_20": 0.6470587685309047,
        "scr_dir2_threshold_20": 0.6470587685309047,
        "scr_dir1_threshold_50": 0.14754101564344832,
        "scr_metric_threshold_50": 0.662745071456604,
        "scr_dir2_threshold_50": 0.662745071456604,
        "scr_dir1_threshold_100": -0.2295081379870114,
        "scr_metric_threshold_100": 0.6509802858264159,
        "scr_dir2_threshold_100": 0.6509802858264159,
        "scr_dir1_threshold_500": -0.3224044054014177,
        "scr_metric_threshold_500": 0.6941176773080023,
        "scr_dir2_threshold_500": 0.6941176773080023
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.09230742426312609,
        "scr_metric_threshold_2": 0.07258066454365199,
        "scr_dir2_threshold_2": 0.07258066454365199,
        "scr_dir1_threshold_5": 0.14358973418467108,
        "scr_metric_threshold_5": 0.1290322658174608,
        "scr_dir2_threshold_5": 0.1290322658174608,
        "scr_dir1_threshold_10": 0.22051274056970427,
        "scr_metric_threshold_10": 0.1491935348194436,
        "scr_dir2_threshold_10": 0.1491935348194436,
        "scr_dir1_threshold_20": 0.24615374269804866,
        "scr_metric_threshold_20": 0.19758072462897314,
        "scr_dir2_threshold_20": 0.19758072462897314,
        "scr_dir1_threshold_50": 0.2615384662409978,
        "scr_metric_threshold_50": 0.27419359490476475,
        "scr_dir2_threshold_50": 0.27419359490476475,
        "scr_dir1_threshold_100": 0.24102560340535104,
        "scr_metric_threshold_100": 0.30241927537102686,
        "scr_dir2_threshold_100": 0.30241927537102686,
        "scr_dir1_threshold_500": 0.3128204704976866,
        "scr_metric_threshold_500": 0.45564525626389474,
        "scr_dir2_threshold_500": 0.45564525626389474
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.14349778781226621,
        "scr_metric_threshold_2": 0.08482138699453473,
        "scr_dir2_threshold_2": 0.08482138699453473,
        "scr_dir1_threshold_5": 0.237668052363351,
        "scr_metric_threshold_5": 0.14285714285714285,
        "scr_dir2_threshold_5": 0.14285714285714285,
        "scr_dir1_threshold_10": 0.31390132731264025,
        "scr_metric_threshold_10": 0.20535712622638533,
        "scr_dir2_threshold_10": 0.20535712622638533,
        "scr_dir1_threshold_20": 0.43049309615138404,
        "scr_metric_threshold_20": 0.28125005820765137,
        "scr_dir2_threshold_20": 0.28125005820765137,
        "scr_dir1_threshold_50": 0.44843035303859413,
        "scr_metric_threshold_50": 0.41071425245277066,
        "scr_dir2_threshold_50": 0.41071425245277066,
        "scr_dir1_threshold_100": 0.4529148677244576,
        "scr_metric_threshold_100": 0.43303565607806294,
        "scr_dir2_threshold_100": 0.43303565607806294,
        "scr_dir1_threshold_500": 0.24215229976379987,
        "scr_metric_threshold_500": 0.4955356394473054,
        "scr_dir2_threshold_500": 0.4955356394473054
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.047210196127387125,
        "scr_metric_threshold_2": 0.047210196127387125,
        "scr_dir2_threshold_2": 0.06666664774456064,
        "scr_dir1_threshold_5": 0.08154502375487709,
        "scr_metric_threshold_5": 0.08154502375487709,
        "scr_dir2_threshold_5": 0.10952379871117751,
        "scr_dir1_threshold_10": 0.1244634303822985,
        "scr_metric_threshold_10": 0.1244634303822985,
        "scr_dir2_threshold_10": 0.17619044645573817,
        "scr_dir1_threshold_20": 0.09012885856869063,
        "scr_metric_threshold_20": 0.09012885856869063,
        "scr_dir2_threshold_20": 0.19523810064441124,
        "scr_dir1_threshold_50": 0.17167388232356773,
        "scr_metric_threshold_50": 0.17167388232356773,
        "scr_dir2_threshold_50": 0.22857128260089646,
        "scr_dir1_threshold_100": 0.20600845413717558,
        "scr_metric_threshold_100": 0.20600845413717558,
        "scr_dir2_threshold_100": 0.18095228904500887,
        "scr_dir1_threshold_500": 0.24463507126463127,
        "scr_metric_threshold_500": 0.24463507126463127,
        "scr_dir2_threshold_500": 0.2761905599883743
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "01e44d3b-5917-44e5-b7e4-3dc15b988f3b",
    "datetime_epoch_millis": 1738225579979,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.9499499999999999,
        "llm_top_1_test_accuracy": 0.64524375,
        "llm_top_2_test_accuracy": 0.718125,
        "llm_top_5_test_accuracy": 0.78138125,
        "llm_top_10_test_accuracy": 0.8316749999999999,
        "llm_top_20_test_accuracy": 0.8780187500000001,
        "llm_top_50_test_accuracy": 0.9208125,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9606313005089759,
        "sae_top_1_test_accuracy": 0.79796875,
        "sae_top_2_test_accuracy": 0.84145625,
        "sae_top_5_test_accuracy": 0.8791749999999999,
        "sae_top_10_test_accuracy": 0.9074562500000001,
        "sae_top_20_test_accuracy": 0.9218562499999999,
        "sae_top_50_test_accuracy": 0.9401375,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.967400050163269,
        "sae_top_1_test_accuracy": 0.7824,
        "sae_top_2_test_accuracy": 0.8522000000000001,
        "sae_top_5_test_accuracy": 0.9,
        "sae_top_10_test_accuracy": 0.9244,
        "sae_top_20_test_accuracy": 0.9338000000000001,
        "sae_top_50_test_accuracy": 0.9556000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9466000000000001,
        "llm_top_1_test_accuracy": 0.6698000000000001,
        "llm_top_2_test_accuracy": 0.7128,
        "llm_top_5_test_accuracy": 0.7607999999999999,
        "llm_top_10_test_accuracy": 0.8094000000000001,
        "llm_top_20_test_accuracy": 0.8594000000000002,
        "llm_top_50_test_accuracy": 0.9032,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9560000538825989,
        "sae_top_1_test_accuracy": 0.7878000000000001,
        "sae_top_2_test_accuracy": 0.8155999999999999,
        "sae_top_5_test_accuracy": 0.852,
        "sae_top_10_test_accuracy": 0.8932,
        "sae_top_20_test_accuracy": 0.9192,
        "sae_top_50_test_accuracy": 0.9349999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9128000000000001,
        "llm_top_1_test_accuracy": 0.6883999999999999,
        "llm_top_2_test_accuracy": 0.7384000000000001,
        "llm_top_5_test_accuracy": 0.7598,
        "llm_top_10_test_accuracy": 0.8074,
        "llm_top_20_test_accuracy": 0.8540000000000001,
        "llm_top_50_test_accuracy": 0.889,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9322000503540039,
        "sae_top_1_test_accuracy": 0.7872,
        "sae_top_2_test_accuracy": 0.8177999999999999,
        "sae_top_5_test_accuracy": 0.8416,
        "sae_top_10_test_accuracy": 0.8827999999999999,
        "sae_top_20_test_accuracy": 0.8976,
        "sae_top_50_test_accuracy": 0.9088,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.9039999999999999,
        "llm_top_1_test_accuracy": 0.6006,
        "llm_top_2_test_accuracy": 0.6402,
        "llm_top_5_test_accuracy": 0.6798,
        "llm_top_10_test_accuracy": 0.744,
        "llm_top_20_test_accuracy": 0.8106,
        "llm_top_50_test_accuracy": 0.8568,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9220000505447388,
        "sae_top_1_test_accuracy": 0.7667999999999999,
        "sae_top_2_test_accuracy": 0.7864,
        "sae_top_5_test_accuracy": 0.818,
        "sae_top_10_test_accuracy": 0.8404,
        "sae_top_20_test_accuracy": 0.858,
        "sae_top_50_test_accuracy": 0.8884000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.9815,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.847,
        "llm_top_50_test_accuracy": 0.933,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9810000658035278,
        "sae_top_1_test_accuracy": 0.893,
        "sae_top_2_test_accuracy": 0.92,
        "sae_top_5_test_accuracy": 0.938,
        "sae_top_10_test_accuracy": 0.951,
        "sae_top_20_test_accuracy": 0.963,
        "sae_top_50_test_accuracy": 0.963,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9632,
        "llm_top_1_test_accuracy": 0.6194,
        "llm_top_2_test_accuracy": 0.6874,
        "llm_top_5_test_accuracy": 0.7604,
        "llm_top_10_test_accuracy": 0.8024000000000001,
        "llm_top_20_test_accuracy": 0.8715999999999999,
        "llm_top_50_test_accuracy": 0.9259999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9738000392913818,
        "sae_top_1_test_accuracy": 0.6272,
        "sae_top_2_test_accuracy": 0.73,
        "sae_top_5_test_accuracy": 0.8234,
        "sae_top_10_test_accuracy": 0.8676,
        "sae_top_20_test_accuracy": 0.89,
        "sae_top_50_test_accuracy": 0.9414,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.9325,
        "llm_top_1_test_accuracy": 0.62875,
        "llm_top_2_test_accuracy": 0.766,
        "llm_top_5_test_accuracy": 0.83025,
        "llm_top_10_test_accuracy": 0.8720000000000001,
        "llm_top_20_test_accuracy": 0.8947499999999999,
        "llm_top_50_test_accuracy": 0.9225000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9532500505447388,
        "sae_top_1_test_accuracy": 0.80175,
        "sae_top_2_test_accuracy": 0.86625,
        "sae_top_5_test_accuracy": 0.8979999999999999,
        "sae_top_10_test_accuracy": 0.90725,
        "sae_top_20_test_accuracy": 0.9222499999999999,
        "sae_top_50_test_accuracy": 0.9315,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9994,
        "llm_top_1_test_accuracy": 0.6407999999999999,
        "llm_top_2_test_accuracy": 0.7846,
        "llm_top_5_test_accuracy": 0.9028,
        "llm_top_10_test_accuracy": 0.9586,
        "llm_top_20_test_accuracy": 0.9906,
        "llm_top_50_test_accuracy": 0.9975999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9994000434875489,
        "sae_top_1_test_accuracy": 0.9376,
        "sae_top_2_test_accuracy": 0.9433999999999999,
        "sae_top_5_test_accuracy": 0.9623999999999999,
        "sae_top_10_test_accuracy": 0.993,
        "sae_top_20_test_accuracy": 0.991,
        "sae_top_50_test_accuracy": 0.9974000000000001,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}