{
  "training results for layer 12": {
    "config": {
      "trainer_class": "TrainerTopK",
      "dict_class": "AutoEncoderTopK",
      "lr": 0.0001414213562373095,
      "steps": 4882,
      "seed": 42,
      "activation_dim": 2304,
      "dict_size": 32768,
      "k": 320,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "AutoEncoderTopK",
      "submodule_name": "resid_post_layer_12",
      "ortho_weight": 0.075
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 2473.705322265625,
      "layer": 12,
      "dict_size": 32768,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "29406e5f-ec2c-418f-9096-8140bb87271c",
    "datetime_epoch_millis": 1738250754932,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.017105504023720932,
        "mean_num_split_features": 1.3333333333333333
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.0011265490048817123,
        "num_absorption": 3,
        "num_probe_true_positives": 2663,
        "num_split_features": 1
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.0018999366687777073,
        "num_absorption": 3,
        "num_probe_true_positives": 1579,
        "num_split_features": 1
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.0003594536304816679,
        "num_absorption": 1,
        "num_probe_true_positives": 2782,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.0031289111389236545,
        "num_absorption": 5,
        "num_probe_true_positives": 1598,
        "num_split_features": 2
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.12136222910216718,
        "num_absorption": 196,
        "num_probe_true_positives": 1615,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.009649122807017544,
        "num_absorption": 11,
        "num_probe_true_positives": 1140,
        "num_split_features": 2
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.0010309278350515464,
        "num_absorption": 1,
        "num_probe_true_positives": 970,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.002308136180034622,
        "num_absorption": 4,
        "num_probe_true_positives": 1733,
        "num_split_features": 1
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.0026041666666666665,
        "num_absorption": 1,
        "num_probe_true_positives": 384,
        "num_split_features": 2
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.007352941176470588,
        "num_absorption": 5,
        "num_probe_true_positives": 680,
        "num_split_features": 3
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1227,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.002184598580010923,
        "num_absorption": 4,
        "num_probe_true_positives": 1831,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.010778443113772455,
        "num_absorption": 9,
        "num_probe_true_positives": 835,
        "num_split_features": 2
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.10900473933649289,
        "num_absorption": 115,
        "num_probe_true_positives": 1055,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 2301,
        "num_split_features": 1
      },
      {
        "first_letter": "q",
        "absorption_rate": 0.005813953488372093,
        "num_absorption": 1,
        "num_probe_true_positives": 172,
        "num_split_features": 2
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.000628140703517588,
        "num_absorption": 1,
        "num_probe_true_positives": 1592,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.024416135881104035,
        "num_absorption": 69,
        "num_probe_true_positives": 2826,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.03526448362720403,
        "num_absorption": 28,
        "num_probe_true_positives": 794,
        "num_split_features": 1
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.0012315270935960591,
        "num_absorption": 1,
        "num_probe_true_positives": 812,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.06470588235294118,
        "num_absorption": 44,
        "num_probe_true_positives": 680,
        "num_split_features": 1
      },
      {
        "first_letter": "x",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 102,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.005681818181818182,
        "num_absorption": 1,
        "num_probe_true_positives": 176,
        "num_split_features": 2
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 229,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 32768,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9908773291925466,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.091796875
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9917763157894737,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 3.015625,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.77734375,
        "mse": 1.3984375,
        "cossim": 0.93359375
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 139.0,
        "l2_ratio": 0.93359375,
        "relative_reconstruction_bias": 1.0
      },
      "sparsity": {
        "l0": 320.0,
        "l1": 900.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr and tpp evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "abc35dc4-0309-473e-92d0-2391cf06649c",
    "datetime_epoch_millis": 1738251038127,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.12505714190720385,
        "scr_metric_threshold_2": 0.05664220817320389,
        "scr_dir2_threshold_2": 0.06050741227713484,
        "scr_dir1_threshold_5": 0.2270587951856543,
        "scr_metric_threshold_5": 0.11651382754150853,
        "scr_dir2_threshold_5": 0.1147792007701458,
        "scr_dir1_threshold_10": 0.21684748981895735,
        "scr_metric_threshold_10": 0.1426404485381542,
        "scr_dir2_threshold_10": 0.14674068268895116,
        "scr_dir1_threshold_20": 0.24150282217492286,
        "scr_metric_threshold_20": 0.17000952937810773,
        "scr_dir2_threshold_20": 0.176130520025696,
        "scr_dir1_threshold_50": 0.20800064842265345,
        "scr_metric_threshold_50": 0.21206841063843562,
        "scr_dir2_threshold_50": 0.2265150752964934,
        "scr_dir1_threshold_100": 0.20676741176922164,
        "scr_metric_threshold_100": 0.2291759976275877,
        "scr_dir2_threshold_100": 0.24939876306942854,
        "scr_dir1_threshold_500": 0.16976730125531633,
        "scr_metric_threshold_500": 0.23146218580697586,
        "scr_dir2_threshold_500": 0.24429174046821067
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.2656245779941345,
        "scr_metric_threshold_2": 0.009828028179079856,
        "scr_dir2_threshold_2": 0.009828028179079856,
        "scr_dir1_threshold_5": 0.46874991268844163,
        "scr_metric_threshold_5": 0.019656056358159712,
        "scr_dir2_threshold_5": 0.019656056358159712,
        "scr_dir1_threshold_10": 0.4843747235133985,
        "scr_metric_threshold_10": 0.024570143672067307,
        "scr_dir2_threshold_10": 0.024570143672067307,
        "scr_dir1_threshold_20": 0.46874991268844163,
        "scr_metric_threshold_20": 0.039312112716319424,
        "scr_dir2_threshold_20": 0.039312112716319424,
        "scr_dir1_threshold_50": 0.390624927240368,
        "scr_metric_threshold_50": 0.05159711132798542,
        "scr_dir2_threshold_50": 0.05159711132798542,
        "scr_dir1_threshold_100": 0.42187454889028175,
        "scr_metric_threshold_100": 0.05896816907447914,
        "scr_dir2_threshold_100": 0.05896816907447914,
        "scr_dir1_threshold_500": 0.37500011641541114,
        "scr_metric_threshold_500": 0.05159711132798542,
        "scr_dir2_threshold_500": 0.05159711132798542
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.07766949277597389,
        "scr_metric_threshold_2": 0.022922513273562452,
        "scr_dir2_threshold_2": 0.022922513273562452,
        "scr_dir1_threshold_5": 0.3106797071617595,
        "scr_metric_threshold_5": 0.06590258858377988,
        "scr_dir2_threshold_5": 0.06590258858377988,
        "scr_dir1_threshold_10": 0.29126189995330004,
        "scr_metric_threshold_10": 0.10601720029621291,
        "scr_dir2_threshold_10": 0.10601720029621291,
        "scr_dir1_threshold_20": 0.29126189995330004,
        "scr_metric_threshold_20": 0.18624642372107894,
        "scr_dir2_threshold_20": 0.18624642372107894,
        "scr_dir1_threshold_50": 0.2718446714307952,
        "scr_metric_threshold_50": 0.21203440059242581,
        "scr_dir2_threshold_50": 0.21203440059242581,
        "scr_dir1_threshold_100": 0.24271824996108338,
        "scr_metric_threshold_100": 0.26361035433511953,
        "scr_dir2_threshold_100": 0.26361035433511953,
        "scr_dir1_threshold_500": -0.04854364999221667,
        "scr_metric_threshold_500": 0.12893988435673434,
        "scr_dir2_threshold_500": 0.12893988435673434
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.4126986229439953,
        "scr_metric_threshold_2": 0.0126583653752278,
        "scr_dir2_threshold_2": 0.0126583653752278,
        "scr_dir1_threshold_5": 0.5238092084411499,
        "scr_metric_threshold_5": 0.03544318161412681,
        "scr_dir2_threshold_5": 0.03544318161412681,
        "scr_dir1_threshold_10": 0.5238092084411499,
        "scr_metric_threshold_10": 0.04556963247779803,
        "scr_dir2_threshold_10": 0.04556963247779803,
        "scr_dir1_threshold_20": 0.5238092084411499,
        "scr_metric_threshold_20": 0.04050640704596242,
        "scr_dir2_threshold_20": 0.04050640704596242,
        "scr_dir1_threshold_50": 0.4126986229439953,
        "scr_metric_threshold_50": 0.07848105047818764,
        "scr_dir2_threshold_50": 0.07848105047818764,
        "scr_dir1_threshold_100": 0.33333364870170723,
        "scr_metric_threshold_100": 0.13164567200155847,
        "scr_dir2_threshold_100": 0.13164567200155847,
        "scr_dir1_threshold_500": 0.2857142857142857,
        "scr_metric_threshold_500": 0.08354442680784264,
        "scr_dir2_threshold_500": 0.08354442680784264
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": 0.1250002328306055,
        "scr_metric_threshold_2": 0.02373891963843859,
        "scr_dir2_threshold_2": 0.02373891963843859,
        "scr_dir1_threshold_5": 0.31250011641530273,
        "scr_metric_threshold_5": 0.050445160014588104,
        "scr_dir2_threshold_5": 0.050445160014588104,
        "scr_dir1_threshold_10": 0.18750034924590825,
        "scr_metric_threshold_10": 0.10089032002917621,
        "scr_dir2_threshold_10": 0.10089032002917621,
        "scr_dir1_threshold_20": 0.2265628055901697,
        "scr_metric_threshold_20": 0.11572710058610643,
        "scr_dir2_threshold_20": 0.11572710058610643,
        "scr_dir1_threshold_50": 0.015625261934431176,
        "scr_metric_threshold_50": 0.17210690207611637,
        "scr_dir2_threshold_50": 0.17210690207611637,
        "scr_dir1_threshold_100": 0.015625261934431176,
        "scr_metric_threshold_100": 0.11572710058610643,
        "scr_dir2_threshold_100": 0.11572710058610643,
        "scr_dir1_threshold_500": 0.15625029103825686,
        "scr_metric_threshold_500": 0.08011872112844853,
        "scr_dir2_threshold_500": 0.08011872112844853
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": -0.01092881936245188,
        "scr_metric_threshold_2": 0.17647061573454761,
        "scr_dir2_threshold_2": 0.17647061573454761,
        "scr_dir1_threshold_5": 0.016393554752069144,
        "scr_metric_threshold_5": 0.4274509950584254,
        "scr_dir2_threshold_5": 0.4274509950584254,
        "scr_dir1_threshold_10": -0.00546440968122594,
        "scr_metric_threshold_10": 0.49019597301756745,
        "scr_dir2_threshold_10": 0.49019597301756745,
        "scr_dir1_threshold_20": -0.01092881936245188,
        "scr_metric_threshold_20": 0.5215685788689659,
        "scr_dir2_threshold_20": 0.5215685788689659,
        "scr_dir1_threshold_50": 0.00546440968122594,
        "scr_metric_threshold_50": 0.5529411847203642,
        "scr_dir2_threshold_50": 0.5529411847203642,
        "scr_dir1_threshold_100": 0.03825119347697291,
        "scr_metric_threshold_100": 0.5490196674248532,
        "scr_dir2_threshold_100": 0.5490196674248532,
        "scr_dir1_threshold_500": -0.06010915791026799,
        "scr_metric_threshold_500": 0.596078342458296,
        "scr_dir2_threshold_500": 0.596078342458296
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.046153559299134936,
        "scr_metric_threshold_2": 0.09677413927777444,
        "scr_dir2_threshold_2": 0.09677413927777444,
        "scr_dir1_threshold_5": 0.05641014354938642,
        "scr_metric_threshold_5": 0.08064531634921589,
        "scr_dir2_threshold_5": 0.08064531634921589,
        "scr_dir1_threshold_10": 0.10256400851337757,
        "scr_metric_threshold_10": 0.12096785435318151,
        "scr_dir2_threshold_10": 0.12096785435318151,
        "scr_dir1_threshold_20": 0.14358973418467108,
        "scr_metric_threshold_20": 0.13306447154960044,
        "scr_dir2_threshold_20": 0.13306447154960044,
        "scr_dir1_threshold_50": 0.16410229135546164,
        "scr_metric_threshold_50": 0.2137097878988163,
        "scr_dir2_threshold_50": 0.2137097878988163,
        "scr_dir1_threshold_100": 0.2564100212834439,
        "scr_metric_threshold_100": 0.2580645316349216,
        "scr_dir2_threshold_100": 0.2580645316349216,
        "scr_dir1_threshold_500": 0.19487173844135988,
        "scr_metric_threshold_500": 0.31048392717659073,
        "scr_dir2_threshold_500": 0.31048392717659073
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.06278026546252806,
        "scr_metric_threshold_2": 0.08928588059328964,
        "scr_dir2_threshold_2": 0.08928588059328964,
        "scr_dir1_threshold_5": 0.08071752234973815,
        "scr_metric_threshold_5": 0.20535712622638533,
        "scr_dir2_threshold_5": 0.20535712622638533,
        "scr_dir1_threshold_10": 0.11210752143829489,
        "scr_metric_threshold_10": 0.21428584733177455,
        "scr_dir2_threshold_10": 0.21428584733177455,
        "scr_dir1_threshold_20": 0.2331838049629021,
        "scr_metric_threshold_20": 0.2678571095956278,
        "scr_dir2_threshold_20": 0.2678571095956278,
        "scr_dir1_threshold_50": 0.30493256522632795,
        "scr_metric_threshold_50": 0.3169644104449672,
        "scr_dir2_threshold_50": 0.3169644104449672,
        "scr_dir1_threshold_100": 0.26008955665100997,
        "scr_metric_threshold_100": 0.37053567270882043,
        "scr_dir2_threshold_100": 0.37053567270882043,
        "scr_dir1_threshold_500": 0.30044831782587905,
        "scr_metric_threshold_500": 0.4464286046900865,
        "scr_dir2_threshold_500": 0.4464286046900865
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.021459203313710703,
        "scr_metric_threshold_2": 0.021459203313710703,
        "scr_dir2_threshold_2": 0.05238083614515829,
        "scr_dir1_threshold_5": 0.047210196127387125,
        "scr_metric_threshold_5": 0.047210196127387125,
        "scr_dir2_threshold_5": 0.033333181956485214,
        "scr_dir1_threshold_10": 0.03862661712745569,
        "scr_metric_threshold_10": 0.03862661712745569,
        "scr_dir2_threshold_10": 0.07142849033383136,
        "scr_dir1_threshold_20": 0.05579403094120067,
        "scr_metric_threshold_20": 0.05579403094120067,
        "scr_dir2_threshold_20": 0.10476195612190681,
        "scr_dir1_threshold_50": 0.09871243756862208,
        "scr_metric_threshold_50": 0.09871243756862208,
        "scr_dir2_threshold_50": 0.21428575483308432,
        "scr_dir1_threshold_100": 0.08583681325484281,
        "scr_metric_threshold_100": 0.08583681325484281,
        "scr_dir2_threshold_100": 0.24761893678956953,
        "scr_dir1_threshold_500": 0.15450646850982275,
        "scr_metric_threshold_500": 0.15450646850982275,
        "scr_dir2_threshold_500": 0.25714290579970117
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 32768,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "7ee5f358-534a-4090-ad13-862fe13683f4",
    "datetime_epoch_millis": 1738251433939,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.9509187499999998,
        "llm_top_1_test_accuracy": 0.6600499999999999,
        "llm_top_2_test_accuracy": 0.7258500000000001,
        "llm_top_5_test_accuracy": 0.7819625,
        "llm_top_10_test_accuracy": 0.83256875,
        "llm_top_20_test_accuracy": 0.87795,
        "llm_top_50_test_accuracy": 0.921,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9589375440031289,
        "sae_top_1_test_accuracy": 0.7497874999999999,
        "sae_top_2_test_accuracy": 0.8037562500000001,
        "sae_top_5_test_accuracy": 0.8658437500000001,
        "sae_top_10_test_accuracy": 0.892475,
        "sae_top_20_test_accuracy": 0.9141499999999999,
        "sae_top_50_test_accuracy": 0.9345125,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.968600046634674,
        "sae_top_1_test_accuracy": 0.7376,
        "sae_top_2_test_accuracy": 0.8332,
        "sae_top_5_test_accuracy": 0.8958,
        "sae_top_10_test_accuracy": 0.9152000000000001,
        "sae_top_20_test_accuracy": 0.9341999999999999,
        "sae_top_50_test_accuracy": 0.9548,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9488,
        "llm_top_1_test_accuracy": 0.673,
        "llm_top_2_test_accuracy": 0.7300000000000001,
        "llm_top_5_test_accuracy": 0.7668000000000001,
        "llm_top_10_test_accuracy": 0.8008,
        "llm_top_20_test_accuracy": 0.8649999999999999,
        "llm_top_50_test_accuracy": 0.8984,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9556000471115113,
        "sae_top_1_test_accuracy": 0.7804,
        "sae_top_2_test_accuracy": 0.8126,
        "sae_top_5_test_accuracy": 0.8676,
        "sae_top_10_test_accuracy": 0.8874000000000001,
        "sae_top_20_test_accuracy": 0.9196,
        "sae_top_50_test_accuracy": 0.9339999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9126,
        "llm_top_1_test_accuracy": 0.687,
        "llm_top_2_test_accuracy": 0.749,
        "llm_top_5_test_accuracy": 0.7636000000000001,
        "llm_top_10_test_accuracy": 0.8086,
        "llm_top_20_test_accuracy": 0.8516,
        "llm_top_50_test_accuracy": 0.8942,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9296000361442566,
        "sae_top_1_test_accuracy": 0.7653999999999999,
        "sae_top_2_test_accuracy": 0.7764,
        "sae_top_5_test_accuracy": 0.8154,
        "sae_top_10_test_accuracy": 0.8555999999999999,
        "sae_top_20_test_accuracy": 0.8712,
        "sae_top_50_test_accuracy": 0.9034000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.8997999999999999,
        "llm_top_1_test_accuracy": 0.6086,
        "llm_top_2_test_accuracy": 0.6472,
        "llm_top_5_test_accuracy": 0.6738000000000001,
        "llm_top_10_test_accuracy": 0.7484,
        "llm_top_20_test_accuracy": 0.805,
        "llm_top_50_test_accuracy": 0.8598000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9190000534057617,
        "sae_top_1_test_accuracy": 0.6683999999999999,
        "sae_top_2_test_accuracy": 0.7142,
        "sae_top_5_test_accuracy": 0.8006,
        "sae_top_10_test_accuracy": 0.8235999999999999,
        "sae_top_20_test_accuracy": 0.8513999999999999,
        "sae_top_50_test_accuracy": 0.8703999999999998,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.9815,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.847,
        "llm_top_50_test_accuracy": 0.9325000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9780000448226929,
        "sae_top_1_test_accuracy": 0.745,
        "sae_top_2_test_accuracy": 0.868,
        "sae_top_5_test_accuracy": 0.9,
        "sae_top_10_test_accuracy": 0.923,
        "sae_top_20_test_accuracy": 0.943,
        "sae_top_50_test_accuracy": 0.957,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9673999999999999,
        "llm_top_1_test_accuracy": 0.6599999999999999,
        "llm_top_2_test_accuracy": 0.7148000000000001,
        "llm_top_5_test_accuracy": 0.7598,
        "llm_top_10_test_accuracy": 0.8062000000000001,
        "llm_top_20_test_accuracy": 0.8728,
        "llm_top_50_test_accuracy": 0.9256,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9676000475883484,
        "sae_top_1_test_accuracy": 0.5926,
        "sae_top_2_test_accuracy": 0.6242000000000001,
        "sae_top_5_test_accuracy": 0.778,
        "sae_top_10_test_accuracy": 0.8412000000000001,
        "sae_top_20_test_accuracy": 0.8764000000000001,
        "sae_top_50_test_accuracy": 0.9276,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.93825,
        "llm_top_1_test_accuracy": 0.69,
        "llm_top_2_test_accuracy": 0.768,
        "llm_top_5_test_accuracy": 0.8274999999999999,
        "llm_top_10_test_accuracy": 0.87475,
        "llm_top_20_test_accuracy": 0.8969999999999999,
        "llm_top_50_test_accuracy": 0.9215,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.953500047326088,
        "sae_top_1_test_accuracy": 0.8275000000000001,
        "sae_top_2_test_accuracy": 0.8642500000000001,
        "sae_top_5_test_accuracy": 0.89675,
        "sae_top_10_test_accuracy": 0.905,
        "sae_top_20_test_accuracy": 0.9219999999999999,
        "sae_top_50_test_accuracy": 0.9324999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9994,
        "llm_top_1_test_accuracy": 0.6476,
        "llm_top_2_test_accuracy": 0.7822,
        "llm_top_5_test_accuracy": 0.907,
        "llm_top_10_test_accuracy": 0.9621999999999999,
        "llm_top_20_test_accuracy": 0.9889999999999999,
        "llm_top_50_test_accuracy": 0.9975999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9996000289916992,
        "sae_top_1_test_accuracy": 0.8814,
        "sae_top_2_test_accuracy": 0.9372,
        "sae_top_5_test_accuracy": 0.9725999999999999,
        "sae_top_10_test_accuracy": 0.9888,
        "sae_top_20_test_accuracy": 0.9954000000000001,
        "sae_top_50_test_accuracy": 0.9964000000000001,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 32768,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}