{
  "training results for layer 12": {
    "config": {
      "trainer_class": "TrainerTopK",
      "dict_class": "AutoEncoderTopK",
      "lr": 0.0001885618083164127,
      "steps": 2441,
      "seed": 42,
      "activation_dim": 2304,
      "dict_size": 18432,
      "k": 120,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "AutoEncoderTopK",
      "submodule_name": "resid_post_layer_12",
      "ortho_weight": 0.01
    },
    "final_info": {
      "training_steps": 2441,
      "final_loss": 3503.50634765625,
      "layer": 12,
      "dict_size": 18432,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "5f701fe6-a2cd-4cb8-b3c7-4d40f6ea086f",
    "datetime_epoch_millis": 1738627950081,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.05351089023954925,
        "mean_num_split_features": 1.2608695652173914
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.061746987951807226,
        "num_absorption": 164,
        "num_probe_true_positives": 2656,
        "num_split_features": 1
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.0025477707006369425,
        "num_absorption": 4,
        "num_probe_true_positives": 1570,
        "num_split_features": 1
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.004813032210292484,
        "num_absorption": 13,
        "num_probe_true_positives": 2701,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.015606242496998799,
        "num_absorption": 26,
        "num_probe_true_positives": 1666,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.026841448189762796,
        "num_absorption": 43,
        "num_probe_true_positives": 1602,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.06543624161073826,
        "num_absorption": 78,
        "num_probe_true_positives": 1192,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.003336113427856547,
        "num_absorption": 4,
        "num_probe_true_positives": 1199,
        "num_split_features": 2
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.08583247156153051,
        "num_absorption": 83,
        "num_probe_true_positives": 967,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.006582884500299222,
        "num_absorption": 11,
        "num_probe_true_positives": 1671,
        "num_split_features": 1
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.002369668246445498,
        "num_absorption": 1,
        "num_probe_true_positives": 422,
        "num_split_features": 2
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.0015037593984962407,
        "num_absorption": 1,
        "num_probe_true_positives": 665,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.15188834154351397,
        "num_absorption": 185,
        "num_probe_true_positives": 1218,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.04632310364794441,
        "num_absorption": 80,
        "num_probe_true_positives": 1727,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.003592814371257485,
        "num_absorption": 3,
        "num_probe_true_positives": 835,
        "num_split_features": 2
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.4289719626168224,
        "num_absorption": 459,
        "num_probe_true_positives": 1070,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.09808102345415778,
        "num_absorption": 230,
        "num_probe_true_positives": 2345,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.05705521472392638,
        "num_absorption": 93,
        "num_probe_true_positives": 1630,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.0825948245303084,
        "num_absorption": 233,
        "num_probe_true_positives": 2821,
        "num_split_features": 2
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.0072992700729927005,
        "num_absorption": 12,
        "num_probe_true_positives": 1644,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.006459948320413436,
        "num_absorption": 5,
        "num_probe_true_positives": 774,
        "num_split_features": 2
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.0011904761904761906,
        "num_absorption": 1,
        "num_probe_true_positives": 840,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.01908957415565345,
        "num_absorption": 13,
        "num_probe_true_positives": 681,
        "num_split_features": 2
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.051587301587301584,
        "num_absorption": 13,
        "num_probe_true_positives": 252,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9808812111801242,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.1923828125
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9802631578947368,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 3.125,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.69140625,
        "mse": 1.9609375,
        "cossim": 0.90234375
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 135.0,
        "l2_ratio": 0.90234375,
        "relative_reconstruction_bias": 1.0
      },
      "sparsity": {
        "l0": 119.99999237060547,
        "l1": 580.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "89a85c37-e838-444c-9cf8-e9dbbdbac256",
    "datetime_epoch_millis": 1738628771466,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.1913667703476992,
        "scr_metric_threshold_2": 0.08852976304022589,
        "scr_dir2_threshold_2": 0.08691265304340293,
        "scr_dir1_threshold_5": 0.2366603478106714,
        "scr_metric_threshold_5": 0.14703586476005165,
        "scr_dir2_threshold_5": 0.14743947578107122,
        "scr_dir1_threshold_10": 0.22056943982794108,
        "scr_metric_threshold_10": 0.20217366819343657,
        "scr_dir2_threshold_10": 0.20346633170009287,
        "scr_dir1_threshold_20": 0.2310895960483163,
        "scr_metric_threshold_20": 0.24688065573060747,
        "scr_dir2_threshold_20": 0.25186224993049183,
        "scr_dir1_threshold_50": 0.2076564196835261,
        "scr_metric_threshold_50": 0.2962730577540368,
        "scr_dir2_threshold_50": 0.30166595541149005,
        "scr_dir1_threshold_100": 0.16929662849508725,
        "scr_metric_threshold_100": 0.32796135563086043,
        "scr_dir2_threshold_100": 0.3347874329168332,
        "scr_dir1_threshold_500": -0.12309917095201517,
        "scr_metric_threshold_500": 0.2503258194370521,
        "scr_dir2_threshold_500": 0.2645808647924706
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.42187454889028175,
        "scr_metric_threshold_2": 0.009828028179079856,
        "scr_dir2_threshold_2": 0.009828028179079856,
        "scr_dir1_threshold_5": 0.45312510186348476,
        "scr_metric_threshold_5": 0.017199085925573582,
        "scr_dir2_threshold_5": 0.017199085925573582,
        "scr_dir1_threshold_10": 0.359374374267165,
        "scr_metric_threshold_10": 0.039312112716319424,
        "scr_dir2_threshold_10": 0.039312112716319424,
        "scr_dir1_threshold_20": 0.42187454889028175,
        "scr_metric_threshold_20": 0.06879605080482366,
        "scr_dir2_threshold_20": 0.06879605080482366,
        "scr_dir1_threshold_50": 0.34374956344220814,
        "scr_metric_threshold_50": 0.11547922126763682,
        "scr_dir2_threshold_50": 0.11547922126763682,
        "scr_dir1_threshold_100": 0.359374374267165,
        "scr_metric_threshold_100": 0.1277642198793028,
        "scr_dir2_threshold_100": 0.1277642198793028,
        "scr_dir1_threshold_500": 0.20312440337101778,
        "scr_metric_threshold_500": -0.004913940865172265,
        "scr_dir2_threshold_500": -0.004913940865172265
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.16504817849915482,
        "scr_metric_threshold_2": 0.12034383513729906,
        "scr_dir2_threshold_2": 0.12034383513729906,
        "scr_dir1_threshold_5": 0.2135918284913715,
        "scr_metric_threshold_5": 0.16618903247138295,
        "scr_dir2_threshold_5": 0.16618903247138295,
        "scr_dir1_threshold_10": 0.28155328569204763,
        "scr_metric_threshold_10": 0.19770776575133966,
        "scr_dir2_threshold_10": 0.19770776575133966,
        "scr_dir1_threshold_20": 0.2718446714307952,
        "scr_metric_threshold_20": 0.25501430511568424,
        "scr_dir2_threshold_20": 0.25501430511568424,
        "scr_dir1_threshold_50": 0.10679591424568576,
        "scr_metric_threshold_50": 0.306590258858378,
        "scr_dir2_threshold_50": 0.306590258858378,
        "scr_dir1_threshold_100": 0.11650452850693815,
        "scr_metric_threshold_100": 0.3724928474421579,
        "scr_dir2_threshold_100": 0.3724928474421579,
        "scr_dir1_threshold_500": -0.56310715007005,
        "scr_metric_threshold_500": 0.14613181200864592,
        "scr_dir2_threshold_500": 0.14613181200864592
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.5396829601737049,
        "scr_metric_threshold_2": 0.030379805284471813,
        "scr_dir2_threshold_2": 0.030379805284471813,
        "scr_dir1_threshold_5": 0.6190479344159929,
        "scr_metric_threshold_5": 0.05316462152337083,
        "scr_dir2_threshold_5": 0.05316462152337083,
        "scr_dir1_threshold_10": 0.5555557658011382,
        "scr_metric_threshold_10": 0.09620264128525105,
        "scr_dir2_threshold_10": 0.09620264128525105,
        "scr_dir1_threshold_20": 0.6031751287885597,
        "scr_metric_threshold_20": 0.10632924304674166,
        "scr_dir2_threshold_20": 0.10632924304674166,
        "scr_dir1_threshold_50": 0.33333364870170723,
        "scr_metric_threshold_50": 0.1620253263882109,
        "scr_dir2_threshold_50": 0.1620253263882109,
        "scr_dir1_threshold_100": 0.36507925995657375,
        "scr_metric_threshold_100": 0.21772156062749953,
        "scr_dir2_threshold_100": 0.21772156062749953,
        "scr_dir1_threshold_500": -1.5555548196960165,
        "scr_metric_threshold_500": 0.09873425400116885,
        "scr_dir2_threshold_500": 0.09873425400116885
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": 0.1484374272404358,
        "scr_metric_threshold_2": 0.05637997835838556,
        "scr_dir2_threshold_2": 0.05637997835838556,
        "scr_dir1_threshold_5": 0.2265628055901697,
        "scr_metric_threshold_5": 0.12759656040532572,
        "scr_dir2_threshold_5": 0.12759656040532572,
        "scr_dir1_threshold_10": 0.0,
        "scr_metric_threshold_10": 0.1899110033707575,
        "scr_dir2_threshold_10": 0.1899110033707575,
        "scr_dir1_threshold_20": 0.015625261934431176,
        "scr_metric_threshold_20": 0.249258302466854,
        "scr_dir2_threshold_20": 0.249258302466854,
        "scr_dir1_threshold_50": 0.1328126309672156,
        "scr_metric_threshold_50": 0.29376864413764464,
        "scr_dir2_threshold_50": 0.29376864413764464,
        "scr_dir1_threshold_100": -0.08593731082513303,
        "scr_metric_threshold_100": 0.33531166507072435,
        "scr_dir2_threshold_100": 0.33531166507072435,
        "scr_dir1_threshold_500": 0.3046877182786926,
        "scr_metric_threshold_500": 0.03264105871994697,
        "scr_dir2_threshold_500": 0.03264105871994697
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.05464474822904205,
        "scr_metric_threshold_2": 0.2745099505842539,
        "scr_dir2_threshold_2": 0.2745099505842539,
        "scr_dir1_threshold_5": 0.027322374114521025,
        "scr_metric_threshold_5": 0.45490208361431267,
        "scr_dir2_threshold_5": 0.45490208361431267,
        "scr_dir1_threshold_10": 0.03278678379574697,
        "scr_metric_threshold_10": 0.5568627020158754,
        "scr_dir2_threshold_10": 0.5568627020158754,
        "scr_dir1_threshold_20": -0.09289626741440628,
        "scr_metric_threshold_20": 0.6392157339398825,
        "scr_dir2_threshold_20": 0.6392157339398825,
        "scr_dir1_threshold_50": -0.03825151918536423,
        "scr_metric_threshold_50": 0.674509857086792,
        "scr_dir2_threshold_50": 0.674509857086792,
        "scr_dir1_threshold_100": -0.2185793186245595,
        "scr_metric_threshold_100": 0.674509857086792,
        "scr_dir2_threshold_100": 0.674509857086792,
        "scr_dir1_threshold_500": -0.18579220912042124,
        "scr_metric_threshold_500": 0.7137254975292127,
        "scr_dir2_threshold_500": 0.7137254975292127
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.05128200425668879,
        "scr_metric_threshold_2": 0.08064531634921589,
        "scr_dir2_threshold_2": 0.08064531634921589,
        "scr_dir1_threshold_5": 0.12820501064172196,
        "scr_metric_threshold_5": 0.09677413927777444,
        "scr_dir2_threshold_5": 0.09677413927777444,
        "scr_dir1_threshold_10": 0.18974359914866223,
        "scr_metric_threshold_10": 0.1572581866250075,
        "scr_dir2_threshold_10": 0.1572581866250075,
        "scr_dir1_threshold_20": 0.22564087986240192,
        "scr_metric_threshold_20": 0.20967734182539205,
        "scr_dir2_threshold_20": 0.20967734182539205,
        "scr_dir1_threshold_50": 0.28205102341178834,
        "scr_metric_threshold_50": 0.23387105690079912,
        "scr_dir2_threshold_50": 0.23387105690079912,
        "scr_dir1_threshold_100": 0.3025638862474351,
        "scr_metric_threshold_100": 0.3064517214444511,
        "scr_dir2_threshold_100": 0.3064517214444511,
        "scr_dir1_threshold_500": 0.3128204704976866,
        "scr_metric_threshold_500": 0.36693552845039956,
        "scr_dir2_threshold_500": 0.36693552845039956
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.09417026455108479,
        "scr_metric_threshold_2": 0.0803571594879004,
        "scr_dir2_threshold_2": 0.0803571594879004,
        "scr_dir1_threshold_5": 0.15246628261316397,
        "scr_metric_threshold_5": 0.18749995010772738,
        "scr_dir2_threshold_5": 0.18749995010772738,
        "scr_dir1_threshold_10": 0.25112106185011224,
        "scr_metric_threshold_10": 0.2857142857142857,
        "scr_dir2_threshold_10": 0.2857142857142857,
        "scr_dir1_threshold_20": 0.30044831782587905,
        "scr_metric_threshold_20": 0.3437500415768938,
        "scr_dir2_threshold_20": 0.3437500415768938,
        "scr_dir1_threshold_50": 0.36771283068885596,
        "scr_metric_threshold_50": 0.4508928321967208,
        "scr_dir2_threshold_50": 0.4508928321967208,
        "scr_dir1_threshold_100": 0.40807159186372505,
        "scr_metric_threshold_100": 0.48214295692740233,
        "scr_dir2_threshold_100": 0.48214295692740233,
        "scr_dir1_threshold_500": 0.3273543367994015,
        "scr_metric_threshold_500": 0.47767846332864744,
        "scr_dir2_threshold_500": 0.47767846332864744
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.05579403094120067,
        "scr_metric_threshold_2": 0.05579403094120067,
        "scr_dir2_threshold_2": 0.042857150966616867,
        "scr_dir1_threshold_5": 0.07296144475494565,
        "scr_metric_threshold_5": 0.07296144475494565,
        "scr_dir2_threshold_5": 0.07619033292310208,
        "scr_dir1_threshold_10": 0.09442064806865635,
        "scr_metric_threshold_10": 0.09442064806865635,
        "scr_dir2_threshold_10": 0.10476195612190681,
        "scr_dir1_threshold_20": 0.10300422706858779,
        "scr_metric_threshold_20": 0.10300422706858779,
        "scr_dir2_threshold_20": 0.14285698066766273,
        "scr_dir1_threshold_50": 0.13304726519611204,
        "scr_metric_threshold_50": 0.13304726519611204,
        "scr_dir2_threshold_50": 0.17619044645573817,
        "scr_dir1_threshold_100": 0.10729601656855352,
        "scr_metric_threshold_100": 0.10729601656855352,
        "scr_dir2_threshold_100": 0.1619046348563358,
        "scr_dir1_threshold_500": 0.17167388232356773,
        "scr_metric_threshold_500": 0.17167388232356773,
        "scr_dir2_threshold_500": 0.2857142451669157
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "tpp evaluations results": {
    "eval_type_id": "tpp",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": false,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "1cd9d437-4c38-4c9b-b2e2-78849d4df8db",
    "datetime_epoch_millis": 1738628919199,
    "eval_result_metrics": {
      "tpp_metrics": {
        "tpp_threshold_2_total_metric": 0.0040499910712242125,
        "tpp_threshold_2_intended_diff_only": 0.006599992513656616,
        "tpp_threshold_2_unintended_diff_only": 0.0025500014424324037,
        "tpp_threshold_5_total_metric": 0.007100002467632293,
        "tpp_threshold_5_intended_diff_only": 0.01069999933242798,
        "tpp_threshold_5_unintended_diff_only": 0.003599996864795685,
        "tpp_threshold_10_total_metric": 0.007449989020824431,
        "tpp_threshold_10_intended_diff_only": 0.012399989366531371,
        "tpp_threshold_10_unintended_diff_only": 0.00495000034570694,
        "tpp_threshold_20_total_metric": 0.01952500343322754,
        "tpp_threshold_20_intended_diff_only": 0.026200002431869505,
        "tpp_threshold_20_unintended_diff_only": 0.006674998998641967,
        "tpp_threshold_50_total_metric": 0.05115001201629639,
        "tpp_threshold_50_intended_diff_only": 0.05840001106262207,
        "tpp_threshold_50_unintended_diff_only": 0.007249999046325683,
        "tpp_threshold_100_total_metric": 0.09742500931024552,
        "tpp_threshold_100_intended_diff_only": 0.10590000748634339,
        "tpp_threshold_100_unintended_diff_only": 0.00847499817609787,
        "tpp_threshold_500_total_metric": 0.3426000207662583,
        "tpp_threshold_500_intended_diff_only": 0.35570002198219297,
        "tpp_threshold_500_unintended_diff_only": 0.013100001215934753
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_tpp_results",
        "tpp_threshold_2_total_metric": 0.0038999944925308225,
        "tpp_threshold_2_intended_diff_only": 0.006400001049041748,
        "tpp_threshold_2_unintended_diff_only": 0.0025000065565109254,
        "tpp_threshold_5_total_metric": 0.006099998950958252,
        "tpp_threshold_5_intended_diff_only": 0.009000003337860107,
        "tpp_threshold_5_unintended_diff_only": 0.0029000043869018555,
        "tpp_threshold_10_total_metric": 0.008749979734420776,
        "tpp_threshold_10_intended_diff_only": 0.012199985980987548,
        "tpp_threshold_10_unintended_diff_only": 0.0034500062465667725,
        "tpp_threshold_20_total_metric": 0.020350009202957153,
        "tpp_threshold_20_intended_diff_only": 0.024600017070770263,
        "tpp_threshold_20_unintended_diff_only": 0.0042500078678131105,
        "tpp_threshold_50_total_metric": 0.055600005388259884,
        "tpp_threshold_50_intended_diff_only": 0.06020001173019409,
        "tpp_threshold_50_unintended_diff_only": 0.004600006341934204,
        "tpp_threshold_100_total_metric": 0.10165000557899476,
        "tpp_threshold_100_intended_diff_only": 0.1068000078201294,
        "tpp_threshold_100_unintended_diff_only": 0.005150002241134643,
        "tpp_threshold_500_total_metric": 0.3990500241518021,
        "tpp_threshold_500_intended_diff_only": 0.40760003328323363,
        "tpp_threshold_500_unintended_diff_only": 0.00855000913143158
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_tpp_results",
        "tpp_threshold_2_total_metric": 0.004199987649917603,
        "tpp_threshold_2_intended_diff_only": 0.0067999839782714845,
        "tpp_threshold_2_unintended_diff_only": 0.0025999963283538817,
        "tpp_threshold_5_total_metric": 0.008100005984306335,
        "tpp_threshold_5_intended_diff_only": 0.01239999532699585,
        "tpp_threshold_5_unintended_diff_only": 0.0042999893426895145,
        "tpp_threshold_10_total_metric": 0.006149998307228088,
        "tpp_threshold_10_intended_diff_only": 0.012599992752075195,
        "tpp_threshold_10_unintended_diff_only": 0.006449994444847107,
        "tpp_threshold_20_total_metric": 0.018699997663497926,
        "tpp_threshold_20_intended_diff_only": 0.02779998779296875,
        "tpp_threshold_20_unintended_diff_only": 0.009099990129470825,
        "tpp_threshold_50_total_metric": 0.04670001864433289,
        "tpp_threshold_50_intended_diff_only": 0.05660001039505005,
        "tpp_threshold_50_unintended_diff_only": 0.009899991750717162,
        "tpp_threshold_100_total_metric": 0.09320001304149628,
        "tpp_threshold_100_intended_diff_only": 0.10500000715255738,
        "tpp_threshold_100_unintended_diff_only": 0.011799994111061095,
        "tpp_threshold_500_total_metric": 0.28615001738071444,
        "tpp_threshold_500_intended_diff_only": 0.30380001068115237,
        "tpp_threshold_500_unintended_diff_only": 0.017649993300437927
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "2cd0d337-c439-414f-9619-15d57ae8ab26",
    "datetime_epoch_millis": 1738630063475,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.9504437500000001,
        "llm_top_1_test_accuracy": 0.6567999999999999,
        "llm_top_2_test_accuracy": 0.7220625,
        "llm_top_5_test_accuracy": 0.7815937500000001,
        "llm_top_10_test_accuracy": 0.8334250000000002,
        "llm_top_20_test_accuracy": 0.8770000000000001,
        "llm_top_50_test_accuracy": 0.9225249999999999,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9576937928795815,
        "sae_top_1_test_accuracy": 0.7827562499999999,
        "sae_top_2_test_accuracy": 0.8243625,
        "sae_top_5_test_accuracy": 0.8719625000000001,
        "sae_top_10_test_accuracy": 0.8999187499999999,
        "sae_top_20_test_accuracy": 0.9256312499999999,
        "sae_top_50_test_accuracy": 0.9412812500000001,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.966800045967102,
        "sae_top_1_test_accuracy": 0.8082,
        "sae_top_2_test_accuracy": 0.8404,
        "sae_top_5_test_accuracy": 0.8704000000000001,
        "sae_top_10_test_accuracy": 0.9048,
        "sae_top_20_test_accuracy": 0.9432,
        "sae_top_50_test_accuracy": 0.9583999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9470000000000001,
        "llm_top_1_test_accuracy": 0.666,
        "llm_top_2_test_accuracy": 0.7386,
        "llm_top_5_test_accuracy": 0.7666000000000001,
        "llm_top_10_test_accuracy": 0.8008000000000001,
        "llm_top_20_test_accuracy": 0.8654,
        "llm_top_50_test_accuracy": 0.9114000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9496000528335571,
        "sae_top_1_test_accuracy": 0.7969999999999999,
        "sae_top_2_test_accuracy": 0.8046,
        "sae_top_5_test_accuracy": 0.8661999999999999,
        "sae_top_10_test_accuracy": 0.9077999999999999,
        "sae_top_20_test_accuracy": 0.9234,
        "sae_top_50_test_accuracy": 0.9366,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9179999999999999,
        "llm_top_1_test_accuracy": 0.6961999999999999,
        "llm_top_2_test_accuracy": 0.7402,
        "llm_top_5_test_accuracy": 0.7656000000000001,
        "llm_top_10_test_accuracy": 0.8094000000000001,
        "llm_top_20_test_accuracy": 0.85,
        "llm_top_50_test_accuracy": 0.8872,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9308000445365906,
        "sae_top_1_test_accuracy": 0.8177999999999999,
        "sae_top_2_test_accuracy": 0.828,
        "sae_top_5_test_accuracy": 0.8715999999999999,
        "sae_top_10_test_accuracy": 0.8864000000000001,
        "sae_top_20_test_accuracy": 0.9,
        "sae_top_50_test_accuracy": 0.9118,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.8956,
        "llm_top_1_test_accuracy": 0.6119999999999999,
        "llm_top_2_test_accuracy": 0.639,
        "llm_top_5_test_accuracy": 0.6718,
        "llm_top_10_test_accuracy": 0.7548,
        "llm_top_20_test_accuracy": 0.8088,
        "llm_top_50_test_accuracy": 0.8608,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9202000379562378,
        "sae_top_1_test_accuracy": 0.6876,
        "sae_top_2_test_accuracy": 0.7202,
        "sae_top_5_test_accuracy": 0.7892,
        "sae_top_10_test_accuracy": 0.8278000000000001,
        "sae_top_20_test_accuracy": 0.8550000000000001,
        "sae_top_50_test_accuracy": 0.8855999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.9815,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.847,
        "llm_top_50_test_accuracy": 0.933,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9770000576972961,
        "sae_top_1_test_accuracy": 0.869,
        "sae_top_2_test_accuracy": 0.91,
        "sae_top_5_test_accuracy": 0.936,
        "sae_top_10_test_accuracy": 0.94,
        "sae_top_20_test_accuracy": 0.959,
        "sae_top_50_test_accuracy": 0.966,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9648,
        "llm_top_1_test_accuracy": 0.6533999999999999,
        "llm_top_2_test_accuracy": 0.6818,
        "llm_top_5_test_accuracy": 0.7647999999999999,
        "llm_top_10_test_accuracy": 0.8066000000000001,
        "llm_top_20_test_accuracy": 0.8676,
        "llm_top_50_test_accuracy": 0.9296,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.966800045967102,
        "sae_top_1_test_accuracy": 0.597,
        "sae_top_2_test_accuracy": 0.6838000000000001,
        "sae_top_5_test_accuracy": 0.7774000000000001,
        "sae_top_10_test_accuracy": 0.8378,
        "sae_top_20_test_accuracy": 0.9097999999999999,
        "sae_top_50_test_accuracy": 0.938,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.93725,
        "llm_top_1_test_accuracy": 0.665,
        "llm_top_2_test_accuracy": 0.7795,
        "llm_top_5_test_accuracy": 0.8267499999999999,
        "llm_top_10_test_accuracy": 0.8740000000000001,
        "llm_top_20_test_accuracy": 0.891,
        "llm_top_50_test_accuracy": 0.922,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9517500400543213,
        "sae_top_1_test_accuracy": 0.77925,
        "sae_top_2_test_accuracy": 0.8455,
        "sae_top_5_test_accuracy": 0.8765,
        "sae_top_10_test_accuracy": 0.89975,
        "sae_top_20_test_accuracy": 0.91925,
        "sae_top_50_test_accuracy": 0.93625,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9998000000000001,
        "llm_top_1_test_accuracy": 0.6476000000000001,
        "llm_top_2_test_accuracy": 0.7818,
        "llm_top_5_test_accuracy": 0.9,
        "llm_top_10_test_accuracy": 0.9621999999999999,
        "llm_top_20_test_accuracy": 0.99,
        "llm_top_50_test_accuracy": 0.9978,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9986000180244445,
        "sae_top_1_test_accuracy": 0.9061999999999999,
        "sae_top_2_test_accuracy": 0.9624,
        "sae_top_5_test_accuracy": 0.9884000000000001,
        "sae_top_10_test_accuracy": 0.9949999999999999,
        "sae_top_20_test_accuracy": 0.9954000000000001,
        "sae_top_50_test_accuracy": 0.9975999999999999,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "unlearning evaluation results": {
    "eval_type_id": "unlearning",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "wmdp-bio",
        "high_school_us_history",
        "college_computer_science",
        "high_school_geography",
        "human_aging"
      ],
      "intervention_method": "clamp_feature_activation",
      "retain_thresholds": [
        0.001,
        0.01
      ],
      "n_features_list": [
        10,
        20
      ],
      "multipliers": [
        25,
        50,
        100,
        200
      ],
      "dataset_size": 1024,
      "seq_len": 1024,
      "n_batch_loss_added": 50,
      "target_metric": "correct",
      "save_metrics": true,
      "model_name": "google/gemma-2-2b-it",
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16"
    },
    "eval_id": "c42496b7-f2a3-470c-8b61-246aaef73438",
    "datetime_epoch_millis": 1738630223333,
    "eval_result_metrics": {
      "unlearning": {
        "unlearning_score": 0.06741571426391602
      }
    },
    "eval_result_details": [],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}