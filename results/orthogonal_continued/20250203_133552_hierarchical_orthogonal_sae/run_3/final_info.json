{
  "training results for layer 12": {
    "config": {
      "trainer_class": "TrainerTopK",
      "dict_class": "AutoEncoderTopK",
      "lr": 0.0001885618083164127,
      "steps": 2441,
      "seed": 42,
      "activation_dim": 2304,
      "dict_size": 18432,
      "k": 120,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "AutoEncoderTopK",
      "submodule_name": "resid_post_layer_12",
      "ortho_weight": 0.001
    },
    "final_info": {
      "training_steps": 2441,
      "final_loss": 3468.35302734375,
      "layer": 12,
      "dict_size": 18432,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "368980c8-bb21-44ec-8454-8fd57c6dccb3",
    "datetime_epoch_millis": 1738615944778,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.041843657822146434,
        "mean_num_split_features": 1.2916666666666667
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.0037650602409638554,
        "num_absorption": 10,
        "num_probe_true_positives": 2656,
        "num_split_features": 2
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.01019108280254777,
        "num_absorption": 16,
        "num_probe_true_positives": 1570,
        "num_split_features": 2
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.00518326545723806,
        "num_absorption": 14,
        "num_probe_true_positives": 2701,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.009603841536614645,
        "num_absorption": 16,
        "num_probe_true_positives": 1666,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.008739076154806492,
        "num_absorption": 14,
        "num_probe_true_positives": 1602,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.0025167785234899327,
        "num_absorption": 3,
        "num_probe_true_positives": 1192,
        "num_split_features": 2
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.005838198498748957,
        "num_absorption": 7,
        "num_probe_true_positives": 1199,
        "num_split_features": 2
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.012409513960703205,
        "num_absorption": 12,
        "num_probe_true_positives": 967,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.007779772591262717,
        "num_absorption": 13,
        "num_probe_true_positives": 1671,
        "num_split_features": 1
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.002369668246445498,
        "num_absorption": 1,
        "num_probe_true_positives": 422,
        "num_split_features": 1
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.0030075187969924814,
        "num_absorption": 2,
        "num_probe_true_positives": 665,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.13054187192118227,
        "num_absorption": 159,
        "num_probe_true_positives": 1218,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.006369426751592357,
        "num_absorption": 11,
        "num_probe_true_positives": 1727,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.0023952095808383233,
        "num_absorption": 2,
        "num_probe_true_positives": 835,
        "num_split_features": 2
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.14672897196261683,
        "num_absorption": 157,
        "num_probe_true_positives": 1070,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.18294243070362473,
        "num_absorption": 429,
        "num_probe_true_positives": 2345,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.30736196319018405,
        "num_absorption": 501,
        "num_probe_true_positives": 1630,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.12548741580999645,
        "num_absorption": 354,
        "num_probe_true_positives": 2821,
        "num_split_features": 2
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.004866180048661801,
        "num_absorption": 8,
        "num_probe_true_positives": 1644,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.007751937984496124,
        "num_absorption": 6,
        "num_probe_true_positives": 774,
        "num_split_features": 2
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.004761904761904762,
        "num_absorption": 4,
        "num_probe_true_positives": 840,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.004405286343612335,
        "num_absorption": 3,
        "num_probe_true_positives": 681,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.005263157894736842,
        "num_absorption": 1,
        "num_probe_true_positives": 190,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.003968253968253968,
        "num_absorption": 1,
        "num_probe_true_positives": 252,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9814635093167702,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.1865234375
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9819078947368421,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 3.109375,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.69140625,
        "mse": 1.9453125,
        "cossim": 0.90625
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 135.0,
        "l2_ratio": 0.90625,
        "relative_reconstruction_bias": 1.0
      },
      "sparsity": {
        "l0": 119.99999237060547,
        "l1": 580.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "73f30df8-256f-497f-9913-3efbd827fc97",
    "datetime_epoch_millis": 1738616725418,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.21848172845096056,
        "scr_metric_threshold_2": 0.10397969041401076,
        "scr_dir2_threshold_2": 0.10462602041623216,
        "scr_dir1_threshold_5": 0.23473057924934582,
        "scr_metric_threshold_5": 0.16553370908518508,
        "scr_dir2_threshold_5": 0.16975149198725706,
        "scr_dir1_threshold_10": 0.2378050762489486,
        "scr_metric_threshold_10": 0.21272398003684087,
        "scr_dir2_threshold_10": 0.21508962289522388,
        "scr_dir1_threshold_20": 0.2226304980302536,
        "scr_metric_threshold_20": 0.259652694936777,
        "scr_dir2_threshold_20": 0.2641565755875423,
        "scr_dir1_threshold_50": 0.19167843204181462,
        "scr_metric_threshold_50": 0.3095515765237804,
        "scr_dir2_threshold_50": 0.314172970446872,
        "scr_dir1_threshold_100": 0.09548876267243309,
        "scr_metric_threshold_100": 0.31513124118672214,
        "scr_dir2_threshold_100": 0.3323114059375563,
        "scr_dir1_threshold_500": -0.12721079178380626,
        "scr_metric_threshold_500": 0.26498462727594474,
        "scr_dir2_threshold_500": 0.2792396726313633
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.45312510186348476,
        "scr_metric_threshold_2": 0.017199085925573582,
        "scr_dir2_threshold_2": 0.017199085925573582,
        "scr_dir1_threshold_5": 0.42187454889028175,
        "scr_metric_threshold_5": 0.027027114104653437,
        "scr_dir2_threshold_5": 0.027027114104653437,
        "scr_dir1_threshold_10": 0.42187454889028175,
        "scr_metric_threshold_10": 0.04176908314890556,
        "scr_dir2_threshold_10": 0.04176908314890556,
        "scr_dir1_threshold_20": 0.4062497380653249,
        "scr_metric_threshold_20": 0.061425139507065275,
        "scr_dir2_threshold_20": 0.061425139507065275,
        "scr_dir1_threshold_50": 0.2812493888190914,
        "scr_metric_threshold_50": 0.09090907759556952,
        "scr_dir2_threshold_50": 0.09090907759556952,
        "scr_dir1_threshold_100": 0.23437495634422081,
        "scr_metric_threshold_100": 0.11793619170022296,
        "scr_dir2_threshold_100": 0.11793619170022296,
        "scr_dir1_threshold_500": 0.24999976716917766,
        "scr_metric_threshold_500": 0.11547922126763682,
        "scr_dir2_threshold_500": 0.11547922126763682
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.23300963569983096,
        "scr_metric_threshold_2": 0.12320912794812448,
        "scr_dir2_threshold_2": 0.12320912794812448,
        "scr_dir1_threshold_5": 0.2524268642223358,
        "scr_metric_threshold_5": 0.17478508169081822,
        "scr_dir2_threshold_5": 0.17478508169081822,
        "scr_dir1_threshold_10": 0.28155328569204763,
        "scr_metric_threshold_10": 0.20630364418381594,
        "scr_dir2_threshold_10": 0.20630364418381594,
        "scr_dir1_threshold_20": 0.16504817849915482,
        "scr_metric_threshold_20": 0.2722062327675958,
        "scr_dir2_threshold_20": 0.2722062327675958,
        "scr_dir1_threshold_50": 0.14563094997665002,
        "scr_metric_threshold_50": 0.3438395777599856,
        "scr_dir2_threshold_50": 0.3438395777599856,
        "scr_dir1_threshold_100": -0.1747573714463619,
        "scr_metric_threshold_100": 0.12607442075894992,
        "scr_dir2_threshold_100": 0.12607442075894992,
        "scr_dir1_threshold_500": -0.7475731357776643,
        "scr_metric_threshold_500": 0.12320912794812448,
        "scr_dir2_threshold_500": 0.12320912794812448
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.5873013770560047,
        "scr_metric_threshold_2": 0.025316579852636207,
        "scr_dir2_threshold_2": 0.025316579852636207,
        "scr_dir1_threshold_5": 0.6190479344159929,
        "scr_metric_threshold_5": 0.05316462152337083,
        "scr_dir2_threshold_5": 0.05316462152337083,
        "scr_dir1_threshold_10": 0.5714285714285714,
        "scr_metric_threshold_10": 0.09620264128525105,
        "scr_dir2_threshold_10": 0.09620264128525105,
        "scr_dir1_threshold_20": 0.49206359718628334,
        "scr_metric_threshold_20": 0.12151907024006786,
        "scr_dir2_threshold_20": 0.12151907024006786,
        "scr_dir1_threshold_50": 0.5079364028137167,
        "scr_metric_threshold_50": 0.1746835408656193,
        "scr_dir2_threshold_50": 0.1746835408656193,
        "scr_dir1_threshold_100": 0.4761907915588501,
        "scr_metric_threshold_100": 0.20759495886600893,
        "scr_dir2_threshold_100": 0.20759495886600893,
        "scr_dir1_threshold_500": -1.063491222509733,
        "scr_metric_threshold_500": 0.09873425400116885,
        "scr_dir2_threshold_500": 0.09873425400116885
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": 0.2421876018633899,
        "scr_metric_threshold_2": 0.04747783927687718,
        "scr_dir2_threshold_2": 0.04747783927687718,
        "scr_dir1_threshold_5": 0.21093754365573852,
        "scr_metric_threshold_5": 0.10385764076688712,
        "scr_dir2_threshold_5": 0.10385764076688712,
        "scr_dir1_threshold_10": 0.07031251455191284,
        "scr_metric_threshold_10": 0.18397636189533567,
        "scr_dir2_threshold_10": 0.18397636189533567,
        "scr_dir1_threshold_20": 0.07812491268852294,
        "scr_metric_threshold_20": 0.249258302466854,
        "scr_dir2_threshold_20": 0.249258302466854,
        "scr_dir1_threshold_50": -0.062499650754091765,
        "scr_metric_threshold_50": 0.3056381039568639,
        "scr_dir2_threshold_50": 0.3056381039568639,
        "scr_dir1_threshold_100": -0.11718736903278441,
        "scr_metric_threshold_100": 0.3649852261845848,
        "scr_dir2_threshold_100": 0.3649852261845848,
        "scr_dir1_threshold_500": 0.17187508731147705,
        "scr_metric_threshold_500": 0.02373891963843859,
        "scr_dir2_threshold_500": 0.02373891963843859
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.04918033854781611,
        "scr_metric_threshold_2": 0.32156862561769683,
        "scr_dir2_threshold_2": 0.32156862561769683,
        "scr_dir1_threshold_5": 0.05464474822904205,
        "scr_metric_threshold_5": 0.4941177240567333,
        "scr_dir2_threshold_5": 0.4941177240567333,
        "scr_dir1_threshold_10": 0.03825119347697291,
        "scr_metric_threshold_10": 0.5764705222370857,
        "scr_dir2_threshold_10": 0.5764705222370857,
        "scr_dir1_threshold_20": -0.01092881936245188,
        "scr_metric_threshold_20": 0.6431372512353937,
        "scr_dir2_threshold_20": 0.6431372512353937,
        "scr_dir1_threshold_50": 0.03278678379574697,
        "scr_metric_threshold_50": 0.6862744089733254,
        "scr_dir2_threshold_50": 0.6862744089733254,
        "scr_dir1_threshold_100": -0.28415288621605345,
        "scr_metric_threshold_100": 0.6862744089733254,
        "scr_dir2_threshold_100": 0.6862744089733254,
        "scr_dir1_threshold_500": -0.2404372830578546,
        "scr_metric_threshold_500": 0.7019607118990246,
        "scr_dir2_threshold_500": 0.7019607118990246
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.046153559299134936,
        "scr_metric_threshold_2": 0.08467752208135552,
        "scr_dir2_threshold_2": 0.08467752208135552,
        "scr_dir1_threshold_5": 0.12820501064172196,
        "scr_metric_threshold_5": 0.12500006008532116,
        "scr_dir2_threshold_5": 0.12500006008532116,
        "scr_dir1_threshold_10": 0.1999998777340575,
        "scr_metric_threshold_10": 0.14516132908730398,
        "scr_dir2_threshold_10": 0.14516132908730398,
        "scr_dir1_threshold_20": 0.22051274056970427,
        "scr_metric_threshold_20": 0.18951607282340924,
        "scr_dir2_threshold_20": 0.18951607282340924,
        "scr_dir1_threshold_50": 0.22564087986240192,
        "scr_metric_threshold_50": 0.24596767409721804,
        "scr_dir2_threshold_50": 0.24596767409721804,
        "scr_dir1_threshold_100": 0.27179474482639304,
        "scr_metric_threshold_100": 0.36693552845039956,
        "scr_dir2_threshold_100": 0.36693552845039956,
        "scr_dir1_threshold_500": 0.2564100212834439,
        "scr_metric_threshold_500": 0.3225807847142943,
        "scr_dir2_threshold_500": 0.3225807847142943
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.08968601715063591,
        "scr_metric_threshold_2": 0.16517854648243513,
        "scr_dir2_threshold_2": 0.16517854648243513,
        "scr_dir1_threshold_5": 0.14349778781226621,
        "scr_metric_threshold_5": 0.2991072343263093,
        "scr_dir2_threshold_5": 0.2991072343263093,
        "scr_dir1_threshold_10": 0.2331838049629021,
        "scr_metric_threshold_10": 0.3660714452021861,
        "scr_dir2_threshold_10": 0.3660714452021861,
        "scr_dir1_threshold_20": 0.31838557471308915,
        "scr_metric_threshold_20": 0.42857142857142855,
        "scr_dir2_threshold_20": 0.42857142857142855,
        "scr_dir1_threshold_50": 0.28251106093866896,
        "scr_metric_threshold_50": 0.508928588059329,
        "scr_dir2_threshold_50": 0.508928588059329,
        "scr_dir1_threshold_100": 0.2331838049629021,
        "scr_metric_threshold_100": 0.5267857641779868,
        "scr_dir2_threshold_100": 0.5267857641779868,
        "scr_dir1_threshold_500": 0.1838565489871353,
        "scr_metric_threshold_500": 0.5625001164153027,
        "scr_dir2_threshold_500": 0.5625001164153027
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.047210196127387125,
        "scr_metric_threshold_2": 0.047210196127387125,
        "scr_dir2_threshold_2": 0.05238083614515829,
        "scr_dir1_threshold_5": 0.047210196127387125,
        "scr_metric_threshold_5": 0.047210196127387125,
        "scr_dir2_threshold_5": 0.08095245934396302,
        "scr_dir1_threshold_10": 0.08583681325484281,
        "scr_metric_threshold_10": 0.08583681325484281,
        "scr_dir2_threshold_10": 0.10476195612190681,
        "scr_dir1_threshold_20": 0.11158806188240133,
        "scr_metric_threshold_20": 0.11158806188240133,
        "scr_dir2_threshold_20": 0.14761910708852366,
        "scr_dir1_threshold_50": 0.12017164088233277,
        "scr_metric_threshold_50": 0.12017164088233277,
        "scr_dir2_threshold_50": 0.1571427922670651,
        "scr_dir1_threshold_100": 0.1244634303822985,
        "scr_metric_threshold_100": 0.1244634303822985,
        "scr_dir2_threshold_100": 0.2619047483889719,
        "scr_dir1_threshold_500": 0.17167388232356773,
        "scr_metric_threshold_500": 0.17167388232356773,
        "scr_dir2_threshold_500": 0.2857142451669157
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "tpp evaluations results": {
    "eval_type_id": "tpp",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": false,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "0198e609-458f-474d-818a-85e821eb9aeb",
    "datetime_epoch_millis": 1738616874065,
    "eval_result_metrics": {
      "tpp_metrics": {
        "tpp_threshold_2_total_metric": 0.0040499955415725705,
        "tpp_threshold_2_intended_diff_only": 0.006699997186660767,
        "tpp_threshold_2_unintended_diff_only": 0.002650001645088196,
        "tpp_threshold_5_total_metric": 0.0068750083446502686,
        "tpp_threshold_5_intended_diff_only": 0.010600006580352784,
        "tpp_threshold_5_unintended_diff_only": 0.003724998235702515,
        "tpp_threshold_10_total_metric": 0.008225008845329285,
        "tpp_threshold_10_intended_diff_only": 0.013300007581710816,
        "tpp_threshold_10_unintended_diff_only": 0.005074998736381531,
        "tpp_threshold_20_total_metric": 0.018925000727176667,
        "tpp_threshold_20_intended_diff_only": 0.025700002908706665,
        "tpp_threshold_20_unintended_diff_only": 0.006775002181529999,
        "tpp_threshold_50_total_metric": 0.05152500271797181,
        "tpp_threshold_50_intended_diff_only": 0.05800000429153443,
        "tpp_threshold_50_unintended_diff_only": 0.006475001573562622,
        "tpp_threshold_100_total_metric": 0.10124999284744263,
        "tpp_threshold_100_intended_diff_only": 0.10899999737739563,
        "tpp_threshold_100_unintended_diff_only": 0.007750004529953003,
        "tpp_threshold_500_total_metric": 0.3469000220298767,
        "tpp_threshold_500_intended_diff_only": 0.3601000249385834,
        "tpp_threshold_500_unintended_diff_only": 0.013200002908706664
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_tpp_results",
        "tpp_threshold_2_total_metric": 0.004249987006187439,
        "tpp_threshold_2_intended_diff_only": 0.0067999958992004395,
        "tpp_threshold_2_unintended_diff_only": 0.0025500088930130007,
        "tpp_threshold_5_total_metric": 0.006800010800361633,
        "tpp_threshold_5_intended_diff_only": 0.009600019454956055,
        "tpp_threshold_5_unintended_diff_only": 0.0028000086545944213,
        "tpp_threshold_10_total_metric": 0.010500004887580872,
        "tpp_threshold_10_intended_diff_only": 0.014000010490417481,
        "tpp_threshold_10_unintended_diff_only": 0.003500005602836609,
        "tpp_threshold_20_total_metric": 0.021050000190734865,
        "tpp_threshold_20_intended_diff_only": 0.025400006771087648,
        "tpp_threshold_20_unintended_diff_only": 0.004350006580352783,
        "tpp_threshold_50_total_metric": 0.055850017070770266,
        "tpp_threshold_50_intended_diff_only": 0.0598000168800354,
        "tpp_threshold_50_unintended_diff_only": 0.003949999809265137,
        "tpp_threshold_100_total_metric": 0.10584999322891235,
        "tpp_threshold_100_intended_diff_only": 0.11100000143051147,
        "tpp_threshold_100_unintended_diff_only": 0.005150008201599121,
        "tpp_threshold_500_total_metric": 0.40395001471042635,
        "tpp_threshold_500_intended_diff_only": 0.41240001916885377,
        "tpp_threshold_500_unintended_diff_only": 0.008450004458427429
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_tpp_results",
        "tpp_threshold_2_total_metric": 0.003850004076957703,
        "tpp_threshold_2_intended_diff_only": 0.006599998474121094,
        "tpp_threshold_2_unintended_diff_only": 0.002749994397163391,
        "tpp_threshold_5_total_metric": 0.006950005888938904,
        "tpp_threshold_5_intended_diff_only": 0.011599993705749512,
        "tpp_threshold_5_unintended_diff_only": 0.004649987816810608,
        "tpp_threshold_10_total_metric": 0.005950012803077697,
        "tpp_threshold_10_intended_diff_only": 0.01260000467300415,
        "tpp_threshold_10_unintended_diff_only": 0.006649991869926453,
        "tpp_threshold_20_total_metric": 0.01680000126361847,
        "tpp_threshold_20_intended_diff_only": 0.025999999046325682,
        "tpp_threshold_20_unintended_diff_only": 0.009199997782707215,
        "tpp_threshold_50_total_metric": 0.04719998836517334,
        "tpp_threshold_50_intended_diff_only": 0.05619999170303345,
        "tpp_threshold_50_unintended_diff_only": 0.009000003337860107,
        "tpp_threshold_100_total_metric": 0.0966499924659729,
        "tpp_threshold_100_intended_diff_only": 0.10699999332427979,
        "tpp_threshold_100_unintended_diff_only": 0.010350000858306885,
        "tpp_threshold_500_total_metric": 0.2898500293493271,
        "tpp_threshold_500_intended_diff_only": 0.30780003070831297,
        "tpp_threshold_500_unintended_diff_only": 0.0179500013589859
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "efc7516d-08fe-49ea-bf1a-bc73825a1aad",
    "datetime_epoch_millis": 1738617314489,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.95100625,
        "llm_top_1_test_accuracy": 0.65321875,
        "llm_top_2_test_accuracy": 0.7223125000000001,
        "llm_top_5_test_accuracy": 0.7811500000000001,
        "llm_top_10_test_accuracy": 0.83061875,
        "llm_top_20_test_accuracy": 0.87975,
        "llm_top_50_test_accuracy": 0.9230437499999999,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9576125510036945,
        "sae_top_1_test_accuracy": 0.79334375,
        "sae_top_2_test_accuracy": 0.8398000000000001,
        "sae_top_5_test_accuracy": 0.8796312500000001,
        "sae_top_10_test_accuracy": 0.90378125,
        "sae_top_20_test_accuracy": 0.92615,
        "sae_top_50_test_accuracy": 0.94045,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9640000581741333,
        "sae_top_1_test_accuracy": 0.8224,
        "sae_top_2_test_accuracy": 0.8392000000000002,
        "sae_top_5_test_accuracy": 0.8664,
        "sae_top_10_test_accuracy": 0.9099999999999999,
        "sae_top_20_test_accuracy": 0.9385999999999999,
        "sae_top_50_test_accuracy": 0.9603999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9466000000000001,
        "llm_top_1_test_accuracy": 0.681,
        "llm_top_2_test_accuracy": 0.7088000000000001,
        "llm_top_5_test_accuracy": 0.7661999999999999,
        "llm_top_10_test_accuracy": 0.7992,
        "llm_top_20_test_accuracy": 0.8622,
        "llm_top_50_test_accuracy": 0.9067999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9498000621795655,
        "sae_top_1_test_accuracy": 0.7941999999999999,
        "sae_top_2_test_accuracy": 0.8236000000000001,
        "sae_top_5_test_accuracy": 0.8789999999999999,
        "sae_top_10_test_accuracy": 0.9067999999999999,
        "sae_top_20_test_accuracy": 0.9248,
        "sae_top_50_test_accuracy": 0.9405999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9134,
        "llm_top_1_test_accuracy": 0.6857999999999999,
        "llm_top_2_test_accuracy": 0.737,
        "llm_top_5_test_accuracy": 0.752,
        "llm_top_10_test_accuracy": 0.7979999999999999,
        "llm_top_20_test_accuracy": 0.8554,
        "llm_top_50_test_accuracy": 0.8872,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9316000461578369,
        "sae_top_1_test_accuracy": 0.8103999999999999,
        "sae_top_2_test_accuracy": 0.8442000000000001,
        "sae_top_5_test_accuracy": 0.8757999999999999,
        "sae_top_10_test_accuracy": 0.8852,
        "sae_top_20_test_accuracy": 0.9048,
        "sae_top_50_test_accuracy": 0.915,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.8959999999999999,
        "llm_top_1_test_accuracy": 0.6038,
        "llm_top_2_test_accuracy": 0.6434,
        "llm_top_5_test_accuracy": 0.6746000000000001,
        "llm_top_10_test_accuracy": 0.7522,
        "llm_top_20_test_accuracy": 0.8089999999999999,
        "llm_top_50_test_accuracy": 0.8628,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9174000501632691,
        "sae_top_1_test_accuracy": 0.7256,
        "sae_top_2_test_accuracy": 0.764,
        "sae_top_5_test_accuracy": 0.8019999999999999,
        "sae_top_10_test_accuracy": 0.8413999999999999,
        "sae_top_20_test_accuracy": 0.8615999999999999,
        "sae_top_50_test_accuracy": 0.8798,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.981,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.847,
        "llm_top_50_test_accuracy": 0.933,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9765000641345978,
        "sae_top_1_test_accuracy": 0.868,
        "sae_top_2_test_accuracy": 0.891,
        "sae_top_5_test_accuracy": 0.931,
        "sae_top_10_test_accuracy": 0.941,
        "sae_top_20_test_accuracy": 0.956,
        "sae_top_50_test_accuracy": 0.963,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.969,
        "llm_top_1_test_accuracy": 0.6574,
        "llm_top_2_test_accuracy": 0.7140000000000001,
        "llm_top_5_test_accuracy": 0.7605999999999999,
        "llm_top_10_test_accuracy": 0.8046,
        "llm_top_20_test_accuracy": 0.877,
        "llm_top_50_test_accuracy": 0.9314,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.967400050163269,
        "sae_top_1_test_accuracy": 0.5944,
        "sae_top_2_test_accuracy": 0.7492000000000001,
        "sae_top_5_test_accuracy": 0.8215999999999999,
        "sae_top_10_test_accuracy": 0.8474,
        "sae_top_20_test_accuracy": 0.9096,
        "sae_top_50_test_accuracy": 0.9432,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.9432499999999999,
        "llm_top_1_test_accuracy": 0.6357499999999999,
        "llm_top_2_test_accuracy": 0.7765000000000001,
        "llm_top_5_test_accuracy": 0.8260000000000001,
        "llm_top_10_test_accuracy": 0.87075,
        "llm_top_20_test_accuracy": 0.902,
        "llm_top_50_test_accuracy": 0.92775,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9550000429153442,
        "sae_top_1_test_accuracy": 0.78375,
        "sae_top_2_test_accuracy": 0.848,
        "sae_top_5_test_accuracy": 0.87025,
        "sae_top_10_test_accuracy": 0.90225,
        "sae_top_20_test_accuracy": 0.9159999999999999,
        "sae_top_50_test_accuracy": 0.924,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9992000000000001,
        "llm_top_1_test_accuracy": 0.6477999999999999,
        "llm_top_2_test_accuracy": 0.7831999999999999,
        "llm_top_5_test_accuracy": 0.9126,
        "llm_top_10_test_accuracy": 0.9606,
        "llm_top_20_test_accuracy": 0.9892000000000001,
        "llm_top_50_test_accuracy": 0.9970000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9992000341415406,
        "sae_top_1_test_accuracy": 0.9480000000000001,
        "sae_top_2_test_accuracy": 0.9592,
        "sae_top_5_test_accuracy": 0.991,
        "sae_top_10_test_accuracy": 0.9962000000000002,
        "sae_top_20_test_accuracy": 0.9978,
        "sae_top_50_test_accuracy": 0.9975999999999999,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "unlearning evaluation results": {
    "eval_type_id": "unlearning",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "wmdp-bio",
        "high_school_us_history",
        "college_computer_science",
        "high_school_geography",
        "human_aging"
      ],
      "intervention_method": "clamp_feature_activation",
      "retain_thresholds": [
        0.001,
        0.01
      ],
      "n_features_list": [
        10,
        20
      ],
      "multipliers": [
        25,
        50,
        100,
        200
      ],
      "dataset_size": 1024,
      "seq_len": 1024,
      "n_batch_loss_added": 50,
      "target_metric": "correct",
      "save_metrics": true,
      "model_name": "google/gemma-2-2b-it",
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16"
    },
    "eval_id": "7188a73b-44f9-4965-a80d-f1713f292029",
    "datetime_epoch_millis": 1738617468713,
    "eval_result_metrics": {
      "unlearning": {
        "unlearning_score": 0.018726587295532227
      }
    },
    "eval_result_details": [],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}