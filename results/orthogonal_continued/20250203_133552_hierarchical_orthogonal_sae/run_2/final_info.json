{
  "training results for layer 12": {
    "config": {
      "trainer_class": "TrainerTopK",
      "dict_class": "AutoEncoderTopK",
      "lr": 0.0001885618083164127,
      "steps": 2441,
      "seed": 42,
      "activation_dim": 2304,
      "dict_size": 18432,
      "k": 120,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "AutoEncoderTopK",
      "submodule_name": "resid_post_layer_12",
      "ortho_weight": 0.1
    },
    "final_info": {
      "training_steps": 2441,
      "final_loss": 3644.23681640625,
      "layer": 12,
      "dict_size": 18432,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "036d5c66-73a2-43bc-84ed-8683ed52a698",
    "datetime_epoch_millis": 1738613101201,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.0461887469654669,
        "mean_num_split_features": 1.125
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.022213855421686746,
        "num_absorption": 59,
        "num_probe_true_positives": 2656,
        "num_split_features": 1
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.07006369426751592,
        "num_absorption": 110,
        "num_probe_true_positives": 1570,
        "num_split_features": 1
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.00518326545723806,
        "num_absorption": 14,
        "num_probe_true_positives": 2701,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.035414165666266505,
        "num_absorption": 59,
        "num_probe_true_positives": 1666,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.02933832709113608,
        "num_absorption": 47,
        "num_probe_true_positives": 1602,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.037751677852348994,
        "num_absorption": 45,
        "num_probe_true_positives": 1192,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.006672226855713094,
        "num_absorption": 8,
        "num_probe_true_positives": 1199,
        "num_split_features": 1
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.07652533609100311,
        "num_absorption": 74,
        "num_probe_true_positives": 967,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.005984440454817474,
        "num_absorption": 10,
        "num_probe_true_positives": 1671,
        "num_split_features": 1
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.0030075187969924814,
        "num_absorption": 2,
        "num_probe_true_positives": 665,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.21182266009852216,
        "num_absorption": 258,
        "num_probe_true_positives": 1218,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.008106543138390272,
        "num_absorption": 14,
        "num_probe_true_positives": 1727,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.003592814371257485,
        "num_absorption": 3,
        "num_probe_true_positives": 835,
        "num_split_features": 2
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.2383177570093458,
        "num_absorption": 255,
        "num_probe_true_positives": 1070,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.07633262260127932,
        "num_absorption": 179,
        "num_probe_true_positives": 2345,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.06012269938650307,
        "num_absorption": 98,
        "num_probe_true_positives": 1630,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.10563629918468628,
        "num_absorption": 298,
        "num_probe_true_positives": 2821,
        "num_split_features": 1
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.015206812652068127,
        "num_absorption": 25,
        "num_probe_true_positives": 1644,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.003875968992248062,
        "num_absorption": 3,
        "num_probe_true_positives": 774,
        "num_split_features": 3
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.004761904761904762,
        "num_absorption": 4,
        "num_probe_true_positives": 840,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.016152716593245228,
        "num_absorption": 11,
        "num_probe_true_positives": 681,
        "num_split_features": 1
      },
      {
        "first_letter": "x",
        "absorption_rate": 0.011627906976744186,
        "num_absorption": 1,
        "num_probe_true_positives": 86,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.005263157894736842,
        "num_absorption": 1,
        "num_probe_true_positives": 190,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.05555555555555555,
        "num_absorption": 14,
        "num_probe_true_positives": 252,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9780667701863354,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.220703125
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9786184210526315,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 3.140625,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.6796875,
        "mse": 2.03125,
        "cossim": 0.8984375
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 135.0,
        "l2_ratio": 0.8984375,
        "relative_reconstruction_bias": 1.0
      },
      "sparsity": {
        "l0": 119.99999237060547,
        "l1": 580.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "27363030-535f-4f24-a363-7ac189e42915",
    "datetime_epoch_millis": 1738613889904,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.16878484803140312,
        "scr_metric_threshold_2": 0.08036109908966996,
        "scr_dir2_threshold_2": 0.07975821180841056,
        "scr_dir1_threshold_5": 0.21707884847655787,
        "scr_metric_threshold_5": 0.13436512757876964,
        "scr_dir2_threshold_5": 0.1379288880420709,
        "scr_dir1_threshold_10": 0.2405918965001025,
        "scr_metric_threshold_10": 0.18205053968341617,
        "scr_dir2_threshold_10": 0.18489389959313174,
        "scr_dir1_threshold_20": 0.22247340266319007,
        "scr_metric_threshold_20": 0.21822270821951517,
        "scr_dir2_threshold_20": 0.2267834122768507,
        "scr_dir1_threshold_50": 0.21449156556074328,
        "scr_metric_threshold_50": 0.27478607144145306,
        "scr_dir2_threshold_50": 0.27488058186424236,
        "scr_dir1_threshold_100": 0.18368203952066292,
        "scr_metric_threshold_100": 0.292259874560567,
        "scr_dir2_threshold_100": 0.29473534175694044,
        "scr_dir1_threshold_500": 0.048179238474727,
        "scr_metric_threshold_500": 0.23763358575121415,
        "scr_dir2_threshold_500": 0.24795697792998922
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.37500011641541114,
        "scr_metric_threshold_2": 0.007371057746493725,
        "scr_dir2_threshold_2": 0.007371057746493725,
        "scr_dir1_threshold_5": 0.37500011641541114,
        "scr_metric_threshold_5": 0.019656056358159712,
        "scr_dir2_threshold_5": 0.019656056358159712,
        "scr_dir1_threshold_10": 0.4062497380653249,
        "scr_metric_threshold_10": 0.04176908314890556,
        "scr_dir2_threshold_10": 0.04176908314890556,
        "scr_dir1_threshold_20": 0.37500011641541114,
        "scr_metric_threshold_20": 0.04914014089539928,
        "scr_dir2_threshold_20": 0.04914014089539928,
        "scr_dir1_threshold_50": 0.2968751309673376,
        "scr_metric_threshold_50": 0.09090907759556952,
        "scr_dir2_threshold_50": 0.09090907759556952,
        "scr_dir1_threshold_100": 0.359374374267165,
        "scr_metric_threshold_100": 0.10073710577464937,
        "scr_dir2_threshold_100": 0.10073710577464937,
        "scr_dir1_threshold_500": 0.359374374267165,
        "scr_metric_threshold_500": -0.004913940865172265,
        "scr_dir2_threshold_500": -0.004913940865172265
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.06796087851472148,
        "scr_metric_threshold_2": 0.10888249310703833,
        "scr_dir2_threshold_2": 0.10888249310703833,
        "scr_dir1_threshold_5": 0.2135918284913715,
        "scr_metric_threshold_5": 0.14899710481947134,
        "scr_dir2_threshold_5": 0.14899710481947134,
        "scr_dir1_threshold_10": 0.26213605716954286,
        "scr_metric_threshold_10": 0.1919770093427298,
        "scr_dir2_threshold_10": 0.1919770093427298,
        "scr_dir1_threshold_20": 0.26213605716954286,
        "scr_metric_threshold_20": 0.24068767027459811,
        "scr_dir2_threshold_20": 0.24068767027459811,
        "scr_dir1_threshold_50": 0.1359223357153976,
        "scr_metric_threshold_50": 0.32378218651028956,
        "scr_dir2_threshold_50": 0.32378218651028956,
        "scr_dir1_threshold_100": 0.16504817849915482,
        "scr_metric_threshold_100": 0.346704870570811,
        "scr_dir2_threshold_100": 0.346704870570811,
        "scr_dir1_threshold_500": -0.4854370786081214,
        "scr_metric_threshold_500": 0.1919770093427298,
        "scr_dir2_threshold_500": 0.1919770093427298
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.5079364028137167,
        "scr_metric_threshold_2": 0.030379805284471813,
        "scr_dir2_threshold_2": 0.030379805284471813,
        "scr_dir1_threshold_5": 0.5714285714285714,
        "scr_metric_threshold_5": 0.07341782504635204,
        "scr_dir2_threshold_5": 0.07341782504635204,
        "scr_dir1_threshold_10": 0.5873013770560047,
        "scr_metric_threshold_10": 0.09620264128525105,
        "scr_dir2_threshold_10": 0.09620264128525105,
        "scr_dir1_threshold_20": 0.5555557658011382,
        "scr_metric_threshold_20": 0.10379747943300446,
        "scr_dir2_threshold_20": 0.10379747943300446,
        "scr_dir1_threshold_50": 0.5079364028137167,
        "scr_metric_threshold_50": 0.14683549919488467,
        "scr_dir2_threshold_50": 0.14683549919488467,
        "scr_dir1_threshold_100": 0.2222221170994309,
        "scr_metric_threshold_100": 0.1898735189567649,
        "scr_dir2_threshold_100": 0.1898735189567649,
        "scr_dir1_threshold_500": -0.30158709134171896,
        "scr_metric_threshold_500": 0.1265822956719035,
        "scr_dir2_threshold_500": 0.1265822956719035
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": 0.18750034924590825,
        "scr_metric_threshold_2": 0.044510518539166266,
        "scr_dir2_threshold_2": 0.044510518539166266,
        "scr_dir1_threshold_5": 0.25,
        "scr_metric_threshold_5": 0.09495550168537875,
        "scr_dir2_threshold_5": 0.09495550168537875,
        "scr_dir1_threshold_10": 0.17968748544808716,
        "scr_metric_threshold_10": 0.1246292396676148,
        "scr_dir2_threshold_10": 0.1246292396676148,
        "scr_dir1_threshold_20": 0.03906245634426147,
        "scr_metric_threshold_20": 0.16913958133840545,
        "scr_dir2_threshold_20": 0.16913958133840545,
        "scr_dir1_threshold_50": 0.05468771827869265,
        "scr_metric_threshold_50": 0.2136499230091961,
        "scr_dir2_threshold_50": 0.2136499230091961,
        "scr_dir1_threshold_100": 0.007812863797821078,
        "scr_metric_threshold_100": 0.27002972449920604,
        "scr_dir2_threshold_100": 0.27002972449920604,
        "scr_dir1_threshold_500": 0.21093754365573852,
        "scr_metric_threshold_500": 0.035608379457657886,
        "scr_dir2_threshold_500": 0.035608379457657886
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.03825119347697291,
        "scr_metric_threshold_2": 0.2862745024707873,
        "scr_dir2_threshold_2": 0.2862745024707873,
        "scr_dir1_threshold_5": 0.03825119347697291,
        "scr_metric_threshold_5": 0.4392157806886135,
        "scr_dir2_threshold_5": 0.4392157806886135,
        "scr_dir1_threshold_10": 0.021857964433295084,
        "scr_metric_threshold_10": 0.5294118472036429,
        "scr_dir2_threshold_10": 0.5294118472036429,
        "scr_dir1_threshold_20": -0.00546440968122594,
        "scr_metric_threshold_20": 0.603921610792973,
        "scr_dir2_threshold_20": 0.603921610792973,
        "scr_dir1_threshold_50": 0.01092881936245188,
        "scr_metric_threshold_50": 0.6509802858264159,
        "scr_dir2_threshold_50": 0.6509802858264159,
        "scr_dir1_threshold_100": -0.1092894964580841,
        "scr_metric_threshold_100": 0.666666588752115,
        "scr_dir2_threshold_100": 0.666666588752115,
        "scr_dir1_threshold_500": -0.19672135419126444,
        "scr_metric_threshold_500": 0.6862744089733254,
        "scr_dir2_threshold_500": 0.6862744089733254
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.0410254200064373,
        "scr_metric_threshold_2": 0.06451625307937271,
        "scr_dir2_threshold_2": 0.06451625307937271,
        "scr_dir1_threshold_5": 0.1333331499344196,
        "scr_metric_threshold_5": 0.11290320254761761,
        "scr_dir2_threshold_5": 0.11290320254761761,
        "scr_dir1_threshold_10": 0.17948701489841076,
        "scr_metric_threshold_10": 0.14516132908730398,
        "scr_dir2_threshold_10": 0.14516132908730398,
        "scr_dir1_threshold_20": 0.21538460127700665,
        "scr_metric_threshold_20": 0.19758072462897314,
        "scr_dir2_threshold_20": 0.19758072462897314,
        "scr_dir1_threshold_50": 0.27179474482639304,
        "scr_metric_threshold_50": 0.2419354683650784,
        "scr_dir2_threshold_50": 0.2419354683650784,
        "scr_dir1_threshold_100": 0.3282048883757795,
        "scr_metric_threshold_100": 0.23387105690079912,
        "scr_dir2_threshold_100": 0.23387105690079912,
        "scr_dir1_threshold_500": 0.2512818819907463,
        "scr_metric_threshold_500": 0.22580640509523522,
        "scr_dir2_threshold_500": 0.22580640509523522
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.08968601715063591,
        "scr_metric_threshold_2": 0.058035755862608125,
        "scr_dir2_threshold_2": 0.058035755862608125,
        "scr_dir1_threshold_5": 0.11210752143829489,
        "scr_metric_threshold_5": 0.14285714285714285,
        "scr_dir2_threshold_5": 0.14285714285714285,
        "scr_dir1_threshold_10": 0.21076230067524315,
        "scr_metric_threshold_10": 0.24999993347696986,
        "scr_dir2_threshold_10": 0.24999993347696986,
        "scr_dir1_threshold_20": 0.27802681353822006,
        "scr_metric_threshold_20": 0.3214286379516016,
        "scr_dir2_threshold_20": 0.3214286379516016,
        "scr_dir1_threshold_50": 0.30044831782587905,
        "scr_metric_threshold_50": 0.3928570763341127,
        "scr_dir2_threshold_50": 0.3928570763341127,
        "scr_dir1_threshold_100": 0.35874433588795823,
        "scr_metric_threshold_100": 0.3928570763341127,
        "scr_dir2_threshold_100": 0.3928570763341127,
        "scr_dir1_threshold_500": 0.35874433588795823,
        "scr_metric_threshold_500": 0.4508928321967208,
        "scr_dir2_threshold_500": 0.4508928321967208
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.042918406627421406,
        "scr_metric_threshold_2": 0.042918406627421406,
        "scr_dir2_threshold_2": 0.03809530837734615,
        "scr_dir1_threshold_5": 0.042918406627421406,
        "scr_metric_threshold_5": 0.042918406627421406,
        "scr_dir2_threshold_5": 0.07142849033383136,
        "scr_dir1_threshold_10": 0.07725323425491137,
        "scr_metric_threshold_10": 0.07725323425491137,
        "scr_dir2_threshold_10": 0.10000011353263609,
        "scr_dir1_threshold_20": 0.060085820441166386,
        "scr_metric_threshold_20": 0.060085820441166386,
        "scr_dir2_threshold_20": 0.12857145289985059,
        "scr_dir1_threshold_50": 0.13733905469607777,
        "scr_metric_threshold_50": 0.13733905469607777,
        "scr_dir2_threshold_50": 0.13809513807839202,
        "scr_dir1_threshold_100": 0.13733905469607777,
        "scr_metric_threshold_100": 0.13733905469607777,
        "scr_dir2_threshold_100": 0.1571427922670651,
        "scr_dir1_threshold_500": 0.1888412961373127,
        "scr_metric_threshold_500": 0.1888412961373127,
        "scr_dir2_threshold_500": 0.27142843356751334
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "tpp evaluations results": {
    "eval_type_id": "tpp",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": false,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "fe616977-8093-40c4-98b5-70049bf2c4c4",
    "datetime_epoch_millis": 1738614045630,
    "eval_result_metrics": {
      "tpp_metrics": {
        "tpp_threshold_2_total_metric": 0.00377500057220459,
        "tpp_threshold_2_intended_diff_only": 0.0064999997615814206,
        "tpp_threshold_2_unintended_diff_only": 0.002724999189376831,
        "tpp_threshold_5_total_metric": 0.0051499992609024044,
        "tpp_threshold_5_intended_diff_only": 0.008600002527236939,
        "tpp_threshold_5_unintended_diff_only": 0.0034500032663345335,
        "tpp_threshold_10_total_metric": 0.00625,
        "tpp_threshold_10_intended_diff_only": 0.010799998044967653,
        "tpp_threshold_10_unintended_diff_only": 0.004549998044967651,
        "tpp_threshold_20_total_metric": 0.013175000250339509,
        "tpp_threshold_20_intended_diff_only": 0.019199997186660767,
        "tpp_threshold_20_unintended_diff_only": 0.006024996936321258,
        "tpp_threshold_50_total_metric": 0.042125013470649716,
        "tpp_threshold_50_intended_diff_only": 0.048200011253356934,
        "tpp_threshold_50_unintended_diff_only": 0.006074997782707214,
        "tpp_threshold_100_total_metric": 0.08024999648332595,
        "tpp_threshold_100_intended_diff_only": 0.08809999823570253,
        "tpp_threshold_100_unintended_diff_only": 0.007850001752376556,
        "tpp_threshold_500_total_metric": 0.30325001627206805,
        "tpp_threshold_500_intended_diff_only": 0.3172000169754028,
        "tpp_threshold_500_unintended_diff_only": 0.013950000703334808
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_tpp_results",
        "tpp_threshold_2_total_metric": 0.004099991917610169,
        "tpp_threshold_2_intended_diff_only": 0.006599998474121094,
        "tpp_threshold_2_unintended_diff_only": 0.0025000065565109254,
        "tpp_threshold_5_total_metric": 0.003699994087219238,
        "tpp_threshold_5_intended_diff_only": 0.006400001049041748,
        "tpp_threshold_5_unintended_diff_only": 0.0027000069618225097,
        "tpp_threshold_10_total_metric": 0.006399989128112794,
        "tpp_threshold_10_intended_diff_only": 0.009599995613098145,
        "tpp_threshold_10_unintended_diff_only": 0.0032000064849853514,
        "tpp_threshold_20_total_metric": 0.014299994707107543,
        "tpp_threshold_20_intended_diff_only": 0.018400001525878906,
        "tpp_threshold_20_unintended_diff_only": 0.004100006818771362,
        "tpp_threshold_50_total_metric": 0.04565000832080841,
        "tpp_threshold_50_intended_diff_only": 0.050000011920928955,
        "tpp_threshold_50_unintended_diff_only": 0.004350003600120544,
        "tpp_threshold_100_total_metric": 0.0808499962091446,
        "tpp_threshold_100_intended_diff_only": 0.08600000143051148,
        "tpp_threshold_100_unintended_diff_only": 0.005150005221366882,
        "tpp_threshold_500_total_metric": 0.34715001583099364,
        "tpp_threshold_500_intended_diff_only": 0.356600022315979,
        "tpp_threshold_500_unintended_diff_only": 0.009450006484985351
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_tpp_results",
        "tpp_threshold_2_total_metric": 0.003450009226799011,
        "tpp_threshold_2_intended_diff_only": 0.006400001049041748,
        "tpp_threshold_2_unintended_diff_only": 0.002949991822242737,
        "tpp_threshold_5_total_metric": 0.006600004434585571,
        "tpp_threshold_5_intended_diff_only": 0.010800004005432129,
        "tpp_threshold_5_unintended_diff_only": 0.004199999570846558,
        "tpp_threshold_10_total_metric": 0.006100010871887208,
        "tpp_threshold_10_intended_diff_only": 0.012000000476837159,
        "tpp_threshold_10_unintended_diff_only": 0.005899989604949951,
        "tpp_threshold_20_total_metric": 0.012050005793571473,
        "tpp_threshold_20_intended_diff_only": 0.019999992847442628,
        "tpp_threshold_20_unintended_diff_only": 0.007949987053871154,
        "tpp_threshold_50_total_metric": 0.038600018620491026,
        "tpp_threshold_50_intended_diff_only": 0.04640001058578491,
        "tpp_threshold_50_unintended_diff_only": 0.007799991965293884,
        "tpp_threshold_100_total_metric": 0.07964999675750732,
        "tpp_threshold_100_intended_diff_only": 0.09019999504089356,
        "tpp_threshold_100_unintended_diff_only": 0.01054999828338623,
        "tpp_threshold_500_total_metric": 0.2593500167131424,
        "tpp_threshold_500_intended_diff_only": 0.27780001163482665,
        "tpp_threshold_500_unintended_diff_only": 0.018449994921684264
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "f79dbc13-9983-43c2-951d-679265a9ccbe",
    "datetime_epoch_millis": 1738614523160,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.95084375,
        "llm_top_1_test_accuracy": 0.6574937500000001,
        "llm_top_2_test_accuracy": 0.7215499999999999,
        "llm_top_5_test_accuracy": 0.78513125,
        "llm_top_10_test_accuracy": 0.8306562499999999,
        "llm_top_20_test_accuracy": 0.8787375,
        "llm_top_50_test_accuracy": 0.9225312499999999,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9579000432044267,
        "sae_top_1_test_accuracy": 0.7772625,
        "sae_top_2_test_accuracy": 0.8257187500000001,
        "sae_top_5_test_accuracy": 0.871375,
        "sae_top_10_test_accuracy": 0.8996125,
        "sae_top_20_test_accuracy": 0.91944375,
        "sae_top_50_test_accuracy": 0.9396625000000001,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9636000275611878,
        "sae_top_1_test_accuracy": 0.7518,
        "sae_top_2_test_accuracy": 0.8390000000000001,
        "sae_top_5_test_accuracy": 0.8619999999999999,
        "sae_top_10_test_accuracy": 0.907,
        "sae_top_20_test_accuracy": 0.9378,
        "sae_top_50_test_accuracy": 0.9583999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9471999999999999,
        "llm_top_1_test_accuracy": 0.6699999999999999,
        "llm_top_2_test_accuracy": 0.7154,
        "llm_top_5_test_accuracy": 0.7639999999999999,
        "llm_top_10_test_accuracy": 0.8030000000000002,
        "llm_top_20_test_accuracy": 0.865,
        "llm_top_50_test_accuracy": 0.9056,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9530000448226928,
        "sae_top_1_test_accuracy": 0.7817999999999999,
        "sae_top_2_test_accuracy": 0.8221999999999999,
        "sae_top_5_test_accuracy": 0.8846,
        "sae_top_10_test_accuracy": 0.9109999999999999,
        "sae_top_20_test_accuracy": 0.9263999999999999,
        "sae_top_50_test_accuracy": 0.9376000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9186,
        "llm_top_1_test_accuracy": 0.6918,
        "llm_top_2_test_accuracy": 0.7366,
        "llm_top_5_test_accuracy": 0.772,
        "llm_top_10_test_accuracy": 0.8008,
        "llm_top_20_test_accuracy": 0.8532,
        "llm_top_50_test_accuracy": 0.8950000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9362000346183776,
        "sae_top_1_test_accuracy": 0.7696000000000001,
        "sae_top_2_test_accuracy": 0.8266,
        "sae_top_5_test_accuracy": 0.8705999999999999,
        "sae_top_10_test_accuracy": 0.8897999999999999,
        "sae_top_20_test_accuracy": 0.8936,
        "sae_top_50_test_accuracy": 0.915,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.8964000000000001,
        "llm_top_1_test_accuracy": 0.6073999999999999,
        "llm_top_2_test_accuracy": 0.6529999999999999,
        "llm_top_5_test_accuracy": 0.6891999999999999,
        "llm_top_10_test_accuracy": 0.7495999999999999,
        "llm_top_20_test_accuracy": 0.8100000000000002,
        "llm_top_50_test_accuracy": 0.8573999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9160000562667847,
        "sae_top_1_test_accuracy": 0.7146,
        "sae_top_2_test_accuracy": 0.76,
        "sae_top_5_test_accuracy": 0.7994000000000001,
        "sae_top_10_test_accuracy": 0.8294,
        "sae_top_20_test_accuracy": 0.8455999999999999,
        "sae_top_50_test_accuracy": 0.8798,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.981,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.847,
        "llm_top_50_test_accuracy": 0.933,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9740000367164612,
        "sae_top_1_test_accuracy": 0.851,
        "sae_top_2_test_accuracy": 0.91,
        "sae_top_5_test_accuracy": 0.933,
        "sae_top_10_test_accuracy": 0.94,
        "sae_top_20_test_accuracy": 0.953,
        "sae_top_50_test_accuracy": 0.965,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9648,
        "llm_top_1_test_accuracy": 0.6641999999999999,
        "llm_top_2_test_accuracy": 0.6978000000000001,
        "llm_top_5_test_accuracy": 0.7644,
        "llm_top_10_test_accuracy": 0.8016,
        "llm_top_20_test_accuracy": 0.8652000000000001,
        "llm_top_50_test_accuracy": 0.9308,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9666000604629517,
        "sae_top_1_test_accuracy": 0.6608,
        "sae_top_2_test_accuracy": 0.6698,
        "sae_top_5_test_accuracy": 0.7564,
        "sae_top_10_test_accuracy": 0.8360000000000001,
        "sae_top_20_test_accuracy": 0.8852,
        "sae_top_50_test_accuracy": 0.9356,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.9397500000000001,
        "llm_top_1_test_accuracy": 0.66875,
        "llm_top_2_test_accuracy": 0.773,
        "llm_top_5_test_accuracy": 0.82525,
        "llm_top_10_test_accuracy": 0.8672499999999999,
        "llm_top_20_test_accuracy": 0.9025000000000001,
        "llm_top_50_test_accuracy": 0.92225,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9560000449419022,
        "sae_top_1_test_accuracy": 0.7845,
        "sae_top_2_test_accuracy": 0.8367500000000001,
        "sae_top_5_test_accuracy": 0.88,
        "sae_top_10_test_accuracy": 0.8955,
        "sae_top_20_test_accuracy": 0.91875,
        "sae_top_50_test_accuracy": 0.9305,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9994,
        "llm_top_1_test_accuracy": 0.6436,
        "llm_top_2_test_accuracy": 0.7809999999999999,
        "llm_top_5_test_accuracy": 0.909,
        "llm_top_10_test_accuracy": 0.9634,
        "llm_top_20_test_accuracy": 0.9907999999999999,
        "llm_top_50_test_accuracy": 0.9978,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9978000402450562,
        "sae_top_1_test_accuracy": 0.9039999999999999,
        "sae_top_2_test_accuracy": 0.9414,
        "sae_top_5_test_accuracy": 0.985,
        "sae_top_10_test_accuracy": 0.9882,
        "sae_top_20_test_accuracy": 0.9952,
        "sae_top_50_test_accuracy": 0.9954000000000001,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "unlearning evaluation results": {
    "eval_type_id": "unlearning",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "wmdp-bio",
        "high_school_us_history",
        "college_computer_science",
        "high_school_geography",
        "human_aging"
      ],
      "intervention_method": "clamp_feature_activation",
      "retain_thresholds": [
        0.001,
        0.01
      ],
      "n_features_list": [
        10,
        20
      ],
      "multipliers": [
        25,
        50,
        100,
        200
      ],
      "dataset_size": 1024,
      "seq_len": 1024,
      "n_batch_loss_added": 50,
      "target_metric": "correct",
      "save_metrics": true,
      "model_name": "google/gemma-2-2b-it",
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16"
    },
    "eval_id": "2faa837b-5d48-4576-8677-e95ed00740b3",
    "datetime_epoch_millis": 1738614682587,
    "eval_result_metrics": {
      "unlearning": {
        "unlearning_score": 0.02059924602508545
      }
    },
    "eval_result_details": [],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}