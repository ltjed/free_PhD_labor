{
  "training results for layer 12": {
    "config": {
      "trainer_class": "TrainerTopK",
      "dict_class": "AutoEncoderTopK",
      "lr": 0.0001885618083164127,
      "steps": 2441,
      "seed": 42,
      "activation_dim": 2304,
      "dict_size": 18432,
      "k": 100,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "AutoEncoderTopK",
      "submodule_name": "resid_post_layer_12",
      "ortho_weight": 0.01
    },
    "final_info": {
      "training_steps": 2441,
      "final_loss": 3621.168212890625,
      "layer": 12,
      "dict_size": 18432,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "4c12370c-09ba-4d53-8db5-01eb022a264a",
    "datetime_epoch_millis": 1738640195198,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.03854944210233294,
        "mean_num_split_features": 1.28
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.0030120481927710845,
        "num_absorption": 8,
        "num_probe_true_positives": 2656,
        "num_split_features": 1
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.0012738853503184713,
        "num_absorption": 2,
        "num_probe_true_positives": 1570,
        "num_split_features": 1
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.042206590151795634,
        "num_absorption": 114,
        "num_probe_true_positives": 2701,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.05042016806722689,
        "num_absorption": 84,
        "num_probe_true_positives": 1666,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.012484394506866416,
        "num_absorption": 20,
        "num_probe_true_positives": 1602,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.0008389261744966443,
        "num_absorption": 1,
        "num_probe_true_positives": 1192,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.0050041701417848205,
        "num_absorption": 6,
        "num_probe_true_positives": 1199,
        "num_split_features": 2
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.014477766287487074,
        "num_absorption": 14,
        "num_probe_true_positives": 967,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.008378216636744464,
        "num_absorption": 14,
        "num_probe_true_positives": 1671,
        "num_split_features": 1
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.002369668246445498,
        "num_absorption": 1,
        "num_probe_true_positives": 422,
        "num_split_features": 1
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.0015037593984962407,
        "num_absorption": 1,
        "num_probe_true_positives": 665,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.03284072249589491,
        "num_absorption": 40,
        "num_probe_true_positives": 1218,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.0052113491603937466,
        "num_absorption": 9,
        "num_probe_true_positives": 1727,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.003592814371257485,
        "num_absorption": 3,
        "num_probe_true_positives": 835,
        "num_split_features": 2
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.3102803738317757,
        "num_absorption": 332,
        "num_probe_true_positives": 1070,
        "num_split_features": 3
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.14541577825159915,
        "num_absorption": 341,
        "num_probe_true_positives": 2345,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.007975460122699387,
        "num_absorption": 13,
        "num_probe_true_positives": 1630,
        "num_split_features": 2
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.14604750088621057,
        "num_absorption": 412,
        "num_probe_true_positives": 2821,
        "num_split_features": 1
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.10583941605839416,
        "num_absorption": 174,
        "num_probe_true_positives": 1644,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.00516795865633075,
        "num_absorption": 4,
        "num_probe_true_positives": 774,
        "num_split_features": 2
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.004761904761904762,
        "num_absorption": 4,
        "num_probe_true_positives": 840,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.033773861967694566,
        "num_absorption": 23,
        "num_probe_true_positives": 681,
        "num_split_features": 1
      },
      {
        "first_letter": "x",
        "absorption_rate": 0.011627906976744186,
        "num_absorption": 1,
        "num_probe_true_positives": 86,
        "num_split_features": 2
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.005263157894736842,
        "num_absorption": 1,
        "num_probe_true_positives": 190,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.003968253968253968,
        "num_absorption": 1,
        "num_probe_true_positives": 252,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9784549689440993,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.216796875
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9786184210526315,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 3.140625,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.6796875,
        "mse": 2.03125,
        "cossim": 0.8984375
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 135.0,
        "l2_ratio": 0.8984375,
        "relative_reconstruction_bias": 1.0
      },
      "sparsity": {
        "l0": 99.99999237060547,
        "l1": 536.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "4eb99ae1-a1d0-41a6-91a6-6558a7582307",
    "datetime_epoch_millis": 1738640960486,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.17683090622381523,
        "scr_metric_threshold_2": 0.10030978229795724,
        "scr_dir2_threshold_2": 0.09982437631228883,
        "scr_dir1_threshold_5": 0.23161143060216302,
        "scr_metric_threshold_5": 0.15819037100865074,
        "scr_dir2_threshold_5": 0.16073990875638844,
        "scr_dir1_threshold_10": 0.2255989282345076,
        "scr_metric_threshold_10": 0.20743827516188806,
        "scr_dir2_threshold_10": 0.21028163507160363,
        "scr_dir1_threshold_20": 0.2014080407854816,
        "scr_metric_threshold_20": 0.2597125236140031,
        "scr_dir2_threshold_20": 0.2627321214554728,
        "scr_dir1_threshold_50": 0.1899749827770617,
        "scr_metric_threshold_50": 0.2934618490723187,
        "scr_dir2_threshold_50": 0.30166231737391264,
        "scr_dir1_threshold_100": 0.13133436915587515,
        "scr_metric_threshold_100": 0.2981035070718139,
        "scr_dir2_threshold_100": 0.29766154380710746,
        "scr_dir1_threshold_500": -0.07589898149990076,
        "scr_metric_threshold_500": 0.2590619404464272,
        "scr_dir2_threshold_500": 0.266358077826132
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.4375002910385279,
        "scr_metric_threshold_2": 0.0,
        "scr_dir2_threshold_2": 0.0,
        "scr_dir1_threshold_5": 0.45312510186348476,
        "scr_metric_threshold_5": 0.009828028179079856,
        "scr_dir2_threshold_5": 0.009828028179079856,
        "scr_dir1_threshold_10": 0.4062497380653249,
        "scr_metric_threshold_10": 0.022113026790745845,
        "scr_dir2_threshold_10": 0.022113026790745845,
        "scr_dir1_threshold_20": 0.42187454889028175,
        "scr_metric_threshold_20": 0.04914014089539928,
        "scr_dir2_threshold_20": 0.04914014089539928,
        "scr_dir1_threshold_50": 0.4062497380653249,
        "scr_metric_threshold_50": 0.07371013811873126,
        "scr_dir2_threshold_50": 0.07371013811873126,
        "scr_dir1_threshold_100": 0.390624927240368,
        "scr_metric_threshold_100": 0.11056513395372923,
        "scr_dir2_threshold_100": 0.11056513395372923,
        "scr_dir1_threshold_500": 0.23437495634422081,
        "scr_metric_threshold_500": 0.14250618892355493,
        "scr_dir2_threshold_500": 0.14250618892355493
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.12621372145414522,
        "scr_metric_threshold_2": 0.11174778591786377,
        "scr_dir2_threshold_2": 0.11174778591786377,
        "scr_dir1_threshold_5": 0.22330102143857855,
        "scr_metric_threshold_5": 0.15759315403890664,
        "scr_dir2_threshold_5": 0.15759315403890664,
        "scr_dir1_threshold_10": 0.2524268642223358,
        "scr_metric_threshold_10": 0.22636103543351196,
        "scr_dir2_threshold_10": 0.22636103543351196,
        "scr_dir1_threshold_20": 0.14563094997665002,
        "scr_metric_threshold_20": 0.26647564714594496,
        "scr_dir2_threshold_20": 0.26647564714594496,
        "scr_dir1_threshold_50": 0.09708729998443334,
        "scr_metric_threshold_50": 0.34957016338163643,
        "scr_dir2_threshold_50": 0.34957016338163643,
        "scr_dir1_threshold_100": -0.10679649293164041,
        "scr_metric_threshold_100": 0.39541553150267933,
        "scr_dir2_threshold_100": 0.39541553150267933,
        "scr_dir1_threshold_500": -0.2912624786392547,
        "scr_metric_threshold_500": 0.16618903247138295,
        "scr_dir2_threshold_500": 0.16618903247138295
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.5238092084411499,
        "scr_metric_threshold_2": 0.04303801976188022,
        "scr_dir2_threshold_2": 0.04303801976188022,
        "scr_dir1_threshold_5": 0.6031751287885597,
        "scr_metric_threshold_5": 0.05063300880745302,
        "scr_dir2_threshold_5": 0.05063300880745302,
        "scr_dir1_threshold_10": 0.5079364028137167,
        "scr_metric_threshold_10": 0.07848105047818764,
        "scr_dir2_threshold_10": 0.07848105047818764,
        "scr_dir1_threshold_20": 0.5555557658011382,
        "scr_metric_threshold_20": 0.11392408119449507,
        "scr_dir2_threshold_20": 0.11392408119449507,
        "scr_dir1_threshold_50": 0.5079364028137167,
        "scr_metric_threshold_50": 0.1544304882404575,
        "scr_dir2_threshold_50": 0.1544304882404575,
        "scr_dir1_threshold_100": 0.2539686744594192,
        "scr_metric_threshold_100": 0.21772156062749953,
        "scr_dir2_threshold_100": 0.21772156062749953,
        "scr_dir1_threshold_500": -1.2539677283542974,
        "scr_metric_threshold_500": 0.08860765223967824,
        "scr_dir2_threshold_500": 0.08860765223967824
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": 0.14062502910382568,
        "scr_metric_threshold_2": 0.05341248075229903,
        "scr_dir2_threshold_2": 0.05341248075229903,
        "scr_dir1_threshold_5": 0.21874994179234863,
        "scr_metric_threshold_5": 0.1246292396676148,
        "scr_dir2_threshold_5": 0.1246292396676148,
        "scr_dir1_threshold_10": 0.1328126309672156,
        "scr_metric_threshold_10": 0.2017804631899768,
        "scr_dir2_threshold_10": 0.2017804631899768,
        "scr_dir1_threshold_20": 0.1328126309672156,
        "scr_metric_threshold_20": 0.2640950830237842,
        "scr_dir2_threshold_20": 0.2640950830237842,
        "scr_dir1_threshold_50": 0.07812491268852294,
        "scr_metric_threshold_50": 0.32047488451379413,
        "scr_dir2_threshold_50": 0.32047488451379413,
        "scr_dir1_threshold_100": 0.03906245634426147,
        "scr_metric_threshold_100": 0.05637997835838556,
        "scr_dir2_threshold_100": 0.05637997835838556,
        "scr_dir1_threshold_500": 0.3671878346939954,
        "scr_metric_threshold_500": 0.0623146198338074,
        "scr_dir2_threshold_500": 0.0623146198338074
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.03825119347697291,
        "scr_metric_threshold_2": 0.3058823226919976,
        "scr_dir2_threshold_2": 0.3058823226919976,
        "scr_dir1_threshold_5": 0.04371592886659017,
        "scr_metric_threshold_5": 0.47058815279635713,
        "scr_dir2_threshold_5": 0.47058815279635713,
        "scr_dir1_threshold_10": 0.021857964433295084,
        "scr_metric_threshold_10": 0.5529411847203642,
        "scr_dir2_threshold_10": 0.5529411847203642,
        "scr_dir1_threshold_20": -0.11475423184770137,
        "scr_metric_threshold_20": 0.6117646453839952,
        "scr_dir2_threshold_20": 0.6117646453839952,
        "scr_dir1_threshold_50": -0.08196712234356307,
        "scr_metric_threshold_50": 0.6431372512353937,
        "scr_dir2_threshold_50": 0.6431372512353937,
        "scr_dir1_threshold_100": -0.1311474608913792,
        "scr_metric_threshold_100": 0.6588235541610928,
        "scr_dir2_threshold_100": 0.6588235541610928,
        "scr_dir1_threshold_500": -0.18579220912042124,
        "scr_metric_threshold_500": 0.7176470148247238,
        "scr_dir2_threshold_500": 0.7176470148247238
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.020512557170790546,
        "scr_metric_threshold_2": 0.08064531634921589,
        "scr_dir2_threshold_2": 0.08064531634921589,
        "scr_dir1_threshold_5": 0.10256400851337757,
        "scr_metric_threshold_5": 0.13306447154960044,
        "scr_dir2_threshold_5": 0.13306447154960044,
        "scr_dir1_threshold_10": 0.16410229135546164,
        "scr_metric_threshold_10": 0.16129039235714715,
        "scr_dir2_threshold_10": 0.16129039235714715,
        "scr_dir1_threshold_20": 0.20512801702675515,
        "scr_metric_threshold_20": 0.2580645316349216,
        "scr_dir2_threshold_20": 0.2580645316349216,
        "scr_dir1_threshold_50": 0.21538460127700665,
        "scr_metric_threshold_50": 0.2782258006369044,
        "scr_dir2_threshold_50": 0.2782258006369044,
        "scr_dir1_threshold_100": 0.2615384662409978,
        "scr_metric_threshold_100": 0.32661299044643394,
        "scr_dir2_threshold_100": 0.32661299044643394,
        "scr_dir1_threshold_500": 0.17435887560571312,
        "scr_metric_threshold_500": 0.2580645316349216,
        "scr_dir2_threshold_500": 0.2580645316349216
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.0762330076638747,
        "scr_metric_threshold_2": 0.15625009146916644,
        "scr_dir2_threshold_2": 0.15625009146916644,
        "scr_dir1_threshold_5": 0.15246628261316397,
        "scr_metric_threshold_5": 0.2633928820889934,
        "scr_dir2_threshold_5": 0.2633928820889934,
        "scr_dir1_threshold_10": 0.24215229976379987,
        "scr_metric_threshold_10": 0.3392858140702595,
        "scr_dir2_threshold_10": 0.3392858140702595,
        "scr_dir1_threshold_20": 0.17488778690082293,
        "scr_metric_threshold_20": 0.4241072010647942,
        "scr_dir2_threshold_20": 0.4241072010647942,
        "scr_dir1_threshold_50": 0.2197307954761409,
        "scr_metric_threshold_50": 0.4508928321967208,
        "scr_dir2_threshold_50": 0.4508928321967208,
        "scr_dir1_threshold_100": 0.20179353858893082,
        "scr_metric_threshold_100": 0.47767846332864744,
        "scr_dir2_threshold_100": 0.47767846332864744,
        "scr_dir1_threshold_500": 0.20627805327479426,
        "scr_metric_threshold_500": 0.4955356394473054,
        "scr_dir2_threshold_500": 0.4955356394473054
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.05150224144123495,
        "scr_metric_threshold_2": 0.05150224144123495,
        "scr_dir2_threshold_2": 0.04761899355588758,
        "scr_dir1_threshold_5": 0.05579403094120067,
        "scr_metric_threshold_5": 0.05579403094120067,
        "scr_dir2_threshold_5": 0.07619033292310208,
        "scr_dir1_threshold_10": 0.07725323425491137,
        "scr_metric_threshold_10": 0.07725323425491137,
        "scr_dir2_threshold_10": 0.10000011353263609,
        "scr_dir1_threshold_20": 0.09012885856869063,
        "scr_metric_threshold_20": 0.09012885856869063,
        "scr_dir2_threshold_20": 0.11428564130044823,
        "scr_dir1_threshold_50": 0.07725323425491137,
        "scr_metric_threshold_50": 0.07725323425491137,
        "scr_dir2_threshold_50": 0.14285698066766273,
        "scr_dir1_threshold_100": 0.1416308441960435,
        "scr_metric_threshold_100": 0.1416308441960435,
        "scr_dir2_threshold_100": 0.13809513807839202,
        "scr_dir1_threshold_500": 0.1416308441960435,
        "scr_metric_threshold_500": 0.1416308441960435,
        "scr_dir2_threshold_500": 0.19999994323368195
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "tpp evaluations results": {
    "eval_type_id": "tpp",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": false,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "ee8c2004-efd3-41a6-9674-b0b2489dfa67",
    "datetime_epoch_millis": 1738641103566,
    "eval_result_metrics": {
      "tpp_metrics": {
        "tpp_threshold_2_total_metric": 0.0038000002503395082,
        "tpp_threshold_2_intended_diff_only": 0.006700003147125244,
        "tpp_threshold_2_unintended_diff_only": 0.0029000028967857364,
        "tpp_threshold_5_total_metric": 0.008099994063377379,
        "tpp_threshold_5_intended_diff_only": 0.011799997091293334,
        "tpp_threshold_5_unintended_diff_only": 0.0037000030279159546,
        "tpp_threshold_10_total_metric": 0.0098999947309494,
        "tpp_threshold_10_intended_diff_only": 0.015399998426437377,
        "tpp_threshold_10_unintended_diff_only": 0.005500003695487976,
        "tpp_threshold_20_total_metric": 0.021324989199638364,
        "tpp_threshold_20_intended_diff_only": 0.027899992465972898,
        "tpp_threshold_20_unintended_diff_only": 0.006575003266334534,
        "tpp_threshold_50_total_metric": 0.05320001095533371,
        "tpp_threshold_50_intended_diff_only": 0.060100007057189944,
        "tpp_threshold_50_unintended_diff_only": 0.006899996101856232,
        "tpp_threshold_100_total_metric": 0.10522500425577164,
        "tpp_threshold_100_intended_diff_only": 0.11340000629425048,
        "tpp_threshold_100_unintended_diff_only": 0.008175002038478851,
        "tpp_threshold_500_total_metric": 0.33655000776052474,
        "tpp_threshold_500_intended_diff_only": 0.34940001368522644,
        "tpp_threshold_500_unintended_diff_only": 0.012850005924701691
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_tpp_results",
        "tpp_threshold_2_total_metric": 0.004649993777275085,
        "tpp_threshold_2_intended_diff_only": 0.007200002670288086,
        "tpp_threshold_2_unintended_diff_only": 0.0025500088930130007,
        "tpp_threshold_5_total_metric": 0.006299987435340881,
        "tpp_threshold_5_intended_diff_only": 0.008799993991851806,
        "tpp_threshold_5_unintended_diff_only": 0.0025000065565109254,
        "tpp_threshold_10_total_metric": 0.0091499924659729,
        "tpp_threshold_10_intended_diff_only": 0.012800002098083496,
        "tpp_threshold_10_unintended_diff_only": 0.0036500096321105957,
        "tpp_threshold_20_total_metric": 0.02189999222755432,
        "tpp_threshold_20_intended_diff_only": 0.025999999046325682,
        "tpp_threshold_20_unintended_diff_only": 0.004100006818771362,
        "tpp_threshold_50_total_metric": 0.05630000233650208,
        "tpp_threshold_50_intended_diff_only": 0.06040000915527344,
        "tpp_threshold_50_unintended_diff_only": 0.004100006818771362,
        "tpp_threshold_100_total_metric": 0.1156000167131424,
        "tpp_threshold_100_intended_diff_only": 0.12060002088546753,
        "tpp_threshold_100_unintended_diff_only": 0.005000004172325134,
        "tpp_threshold_500_total_metric": 0.3832000136375427,
        "tpp_threshold_500_intended_diff_only": 0.3918000221252441,
        "tpp_threshold_500_unintended_diff_only": 0.008600008487701417
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_tpp_results",
        "tpp_threshold_2_total_metric": 0.0029500067234039308,
        "tpp_threshold_2_intended_diff_only": 0.0062000036239624025,
        "tpp_threshold_2_unintended_diff_only": 0.0032499969005584718,
        "tpp_threshold_5_total_metric": 0.009900000691413878,
        "tpp_threshold_5_intended_diff_only": 0.014800000190734863,
        "tpp_threshold_5_unintended_diff_only": 0.004899999499320984,
        "tpp_threshold_10_total_metric": 0.010649996995925903,
        "tpp_threshold_10_intended_diff_only": 0.01799999475479126,
        "tpp_threshold_10_unintended_diff_only": 0.0073499977588653564,
        "tpp_threshold_20_total_metric": 0.020749986171722412,
        "tpp_threshold_20_intended_diff_only": 0.029799985885620116,
        "tpp_threshold_20_unintended_diff_only": 0.009049999713897704,
        "tpp_threshold_50_total_metric": 0.05010001957416534,
        "tpp_threshold_50_intended_diff_only": 0.059800004959106444,
        "tpp_threshold_50_unintended_diff_only": 0.009699985384941101,
        "tpp_threshold_100_total_metric": 0.09484999179840088,
        "tpp_threshold_100_intended_diff_only": 0.10619999170303344,
        "tpp_threshold_100_unintended_diff_only": 0.011349999904632568,
        "tpp_threshold_500_total_metric": 0.2899000018835068,
        "tpp_threshold_500_intended_diff_only": 0.30700000524520876,
        "tpp_threshold_500_unintended_diff_only": 0.017100003361701966
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "e169f7e5-acdb-4541-a6bf-755b2770bafe",
    "datetime_epoch_millis": 1738641527000,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.9514062500000001,
        "llm_top_1_test_accuracy": 0.66194375,
        "llm_top_2_test_accuracy": 0.72325625,
        "llm_top_5_test_accuracy": 0.78335625,
        "llm_top_10_test_accuracy": 0.83066875,
        "llm_top_20_test_accuracy": 0.8777999999999999,
        "llm_top_50_test_accuracy": 0.9224687500000001,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9579000454396011,
        "sae_top_1_test_accuracy": 0.76345625,
        "sae_top_2_test_accuracy": 0.8132312500000002,
        "sae_top_5_test_accuracy": 0.8650625,
        "sae_top_10_test_accuracy": 0.904625,
        "sae_top_20_test_accuracy": 0.9234562500000001,
        "sae_top_50_test_accuracy": 0.93824375,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9638000369071961,
        "sae_top_1_test_accuracy": 0.7318,
        "sae_top_2_test_accuracy": 0.828,
        "sae_top_5_test_accuracy": 0.8713999999999998,
        "sae_top_10_test_accuracy": 0.9174,
        "sae_top_20_test_accuracy": 0.9408,
        "sae_top_50_test_accuracy": 0.9560000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9484,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.7298,
        "llm_top_5_test_accuracy": 0.7633999999999999,
        "llm_top_10_test_accuracy": 0.8051999999999999,
        "llm_top_20_test_accuracy": 0.8628,
        "llm_top_50_test_accuracy": 0.9099999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9490000486373902,
        "sae_top_1_test_accuracy": 0.8498000000000001,
        "sae_top_2_test_accuracy": 0.8564,
        "sae_top_5_test_accuracy": 0.8838000000000001,
        "sae_top_10_test_accuracy": 0.9066000000000001,
        "sae_top_20_test_accuracy": 0.9221999999999999,
        "sae_top_50_test_accuracy": 0.9342,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9178000000000001,
        "llm_top_1_test_accuracy": 0.6908000000000001,
        "llm_top_2_test_accuracy": 0.7378,
        "llm_top_5_test_accuracy": 0.7752,
        "llm_top_10_test_accuracy": 0.797,
        "llm_top_20_test_accuracy": 0.8497999999999999,
        "llm_top_50_test_accuracy": 0.8928,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9352000474929809,
        "sae_top_1_test_accuracy": 0.7707999999999999,
        "sae_top_2_test_accuracy": 0.8520000000000001,
        "sae_top_5_test_accuracy": 0.8716000000000002,
        "sae_top_10_test_accuracy": 0.8916000000000001,
        "sae_top_20_test_accuracy": 0.907,
        "sae_top_50_test_accuracy": 0.9106,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.9016,
        "llm_top_1_test_accuracy": 0.5992000000000001,
        "llm_top_2_test_accuracy": 0.6504,
        "llm_top_5_test_accuracy": 0.6674,
        "llm_top_10_test_accuracy": 0.7491999999999999,
        "llm_top_20_test_accuracy": 0.8122,
        "llm_top_50_test_accuracy": 0.8558,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.92160005569458,
        "sae_top_1_test_accuracy": 0.7310000000000001,
        "sae_top_2_test_accuracy": 0.7648,
        "sae_top_5_test_accuracy": 0.808,
        "sae_top_10_test_accuracy": 0.8472000000000002,
        "sae_top_20_test_accuracy": 0.8664,
        "sae_top_50_test_accuracy": 0.8842000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.981,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.847,
        "llm_top_50_test_accuracy": 0.933,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9750000536441803,
        "sae_top_1_test_accuracy": 0.71,
        "sae_top_2_test_accuracy": 0.815,
        "sae_top_5_test_accuracy": 0.901,
        "sae_top_10_test_accuracy": 0.925,
        "sae_top_20_test_accuracy": 0.945,
        "sae_top_50_test_accuracy": 0.956,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9644,
        "llm_top_1_test_accuracy": 0.6614000000000001,
        "llm_top_2_test_accuracy": 0.6982000000000002,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.8051999999999999,
        "llm_top_20_test_accuracy": 0.8672000000000001,
        "llm_top_50_test_accuracy": 0.9269999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9694000482559204,
        "sae_top_1_test_accuracy": 0.592,
        "sae_top_2_test_accuracy": 0.5952,
        "sae_top_5_test_accuracy": 0.721,
        "sae_top_10_test_accuracy": 0.8604,
        "sae_top_20_test_accuracy": 0.9019999999999999,
        "sae_top_50_test_accuracy": 0.9344000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.93925,
        "llm_top_1_test_accuracy": 0.63075,
        "llm_top_2_test_accuracy": 0.77725,
        "llm_top_5_test_accuracy": 0.8222499999999999,
        "llm_top_10_test_accuracy": 0.86875,
        "llm_top_20_test_accuracy": 0.898,
        "llm_top_50_test_accuracy": 0.9247500000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9510000497102737,
        "sae_top_1_test_accuracy": 0.8282499999999999,
        "sae_top_2_test_accuracy": 0.85325,
        "sae_top_5_test_accuracy": 0.8835,
        "sae_top_10_test_accuracy": 0.898,
        "sae_top_20_test_accuracy": 0.91225,
        "sae_top_50_test_accuracy": 0.9347500000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9992000000000001,
        "llm_top_1_test_accuracy": 0.7282,
        "llm_top_2_test_accuracy": 0.7769999999999999,
        "llm_top_5_test_accuracy": 0.9154,
        "llm_top_10_test_accuracy": 0.9603999999999999,
        "llm_top_20_test_accuracy": 0.9892,
        "llm_top_50_test_accuracy": 0.998,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9982000231742859,
        "sae_top_1_test_accuracy": 0.8939999999999999,
        "sae_top_2_test_accuracy": 0.9411999999999999,
        "sae_top_5_test_accuracy": 0.9802,
        "sae_top_10_test_accuracy": 0.9907999999999999,
        "sae_top_20_test_accuracy": 0.9920000000000002,
        "sae_top_50_test_accuracy": 0.9958,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "unlearning evaluation results": {
    "eval_type_id": "unlearning",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "wmdp-bio",
        "high_school_us_history",
        "college_computer_science",
        "high_school_geography",
        "human_aging"
      ],
      "intervention_method": "clamp_feature_activation",
      "retain_thresholds": [
        0.001,
        0.01
      ],
      "n_features_list": [
        10,
        20
      ],
      "multipliers": [
        25,
        50,
        100,
        200
      ],
      "dataset_size": 1024,
      "seq_len": 1024,
      "n_batch_loss_added": 50,
      "target_metric": "correct",
      "save_metrics": true,
      "model_name": "google/gemma-2-2b-it",
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16"
    },
    "eval_id": "176ebd82-bede-4338-af96-f7fe53010d44",
    "datetime_epoch_millis": 1738641689814,
    "eval_result_metrics": {
      "unlearning": {
        "unlearning_score": 0.0992509126663208
      }
    },
    "eval_result_details": [],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}