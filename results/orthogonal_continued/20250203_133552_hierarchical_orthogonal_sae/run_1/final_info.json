{
  "training results for layer 12": {
    "config": {
      "trainer_class": "TrainerTopK",
      "dict_class": "AutoEncoderTopK",
      "lr": 0.0001885618083164127,
      "steps": 2441,
      "seed": 42,
      "activation_dim": 2304,
      "dict_size": 18432,
      "k": 120,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "AutoEncoderTopK",
      "submodule_name": "resid_post_layer_12",
      "ortho_weight": 0.1
    },
    "final_info": {
      "training_steps": 2441,
      "final_loss": 3678.6611328125,
      "layer": 12,
      "dict_size": 18432,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "8d9ceb98-d532-4371-9da4-1010283946e2",
    "datetime_epoch_millis": 1738609308317,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.04807216856360021,
        "mean_num_split_features": 1.2083333333333333
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.10240963855421686,
        "num_absorption": 272,
        "num_probe_true_positives": 2656,
        "num_split_features": 1
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.018471337579617834,
        "num_absorption": 29,
        "num_probe_true_positives": 1570,
        "num_split_features": 1
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.011847463902258423,
        "num_absorption": 32,
        "num_probe_true_positives": 2701,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.05582232893157263,
        "num_absorption": 93,
        "num_probe_true_positives": 1666,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.02372034956304619,
        "num_absorption": 38,
        "num_probe_true_positives": 1602,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.07298657718120806,
        "num_absorption": 87,
        "num_probe_true_positives": 1192,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.0050041701417848205,
        "num_absorption": 6,
        "num_probe_true_positives": 1199,
        "num_split_features": 1
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.14788004136504654,
        "num_absorption": 143,
        "num_probe_true_positives": 967,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.007779772591262717,
        "num_absorption": 13,
        "num_probe_true_positives": 1671,
        "num_split_features": 1
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.016587677725118485,
        "num_absorption": 7,
        "num_probe_true_positives": 422,
        "num_split_features": 1
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.0015037593984962407,
        "num_absorption": 1,
        "num_probe_true_positives": 665,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.1962233169129721,
        "num_absorption": 239,
        "num_probe_true_positives": 1218,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.013317892298784018,
        "num_absorption": 23,
        "num_probe_true_positives": 1727,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.003592814371257485,
        "num_absorption": 3,
        "num_probe_true_positives": 835,
        "num_split_features": 2
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.16822429906542055,
        "num_absorption": 180,
        "num_probe_true_positives": 1070,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.07505330490405117,
        "num_absorption": 176,
        "num_probe_true_positives": 2345,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.046625766871165646,
        "num_absorption": 76,
        "num_probe_true_positives": 1630,
        "num_split_features": 2
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.06699751861042183,
        "num_absorption": 189,
        "num_probe_true_positives": 2821,
        "num_split_features": 2
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.011557177615571776,
        "num_absorption": 19,
        "num_probe_true_positives": 1644,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.002583979328165375,
        "num_absorption": 2,
        "num_probe_true_positives": 774,
        "num_split_features": 3
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.004761904761904762,
        "num_absorption": 4,
        "num_probe_true_positives": 840,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.016152716593245228,
        "num_absorption": 11,
        "num_probe_true_positives": 681,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.005263157894736842,
        "num_absorption": 1,
        "num_probe_true_positives": 190,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.07936507936507936,
        "num_absorption": 20,
        "num_probe_true_positives": 252,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9776785714285714,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.224609375
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9769736842105263,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 3.15625,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.67578125,
        "mse": 2.0625,
        "cossim": 0.8984375
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 135.0,
        "l2_ratio": 0.8984375,
        "relative_reconstruction_bias": 1.0
      },
      "sparsity": {
        "l0": 119.99999237060547,
        "l1": 580.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "e16a7665-605b-4e79-a0aa-ac0e341b9a3b",
    "datetime_epoch_millis": 1738610094969,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.15452529216470345,
        "scr_metric_threshold_2": 0.09892723675472725,
        "scr_dir2_threshold_2": 0.09552440030797897,
        "scr_dir1_threshold_5": 0.21542753515989896,
        "scr_metric_threshold_5": 0.13779511760967697,
        "scr_dir2_threshold_5": 0.14070489111315626,
        "scr_dir1_threshold_10": 0.23031061666774186,
        "scr_metric_threshold_10": 0.178718583658543,
        "scr_dir2_threshold_10": 0.18108422651692602,
        "scr_dir1_threshold_20": 0.22297741975453145,
        "scr_metric_threshold_20": 0.21683157921659676,
        "scr_dir2_threshold_20": 0.22664150055741308,
        "scr_dir1_threshold_50": 0.16581064448625227,
        "scr_metric_threshold_50": 0.26140818024557405,
        "scr_dir2_threshold_50": 0.2713867180394927,
        "scr_dir1_threshold_100": 0.15167247750345686,
        "scr_metric_threshold_100": 0.27224938547587607,
        "scr_dir2_threshold_100": 0.27841381884442634,
        "scr_dir1_threshold_500": -0.05752503936191485,
        "scr_metric_threshold_500": 0.24450015146632167,
        "scr_dir2_threshold_500": 0.25798369308737845
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.3124999417922944,
        "scr_metric_threshold_2": 0.004914087313907592,
        "scr_dir2_threshold_2": 0.004914087313907592,
        "scr_dir1_threshold_5": 0.390624927240368,
        "scr_metric_threshold_5": 0.007371057746493725,
        "scr_dir2_threshold_5": 0.007371057746493725,
        "scr_dir1_threshold_10": 0.390624927240368,
        "scr_metric_threshold_10": 0.02948408453723957,
        "scr_dir2_threshold_10": 0.02948408453723957,
        "scr_dir1_threshold_20": 0.37500011641541114,
        "scr_metric_threshold_20": 0.04422605358149169,
        "scr_dir2_threshold_20": 0.04422605358149169,
        "scr_dir1_threshold_50": 0.3124999417922944,
        "scr_metric_threshold_50": 0.06633908037223754,
        "scr_dir2_threshold_50": 0.06633908037223754,
        "scr_dir1_threshold_100": 0.32812475261725127,
        "scr_metric_threshold_100": 0.08599513673039726,
        "scr_dir2_threshold_100": 0.08599513673039726,
        "scr_dir1_threshold_500": 0.3124999417922944,
        "scr_metric_threshold_500": -0.007370911297758397,
        "scr_dir2_threshold_500": -0.007370911297758397
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.06796087851472148,
        "scr_metric_threshold_2": 0.10888249310703833,
        "scr_dir2_threshold_2": 0.10888249310703833,
        "scr_dir1_threshold_5": 0.23300963569983096,
        "scr_metric_threshold_5": 0.12893988435673434,
        "scr_dir2_threshold_5": 0.12893988435673434,
        "scr_dir1_threshold_10": 0.23300963569983096,
        "scr_metric_threshold_10": 0.1805156673124691,
        "scr_dir2_threshold_10": 0.1805156673124691,
        "scr_dir1_threshold_20": 0.28155328569204763,
        "scr_metric_threshold_20": 0.2292263282443374,
        "scr_dir2_threshold_20": 0.2292263282443374,
        "scr_dir1_threshold_50": 0.02912584278375721,
        "scr_metric_threshold_50": 0.2893983312064664,
        "scr_dir2_threshold_50": 0.2893983312064664,
        "scr_dir1_threshold_100": 0.15533956423790243,
        "scr_metric_threshold_100": 0.14040105560003607,
        "scr_dir2_threshold_100": 0.14040105560003607,
        "scr_dir1_threshold_500": -0.56310715007005,
        "scr_metric_threshold_500": 0.1719197888799928,
        "scr_dir2_threshold_500": 0.1719197888799928
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.49206359718628334,
        "scr_metric_threshold_2": 0.022784816238899015,
        "scr_dir2_threshold_2": 0.022784816238899015,
        "scr_dir1_threshold_5": 0.5555557658011382,
        "scr_metric_threshold_5": 0.06582283600077923,
        "scr_dir2_threshold_5": 0.06582283600077923,
        "scr_dir1_threshold_10": 0.5555557658011382,
        "scr_metric_threshold_10": 0.08860765223967824,
        "scr_dir2_threshold_10": 0.08860765223967824,
        "scr_dir1_threshold_20": 0.5555557658011382,
        "scr_metric_threshold_20": 0.11898745752415006,
        "scr_dir2_threshold_20": 0.11898745752415006,
        "scr_dir1_threshold_50": 0.49206359718628334,
        "scr_metric_threshold_50": 0.13924051014931188,
        "scr_dir2_threshold_50": 0.13924051014931188,
        "scr_dir1_threshold_100": 0.2539686744594192,
        "scr_metric_threshold_100": 0.1898735189567649,
        "scr_dir2_threshold_100": 0.1898735189567649,
        "scr_dir1_threshold_500": -0.6507935456708595,
        "scr_metric_threshold_500": 0.09367087767151386,
        "scr_dir2_threshold_500": 0.09367087767151386
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": 0.1328126309672156,
        "scr_metric_threshold_2": 0.026706240376149513,
        "scr_dir2_threshold_2": 0.026706240376149513,
        "scr_dir1_threshold_5": 0.19531274738251833,
        "scr_metric_threshold_5": 0.08308621873453508,
        "scr_dir2_threshold_5": 0.08308621873453508,
        "scr_dir1_threshold_10": 0.16406268917486697,
        "scr_metric_threshold_10": 0.10089032002917621,
        "scr_dir2_threshold_10": 0.10089032002917621,
        "scr_dir1_threshold_20": 0.007812863797821078,
        "scr_metric_threshold_20": 0.17210690207611637,
        "scr_dir2_threshold_20": 0.17210690207611637,
        "scr_dir1_threshold_50": 0.05468771827869265,
        "scr_metric_threshold_50": 0.2136499230091961,
        "scr_dir2_threshold_50": 0.2136499230091961,
        "scr_dir1_threshold_100": -0.03906245634426147,
        "scr_metric_threshold_100": 0.2640950830237842,
        "scr_dir2_threshold_100": 0.2640950830237842,
        "scr_dir1_threshold_500": 0.07812491268852294,
        "scr_metric_threshold_500": 0.05341248075229903,
        "scr_dir2_threshold_500": 0.05341248075229903
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.04371592886659017,
        "scr_metric_threshold_2": 0.4627451182053349,
        "scr_dir2_threshold_2": 0.4627451182053349,
        "scr_dir1_threshold_5": 0.04371592886659017,
        "scr_metric_threshold_5": 0.525490096164477,
        "scr_dir2_threshold_5": 0.525490096164477,
        "scr_dir1_threshold_10": 0.021857964433295084,
        "scr_metric_threshold_10": 0.5764705222370857,
        "scr_dir2_threshold_10": 0.5764705222370857,
        "scr_dir1_threshold_20": 0.00546440968122594,
        "scr_metric_threshold_20": 0.6470587685309047,
        "scr_dir2_threshold_20": 0.6470587685309047,
        "scr_dir1_threshold_50": -0.26775965717237565,
        "scr_metric_threshold_50": 0.6705881060476262,
        "scr_dir2_threshold_50": 0.6705881060476262,
        "scr_dir1_threshold_100": -0.3005464409681226,
        "scr_metric_threshold_100": 0.6823528916778143,
        "scr_dir2_threshold_100": 0.6823528916778143,
        "scr_dir1_threshold_500": -0.33333322476386956,
        "scr_metric_threshold_500": 0.725490049415746,
        "scr_dir2_threshold_500": 0.725490049415746
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.046153559299134936,
        "scr_metric_threshold_2": 0.060483807005948444,
        "scr_dir2_threshold_2": 0.060483807005948444,
        "scr_dir1_threshold_5": 0.12307687134902433,
        "scr_metric_threshold_5": 0.09677413927777444,
        "scr_dir2_threshold_5": 0.09677413927777444,
        "scr_dir1_threshold_10": 0.18974359914866223,
        "scr_metric_threshold_10": 0.1491935348194436,
        "scr_dir2_threshold_10": 0.1491935348194436,
        "scr_dir1_threshold_20": 0.22051274056970427,
        "scr_metric_threshold_20": 0.17741945562699032,
        "scr_dir2_threshold_20": 0.17741945562699032,
        "scr_dir1_threshold_50": 0.27179474482639304,
        "scr_metric_threshold_50": 0.22580640509523522,
        "scr_dir2_threshold_50": 0.22580640509523522,
        "scr_dir1_threshold_100": 0.29743574695473746,
        "scr_metric_threshold_100": 0.2943548639067476,
        "scr_dir2_threshold_100": 0.2943548639067476,
        "scr_dir1_threshold_500": 0.2102561563194528,
        "scr_metric_threshold_500": 0.3225807847142943,
        "scr_dir2_threshold_500": 0.3225807847142943
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.08520176975018703,
        "scr_metric_threshold_2": 0.04910730084933944,
        "scr_dir2_threshold_2": 0.04910730084933944,
        "scr_dir1_threshold_5": 0.14349778781226621,
        "scr_metric_threshold_5": 0.15625009146916644,
        "scr_dir2_threshold_5": 0.15625009146916644,
        "scr_dir1_threshold_10": 0.20179353858893082,
        "scr_metric_threshold_10": 0.21875007483840891,
        "scr_dir2_threshold_10": 0.21875007483840891,
        "scr_dir1_threshold_20": 0.27354256613777117,
        "scr_metric_threshold_20": 0.28125005820765137,
        "scr_dir2_threshold_20": 0.28125005820765137,
        "scr_dir1_threshold_50": 0.31390132731264025,
        "scr_metric_threshold_50": 0.3660714452021861,
        "scr_dir2_threshold_50": 0.3660714452021861,
        "scr_dir1_threshold_100": 0.37219734537471943,
        "scr_metric_threshold_100": 0.37499990021545476,
        "scr_dir2_threshold_100": 0.37499990021545476,
        "scr_dir1_threshold_500": 0.3273543367994015,
        "scr_metric_threshold_500": 0.43749988358469727,
        "scr_dir2_threshold_500": 0.43749988358469727
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.05579403094120067,
        "scr_metric_threshold_2": 0.05579403094120067,
        "scr_dir2_threshold_2": 0.0285713393672145,
        "scr_dir1_threshold_5": 0.03862661712745569,
        "scr_metric_threshold_5": 0.03862661712745569,
        "scr_dir2_threshold_5": 0.06190480515528994,
        "scr_dir1_threshold_10": 0.08583681325484281,
        "scr_metric_threshold_10": 0.08583681325484281,
        "scr_dir2_threshold_10": 0.10476195612190681,
        "scr_dir1_threshold_20": 0.0643776099411321,
        "scr_metric_threshold_20": 0.0643776099411321,
        "scr_dir2_threshold_20": 0.14285698066766273,
        "scr_dir1_threshold_50": 0.12017164088233277,
        "scr_metric_threshold_50": 0.12017164088233277,
        "scr_dir2_threshold_50": 0.19999994323368195,
        "scr_dir1_threshold_100": 0.1459226336960092,
        "scr_metric_threshold_100": 0.1459226336960092,
        "scr_dir2_threshold_100": 0.19523810064441124,
        "scr_dir1_threshold_500": 0.15879825800978847,
        "scr_metric_threshold_500": 0.15879825800978847,
        "scr_dir2_threshold_500": 0.2666665909782426
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "tpp evaluations results": {
    "eval_type_id": "tpp",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": false,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "5caf7cfe-522f-4f34-8189-d0b75f3f6849",
    "datetime_epoch_millis": 1738610244722,
    "eval_result_metrics": {
      "tpp_metrics": {
        "tpp_threshold_2_total_metric": 0.003549997508525848,
        "tpp_threshold_2_intended_diff_only": 0.006099998950958252,
        "tpp_threshold_2_unintended_diff_only": 0.0025500014424324037,
        "tpp_threshold_5_total_metric": 0.0063750013709068295,
        "tpp_threshold_5_intended_diff_only": 0.00950000286102295,
        "tpp_threshold_5_unintended_diff_only": 0.003125001490116119,
        "tpp_threshold_10_total_metric": 0.006425005197525023,
        "tpp_threshold_10_intended_diff_only": 0.010700005292892455,
        "tpp_threshold_10_unintended_diff_only": 0.004275000095367432,
        "tpp_threshold_20_total_metric": 0.01430000364780426,
        "tpp_threshold_20_intended_diff_only": 0.01990000009536743,
        "tpp_threshold_20_unintended_diff_only": 0.005599996447563172,
        "tpp_threshold_50_total_metric": 0.041125011444091794,
        "tpp_threshold_50_intended_diff_only": 0.04660000801086425,
        "tpp_threshold_50_unintended_diff_only": 0.005474996566772462,
        "tpp_threshold_100_total_metric": 0.0761750027537346,
        "tpp_threshold_100_intended_diff_only": 0.08340000510215759,
        "tpp_threshold_100_unintended_diff_only": 0.0072250023484230035,
        "tpp_threshold_500_total_metric": 0.2988750010728836,
        "tpp_threshold_500_intended_diff_only": 0.31300000548362733,
        "tpp_threshold_500_unintended_diff_only": 0.014125004410743713
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_tpp_results",
        "tpp_threshold_2_total_metric": 0.004249992966651917,
        "tpp_threshold_2_intended_diff_only": 0.006599998474121094,
        "tpp_threshold_2_unintended_diff_only": 0.0023500055074691774,
        "tpp_threshold_5_total_metric": 0.004049998521804809,
        "tpp_threshold_5_intended_diff_only": 0.006400001049041748,
        "tpp_threshold_5_unintended_diff_only": 0.0023500025272369385,
        "tpp_threshold_10_total_metric": 0.005600008368492126,
        "tpp_threshold_10_intended_diff_only": 0.008800017833709716,
        "tpp_threshold_10_unintended_diff_only": 0.0032000094652175903,
        "tpp_threshold_20_total_metric": 0.014850005507469177,
        "tpp_threshold_20_intended_diff_only": 0.018800008296966552,
        "tpp_threshold_20_unintended_diff_only": 0.003950002789497376,
        "tpp_threshold_50_total_metric": 0.04305000007152557,
        "tpp_threshold_50_intended_diff_only": 0.047000002861022946,
        "tpp_threshold_50_unintended_diff_only": 0.003950002789497376,
        "tpp_threshold_100_total_metric": 0.07684999704360962,
        "tpp_threshold_100_intended_diff_only": 0.08200000524520874,
        "tpp_threshold_100_unintended_diff_only": 0.005150008201599121,
        "tpp_threshold_500_total_metric": 0.33305000364780424,
        "tpp_threshold_500_intended_diff_only": 0.3424000144004822,
        "tpp_threshold_500_unintended_diff_only": 0.009350010752677917
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_tpp_results",
        "tpp_threshold_2_total_metric": 0.0028500020503997798,
        "tpp_threshold_2_intended_diff_only": 0.00559999942779541,
        "tpp_threshold_2_unintended_diff_only": 0.00274999737739563,
        "tpp_threshold_5_total_metric": 0.00870000422000885,
        "tpp_threshold_5_intended_diff_only": 0.01260000467300415,
        "tpp_threshold_5_unintended_diff_only": 0.0039000004529953004,
        "tpp_threshold_10_total_metric": 0.007250002026557922,
        "tpp_threshold_10_intended_diff_only": 0.012599992752075195,
        "tpp_threshold_10_unintended_diff_only": 0.005349990725517273,
        "tpp_threshold_20_total_metric": 0.013750001788139345,
        "tpp_threshold_20_intended_diff_only": 0.020999991893768312,
        "tpp_threshold_20_unintended_diff_only": 0.007249990105628967,
        "tpp_threshold_50_total_metric": 0.03920002281665802,
        "tpp_threshold_50_intended_diff_only": 0.046200013160705565,
        "tpp_threshold_50_unintended_diff_only": 0.006999990344047547,
        "tpp_threshold_100_total_metric": 0.07550000846385956,
        "tpp_threshold_100_intended_diff_only": 0.08480000495910645,
        "tpp_threshold_100_unintended_diff_only": 0.009299996495246887,
        "tpp_threshold_500_total_metric": 0.264699998497963,
        "tpp_threshold_500_intended_diff_only": 0.2835999965667725,
        "tpp_threshold_500_unintended_diff_only": 0.018899998068809508
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "294e7fc9-f19b-47e8-845d-6cfc0d249cdb",
    "datetime_epoch_millis": 1738610707851,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.95135625,
        "llm_top_1_test_accuracy": 0.65635,
        "llm_top_2_test_accuracy": 0.7217500000000001,
        "llm_top_5_test_accuracy": 0.78729375,
        "llm_top_10_test_accuracy": 0.8318125,
        "llm_top_20_test_accuracy": 0.88026875,
        "llm_top_50_test_accuracy": 0.9220875,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9576437916606666,
        "sae_top_1_test_accuracy": 0.7806875,
        "sae_top_2_test_accuracy": 0.8111812500000002,
        "sae_top_5_test_accuracy": 0.8678687500000001,
        "sae_top_10_test_accuracy": 0.903275,
        "sae_top_20_test_accuracy": 0.9198125,
        "sae_top_50_test_accuracy": 0.9371499999999999,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9630000472068787,
        "sae_top_1_test_accuracy": 0.8082,
        "sae_top_2_test_accuracy": 0.8376000000000001,
        "sae_top_5_test_accuracy": 0.8728,
        "sae_top_10_test_accuracy": 0.9152000000000001,
        "sae_top_20_test_accuracy": 0.9348000000000001,
        "sae_top_50_test_accuracy": 0.9484,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9465999999999999,
        "llm_top_1_test_accuracy": 0.6746000000000001,
        "llm_top_2_test_accuracy": 0.709,
        "llm_top_5_test_accuracy": 0.7718,
        "llm_top_10_test_accuracy": 0.8093999999999999,
        "llm_top_20_test_accuracy": 0.8704000000000001,
        "llm_top_50_test_accuracy": 0.9056000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9484000444412232,
        "sae_top_1_test_accuracy": 0.8123999999999999,
        "sae_top_2_test_accuracy": 0.8204,
        "sae_top_5_test_accuracy": 0.8778,
        "sae_top_10_test_accuracy": 0.9006000000000001,
        "sae_top_20_test_accuracy": 0.9192,
        "sae_top_50_test_accuracy": 0.9396000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9134,
        "llm_top_1_test_accuracy": 0.6886,
        "llm_top_2_test_accuracy": 0.7452000000000001,
        "llm_top_5_test_accuracy": 0.7626000000000001,
        "llm_top_10_test_accuracy": 0.8061999999999999,
        "llm_top_20_test_accuracy": 0.8506,
        "llm_top_50_test_accuracy": 0.8904,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9332000374794006,
        "sae_top_1_test_accuracy": 0.766,
        "sae_top_2_test_accuracy": 0.7964,
        "sae_top_5_test_accuracy": 0.8814,
        "sae_top_10_test_accuracy": 0.8916000000000001,
        "sae_top_20_test_accuracy": 0.9027999999999998,
        "sae_top_50_test_accuracy": 0.9086000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.9,
        "llm_top_1_test_accuracy": 0.6022,
        "llm_top_2_test_accuracy": 0.6437999999999999,
        "llm_top_5_test_accuracy": 0.7020000000000001,
        "llm_top_10_test_accuracy": 0.7478,
        "llm_top_20_test_accuracy": 0.8138000000000002,
        "llm_top_50_test_accuracy": 0.8560000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9198000431060791,
        "sae_top_1_test_accuracy": 0.705,
        "sae_top_2_test_accuracy": 0.7565999999999999,
        "sae_top_5_test_accuracy": 0.8048,
        "sae_top_10_test_accuracy": 0.8358000000000001,
        "sae_top_20_test_accuracy": 0.8526,
        "sae_top_50_test_accuracy": 0.8842000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.9815,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.847,
        "llm_top_50_test_accuracy": 0.9325000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9755000472068787,
        "sae_top_1_test_accuracy": 0.86,
        "sae_top_2_test_accuracy": 0.868,
        "sae_top_5_test_accuracy": 0.92,
        "sae_top_10_test_accuracy": 0.944,
        "sae_top_20_test_accuracy": 0.955,
        "sae_top_50_test_accuracy": 0.965,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9676,
        "llm_top_1_test_accuracy": 0.6614000000000001,
        "llm_top_2_test_accuracy": 0.7106,
        "llm_top_5_test_accuracy": 0.7636000000000001,
        "llm_top_10_test_accuracy": 0.8012,
        "llm_top_20_test_accuracy": 0.8716000000000002,
        "llm_top_50_test_accuracy": 0.9299999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9690000534057617,
        "sae_top_1_test_accuracy": 0.6032,
        "sae_top_2_test_accuracy": 0.6172,
        "sae_top_5_test_accuracy": 0.7182000000000001,
        "sae_top_10_test_accuracy": 0.8438000000000002,
        "sae_top_20_test_accuracy": 0.8842000000000001,
        "sae_top_50_test_accuracy": 0.9318,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.9427500000000001,
        "llm_top_1_test_accuracy": 0.6659999999999999,
        "llm_top_2_test_accuracy": 0.7690000000000001,
        "llm_top_5_test_accuracy": 0.8247500000000001,
        "llm_top_10_test_accuracy": 0.8665,
        "llm_top_20_test_accuracy": 0.9027499999999999,
        "llm_top_50_test_accuracy": 0.925,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9532500356435776,
        "sae_top_1_test_accuracy": 0.7935,
        "sae_top_2_test_accuracy": 0.85425,
        "sae_top_5_test_accuracy": 0.88475,
        "sae_top_10_test_accuracy": 0.907,
        "sae_top_20_test_accuracy": 0.9185000000000001,
        "sae_top_50_test_accuracy": 0.9239999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9994,
        "llm_top_1_test_accuracy": 0.6437999999999999,
        "llm_top_2_test_accuracy": 0.7807999999999999,
        "llm_top_5_test_accuracy": 0.9164,
        "llm_top_10_test_accuracy": 0.9638,
        "llm_top_20_test_accuracy": 0.9898,
        "llm_top_50_test_accuracy": 0.9987999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9990000247955322,
        "sae_top_1_test_accuracy": 0.8972,
        "sae_top_2_test_accuracy": 0.9390000000000001,
        "sae_top_5_test_accuracy": 0.9832000000000001,
        "sae_top_10_test_accuracy": 0.9882,
        "sae_top_20_test_accuracy": 0.9914000000000002,
        "sae_top_50_test_accuracy": 0.9955999999999999,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "unlearning evaluation results": {
    "eval_type_id": "unlearning",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "wmdp-bio",
        "high_school_us_history",
        "college_computer_science",
        "high_school_geography",
        "human_aging"
      ],
      "intervention_method": "clamp_feature_activation",
      "retain_thresholds": [
        0.001,
        0.01
      ],
      "n_features_list": [
        10,
        20
      ],
      "multipliers": [
        25,
        50,
        100,
        200
      ],
      "dataset_size": 1024,
      "seq_len": 1024,
      "n_batch_loss_added": 50,
      "target_metric": "correct",
      "save_metrics": true,
      "model_name": "google/gemma-2-2b-it",
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16"
    },
    "eval_id": "7a9e7518-333c-44b5-869f-2753cdbffff4",
    "datetime_epoch_millis": 1738611271242,
    "eval_result_metrics": {
      "unlearning": {
        "unlearning_score": 0.059925079345703125
      }
    },
    "eval_result_details": [],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}