{
  "training results for layer 12": {
    "config": {
      "trainer_class": "TrainerTopK",
      "dict_class": "AutoEncoderTopK",
      "lr": 0.0001885618083164127,
      "steps": 4882,
      "seed": 42,
      "activation_dim": 2304,
      "dict_size": 18432,
      "k": 320,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "AutoEncoderTopK",
      "submodule_name": "resid_post_layer_12"
    },
    "final_info": {
      "training_steps": 4882,
      "final_loss": 2490.71484375,
      "layer": 12,
      "dict_size": 18432,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "8a77b97b-0aa7-4019-b88e-1d5fc86e7e35",
    "datetime_epoch_millis": 1738260105364,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.011311560801835012,
        "mean_num_split_features": 1.2380952380952381
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.0003755163349605708,
        "num_absorption": 1,
        "num_probe_true_positives": 2663,
        "num_split_features": 2
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.0006333122229259025,
        "num_absorption": 1,
        "num_probe_true_positives": 1579,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.0012515644555694619,
        "num_absorption": 2,
        "num_probe_true_positives": 1598,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.002476780185758514,
        "num_absorption": 4,
        "num_probe_true_positives": 1615,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.0017543859649122807,
        "num_absorption": 2,
        "num_probe_true_positives": 1140,
        "num_split_features": 1
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.002061855670103093,
        "num_absorption": 2,
        "num_probe_true_positives": 970,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.0005770340450086555,
        "num_absorption": 1,
        "num_probe_true_positives": 1733,
        "num_split_features": 1
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.0026041666666666665,
        "num_absorption": 1,
        "num_probe_true_positives": 384,
        "num_split_features": 2
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.0661764705882353,
        "num_absorption": 45,
        "num_probe_true_positives": 680,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.002730748225013654,
        "num_absorption": 5,
        "num_probe_true_positives": 1831,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 835,
        "num_split_features": 1
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.06350710900473934,
        "num_absorption": 67,
        "num_probe_true_positives": 1055,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.000869187309865276,
        "num_absorption": 2,
        "num_probe_true_positives": 2301,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 1592,
        "num_split_features": 1
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.0010615711252653928,
        "num_absorption": 3,
        "num_probe_true_positives": 2826,
        "num_split_features": 1
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.0718266253869969,
        "num_absorption": 116,
        "num_probe_true_positives": 1615,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.0025188916876574307,
        "num_absorption": 2,
        "num_probe_true_positives": 794,
        "num_split_features": 1
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.0012315270935960591,
        "num_absorption": 1,
        "num_probe_true_positives": 812,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.0014705882352941176,
        "num_absorption": 1,
        "num_probe_true_positives": 680,
        "num_split_features": 2
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.005681818181818182,
        "num_absorption": 1,
        "num_probe_true_positives": 176,
        "num_split_features": 2
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.008733624454148471,
        "num_absorption": 2,
        "num_probe_true_positives": 229,
        "num_split_features": 2
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9909258540372671,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.09130859375
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9917763157894737,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 3.015625,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.77734375,
        "mse": 1.4140625,
        "cossim": 0.9296875
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 139.0,
        "l2_ratio": 0.9296875,
        "relative_reconstruction_bias": 1.0
      },
      "sparsity": {
        "l0": 320.0,
        "l1": 952.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "unlearning evaluation results": {
    "eval_type_id": "unlearning",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "wmdp-bio",
        "high_school_us_history",
        "college_computer_science",
        "high_school_geography",
        "human_aging"
      ],
      "intervention_method": "clamp_feature_activation",
      "retain_thresholds": [
        0.001,
        0.005,
        0.01,
        0.02
      ],
      "n_features_list": [
        10,
        100,
        1000
      ],
      "multipliers": [
        10,
        25,
        50,
        100,
        200
      ],
      "dataset_size": 1024,
      "seq_len": 1024,
      "n_batch_loss_added": 50,
      "target_metric": "correct",
      "save_metrics": true,
      "model_name": "google/gemma-2-2b-it",
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16"
    },
    "eval_id": "934ed73e-60b9-4548-8843-7eb782da85b6",
    "datetime_epoch_millis": 1738206942591,
    "eval_result_metrics": {
      "unlearning": {
        "unlearning_score": 0.0018726587295532227
      }
    },
    "eval_result_details": [],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 4608,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "Custom",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "relu",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "scr and tpp evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "eca00384-2815-4f3b-9a0f-c43a9641dd09",
    "datetime_epoch_millis": 1738262060787,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.1666135003720485,
        "scr_metric_threshold_2": 0.117377050053775,
        "scr_dir2_threshold_2": 0.11814089683053615,
        "scr_dir1_threshold_5": 0.26866832487791314,
        "scr_metric_threshold_5": 0.16687787413342567,
        "scr_dir2_threshold_5": 0.17085293805429583,
        "scr_dir1_threshold_10": 0.29196175141811176,
        "scr_metric_threshold_10": 0.19463704992358133,
        "scr_dir2_threshold_10": 0.19872197015917717,
        "scr_dir1_threshold_20": 0.28666004993807526,
        "scr_metric_threshold_20": 0.24151138199522765,
        "scr_dir2_threshold_20": 0.24088549186443128,
        "scr_dir1_threshold_50": 0.25061022779634345,
        "scr_metric_threshold_50": 0.2917936325253217,
        "scr_dir2_threshold_50": 0.28765504613083787,
        "scr_dir1_threshold_100": 0.20003832117510784,
        "scr_metric_threshold_100": 0.3192698599244855,
        "scr_dir2_threshold_100": 0.3136981258782174,
        "scr_dir1_threshold_500": 0.026976481243512648,
        "scr_metric_threshold_500": 0.23864530477936774,
        "scr_dir2_threshold_500": 0.22937694760332222
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.37500011641541114,
        "scr_metric_threshold_2": 0.017199085925573582,
        "scr_dir2_threshold_2": 0.017199085925573582,
        "scr_dir1_threshold_5": 0.4843747235133985,
        "scr_metric_threshold_5": 0.017199085925573582,
        "scr_dir2_threshold_5": 0.017199085925573582,
        "scr_dir1_threshold_10": 0.5156252764866015,
        "scr_metric_threshold_10": 0.02948408453723957,
        "scr_dir2_threshold_10": 0.02948408453723957,
        "scr_dir1_threshold_20": 0.4375002910385279,
        "scr_metric_threshold_20": 0.05896816907447914,
        "scr_dir2_threshold_20": 0.05896816907447914,
        "scr_dir1_threshold_50": 0.2968751309673376,
        "scr_metric_threshold_50": 0.09582316490947711,
        "scr_dir2_threshold_50": 0.09582316490947711,
        "scr_dir1_threshold_100": 0.3124999417922944,
        "scr_metric_threshold_100": 0.09828013534206324,
        "scr_dir2_threshold_100": 0.09828013534206324,
        "scr_dir1_threshold_500": 0.34374956344220814,
        "scr_metric_threshold_500": 0.027027114104653437,
        "scr_dir2_threshold_500": 0.027027114104653437
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.05825226425346908,
        "scr_metric_threshold_2": 0.1346704699783852,
        "scr_dir2_threshold_2": 0.1346704699783852,
        "scr_dir1_threshold_5": 0.26213605716954286,
        "scr_metric_threshold_5": 0.1719197888799928,
        "scr_dir2_threshold_5": 0.1719197888799928,
        "scr_dir1_threshold_10": 0.26213605716954286,
        "scr_metric_threshold_10": 0.19770776575133966,
        "scr_dir2_threshold_10": 0.19770776575133966,
        "scr_dir1_threshold_20": 0.29126189995330004,
        "scr_metric_threshold_20": 0.26647564714594496,
        "scr_dir2_threshold_20": 0.26647564714594496,
        "scr_dir1_threshold_50": 0.16504817849915482,
        "scr_metric_threshold_50": 0.32951294291889943,
        "scr_dir2_threshold_50": 0.32951294291889943,
        "scr_dir1_threshold_100": -0.20388379291607375,
        "scr_metric_threshold_100": 0.3839541894724186,
        "scr_dir2_threshold_100": 0.3839541894724186,
        "scr_dir1_threshold_500": -0.7475731357776643,
        "scr_metric_threshold_500": 0.07163317420543075,
        "scr_dir2_threshold_500": 0.07163317420543075
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.42857142857142855,
        "scr_metric_threshold_2": 0.03544318161412681,
        "scr_dir2_threshold_2": 0.03544318161412681,
        "scr_dir1_threshold_5": 0.5873013770560047,
        "scr_metric_threshold_5": 0.058227846955206435,
        "scr_dir2_threshold_5": 0.058227846955206435,
        "scr_dir1_threshold_10": 0.6349207400434262,
        "scr_metric_threshold_10": 0.09113926495559606,
        "scr_dir2_threshold_10": 0.09113926495559606,
        "scr_dir1_threshold_20": 0.5714285714285714,
        "scr_metric_threshold_20": 0.10886085576265946,
        "scr_dir2_threshold_20": 0.10886085576265946,
        "scr_dir1_threshold_50": 0.36507925995657375,
        "scr_metric_threshold_50": 0.1518987246267203,
        "scr_dir2_threshold_50": 0.1518987246267203,
        "scr_dir1_threshold_100": 0.42857142857142855,
        "scr_metric_threshold_100": 0.20000012071825551,
        "scr_dir2_threshold_100": 0.20000012071825551,
        "scr_dir1_threshold_500": -0.17460275411200937,
        "scr_metric_threshold_500": 0.05063300880745302,
        "scr_dir2_threshold_500": 0.05063300880745302
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": 0.1171878346939954,
        "scr_metric_threshold_2": 0.041543020933079725,
        "scr_dir2_threshold_2": 0.041543020933079725,
        "scr_dir1_threshold_5": 0.31250011641530273,
        "scr_metric_threshold_5": 0.0890208602099569,
        "scr_dir2_threshold_5": 0.0890208602099569,
        "scr_dir1_threshold_10": 0.20312514551912844,
        "scr_metric_threshold_10": 0.11572710058610643,
        "scr_dir2_threshold_10": 0.11572710058610643,
        "scr_dir1_threshold_20": 0.07031251455191284,
        "scr_metric_threshold_20": 0.14836798243767776,
        "scr_dir2_threshold_20": 0.14836798243767776,
        "scr_dir1_threshold_50": 0.08593777648634401,
        "scr_metric_threshold_50": 0.22551938282841538,
        "scr_dir2_threshold_50": 0.22551938282841538,
        "scr_dir1_threshold_100": 0.06250011641530274,
        "scr_metric_threshold_100": 0.25816026467998676,
        "scr_dir2_threshold_100": 0.25816026467998676,
        "scr_dir1_threshold_500": 0.25,
        "scr_metric_threshold_500": -0.03857552332699319,
        "scr_dir2_threshold_500": -0.03857552332699319
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.04371592886659017,
        "scr_metric_threshold_2": 0.49019597301756745,
        "scr_dir2_threshold_2": 0.49019597301756745,
        "scr_dir1_threshold_5": 0.03278678379574697,
        "scr_metric_threshold_5": 0.6274509483096945,
        "scr_dir2_threshold_5": 0.6274509483096945,
        "scr_dir1_threshold_10": 0.04371592886659017,
        "scr_metric_threshold_10": 0.662745071456604,
        "scr_dir2_threshold_10": 0.662745071456604,
        "scr_dir1_threshold_20": 0.03278678379574697,
        "scr_metric_threshold_20": 0.6823528916778143,
        "scr_dir2_threshold_20": 0.6823528916778143,
        "scr_dir1_threshold_50": 0.09836067709563222,
        "scr_metric_threshold_50": 0.6862744089733254,
        "scr_dir2_threshold_50": 0.6862744089733254,
        "scr_dir1_threshold_100": -0.03278678379574697,
        "scr_metric_threshold_100": 0.6823528916778143,
        "scr_dir2_threshold_100": 0.6823528916778143,
        "scr_dir1_threshold_500": -0.3114752603305745,
        "scr_metric_threshold_500": 0.6823528916778143,
        "scr_dir2_threshold_500": 0.6823528916778143
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.09743586922067994,
        "scr_metric_threshold_2": 0.0927419335456348,
        "scr_dir2_threshold_2": 0.0927419335456348,
        "scr_dir1_threshold_5": 0.16410229135546164,
        "scr_metric_threshold_5": 0.13306447154960044,
        "scr_dir2_threshold_5": 0.13306447154960044,
        "scr_dir1_threshold_10": 0.21538460127700665,
        "scr_metric_threshold_10": 0.1572581866250075,
        "scr_dir2_threshold_10": 0.1572581866250075,
        "scr_dir1_threshold_20": 0.29230760766203984,
        "scr_metric_threshold_20": 0.20967734182539205,
        "scr_dir2_threshold_20": 0.20967734182539205,
        "scr_dir1_threshold_50": 0.29743574695473746,
        "scr_metric_threshold_50": 0.2943548639067476,
        "scr_dir2_threshold_50": 0.2943548639067476,
        "scr_dir1_threshold_100": 0.2666666055336954,
        "scr_metric_threshold_100": 0.3145161329087304,
        "scr_dir2_threshold_100": 0.3145161329087304,
        "scr_dir1_threshold_500": 0.29230760766203984,
        "scr_metric_threshold_500": 0.4112902721865048,
        "scr_dir2_threshold_500": 0.4112902721865048
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.15695053001361284,
        "scr_metric_threshold_2": 0.0714287044746317,
        "scr_dir2_threshold_2": 0.0714287044746317,
        "scr_dir1_threshold_5": 0.2331838049629021,
        "scr_metric_threshold_5": 0.16517854648243513,
        "scr_dir2_threshold_5": 0.16517854648243513,
        "scr_dir1_threshold_10": 0.33632283160029924,
        "scr_metric_threshold_10": 0.17857149509445872,
        "scr_dir2_threshold_10": 0.17857149509445872,
        "scr_dir1_threshold_20": 0.42600884875093514,
        "scr_metric_threshold_20": 0.2857142857142857,
        "scr_dir2_threshold_20": 0.2857142857142857,
        "scr_dir1_threshold_50": 0.5201793805874345,
        "scr_metric_threshold_50": 0.37499990021545476,
        "scr_dir2_threshold_50": 0.37499990021545476,
        "scr_dir1_threshold_100": 0.5650223891627525,
        "scr_metric_threshold_100": 0.415178479959405,
        "scr_dir2_threshold_100": 0.415178479959405,
        "scr_dir1_threshold_500": 0.3273543367994015,
        "scr_metric_threshold_500": 0.4687500083153788,
        "scr_dir2_threshold_500": 0.4687500083153788
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.05579403094120067,
        "scr_metric_threshold_2": 0.05579403094120067,
        "scr_dir2_threshold_2": 0.06190480515528994,
        "scr_dir1_threshold_5": 0.07296144475494565,
        "scr_metric_threshold_5": 0.07296144475494565,
        "scr_dir2_threshold_5": 0.10476195612190681,
        "scr_dir1_threshold_10": 0.1244634303822985,
        "scr_metric_threshold_10": 0.1244634303822985,
        "scr_dir2_threshold_10": 0.1571427922670651,
        "scr_dir1_threshold_20": 0.17167388232356773,
        "scr_metric_threshold_20": 0.17167388232356773,
        "scr_dir2_threshold_20": 0.16666676127719673,
        "scr_dir1_threshold_50": 0.17596567182353345,
        "scr_metric_threshold_50": 0.17596567182353345,
        "scr_dir2_threshold_50": 0.14285698066766273,
        "scr_dir1_threshold_100": 0.20171666463720986,
        "scr_metric_threshold_100": 0.20171666463720986,
        "scr_dir2_threshold_100": 0.1571427922670651,
        "scr_dir1_threshold_500": 0.23605149226469982,
        "scr_metric_threshold_500": 0.23605149226469982,
        "scr_dir2_threshold_500": 0.1619046348563358
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "de1771b1-1543-4d2f-a6a8-28d5dd789f6e",
    "datetime_epoch_millis": 1738262879913,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.9510437500000001,
        "llm_top_1_test_accuracy": 0.6663687500000001,
        "llm_top_2_test_accuracy": 0.7159999999999999,
        "llm_top_5_test_accuracy": 0.78038125,
        "llm_top_10_test_accuracy": 0.8332875,
        "llm_top_20_test_accuracy": 0.87871875,
        "llm_top_50_test_accuracy": 0.9227,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9603125378489494,
        "sae_top_1_test_accuracy": 0.7960375000000001,
        "sae_top_2_test_accuracy": 0.8386062499999999,
        "sae_top_5_test_accuracy": 0.87916875,
        "sae_top_10_test_accuracy": 0.90693125,
        "sae_top_20_test_accuracy": 0.9256937500000001,
        "sae_top_50_test_accuracy": 0.9390124999999999,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9680000424385071,
        "sae_top_1_test_accuracy": 0.8231999999999999,
        "sae_top_2_test_accuracy": 0.8662000000000001,
        "sae_top_5_test_accuracy": 0.9026,
        "sae_top_10_test_accuracy": 0.9198000000000001,
        "sae_top_20_test_accuracy": 0.9338000000000001,
        "sae_top_50_test_accuracy": 0.9538,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9498000000000001,
        "llm_top_1_test_accuracy": 0.6738000000000001,
        "llm_top_2_test_accuracy": 0.7138,
        "llm_top_5_test_accuracy": 0.7634000000000001,
        "llm_top_10_test_accuracy": 0.8099999999999999,
        "llm_top_20_test_accuracy": 0.8714000000000001,
        "llm_top_50_test_accuracy": 0.9036000000000002,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9518000483512878,
        "sae_top_1_test_accuracy": 0.7727999999999999,
        "sae_top_2_test_accuracy": 0.8100000000000002,
        "sae_top_5_test_accuracy": 0.8492000000000001,
        "sae_top_10_test_accuracy": 0.9027999999999998,
        "sae_top_20_test_accuracy": 0.9198000000000001,
        "sae_top_50_test_accuracy": 0.9356,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9103999999999999,
        "llm_top_1_test_accuracy": 0.6928000000000001,
        "llm_top_2_test_accuracy": 0.7366,
        "llm_top_5_test_accuracy": 0.7564,
        "llm_top_10_test_accuracy": 0.8016,
        "llm_top_20_test_accuracy": 0.8508000000000001,
        "llm_top_50_test_accuracy": 0.8962,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9362000346183776,
        "sae_top_1_test_accuracy": 0.7886000000000001,
        "sae_top_2_test_accuracy": 0.8242,
        "sae_top_5_test_accuracy": 0.8573999999999999,
        "sae_top_10_test_accuracy": 0.8821999999999999,
        "sae_top_20_test_accuracy": 0.8986000000000001,
        "sae_top_50_test_accuracy": 0.9019999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.9030000000000001,
        "llm_top_1_test_accuracy": 0.6176,
        "llm_top_2_test_accuracy": 0.6417999999999999,
        "llm_top_5_test_accuracy": 0.6740000000000002,
        "llm_top_10_test_accuracy": 0.7554000000000001,
        "llm_top_20_test_accuracy": 0.8074,
        "llm_top_50_test_accuracy": 0.8564,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9218000411987305,
        "sae_top_1_test_accuracy": 0.7404000000000001,
        "sae_top_2_test_accuracy": 0.7754,
        "sae_top_5_test_accuracy": 0.8224,
        "sae_top_10_test_accuracy": 0.8291999999999999,
        "sae_top_20_test_accuracy": 0.8658000000000001,
        "sae_top_50_test_accuracy": 0.8785999999999999,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.981,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.847,
        "llm_top_50_test_accuracy": 0.9325000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9785000383853912,
        "sae_top_1_test_accuracy": 0.9,
        "sae_top_2_test_accuracy": 0.919,
        "sae_top_5_test_accuracy": 0.935,
        "sae_top_10_test_accuracy": 0.949,
        "sae_top_20_test_accuracy": 0.966,
        "sae_top_50_test_accuracy": 0.972,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9678000000000001,
        "llm_top_1_test_accuracy": 0.6456,
        "llm_top_2_test_accuracy": 0.6936000000000001,
        "llm_top_5_test_accuracy": 0.768,
        "llm_top_10_test_accuracy": 0.7974,
        "llm_top_20_test_accuracy": 0.8684,
        "llm_top_50_test_accuracy": 0.9284000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9736000299453735,
        "sae_top_1_test_accuracy": 0.6056,
        "sae_top_2_test_accuracy": 0.7094,
        "sae_top_5_test_accuracy": 0.8082,
        "sae_top_10_test_accuracy": 0.8699999999999999,
        "sae_top_20_test_accuracy": 0.9032,
        "sae_top_50_test_accuracy": 0.9376,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.93775,
        "llm_top_1_test_accuracy": 0.65875,
        "llm_top_2_test_accuracy": 0.738,
        "llm_top_5_test_accuracy": 0.8182499999999999,
        "llm_top_10_test_accuracy": 0.8775000000000001,
        "llm_top_20_test_accuracy": 0.89675,
        "llm_top_50_test_accuracy": 0.9285,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9530000388622284,
        "sae_top_1_test_accuracy": 0.7965,
        "sae_top_2_test_accuracy": 0.86225,
        "sae_top_5_test_accuracy": 0.89575,
        "sae_top_10_test_accuracy": 0.91225,
        "sae_top_20_test_accuracy": 0.9247500000000001,
        "sae_top_50_test_accuracy": 0.9345,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.999,
        "llm_top_1_test_accuracy": 0.7282,
        "llm_top_2_test_accuracy": 0.7886,
        "llm_top_5_test_accuracy": 0.9057999999999999,
        "llm_top_10_test_accuracy": 0.9648,
        "llm_top_20_test_accuracy": 0.9917999999999999,
        "llm_top_50_test_accuracy": 0.9975999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9996000289916992,
        "sae_top_1_test_accuracy": 0.9411999999999999,
        "sae_top_2_test_accuracy": 0.9423999999999999,
        "sae_top_5_test_accuracy": 0.9628,
        "sae_top_10_test_accuracy": 0.9902,
        "sae_top_20_test_accuracy": 0.9936,
        "sae_top_50_test_accuracy": 0.998,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}