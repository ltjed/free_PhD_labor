{
  "training results for layer 12": {
    "config": {
      "trainer_class": "TrainerTopK",
      "dict_class": "AutoEncoderTopK",
      "lr": 0.0001885618083164127,
      "steps": 2441,
      "seed": 42,
      "activation_dim": 2304,
      "dict_size": 18432,
      "k": 120,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "AutoEncoderTopK",
      "submodule_name": "resid_post_layer_12",
      "ortho_weight": 0.005
    },
    "final_info": {
      "training_steps": 2441,
      "final_loss": 3445.33984375,
      "layer": 12,
      "dict_size": 18432,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "cee1da00-637a-4179-9dfe-ce7a0215da52",
    "datetime_epoch_millis": 1738296012669,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.03789432955398956,
        "mean_num_split_features": 1.25
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.003755163349605708,
        "num_absorption": 10,
        "num_probe_true_positives": 2663,
        "num_split_features": 1
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.008866371120962635,
        "num_absorption": 14,
        "num_probe_true_positives": 1579,
        "num_split_features": 3
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.0007189072609633358,
        "num_absorption": 2,
        "num_probe_true_positives": 2782,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.015018773466833541,
        "num_absorption": 24,
        "num_probe_true_positives": 1598,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.009907120743034056,
        "num_absorption": 16,
        "num_probe_true_positives": 1615,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.004152823920265781,
        "num_absorption": 5,
        "num_probe_true_positives": 1204,
        "num_split_features": 2
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.0061403508771929825,
        "num_absorption": 7,
        "num_probe_true_positives": 1140,
        "num_split_features": 1
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.03402061855670103,
        "num_absorption": 33,
        "num_probe_true_positives": 970,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.0051933064050779,
        "num_absorption": 9,
        "num_probe_true_positives": 1733,
        "num_split_features": 1
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.013020833333333334,
        "num_absorption": 5,
        "num_probe_true_positives": 384,
        "num_split_features": 1
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.0029411764705882353,
        "num_absorption": 2,
        "num_probe_true_positives": 680,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.1947840260798696,
        "num_absorption": 239,
        "num_probe_true_positives": 1227,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.005461496450027308,
        "num_absorption": 10,
        "num_probe_true_positives": 1831,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.003592814371257485,
        "num_absorption": 3,
        "num_probe_true_positives": 835,
        "num_split_features": 2
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.23127962085308057,
        "num_absorption": 244,
        "num_probe_true_positives": 1055,
        "num_split_features": 1
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.1933941764450239,
        "num_absorption": 445,
        "num_probe_true_positives": 2301,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.0018844221105527637,
        "num_absorption": 3,
        "num_probe_true_positives": 1592,
        "num_split_features": 2
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.11181882519462137,
        "num_absorption": 316,
        "num_probe_true_positives": 2826,
        "num_split_features": 2
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.0018575851393188853,
        "num_absorption": 3,
        "num_probe_true_positives": 1615,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.030226700251889168,
        "num_absorption": 24,
        "num_probe_true_positives": 794,
        "num_split_features": 1
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.0024630541871921183,
        "num_absorption": 2,
        "num_probe_true_positives": 812,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.013235294117647059,
        "num_absorption": 9,
        "num_probe_true_positives": 680,
        "num_split_features": 1
      },
      {
        "first_letter": "y",
        "absorption_rate": 0.011363636363636364,
        "num_absorption": 2,
        "num_probe_true_positives": 176,
        "num_split_features": 1
      },
      {
        "first_letter": "z",
        "absorption_rate": 0.004366812227074236,
        "num_absorption": 1,
        "num_probe_true_positives": 229,
        "num_split_features": 1
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9818517080745341,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.1826171875
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9819078947368421,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 3.109375,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.6953125,
        "mse": 1.9296875,
        "cossim": 0.90625
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 136.0,
        "l2_ratio": 0.90625,
        "relative_reconstruction_bias": 1.0
      },
      "sparsity": {
        "l0": 119.99999237060547,
        "l1": 580.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "76935ad0-d108-438c-b567-0cde5b50610a",
    "datetime_epoch_millis": 1738296671358,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.22038188105368703,
        "scr_metric_threshold_2": 0.07504716317331239,
        "scr_dir2_threshold_2": 0.07390780220455728,
        "scr_dir1_threshold_5": 0.22866113982168484,
        "scr_metric_threshold_5": 0.13254656561669154,
        "scr_dir2_threshold_5": 0.13336916902961582,
        "scr_dir1_threshold_10": 0.21943636878647407,
        "scr_metric_threshold_10": 0.1997383857129953,
        "scr_dir2_threshold_10": 0.20383096290619168,
        "scr_dir1_threshold_20": 0.21513436539907424,
        "scr_metric_threshold_20": 0.2565393422860719,
        "scr_dir2_threshold_20": 0.25991148344673387,
        "scr_dir1_threshold_50": 0.18805344178580097,
        "scr_metric_threshold_50": 0.30732916617517003,
        "scr_dir2_threshold_50": 0.31111264277013617,
        "scr_dir1_threshold_100": 0.11419431244408287,
        "scr_metric_threshold_100": 0.3162296310138861,
        "scr_dir2_threshold_100": 0.3216225286713394,
        "scr_dir1_threshold_500": -0.10092321756118683,
        "scr_metric_threshold_500": 0.24447584085152543,
        "scr_dir2_threshold_500": 0.2606928825653586
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.45312510186348476,
        "scr_metric_threshold_2": 0.017199085925573582,
        "scr_dir2_threshold_2": 0.017199085925573582,
        "scr_dir1_threshold_5": 0.42187454889028175,
        "scr_metric_threshold_5": 0.02948408453723957,
        "scr_dir2_threshold_5": 0.02948408453723957,
        "scr_dir1_threshold_10": 0.4062497380653249,
        "scr_metric_threshold_10": 0.04914014089539928,
        "scr_dir2_threshold_10": 0.04914014089539928,
        "scr_dir1_threshold_20": 0.42187454889028175,
        "scr_metric_threshold_20": 0.0638821099396514,
        "scr_dir2_threshold_20": 0.0638821099396514,
        "scr_dir1_threshold_50": 0.24999976716917766,
        "scr_metric_threshold_50": 0.09582316490947711,
        "scr_dir2_threshold_50": 0.09582316490947711,
        "scr_dir1_threshold_100": 0.3124999417922944,
        "scr_metric_threshold_100": 0.12530710299798134,
        "scr_dir2_threshold_100": 0.12530710299798134,
        "scr_dir1_threshold_500": 0.23437495634422081,
        "scr_metric_threshold_500": -0.019655909909424386,
        "scr_dir2_threshold_500": -0.019655909909424386
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.24271824996108338,
        "scr_metric_threshold_2": 0.12320912794812448,
        "scr_dir2_threshold_2": 0.12320912794812448,
        "scr_dir1_threshold_5": 0.3106797071617595,
        "scr_metric_threshold_5": 0.16905449606916736,
        "scr_dir2_threshold_5": 0.16905449606916736,
        "scr_dir1_threshold_10": 0.30097051421455245,
        "scr_metric_threshold_10": 0.20630364418381594,
        "scr_dir2_threshold_10": 0.20630364418381594,
        "scr_dir1_threshold_20": 0.22330102143857855,
        "scr_metric_threshold_20": 0.27507169636538026,
        "scr_dir2_threshold_20": 0.27507169636538026,
        "scr_dir1_threshold_50": 0.1747573714463619,
        "scr_metric_threshold_50": 0.34957016338163643,
        "scr_dir2_threshold_50": 0.34957016338163643,
        "scr_dir1_threshold_100": 0.12621372145414522,
        "scr_metric_threshold_100": 0.12607442075894992,
        "scr_dir2_threshold_100": 0.12607442075894992,
        "scr_dir1_threshold_500": -0.42718481435465233,
        "scr_metric_threshold_500": 0.1518623976302968,
        "scr_dir2_threshold_500": 0.1518623976302968
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.6031751287885597,
        "scr_metric_threshold_2": 0.022784816238899015,
        "scr_dir2_threshold_2": 0.022784816238899015,
        "scr_dir1_threshold_5": 0.6349207400434262,
        "scr_metric_threshold_5": 0.05063300880745302,
        "scr_dir2_threshold_5": 0.05063300880745302,
        "scr_dir1_threshold_10": 0.5714285714285714,
        "scr_metric_threshold_10": 0.09367087767151386,
        "scr_dir2_threshold_10": 0.09367087767151386,
        "scr_dir1_threshold_20": 0.49206359718628334,
        "scr_metric_threshold_20": 0.1265822956719035,
        "scr_dir2_threshold_20": 0.1265822956719035,
        "scr_dir1_threshold_50": 0.4603179859314168,
        "scr_metric_threshold_50": 0.1645570900019481,
        "scr_dir2_threshold_50": 0.1645570900019481,
        "scr_dir1_threshold_100": -0.19047555973944266,
        "scr_metric_threshold_100": 0.22531654967307232,
        "scr_dir2_threshold_100": 0.22531654967307232,
        "scr_dir1_threshold_500": -1.5238092084411499,
        "scr_metric_threshold_500": 0.10632924304674166,
        "scr_dir2_threshold_500": 0.10632924304674166
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": 0.2578123981366101,
        "scr_metric_threshold_2": 0.1246292396676148,
        "scr_dir2_threshold_2": 0.1246292396676148,
        "scr_dir1_threshold_5": 0.10937497089617432,
        "scr_metric_threshold_5": 0.15727012151918615,
        "scr_dir2_threshold_5": 0.15727012151918615,
        "scr_dir1_threshold_10": 0.0,
        "scr_metric_threshold_10": 0.21068260227148516,
        "scr_dir2_threshold_10": 0.21068260227148516,
        "scr_dir1_threshold_20": -0.015624796273220196,
        "scr_metric_threshold_20": 0.2789318635807144,
        "scr_dir2_threshold_20": 0.2789318635807144,
        "scr_dir1_threshold_50": -0.062499650754091765,
        "scr_metric_threshold_50": 0.33531166507072435,
        "scr_dir2_threshold_50": 0.33531166507072435,
        "scr_dir1_threshold_100": -0.11718736903278441,
        "scr_metric_threshold_100": 0.4065282471176645,
        "scr_dir2_threshold_100": 0.4065282471176645,
        "scr_dir1_threshold_500": 0.2890624563442615,
        "scr_metric_threshold_500": -0.008901962213132759,
        "scr_dir2_threshold_500": -0.008901962213132759
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.03278678379574697,
        "scr_metric_threshold_2": 0.09411781755419522,
        "scr_dir2_threshold_2": 0.09411781755419522,
        "scr_dir1_threshold_5": 0.04371592886659017,
        "scr_metric_threshold_5": 0.2823529851752762,
        "scr_dir2_threshold_5": 0.2823529851752762,
        "scr_dir1_threshold_10": -0.021857964433295084,
        "scr_metric_threshold_10": 0.4980392413522444,
        "scr_dir2_threshold_10": 0.4980392413522444,
        "scr_dir1_threshold_20": -0.06557389329988525,
        "scr_metric_threshold_20": 0.6274509483096945,
        "scr_dir2_threshold_20": 0.6274509483096945,
        "scr_dir1_threshold_50": -0.027322374114521025,
        "scr_metric_threshold_50": 0.6705881060476262,
        "scr_dir2_threshold_50": 0.6705881060476262,
        "scr_dir1_threshold_100": 0.00546440968122594,
        "scr_metric_threshold_100": 0.6980391946035135,
        "scr_dir2_threshold_100": 0.6980391946035135,
        "scr_dir1_threshold_500": -0.04371592886659017,
        "scr_metric_threshold_500": 0.7294118004549119,
        "scr_dir2_threshold_500": 0.7294118004549119
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.0410254200064373,
        "scr_metric_threshold_2": 0.06854845881151235,
        "scr_dir2_threshold_2": 0.06854845881151235,
        "scr_dir1_threshold_5": 0.12307687134902433,
        "scr_metric_threshold_5": 0.0927419335456348,
        "scr_dir2_threshold_5": 0.0927419335456348,
        "scr_dir1_threshold_10": 0.17948701489841076,
        "scr_metric_threshold_10": 0.1370969176230247,
        "scr_dir2_threshold_10": 0.1370969176230247,
        "scr_dir1_threshold_20": 0.23076901915509954,
        "scr_metric_threshold_20": 0.18951607282340924,
        "scr_dir2_threshold_20": 0.18951607282340924,
        "scr_dir1_threshold_50": 0.2358974641126534,
        "scr_metric_threshold_50": 0.24596767409721804,
        "scr_dir2_threshold_50": 0.24596767409721804,
        "scr_dir1_threshold_100": 0.27179474482639304,
        "scr_metric_threshold_100": 0.3467742594484168,
        "scr_dir2_threshold_100": 0.3467742594484168,
        "scr_dir1_threshold_500": 0.24615374269804866,
        "scr_metric_threshold_500": 0.2943548639067476,
        "scr_dir2_threshold_500": 0.2943548639067476
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.08520176975018703,
        "scr_metric_threshold_2": 0.10267856311319266,
        "scr_dir2_threshold_2": 0.10267856311319266,
        "scr_dir1_threshold_5": 0.12556053092505612,
        "scr_metric_threshold_5": 0.21875007483840891,
        "scr_dir2_threshold_5": 0.21875007483840891,
        "scr_dir1_threshold_10": 0.237668052363351,
        "scr_metric_threshold_10": 0.3214286379516016,
        "scr_dir2_threshold_10": 0.3214286379516016,
        "scr_dir1_threshold_20": 0.31838557471308915,
        "scr_metric_threshold_20": 0.37499990021545476,
        "scr_dir2_threshold_20": 0.37499990021545476,
        "scr_dir1_threshold_50": 0.3273543367994015,
        "scr_metric_threshold_50": 0.4508928321967208,
        "scr_dir2_threshold_50": 0.4508928321967208,
        "scr_dir1_threshold_100": 0.37219734537471943,
        "scr_metric_threshold_100": 0.4687500083153788,
        "scr_dir2_threshold_100": 0.4687500083153788,
        "scr_dir1_threshold_500": 0.2331838049629021,
        "scr_metric_threshold_500": 0.5178570430725976,
        "scr_dir2_threshold_500": 0.5178570430725976
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.047210196127387125,
        "scr_metric_threshold_2": 0.047210196127387125,
        "scr_dir2_threshold_2": 0.03809530837734615,
        "scr_dir1_threshold_5": 0.060085820441166386,
        "scr_metric_threshold_5": 0.060085820441166386,
        "scr_dir2_threshold_5": 0.06666664774456064,
        "scr_dir1_threshold_10": 0.08154502375487709,
        "scr_metric_threshold_10": 0.08154502375487709,
        "scr_dir2_threshold_10": 0.11428564130044823,
        "scr_dir1_threshold_20": 0.11587985138236706,
        "scr_metric_threshold_20": 0.11587985138236706,
        "scr_dir2_threshold_20": 0.14285698066766273,
        "scr_dir1_threshold_50": 0.1459226336960092,
        "scr_metric_threshold_50": 0.1459226336960092,
        "scr_dir2_threshold_50": 0.17619044645573817,
        "scr_dir1_threshold_100": 0.13304726519611204,
        "scr_metric_threshold_100": 0.13304726519611204,
        "scr_dir2_threshold_100": 0.17619044645573817,
        "scr_dir1_threshold_500": 0.18454925082346488,
        "scr_metric_threshold_500": 0.18454925082346488,
        "scr_dir2_threshold_500": 0.3142855845341302
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "tpp evaluations results": {
    "eval_type_id": "tpp",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": false,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "3575f232-6969-485c-9ea0-9153c65b83d1",
    "datetime_epoch_millis": 1738296800124,
    "eval_result_metrics": {
      "tpp_metrics": {
        "tpp_threshold_2_total_metric": 0.003475002944469452,
        "tpp_threshold_2_intended_diff_only": 0.006099998950958252,
        "tpp_threshold_2_unintended_diff_only": 0.0026249960064888,
        "tpp_threshold_5_total_metric": 0.007400007545948028,
        "tpp_threshold_5_intended_diff_only": 0.01050000786781311,
        "tpp_threshold_5_unintended_diff_only": 0.003100000321865082,
        "tpp_threshold_10_total_metric": 0.00862499177455902,
        "tpp_threshold_10_intended_diff_only": 0.013499993085861205,
        "tpp_threshold_10_unintended_diff_only": 0.004875001311302186,
        "tpp_threshold_20_total_metric": 0.02082499861717224,
        "tpp_threshold_20_intended_diff_only": 0.027200001478195193,
        "tpp_threshold_20_unintended_diff_only": 0.006375002861022949,
        "tpp_threshold_50_total_metric": 0.05612500607967377,
        "tpp_threshold_50_intended_diff_only": 0.06300000548362732,
        "tpp_threshold_50_unintended_diff_only": 0.006874999403953553,
        "tpp_threshold_100_total_metric": 0.11227499097585678,
        "tpp_threshold_100_intended_diff_only": 0.12019999623298645,
        "tpp_threshold_100_unintended_diff_only": 0.007925005257129669,
        "tpp_threshold_500_total_metric": 0.3581750124692917,
        "tpp_threshold_500_intended_diff_only": 0.37170001268386843,
        "tpp_threshold_500_unintended_diff_only": 0.013525000214576722
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_tpp_results",
        "tpp_threshold_2_total_metric": 0.005199995636940003,
        "tpp_threshold_2_intended_diff_only": 0.0075999975204467775,
        "tpp_threshold_2_unintended_diff_only": 0.002400001883506775,
        "tpp_threshold_5_total_metric": 0.0073000043630599976,
        "tpp_threshold_5_intended_diff_only": 0.0096000075340271,
        "tpp_threshold_5_unintended_diff_only": 0.002300003170967102,
        "tpp_threshold_10_total_metric": 0.010250002145767212,
        "tpp_threshold_10_intended_diff_only": 0.013400006294250488,
        "tpp_threshold_10_unintended_diff_only": 0.0031500041484832765,
        "tpp_threshold_20_total_metric": 0.0228500097990036,
        "tpp_threshold_20_intended_diff_only": 0.02660001516342163,
        "tpp_threshold_20_unintended_diff_only": 0.00375000536441803,
        "tpp_threshold_50_total_metric": 0.062200006842613224,
        "tpp_threshold_50_intended_diff_only": 0.0662000060081482,
        "tpp_threshold_50_unintended_diff_only": 0.0039999991655349735,
        "tpp_threshold_100_total_metric": 0.12149998545646667,
        "tpp_threshold_100_intended_diff_only": 0.12680000066757202,
        "tpp_threshold_100_unintended_diff_only": 0.005300015211105347,
        "tpp_threshold_500_total_metric": 0.41890001893043516,
        "tpp_threshold_500_intended_diff_only": 0.42700002193450926,
        "tpp_threshold_500_unintended_diff_only": 0.008100003004074097
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_tpp_results",
        "tpp_threshold_2_total_metric": 0.001750010251998901,
        "tpp_threshold_2_intended_diff_only": 0.004600000381469726,
        "tpp_threshold_2_unintended_diff_only": 0.0028499901294708253,
        "tpp_threshold_5_total_metric": 0.007500010728836059,
        "tpp_threshold_5_intended_diff_only": 0.01140000820159912,
        "tpp_threshold_5_unintended_diff_only": 0.0038999974727630614,
        "tpp_threshold_10_total_metric": 0.006999981403350829,
        "tpp_threshold_10_intended_diff_only": 0.013599979877471923,
        "tpp_threshold_10_unintended_diff_only": 0.006599998474121094,
        "tpp_threshold_20_total_metric": 0.018799987435340882,
        "tpp_threshold_20_intended_diff_only": 0.02779998779296875,
        "tpp_threshold_20_unintended_diff_only": 0.00900000035762787,
        "tpp_threshold_50_total_metric": 0.050050005316734314,
        "tpp_threshold_50_intended_diff_only": 0.059800004959106444,
        "tpp_threshold_50_unintended_diff_only": 0.009749999642372132,
        "tpp_threshold_100_total_metric": 0.10304999649524689,
        "tpp_threshold_100_intended_diff_only": 0.11359999179840088,
        "tpp_threshold_100_unintended_diff_only": 0.010549995303153991,
        "tpp_threshold_500_total_metric": 0.2974500060081482,
        "tpp_threshold_500_intended_diff_only": 0.31640000343322755,
        "tpp_threshold_500_unintended_diff_only": 0.018949997425079346
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "449d047c-cbb2-4497-b058-16e7b93bddcc",
    "datetime_epoch_millis": 1738297165592,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.95121875,
        "llm_top_1_test_accuracy": 0.6673875,
        "llm_top_2_test_accuracy": 0.7215375,
        "llm_top_5_test_accuracy": 0.779725,
        "llm_top_10_test_accuracy": 0.8331375,
        "llm_top_20_test_accuracy": 0.878325,
        "llm_top_50_test_accuracy": 0.9221374999999999,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9558687932789326,
        "sae_top_1_test_accuracy": 0.7895312499999999,
        "sae_top_2_test_accuracy": 0.8327625,
        "sae_top_5_test_accuracy": 0.88275625,
        "sae_top_10_test_accuracy": 0.90985625,
        "sae_top_20_test_accuracy": 0.9256937500000001,
        "sae_top_50_test_accuracy": 0.9417937500000001,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.964400053024292,
        "sae_top_1_test_accuracy": 0.818,
        "sae_top_2_test_accuracy": 0.8276,
        "sae_top_5_test_accuracy": 0.8714000000000001,
        "sae_top_10_test_accuracy": 0.9082000000000001,
        "sae_top_20_test_accuracy": 0.9436,
        "sae_top_50_test_accuracy": 0.9618,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9468,
        "llm_top_1_test_accuracy": 0.6752,
        "llm_top_2_test_accuracy": 0.7150000000000001,
        "llm_top_5_test_accuracy": 0.7642,
        "llm_top_10_test_accuracy": 0.8094000000000001,
        "llm_top_20_test_accuracy": 0.8638,
        "llm_top_50_test_accuracy": 0.9056,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9476000308990479,
        "sae_top_1_test_accuracy": 0.7931999999999999,
        "sae_top_2_test_accuracy": 0.8192,
        "sae_top_5_test_accuracy": 0.8737999999999999,
        "sae_top_10_test_accuracy": 0.9086000000000001,
        "sae_top_20_test_accuracy": 0.9188000000000001,
        "sae_top_50_test_accuracy": 0.9364000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.9128000000000001,
        "llm_top_1_test_accuracy": 0.6883999999999999,
        "llm_top_2_test_accuracy": 0.7384000000000001,
        "llm_top_5_test_accuracy": 0.7598,
        "llm_top_10_test_accuracy": 0.8074,
        "llm_top_20_test_accuracy": 0.8540000000000001,
        "llm_top_50_test_accuracy": 0.889,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9314000368118286,
        "sae_top_1_test_accuracy": 0.8162,
        "sae_top_2_test_accuracy": 0.8315999999999999,
        "sae_top_5_test_accuracy": 0.8790000000000001,
        "sae_top_10_test_accuracy": 0.8934000000000001,
        "sae_top_20_test_accuracy": 0.9016,
        "sae_top_50_test_accuracy": 0.9158,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.9042,
        "llm_top_1_test_accuracy": 0.603,
        "llm_top_2_test_accuracy": 0.6569999999999998,
        "llm_top_5_test_accuracy": 0.6774,
        "llm_top_10_test_accuracy": 0.7524,
        "llm_top_20_test_accuracy": 0.8131999999999999,
        "llm_top_50_test_accuracy": 0.8625999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9160000443458557,
        "sae_top_1_test_accuracy": 0.7074,
        "sae_top_2_test_accuracy": 0.7664000000000001,
        "sae_top_5_test_accuracy": 0.8109999999999999,
        "sae_top_10_test_accuracy": 0.8325999999999999,
        "sae_top_20_test_accuracy": 0.859,
        "sae_top_50_test_accuracy": 0.8844000000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.9815,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.847,
        "llm_top_50_test_accuracy": 0.933,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9735000431537628,
        "sae_top_1_test_accuracy": 0.853,
        "sae_top_2_test_accuracy": 0.916,
        "sae_top_5_test_accuracy": 0.937,
        "sae_top_10_test_accuracy": 0.946,
        "sae_top_20_test_accuracy": 0.957,
        "sae_top_50_test_accuracy": 0.963,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9672000000000001,
        "llm_top_1_test_accuracy": 0.6644,
        "llm_top_2_test_accuracy": 0.6996,
        "llm_top_5_test_accuracy": 0.7538,
        "llm_top_10_test_accuracy": 0.8022,
        "llm_top_20_test_accuracy": 0.8694,
        "llm_top_50_test_accuracy": 0.9269999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9660000443458557,
        "sae_top_1_test_accuracy": 0.6576000000000001,
        "sae_top_2_test_accuracy": 0.6878,
        "sae_top_5_test_accuracy": 0.8220000000000001,
        "sae_top_10_test_accuracy": 0.8820000000000002,
        "sae_top_20_test_accuracy": 0.9122,
        "sae_top_50_test_accuracy": 0.9416,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.93825,
        "llm_top_1_test_accuracy": 0.6695,
        "llm_top_2_test_accuracy": 0.7725000000000001,
        "llm_top_5_test_accuracy": 0.8200000000000001,
        "llm_top_10_test_accuracy": 0.8694999999999999,
        "llm_top_20_test_accuracy": 0.8939999999999999,
        "llm_top_50_test_accuracy": 0.9235,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9492500424385071,
        "sae_top_1_test_accuracy": 0.76425,
        "sae_top_2_test_accuracy": 0.8545,
        "sae_top_5_test_accuracy": 0.87725,
        "sae_top_10_test_accuracy": 0.91325,
        "sae_top_20_test_accuracy": 0.9177500000000001,
        "sae_top_50_test_accuracy": 0.9337500000000001,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9994,
        "llm_top_1_test_accuracy": 0.7244,
        "llm_top_2_test_accuracy": 0.7742000000000001,
        "llm_top_5_test_accuracy": 0.9054,
        "llm_top_10_test_accuracy": 0.9646000000000001,
        "llm_top_20_test_accuracy": 0.9890000000000001,
        "llm_top_50_test_accuracy": 0.998,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9988000512123107,
        "sae_top_1_test_accuracy": 0.9065999999999999,
        "sae_top_2_test_accuracy": 0.959,
        "sae_top_5_test_accuracy": 0.9906,
        "sae_top_10_test_accuracy": 0.9948,
        "sae_top_20_test_accuracy": 0.9956000000000002,
        "sae_top_50_test_accuracy": 0.9976,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "unlearning evaluation results": {
    "eval_type_id": "unlearning",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "wmdp-bio",
        "high_school_us_history",
        "college_computer_science",
        "high_school_geography",
        "human_aging"
      ],
      "intervention_method": "clamp_feature_activation",
      "retain_thresholds": [
        0.001,
        0.01
      ],
      "n_features_list": [
        10,
        20
      ],
      "multipliers": [
        25,
        50,
        100,
        200
      ],
      "dataset_size": 1024,
      "seq_len": 1024,
      "n_batch_loss_added": 50,
      "target_metric": "correct",
      "save_metrics": true,
      "model_name": "google/gemma-2-2b-it",
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16"
    },
    "eval_id": "7909b23b-cddf-4a18-b05e-4846b759d61b",
    "datetime_epoch_millis": 1738297304640,
    "eval_result_metrics": {
      "unlearning": {
        "unlearning_score": 0.024344563484191895
      }
    },
    "eval_result_details": [],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}