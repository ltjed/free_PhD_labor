{
  "training results for layer 12": {
    "config": {
      "trainer_class": "TrainerTopK",
      "dict_class": "AutoEncoderTopK",
      "lr": 0.0001885618083164127,
      "steps": 2441,
      "seed": 42,
      "activation_dim": 2304,
      "dict_size": 18432,
      "k": 120,
      "device": "cuda",
      "layer": 12,
      "lm_name": "google/gemma-2-2b",
      "wandb_name": "AutoEncoderTopK",
      "submodule_name": "resid_post_layer_12",
      "ortho_weight": 0.01
    },
    "final_info": {
      "training_steps": 2441,
      "final_loss": 3459.066650390625,
      "layer": 12,
      "dict_size": 18432,
      "learning_rate": 0.0003,
      "sparsity_penalty": 0.04
    }
  },
  "absorption evaluation results": {
    "eval_type_id": "absorption_first_letter",
    "eval_config": {
      "model_name": "google/gemma-2-2b",
      "random_seed": 42,
      "f1_jump_threshold": 0.03,
      "max_k_value": 10,
      "prompt_template": "{word} has the first letter:",
      "prompt_token_pos": -6,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "k_sparse_probe_l1_decay": 0.01,
      "k_sparse_probe_batch_size": 4096,
      "k_sparse_probe_num_epochs": 50
    },
    "eval_id": "bc766643-9355-44c3-8057-f62e739127c1",
    "datetime_epoch_millis": 1738293697885,
    "eval_result_metrics": {
      "mean": {
        "mean_absorption_score": 0.033550338002993514,
        "mean_num_split_features": 1.3478260869565217
      }
    },
    "eval_result_details": [
      {
        "first_letter": "a",
        "absorption_rate": 0.008261359369132557,
        "num_absorption": 22,
        "num_probe_true_positives": 2663,
        "num_split_features": 1
      },
      {
        "first_letter": "b",
        "absorption_rate": 0.005699810006333122,
        "num_absorption": 9,
        "num_probe_true_positives": 1579,
        "num_split_features": 2
      },
      {
        "first_letter": "c",
        "absorption_rate": 0.004313443565780014,
        "num_absorption": 12,
        "num_probe_true_positives": 2782,
        "num_split_features": 1
      },
      {
        "first_letter": "d",
        "absorption_rate": 0.017521902377972465,
        "num_absorption": 28,
        "num_probe_true_positives": 1598,
        "num_split_features": 1
      },
      {
        "first_letter": "e",
        "absorption_rate": 0.0086687306501548,
        "num_absorption": 14,
        "num_probe_true_positives": 1615,
        "num_split_features": 1
      },
      {
        "first_letter": "f",
        "absorption_rate": 0.0016611295681063123,
        "num_absorption": 2,
        "num_probe_true_positives": 1204,
        "num_split_features": 1
      },
      {
        "first_letter": "g",
        "absorption_rate": 0.0035087719298245615,
        "num_absorption": 4,
        "num_probe_true_positives": 1140,
        "num_split_features": 2
      },
      {
        "first_letter": "h",
        "absorption_rate": 0.0443298969072165,
        "num_absorption": 43,
        "num_probe_true_positives": 970,
        "num_split_features": 1
      },
      {
        "first_letter": "i",
        "absorption_rate": 0.0028851702250432777,
        "num_absorption": 5,
        "num_probe_true_positives": 1733,
        "num_split_features": 1
      },
      {
        "first_letter": "j",
        "absorption_rate": 0.010416666666666666,
        "num_absorption": 4,
        "num_probe_true_positives": 384,
        "num_split_features": 2
      },
      {
        "first_letter": "k",
        "absorption_rate": 0.0014705882352941176,
        "num_absorption": 1,
        "num_probe_true_positives": 680,
        "num_split_features": 1
      },
      {
        "first_letter": "l",
        "absorption_rate": 0.19967400162999185,
        "num_absorption": 245,
        "num_probe_true_positives": 1227,
        "num_split_features": 1
      },
      {
        "first_letter": "m",
        "absorption_rate": 0.008738394320043691,
        "num_absorption": 16,
        "num_probe_true_positives": 1831,
        "num_split_features": 1
      },
      {
        "first_letter": "n",
        "absorption_rate": 0.0,
        "num_absorption": 0,
        "num_probe_true_positives": 835,
        "num_split_features": 2
      },
      {
        "first_letter": "o",
        "absorption_rate": 0.22085308056872038,
        "num_absorption": 233,
        "num_probe_true_positives": 1055,
        "num_split_features": 2
      },
      {
        "first_letter": "p",
        "absorption_rate": 0.1016949152542373,
        "num_absorption": 234,
        "num_probe_true_positives": 2301,
        "num_split_features": 1
      },
      {
        "first_letter": "q",
        "absorption_rate": 0.005813953488372093,
        "num_absorption": 1,
        "num_probe_true_positives": 172,
        "num_split_features": 1
      },
      {
        "first_letter": "r",
        "absorption_rate": 0.02763819095477387,
        "num_absorption": 44,
        "num_probe_true_positives": 1592,
        "num_split_features": 2
      },
      {
        "first_letter": "s",
        "absorption_rate": 0.07183297947629158,
        "num_absorption": 203,
        "num_probe_true_positives": 2826,
        "num_split_features": 1
      },
      {
        "first_letter": "t",
        "absorption_rate": 0.006811145510835914,
        "num_absorption": 11,
        "num_probe_true_positives": 1615,
        "num_split_features": 1
      },
      {
        "first_letter": "u",
        "absorption_rate": 0.008816120906801008,
        "num_absorption": 7,
        "num_probe_true_positives": 794,
        "num_split_features": 2
      },
      {
        "first_letter": "v",
        "absorption_rate": 0.003694581280788177,
        "num_absorption": 3,
        "num_probe_true_positives": 812,
        "num_split_features": 1
      },
      {
        "first_letter": "w",
        "absorption_rate": 0.007352941176470588,
        "num_absorption": 5,
        "num_probe_true_positives": 680,
        "num_split_features": 2
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "core evaluation results": {
    "unique_id": "google/gemma-2-2b_layer_12_sae_custom_sae",
    "sae_set": "google/gemma-2-2b_layer_12_sae",
    "sae_id": "custom_sae",
    "eval_cfg": {
      "model_name": "google/gemma-2-2b",
      "llm_dtype": "bfloat16",
      "batch_size_prompts": 16,
      "n_eval_reconstruction_batches": 200,
      "n_eval_sparsity_variance_batches": 2000,
      "dataset": "Skylion007/openwebtext",
      "context_size": 128,
      "compute_kl": true,
      "compute_ce_loss": true,
      "compute_l2_norms": true,
      "compute_sparsity_metrics": true,
      "compute_variance_metrics": true,
      "compute_featurewise_density_statistics": false,
      "compute_featurewise_weight_based_metrics": false,
      "exclude_special_tokens_from_reconstruction": true,
      "verbose": false
    },
    "metrics": {
      "model_behavior_preservation": {
        "kl_div_score": 0.9816576086956522,
        "kl_div_with_ablation": 10.0625,
        "kl_div_with_sae": 0.1845703125
      },
      "model_performance_preservation": {
        "ce_loss_score": 0.9819078947368421,
        "ce_loss_with_ablation": 12.4375,
        "ce_loss_with_sae": 3.109375,
        "ce_loss_without_sae": 2.9375
      },
      "reconstruction_quality": {
        "explained_variance": 0.6953125,
        "mse": 1.9375,
        "cossim": 0.90625
      },
      "shrinkage": {
        "l2_norm_in": 149.0,
        "l2_norm_out": 135.0,
        "l2_ratio": 0.90625,
        "relative_reconstruction_bias": 1.0
      },
      "sparsity": {
        "l0": 119.99999237060547,
        "l1": 580.0
      },
      "token_stats": {
        "total_tokens_eval_reconstruction": 409600,
        "total_tokens_eval_sparsity_variance": 4096000
      }
    }
  },
  "scr evaluations results": {
    "eval_type_id": "scr",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": true,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "715f84a4-5a7c-40e2-9754-a09a44fc578f",
    "datetime_epoch_millis": 1738294387339,
    "eval_result_metrics": {
      "scr_metrics": {
        "scr_dir1_threshold_2": 0.1977719633179738,
        "scr_metric_threshold_2": 0.10643361034616636,
        "scr_dir2_threshold_2": 0.10588947970107009,
        "scr_dir1_threshold_5": 0.22734171107297071,
        "scr_metric_threshold_5": 0.16594678084912118,
        "scr_dir2_threshold_5": 0.17183274144984345,
        "scr_dir1_threshold_10": 0.21052289447642997,
        "scr_metric_threshold_10": 0.2257783264464846,
        "scr_dir2_threshold_10": 0.22868044299236331,
        "scr_dir1_threshold_20": 0.23798111729304153,
        "scr_metric_threshold_20": 0.2649443741674508,
        "scr_dir2_threshold_20": 0.26915446813518695,
        "scr_dir1_threshold_50": 0.17583316201907767,
        "scr_metric_threshold_50": 0.3110287136501568,
        "scr_dir2_threshold_50": 0.31660557365264874,
        "scr_dir1_threshold_100": 0.1299698963550202,
        "scr_metric_threshold_100": 0.26887259990684975,
        "scr_dir2_threshold_100": 0.28581773461081794,
        "scr_dir1_threshold_500": -0.1710424689430026,
        "scr_metric_threshold_500": 0.2722496357027284,
        "scr_dir2_threshold_500": 0.2915680382459449
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
        "scr_dir1_threshold_2": 0.4375002910385279,
        "scr_metric_threshold_2": 0.01474211549298745,
        "scr_dir2_threshold_2": 0.01474211549298745,
        "scr_dir1_threshold_5": 0.42187454889028175,
        "scr_metric_threshold_5": 0.02948408453723957,
        "scr_dir2_threshold_5": 0.02948408453723957,
        "scr_dir1_threshold_10": 0.359374374267165,
        "scr_metric_threshold_10": 0.039312112716319424,
        "scr_dir2_threshold_10": 0.039312112716319424,
        "scr_dir1_threshold_20": 0.4375002910385279,
        "scr_metric_threshold_20": 0.07125316768614513,
        "scr_dir2_threshold_20": 0.07125316768614513,
        "scr_dir1_threshold_50": 0.2968751309673376,
        "scr_metric_threshold_50": 0.09090907759556952,
        "scr_dir2_threshold_50": 0.09090907759556952,
        "scr_dir1_threshold_100": 0.23437495634422081,
        "scr_metric_threshold_100": 0.10565119308855696,
        "scr_dir2_threshold_100": 0.10565119308855696,
        "scr_dir1_threshold_500": 0.17187478172110407,
        "scr_metric_threshold_500": 0.13759224805838266,
        "scr_dir2_threshold_500": 0.13759224805838266
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
        "scr_dir1_threshold_2": 0.1844659857076143,
        "scr_metric_threshold_2": 0.10888249310703833,
        "scr_dir2_threshold_2": 0.10888249310703833,
        "scr_dir1_threshold_5": 0.2524268642223358,
        "scr_metric_threshold_5": 0.14899710481947134,
        "scr_dir2_threshold_5": 0.14899710481947134,
        "scr_dir1_threshold_10": 0.2718446714307952,
        "scr_metric_threshold_10": 0.2206302790249021,
        "scr_dir2_threshold_10": 0.2206302790249021,
        "scr_dir1_threshold_20": 0.3300969356842643,
        "scr_metric_threshold_20": 0.26361035433511953,
        "scr_dir2_threshold_20": 0.26361035433511953,
        "scr_dir1_threshold_50": 0.14563094997665002,
        "scr_metric_threshold_50": 0.34097428494916016,
        "scr_dir2_threshold_50": 0.34097428494916016,
        "scr_dir1_threshold_100": 0.12621372145414522,
        "scr_metric_threshold_100": 0.12034383513729906,
        "scr_dir2_threshold_100": 0.12034383513729906,
        "scr_dir1_threshold_500": -0.475728464346869,
        "scr_metric_threshold_500": 0.1146130787286892,
        "scr_dir2_threshold_500": 0.1146130787286892
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
        "scr_dir1_threshold_2": 0.5555557658011382,
        "scr_metric_threshold_2": 0.037974794330044616,
        "scr_dir2_threshold_2": 0.037974794330044616,
        "scr_dir1_threshold_5": 0.6349207400434262,
        "scr_metric_threshold_5": 0.055696234239288635,
        "scr_dir2_threshold_5": 0.055696234239288635,
        "scr_dir1_threshold_10": 0.5238092084411499,
        "scr_metric_threshold_10": 0.11392408119449507,
        "scr_dir2_threshold_10": 0.11392408119449507,
        "scr_dir1_threshold_20": 0.5555557658011382,
        "scr_metric_threshold_20": 0.13417728471747628,
        "scr_dir2_threshold_20": 0.13417728471747628,
        "scr_dir1_threshold_50": 0.396825817316562,
        "scr_metric_threshold_50": 0.1898735189567649,
        "scr_dir2_threshold_50": 0.1898735189567649,
        "scr_dir1_threshold_100": 0.0,
        "scr_metric_threshold_100": 0.22278493695715454,
        "scr_dir2_threshold_100": 0.22278493695715454,
        "scr_dir1_threshold_500": -1.507935456708595,
        "scr_metric_threshold_500": 0.06582283600077923,
        "scr_dir2_threshold_500": 0.06582283600077923
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
        "scr_dir1_threshold_2": 0.18750034924590825,
        "scr_metric_threshold_2": 0.08308621873453508,
        "scr_dir2_threshold_2": 0.08308621873453508,
        "scr_dir1_threshold_5": 0.18750034924590825,
        "scr_metric_threshold_5": 0.1780415435515382,
        "scr_dir2_threshold_5": 0.1780415435515382,
        "scr_dir1_threshold_10": -0.03125005820765137,
        "scr_metric_threshold_10": 0.23738884264763468,
        "scr_dir2_threshold_10": 0.23738884264763468,
        "scr_dir1_threshold_20": -0.015624796273220196,
        "scr_metric_threshold_20": 0.2997032856130665,
        "scr_dir2_threshold_20": 0.2997032856130665,
        "scr_dir1_threshold_50": -0.07812491268852294,
        "scr_metric_threshold_50": 0.3531157663653655,
        "scr_dir2_threshold_50": 0.3531157663653655,
        "scr_dir1_threshold_100": -0.062499650754091765,
        "scr_metric_threshold_100": 0.07121675891531577,
        "scr_dir2_threshold_100": 0.07121675891531577,
        "scr_dir1_threshold_500": 0.1328126309672156,
        "scr_metric_threshold_500": -0.01186928295084368,
        "scr_dir2_threshold_500": -0.01186928295084368
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
        "scr_dir1_threshold_2": 0.04371592886659017,
        "scr_metric_threshold_2": 0.3843138373204936,
        "scr_dir2_threshold_2": 0.3843138373204936,
        "scr_dir1_threshold_5": 0.04371592886659017,
        "scr_metric_threshold_5": 0.525490096164477,
        "scr_dir2_threshold_5": 0.525490096164477,
        "scr_dir1_threshold_10": 0.05464474822904205,
        "scr_metric_threshold_10": 0.603921610792973,
        "scr_dir2_threshold_10": 0.603921610792973,
        "scr_dir1_threshold_20": -0.01092881936245188,
        "scr_metric_threshold_20": 0.6470587685309047,
        "scr_dir2_threshold_20": 0.6470587685309047,
        "scr_dir1_threshold_50": 0.00546440968122594,
        "scr_metric_threshold_50": 0.6862744089733254,
        "scr_dir2_threshold_50": 0.6862744089733254,
        "scr_dir1_threshold_100": -0.01092881936245188,
        "scr_metric_threshold_100": 0.6862744089733254,
        "scr_dir2_threshold_100": 0.6862744089733254,
        "scr_dir1_threshold_500": -0.24590169273908055,
        "scr_metric_threshold_500": 0.6941176773080023,
        "scr_dir2_threshold_500": 0.6941176773080023
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
        "scr_dir1_threshold_2": 0.0410254200064373,
        "scr_metric_threshold_2": 0.07258066454365199,
        "scr_dir2_threshold_2": 0.07258066454365199,
        "scr_dir1_threshold_5": 0.12307687134902433,
        "scr_metric_threshold_5": 0.09677413927777444,
        "scr_dir2_threshold_5": 0.09677413927777444,
        "scr_dir1_threshold_10": 0.1999998777340575,
        "scr_metric_threshold_10": 0.16129039235714715,
        "scr_dir2_threshold_10": 0.16129039235714715,
        "scr_dir1_threshold_20": 0.22564087986240192,
        "scr_metric_threshold_20": 0.18951607282340924,
        "scr_dir2_threshold_20": 0.18951607282340924,
        "scr_dir1_threshold_50": 0.24102560340535104,
        "scr_metric_threshold_50": 0.2419354683650784,
        "scr_dir2_threshold_50": 0.2419354683650784,
        "scr_dir1_threshold_100": 0.3179486097903842,
        "scr_metric_threshold_100": 0.3508064651805564,
        "scr_dir2_threshold_100": 0.3508064651805564,
        "scr_dir1_threshold_500": 0.27179474482639304,
        "scr_metric_threshold_500": 0.4516130505317551,
        "scr_dir2_threshold_500": 0.4516130505317551
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
        "scr_dir1_threshold_2": 0.08520176975018703,
        "scr_metric_threshold_2": 0.10267856311319266,
        "scr_dir2_threshold_2": 0.10267856311319266,
        "scr_dir1_threshold_5": 0.11659176883874377,
        "scr_metric_threshold_5": 0.25446442707572475,
        "scr_dir2_threshold_5": 0.25446442707572475,
        "scr_dir1_threshold_10": 0.22421531016200436,
        "scr_metric_threshold_10": 0.3482142690835282,
        "scr_dir2_threshold_10": 0.3482142690835282,
        "scr_dir1_threshold_20": 0.2914798230249813,
        "scr_metric_threshold_20": 0.4241072010647942,
        "scr_dir2_threshold_20": 0.4241072010647942,
        "scr_dir1_threshold_50": 0.29596407042543016,
        "scr_metric_threshold_50": 0.48214295692740233,
        "scr_dir2_threshold_50": 0.48214295692740233,
        "scr_dir1_threshold_100": 0.3273543367994015,
        "scr_metric_threshold_100": 0.4866071844340367,
        "scr_dir2_threshold_100": 0.4866071844340367,
        "scr_dir1_threshold_500": 0.13452902572595388,
        "scr_metric_threshold_500": 0.5758927989352057,
        "scr_dir2_threshold_500": 0.5758927989352057
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
        "scr_dir1_threshold_2": 0.047210196127387125,
        "scr_metric_threshold_2": 0.047210196127387125,
        "scr_dir2_threshold_2": 0.042857150966616867,
        "scr_dir1_threshold_5": 0.03862661712745569,
        "scr_metric_threshold_5": 0.03862661712745569,
        "scr_dir2_threshold_5": 0.08571430193323373,
        "scr_dir1_threshold_10": 0.08154502375487709,
        "scr_metric_threshold_10": 0.08154502375487709,
        "scr_dir2_threshold_10": 0.10476195612190681,
        "scr_dir1_threshold_20": 0.09012885856869063,
        "scr_metric_threshold_20": 0.09012885856869063,
        "scr_dir2_threshold_20": 0.12380961031057988,
        "scr_dir1_threshold_50": 0.10300422706858779,
        "scr_metric_threshold_50": 0.10300422706858779,
        "scr_dir2_threshold_50": 0.14761910708852366,
        "scr_dir1_threshold_100": 0.10729601656855352,
        "scr_metric_threshold_100": 0.10729601656855352,
        "scr_dir2_threshold_100": 0.24285709420029883,
        "scr_dir1_threshold_500": 0.15021467900985702,
        "scr_metric_threshold_500": 0.15021467900985702,
        "scr_dir2_threshold_500": 0.3047618993555888
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "tpp evaluations results": {
    "eval_type_id": "tpp",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "canrager/amazon_reviews_mcauley_1and5"
      ],
      "perform_scr": false,
      "early_stopping_patience": 20,
      "train_set_size": 4000,
      "test_set_size": 1000,
      "context_length": 128,
      "probe_train_batch_size": 16,
      "probe_test_batch_size": 500,
      "probe_epochs": 20,
      "probe_lr": 0.001,
      "probe_l1_penalty": 0.001,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "lower_vram_usage": false,
      "model_name": "google/gemma-2-2b",
      "n_values": [
        2,
        5,
        10,
        20,
        50,
        100,
        500
      ],
      "column1_vals_lookup": {
        "LabHC/bias_in_bios_class_set1": [
          [
            "professor",
            "nurse"
          ],
          [
            "architect",
            "journalist"
          ],
          [
            "surgeon",
            "psychologist"
          ],
          [
            "attorney",
            "teacher"
          ]
        ],
        "canrager/amazon_reviews_mcauley_1and5": [
          [
            "Books",
            "CDs_and_Vinyl"
          ],
          [
            "Software",
            "Electronics"
          ],
          [
            "Pet_Supplies",
            "Office_Products"
          ],
          [
            "Industrial_and_Scientific",
            "Toys_and_Games"
          ]
        ]
      }
    },
    "eval_id": "ac203462-1e89-49cc-a882-41fba045cb56",
    "datetime_epoch_millis": 1738294522149,
    "eval_result_metrics": {
      "tpp_metrics": {
        "tpp_threshold_2_total_metric": 0.004200001060962678,
        "tpp_threshold_2_intended_diff_only": 0.006800001859664917,
        "tpp_threshold_2_unintended_diff_only": 0.0026000007987022396,
        "tpp_threshold_5_total_metric": 0.008974990248680115,
        "tpp_threshold_5_intended_diff_only": 0.0122999906539917,
        "tpp_threshold_5_unintended_diff_only": 0.0033250004053115845,
        "tpp_threshold_10_total_metric": 0.010324999690055847,
        "tpp_threshold_10_intended_diff_only": 0.015500003099441528,
        "tpp_threshold_10_unintended_diff_only": 0.005175003409385681,
        "tpp_threshold_20_total_metric": 0.023099991679191592,
        "tpp_threshold_20_intended_diff_only": 0.029799997806549072,
        "tpp_threshold_20_unintended_diff_only": 0.006700006127357483,
        "tpp_threshold_50_total_metric": 0.05897499769926071,
        "tpp_threshold_50_intended_diff_only": 0.06600000262260437,
        "tpp_threshold_50_unintended_diff_only": 0.007025004923343658,
        "tpp_threshold_100_total_metric": 0.1082500010728836,
        "tpp_threshold_100_intended_diff_only": 0.11650000214576721,
        "tpp_threshold_100_unintended_diff_only": 0.008250001072883605,
        "tpp_threshold_500_total_metric": 0.35387501269578936,
        "tpp_threshold_500_intended_diff_only": 0.36680001616477964,
        "tpp_threshold_500_unintended_diff_only": 0.012925003468990327
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_tpp_results",
        "tpp_threshold_2_total_metric": 0.005199989676475525,
        "tpp_threshold_2_intended_diff_only": 0.007799994945526123,
        "tpp_threshold_2_unintended_diff_only": 0.002600005269050598,
        "tpp_threshold_5_total_metric": 0.007949993014335632,
        "tpp_threshold_5_intended_diff_only": 0.010399997234344482,
        "tpp_threshold_5_unintended_diff_only": 0.00245000422000885,
        "tpp_threshold_10_total_metric": 0.01159999668598175,
        "tpp_threshold_10_intended_diff_only": 0.015200006961822509,
        "tpp_threshold_10_unintended_diff_only": 0.0036000102758407594,
        "tpp_threshold_20_total_metric": 0.024499985575675967,
        "tpp_threshold_20_intended_diff_only": 0.028999996185302735,
        "tpp_threshold_20_unintended_diff_only": 0.00450001060962677,
        "tpp_threshold_50_total_metric": 0.05940000414848328,
        "tpp_threshold_50_intended_diff_only": 0.06380001306533814,
        "tpp_threshold_50_unintended_diff_only": 0.004400008916854858,
        "tpp_threshold_100_total_metric": 0.11355000436306,
        "tpp_threshold_100_intended_diff_only": 0.11860001087188721,
        "tpp_threshold_100_unintended_diff_only": 0.00505000650882721,
        "tpp_threshold_500_total_metric": 0.40980002582073216,
        "tpp_threshold_500_intended_diff_only": 0.4178000330924988,
        "tpp_threshold_500_unintended_diff_only": 0.008000007271766663
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_tpp_results",
        "tpp_threshold_2_total_metric": 0.0032000124454498293,
        "tpp_threshold_2_intended_diff_only": 0.005800008773803711,
        "tpp_threshold_2_unintended_diff_only": 0.0025999963283538817,
        "tpp_threshold_5_total_metric": 0.009999987483024598,
        "tpp_threshold_5_intended_diff_only": 0.014199984073638917,
        "tpp_threshold_5_unintended_diff_only": 0.004199996590614319,
        "tpp_threshold_10_total_metric": 0.009050002694129944,
        "tpp_threshold_10_intended_diff_only": 0.015799999237060547,
        "tpp_threshold_10_unintended_diff_only": 0.006749996542930603,
        "tpp_threshold_20_total_metric": 0.021699997782707214,
        "tpp_threshold_20_intended_diff_only": 0.03059999942779541,
        "tpp_threshold_20_unintended_diff_only": 0.008900001645088196,
        "tpp_threshold_50_total_metric": 0.058549991250038146,
        "tpp_threshold_50_intended_diff_only": 0.0681999921798706,
        "tpp_threshold_50_unintended_diff_only": 0.009650000929832458,
        "tpp_threshold_100_total_metric": 0.1029499977827072,
        "tpp_threshold_100_intended_diff_only": 0.11439999341964721,
        "tpp_threshold_100_unintended_diff_only": 0.011449995636940002,
        "tpp_threshold_500_total_metric": 0.29794999957084656,
        "tpp_threshold_500_intended_diff_only": 0.31579999923706054,
        "tpp_threshold_500_unintended_diff_only": 0.01784999966621399
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "sparse probing evaluation results": {
    "eval_type_id": "sparse_probing",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "LabHC/bias_in_bios_class_set1",
        "LabHC/bias_in_bios_class_set2",
        "LabHC/bias_in_bios_class_set3",
        "canrager/amazon_reviews_mcauley_1and5",
        "canrager/amazon_reviews_mcauley_1and5_sentiment",
        "codeparrot/github-code",
        "fancyzhx/ag_news",
        "Helsinki-NLP/europarl"
      ],
      "probe_train_set_size": 4000,
      "probe_test_set_size": 1000,
      "context_length": 128,
      "sae_batch_size": 125,
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16",
      "model_name": "google/gemma-2-2b",
      "k_values": [
        1,
        2,
        5,
        10,
        20,
        50
      ],
      "lower_vram_usage": false
    },
    "eval_id": "862a26cd-eedf-4891-bb64-bbe5a3616a1b",
    "datetime_epoch_millis": 1738294904180,
    "eval_result_metrics": {
      "llm": {
        "llm_test_accuracy": 0.9510562499999999,
        "llm_top_1_test_accuracy": 0.65568125,
        "llm_top_2_test_accuracy": 0.71975625,
        "llm_top_5_test_accuracy": 0.7875,
        "llm_top_10_test_accuracy": 0.8297312499999999,
        "llm_top_20_test_accuracy": 0.87933125,
        "llm_top_50_test_accuracy": 0.92219375,
        "llm_top_100_test_accuracy": null
      },
      "sae": {
        "sae_test_accuracy": 0.9566750418394804,
        "sae_top_1_test_accuracy": 0.79313125,
        "sae_top_2_test_accuracy": 0.8332375,
        "sae_top_5_test_accuracy": 0.8844749999999999,
        "sae_top_10_test_accuracy": 0.9083312499999999,
        "sae_top_20_test_accuracy": 0.9249250000000001,
        "sae_top_50_test_accuracy": 0.9415562500000001,
        "sae_top_100_test_accuracy": null
      }
    },
    "eval_result_details": [
      {
        "dataset_name": "LabHC/bias_in_bios_class_set1_results",
        "llm_test_accuracy": 0.9596,
        "llm_top_1_test_accuracy": 0.6432,
        "llm_top_2_test_accuracy": 0.6916,
        "llm_top_5_test_accuracy": 0.7912,
        "llm_top_10_test_accuracy": 0.8336,
        "llm_top_20_test_accuracy": 0.8962,
        "llm_top_50_test_accuracy": 0.9384,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9638000369071961,
        "sae_top_1_test_accuracy": 0.8268000000000001,
        "sae_top_2_test_accuracy": 0.8394,
        "sae_top_5_test_accuracy": 0.8661999999999999,
        "sae_top_10_test_accuracy": 0.9186,
        "sae_top_20_test_accuracy": 0.9442,
        "sae_top_50_test_accuracy": 0.9614,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set2_results",
        "llm_test_accuracy": 0.9460000000000001,
        "llm_top_1_test_accuracy": 0.6674,
        "llm_top_2_test_accuracy": 0.7302,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.8074,
        "llm_top_20_test_accuracy": 0.8624,
        "llm_top_50_test_accuracy": 0.9112,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9468000411987305,
        "sae_top_1_test_accuracy": 0.7934,
        "sae_top_2_test_accuracy": 0.8061999999999999,
        "sae_top_5_test_accuracy": 0.8892,
        "sae_top_10_test_accuracy": 0.9052,
        "sae_top_20_test_accuracy": 0.9254000000000001,
        "sae_top_50_test_accuracy": 0.9352,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "LabHC/bias_in_bios_class_set3_results",
        "llm_test_accuracy": 0.917,
        "llm_top_1_test_accuracy": 0.6814,
        "llm_top_2_test_accuracy": 0.7346,
        "llm_top_5_test_accuracy": 0.7758,
        "llm_top_10_test_accuracy": 0.798,
        "llm_top_20_test_accuracy": 0.8506,
        "llm_top_50_test_accuracy": 0.8917999999999999,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.93100004196167,
        "sae_top_1_test_accuracy": 0.8094000000000001,
        "sae_top_2_test_accuracy": 0.8276,
        "sae_top_5_test_accuracy": 0.8842000000000001,
        "sae_top_10_test_accuracy": 0.8904,
        "sae_top_20_test_accuracy": 0.9012,
        "sae_top_50_test_accuracy": 0.9112,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_results",
        "llm_test_accuracy": 0.9,
        "llm_top_1_test_accuracy": 0.6022,
        "llm_top_2_test_accuracy": 0.6437999999999999,
        "llm_top_5_test_accuracy": 0.7020000000000001,
        "llm_top_10_test_accuracy": 0.7478,
        "llm_top_20_test_accuracy": 0.8138000000000002,
        "llm_top_50_test_accuracy": 0.8560000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9182000398635864,
        "sae_top_1_test_accuracy": 0.7238,
        "sae_top_2_test_accuracy": 0.7678,
        "sae_top_5_test_accuracy": 0.7966,
        "sae_top_10_test_accuracy": 0.8412000000000001,
        "sae_top_20_test_accuracy": 0.8597999999999999,
        "sae_top_50_test_accuracy": 0.8834,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "canrager/amazon_reviews_mcauley_1and5_sentiment_results",
        "llm_test_accuracy": 0.9815,
        "llm_top_1_test_accuracy": 0.671,
        "llm_top_2_test_accuracy": 0.724,
        "llm_top_5_test_accuracy": 0.766,
        "llm_top_10_test_accuracy": 0.826,
        "llm_top_20_test_accuracy": 0.8474999999999999,
        "llm_top_50_test_accuracy": 0.9325000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9730000495910645,
        "sae_top_1_test_accuracy": 0.851,
        "sae_top_2_test_accuracy": 0.883,
        "sae_top_5_test_accuracy": 0.938,
        "sae_top_10_test_accuracy": 0.939,
        "sae_top_20_test_accuracy": 0.958,
        "sae_top_50_test_accuracy": 0.966,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "codeparrot/github-code_results",
        "llm_test_accuracy": 0.9662,
        "llm_top_1_test_accuracy": 0.6656000000000001,
        "llm_top_2_test_accuracy": 0.6932,
        "llm_top_5_test_accuracy": 0.77,
        "llm_top_10_test_accuracy": 0.7908000000000001,
        "llm_top_20_test_accuracy": 0.8772,
        "llm_top_50_test_accuracy": 0.924,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9678000569343567,
        "sae_top_1_test_accuracy": 0.6654,
        "sae_top_2_test_accuracy": 0.7455999999999999,
        "sae_top_5_test_accuracy": 0.8431999999999998,
        "sae_top_10_test_accuracy": 0.8778,
        "sae_top_20_test_accuracy": 0.9007999999999999,
        "sae_top_50_test_accuracy": 0.9469999999999998,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "fancyzhx/ag_news_results",
        "llm_test_accuracy": 0.93875,
        "llm_top_1_test_accuracy": 0.67425,
        "llm_top_2_test_accuracy": 0.75925,
        "llm_top_5_test_accuracy": 0.8250000000000001,
        "llm_top_10_test_accuracy": 0.8712500000000001,
        "llm_top_20_test_accuracy": 0.89875,
        "llm_top_50_test_accuracy": 0.92625,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9540000408887863,
        "sae_top_1_test_accuracy": 0.77225,
        "sae_top_2_test_accuracy": 0.8345,
        "sae_top_5_test_accuracy": 0.868,
        "sae_top_10_test_accuracy": 0.90025,
        "sae_top_20_test_accuracy": 0.916,
        "sae_top_50_test_accuracy": 0.93125,
        "sae_top_100_test_accuracy": null
      },
      {
        "dataset_name": "Helsinki-NLP/europarl_results",
        "llm_test_accuracy": 0.9994,
        "llm_top_1_test_accuracy": 0.6403999999999999,
        "llm_top_2_test_accuracy": 0.7813999999999999,
        "llm_top_5_test_accuracy": 0.9039999999999999,
        "llm_top_10_test_accuracy": 0.9630000000000001,
        "llm_top_20_test_accuracy": 0.9882,
        "llm_top_50_test_accuracy": 0.9974000000000001,
        "llm_top_100_test_accuracy": null,
        "sae_test_accuracy": 0.9988000273704529,
        "sae_top_1_test_accuracy": 0.9029999999999999,
        "sae_top_2_test_accuracy": 0.9617999999999999,
        "sae_top_5_test_accuracy": 0.9904,
        "sae_top_10_test_accuracy": 0.9942,
        "sae_top_20_test_accuracy": 0.994,
        "sae_top_50_test_accuracy": 0.9969999999999999,
        "sae_top_100_test_accuracy": null
      }
    ],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  },
  "unlearning evaluation results": {
    "eval_type_id": "unlearning",
    "eval_config": {
      "random_seed": 42,
      "dataset_names": [
        "wmdp-bio",
        "high_school_us_history",
        "college_computer_science",
        "high_school_geography",
        "human_aging"
      ],
      "intervention_method": "clamp_feature_activation",
      "retain_thresholds": [
        0.001,
        0.01
      ],
      "n_features_list": [
        10,
        20
      ],
      "multipliers": [
        25,
        50,
        100,
        200
      ],
      "dataset_size": 1024,
      "seq_len": 1024,
      "n_batch_loss_added": 50,
      "target_metric": "correct",
      "save_metrics": true,
      "model_name": "google/gemma-2-2b-it",
      "llm_batch_size": 32,
      "llm_dtype": "bfloat16"
    },
    "eval_id": "dba4533c-b0e0-4c6d-b5fe-b3b798761b71",
    "datetime_epoch_millis": 1738295053325,
    "eval_result_metrics": {
      "unlearning": {
        "unlearning_score": 0.07116103172302246
      }
    },
    "eval_result_details": [],
    "sae_bench_commit_hash": "60adde367f8d77d5f375d2bc8d39ed57e71595f0",
    "sae_lens_id": "custom_sae",
    "sae_lens_release_id": "google/gemma-2-2b_layer_12_sae",
    "sae_lens_version": "5.3.0",
    "sae_cfg_dict": {
      "model_name": "google/gemma-2-2b",
      "d_in": 2304,
      "d_sae": 18432,
      "hook_layer": 12,
      "hook_name": "blocks.12.hook_resid_post",
      "context_size": null,
      "hook_head_index": null,
      "architecture": "TopK",
      "apply_b_dec_to_input": true,
      "finetuning_scaling_factor": null,
      "activation_fn_str": "TopK",
      "prepend_bos": true,
      "normalize_activations": "none",
      "dtype": "bfloat16",
      "device": "",
      "dataset_path": "",
      "dataset_trust_remote_code": true,
      "seqpos_slice": [
        null
      ],
      "training_tokens": -100000,
      "sae_lens_training_version": null,
      "neuronpedia_id": null
    },
    "eval_result_unstructured": null
  }
}